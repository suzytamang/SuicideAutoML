
@book{laude_data_2016,
	title = {Data scientist et langage {R} : {Guide} d'autoformation à l'exploitation des {Big} {Data}},
	publisher = {ENI Editions},
	author = {Laude, Henri},
	year = {2016},
	note = {P. 410 for citation about using R for reproducibility},
	keywords = {reproducibility, francais, France, stats}
}

@inproceedings{noauthor_empirical_nodate,
	title = {Empirical investigation of statistical significance in {NLP}},
	url = {http://www.aclweb.org/anthology/D12-1091},
	keywords = {reproducibility, stats},
	file = {Empirical investigation of statistical significance in NLP.pdf:/Users/transfer/Zotero/storage/GQK7IG7U/Empirical investigation of statistical significance in NLP.pdf:application/pdf}
}

@misc{noauthor_type-token_nodate,
	title = {Type-token moving average},
	keywords = {tokenization},
	file = {Type token moving average.pdf:/Users/transfer/Zotero/storage/XGE7C8AK/Type token moving average.pdf:application/pdf}
}

@inproceedings{berg-kirkpatrick_empirical_2012,
	title = {An empirical investigation of statistical significance in {NLP}},
	booktitle = {Proceedings of the 2012 {Joint} {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Berg-Kirkpatrick, Taylor and Burkett, David and Klein, Dan},
	year = {2012},
	keywords = {reproducibility},
	pages = {995--1005},
	file = {Empirical investigation of statistical significance in NLP.pdf:/Users/transfer/Zotero/storage/SZ8RULDW/Empirical investigation of statistical significance in NLP.pdf:application/pdf}
}

@inproceedings{church_parsing_1980,
	title = {On parsing strategies and closure},
	booktitle = {Proceedings of the 18th annual meeting on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Church, Kenneth},
	year = {1980},
	pages = {107--111},
	file = {P80-1028 (1).pdf:/Users/transfer/Zotero/storage/DAYZ6Z3V/P80-1028 (1).pdf:application/pdf}
}

@inproceedings{sable_nlp_2002,
	title = {{NLP} found helpful (at least for one text categorization task)},
	booktitle = {Proceedings of the {ACL}-02 conference on {Empirical} methods in natural language processing-{Volume} 10},
	publisher = {Association for Computational Linguistics},
	author = {Sable, Carl and McKeown, Kathleen and Church, Kenneth W},
	year = {2002},
	pages = {172--179}
}

@article{hand_classifier_2006,
	title = {Classifier technology and the illusion of progress},
	volume = {21},
	number = {1},
	journal = {Statistical science},
	author = {Hand, David J},
	year = {2006},
	keywords = {reproducibility},
	pages = {1--14}
}

@article{percha_expanding_2018,
	title = {Expanding a radiology lexicon using contextual patterns in radiology reports},
	journal = {Journal of the American Medical Informatics Association},
	author = {Percha, Bethany and Zhang, Yuhao and Bozkurt, Selen and Rubin, Daniel and Altman, Russ B and Langlotz, Curtis P},
	year = {2018},
	keywords = {female first or senior}
}

@inproceedings{santana_learning_2015,
	title = {Learning joint features for color and depth images with {Convolutional} {Neural} {Networks} for object classification},
	booktitle = {Acoustics, {Speech} and {Signal} {Processing} ({ICASSP}), 2015 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Santana, Eder and Dockendorf, Karl and Principe, Jose C},
	year = {2015},
	pages = {1320--1323}
}

@inproceedings{reiter_has_1994,
	address = {Stroudsburg, PA, USA},
	series = {{INLG} '94},
	title = {Has a {Consensus} {NL} {Generation} {Architecture} {Appeared}, and is {It} {Psycholinguistically} {Plausible}?},
	url = {http://dl.acm.org/citation.cfm?id=1641417.1641436},
	booktitle = {Proceedings of the {Seventh} {International} {Workshop} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Reiter, Ehud},
	year = {1994},
	pages = {163--170}
}

@article{gildea_automatic_2002,
	title = {Automatic labeling of semantic roles},
	volume = {28},
	number = {3},
	journal = {Computational linguistics},
	author = {Gildea, Daniel and Jurafsky, Daniel},
	year = {2002},
	pages = {245--288}
}

@article{manning_computational_2015,
	title = {Computational linguistics and deep learning},
	volume = {41},
	number = {4},
	journal = {Computational Linguistics},
	author = {Manning, Christopher D},
	year = {2015},
	pages = {701--707},
	file = {Fulltext:/Users/transfer/Zotero/storage/JP93JLBW/COLI_a_00239.html:text/html;Snapshot:/Users/transfer/Zotero/storage/KUMKYZ26/COLI_a_00239.html:text/html}
}

@inproceedings{boguslav_improving_2018,
	title = {Improving precision in concept normalization},
	volume = {23},
	booktitle = {Pacific {Symposium} on {Biocomputing}. {Pacific} {Symposium} on {Biocomputing}},
	publisher = {World Scientific},
	author = {Boguslav, Mayla and Cohen, K Bretonnel and Baumgartner Jr, William A and Hunter, Lawrence E},
	year = {2018},
	keywords = {female first or senior, normalization},
	pages = {566--577}
}

@inproceedings{watson_structure_1953,
	title = {The structure of {DNA}},
	volume = {18},
	booktitle = {Cold {Spring} {Harbor} symposia on quantitative biology},
	publisher = {Cold Spring Harbor Laboratory Press},
	author = {Watson, James D and Crick, Francis HC},
	year = {1953},
	pages = {123--131}
}

@article{swenson_representing_2005,
	title = {Representing {Modernity} in {Jane} {Barker}'s {Galesia} {Trilogy}: {Jacobite} {Allegory} and the {Patch}-{Work} {Aesthetic}},
	volume = {34},
	number = {1},
	journal = {Studies in Eighteenth-Century Culture},
	author = {Swenson, Rivka},
	year = {2005},
	keywords = {female first or senior},
	pages = {55--80}
}

@article{swenson_optics_2010,
	title = {Optics, gender, and the eighteenth-century gaze: {Looking} at {Eliza} {Haywood}'s {Anti}-{Pamela}},
	volume = {51},
	number = {1},
	journal = {The Eighteenth Century},
	author = {Swenson, Rivka},
	year = {2010},
	keywords = {female first or senior},
	pages = {27--43}
}

@inproceedings{trieschnigg_influence_2007,
	title = {The influence of basic tokenization on biomedical document retrieval},
	booktitle = {Proceedings of the 30th annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {ACM},
	author = {Trieschnigg, Dolf and Kraaij, Wessel and de Jong, Franciska},
	year = {2007},
	keywords = {tokenization},
	pages = {803--804}
}

@article{altschul_basic_1990,
	title = {Basic local alignment search tool},
	volume = {215},
	number = {3},
	journal = {Journal of molecular biology},
	author = {Altschul, Stephen F and Gish, Warren and Miller, Webb and Myers, Eugene W and Lipman, David J},
	year = {1990},
	pages = {403--410}
}

@book{good_common_2012,
	title = {Common errors in statistics (and how to avoid them)},
	publisher = {John Wiley \& Sons},
	author = {Good, Phillip I and Hardin, James W},
	year = {2012},
	keywords = {stats}
}

@article{palmer_proposition_2005,
	title = {The proposition bank: {An} annotated corpus of semantic roles},
	volume = {31},
	number = {1},
	journal = {Computational linguistics},
	author = {Palmer, Martha and Gildea, Daniel and Kingsbury, Paul},
	year = {2005},
	keywords = {female first or senior, SRL},
	pages = {71--106}
}

@article{ashburner_gene_2000,
	title = {Gene {Ontology}: tool for the unification of biology},
	volume = {25},
	number = {1},
	journal = {Nature genetics},
	author = {Ashburner, Michael and Ball, Catherine A and Blake, Judith A and Botstein, David and Butler, Heather and Cherry, J Michael and Davis, Allan P and Dolinski, Kara and Dwight, Selina S and Eppig, Janan T and {others}},
	year = {2000},
	pages = {25--29}
}

@inproceedings{caporaso_intrinsic_2008,
	title = {Intrinsic evaluation of text mining tools may not predict performance on realistic tasks},
	booktitle = {Pacific symposium on biocomputing. {Pacific} symposium on biocomputing},
	publisher = {NIH Public Access},
	author = {Caporaso, J Gregory and Deshpande, Nita and Fink, J Lynn and Bourne, Philip E and Cohen, K Bretonnel and Hunter, Lawrence},
	year = {2008},
	keywords = {reproducibility},
	pages = {640}
}

@book{tufte_beautiful_2006,
	edition = {First},
	title = {Beautiful {Evidence}},
	isbn = {0-9613921-7-7},
	publisher = {Graphics Press, LLC},
	author = {Tufte, Edward R.},
	month = may,
	year = {2006}
}

@book{tufte_visual_2001,
	address = {Cheshire, Connecticut},
	title = {The {Visual} {Display} of {Quantitative} {Information}},
	isbn = {0-9613921-4-2},
	publisher = {Graphics Press},
	author = {Tufte, Edward R.},
	year = {2001}
}

@book{tufte_envisioning_1990,
	address = {Cheshire, Connecticut},
	title = {Envisioning {Information}},
	isbn = {0-9613921-1-8},
	publisher = {Graphics Press},
	author = {Tufte, Edward R.},
	year = {1990}
}

@book{tufte_visual_1997,
	address = {Cheshire, Connecticut},
	title = {Visual {Explanations}},
	isbn = {0-9613921-2-6},
	publisher = {Graphics Press},
	author = {Tufte, Edward R.},
	year = {1997}
}

@book{bringhurst_elements_2005,
	edition = {3.1},
	title = {The {Elements} of {Typography}},
	isbn = {0-88179-205-5},
	publisher = {Hartley \& Marks},
	author = {Bringhurst, Robert},
	year = {2005}
}

@book{mittelbach_latex_2004,
	edition = {Second},
	title = {The {\textbackslash}{LaTeX}{\textbackslash} {Companion}},
	isbn = {0-201-36299-6},
	publisher = {Addison–Wesley},
	author = {Mittelbach, Frank and Goossens, Michel},
	year = {2004}
}

@book{umeki_textttgeometry_2008,
	title = {The {\textbackslash}textttgeometry package},
	url = {http://ctan.org/pkg/geometry},
	author = {Umeki, Hideo},
	month = dec,
	year = {2008}
}

@article{noauthor_notitle_nodate
}

@misc{pubmeddev_cohen_nodate,
	title = {cohen kb[au] - {PubMed} - {NCBI}},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/?term=cohen+kb%5Bau%5D},
	abstract = {PubMed comprises more than 28 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full-text content from PubMed Central and publisher web sites.},
	urldate = {2018-01-26},
	author = {pubmeddev},
	file = {Snapshot:/Users/transfer/Zotero/storage/JSJM34HJ/pubmed.html:text/html}
}

@article{yadav_semantic_2017,
	title = {Semantic {Relations} in {Compound} {Nouns}: {Perspectives} from {Inter}-{Annotator} {Agreement}},
	volume = {245},
	issn = {0926-9630},
	shorttitle = {Semantic {Relations} in {Compound} {Nouns}},
	abstract = {Semantic relations have been studied for decades without yet reaching consensus on the set of these relations. However, biomedical language processing and ontologies rely on these relations, so it is important to be able to evaluate their suitability. In this paper we examine the role of inter-annotator agreement in choosing between competing proposals regarding the set of such relations. The experiments consisted of labeling the semantic relations between two elements of noun-noun compounds (e.g. cell migration). Two judges annotated a dataset of terms from the biomedical domain using two competing sets of relations and analyzed the inter-annotator agreement. With no training and little documentation, agreement on this task was fairly high and disagreements were consistent. The results support the utility of the relation-based approach to semantic representation.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Yadav, Prabha and Jezek, Elisabetta and Bouillon, Pierrette and Callahan, Tiffany J. and Bada, Michael and Hunter, Lawrence E. and Cohen, K. Bretonnel},
	year = {2017},
	pmid = {29295175},
	keywords = {female first or senior},
	pages = {644--648},
	file = {SHTI245-0644 (1).pdf:/Users/transfer/Zotero/storage/L3A5WJ22/SHTI245-0644 (1).pdf:application/pdf}
}

@article{cohen_translational_2017,
	title = {Translational {Morphosyntax}: {Distribution} of {Negation} in {Clinical} {Records} and {Biomedical} {Journal} {Articles}},
	volume = {245},
	issn = {0926-9630},
	shorttitle = {Translational {Morphosyntax}},
	abstract = {Prior knowledge of the distributional characteristics of linguistic phenomena can be useful for a variety of language processing tasks. This paper describes the distribution of negation in two types of biomedical texts: scientific journal articles and progress notes. Two types of negation are examined: explicit negation at the syntactic level and affixal negation at the sub-word level. The data show that the distribution of negation is significantly different in the two document types, with explicit negation more frequent in the clinical documents than in the scientific publications and affixal negation more frequent in the journal articles at the type level and token levels. All code is available on GitHub {\textless}fnr rid="fn001" /{\textgreater}{\textless}fn id="fn001"{\textgreater}https://github.com/KevinBretonnelCohen/NegationDistribution {\textless}/fn{\textgreater}.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Cohen, K. Bretonnel and Goss, Foster R. and Zweigenbaum, Pierre and Hunter, Lawrence E.},
	year = {2017},
	pmid = {29295113},
	pages = {346--350},
	file = {SHTI245-0346.pdf:/Users/transfer/Zotero/storage/KJAZLE6S/SHTI245-0346.pdf:application/pdf}
}

@article{boguslav_inter-annotator_2017,
	title = {Inter-{Annotator} {Agreement} and the {Upper} {Limit} on {Machine} {Performance}: {Evidence} from {Biomedical} {Natural} {Language} {Processing}},
	volume = {245},
	issn = {0926-9630},
	shorttitle = {Inter-{Annotator} {Agreement} and the {Upper} {Limit} on {Machine} {Performance}},
	abstract = {Human-annotated data is a fundamental part of natural language processing system development and evaluation. The quality of that data is typically assessed by calculating the agreement between the annotators. It is widely assumed that this agreement between annotators is the upper limit on system performance in natural language processing: if humans can't agree with each other about the classification more than some percentage of the time, we don't expect a computer to do any better. We trace the logical positivist roots of the motivation for measuring inter-annotator agreement, demonstrate the prevalence of the widely-held assumption about the relationship between inter-annotator agreement and system performance, and present data that suggest that inter-annotator agreement is not, in fact, an upper bound on language processing system performance.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Boguslav, Mayla and Cohen, Kevin Bretonnel},
	year = {2017},
	pmid = {29295103},
	keywords = {reproducibility, female first or senior},
	pages = {298--302}
}

@article{boguslav_improving_2018-1,
	title = {Improving precision in concept normalization},
	volume = {23},
	issn = {2335-6936},
	abstract = {Most natural language processing applications exhibit a trade-off between precision and recall. In some use cases for natural language processing, there are reasons to prefer to tilt that trade-off toward high precision. Relying on the Zipfian distribution of false positive results, we describe a strategy for increasing precision, using a variety of both pre-processing and post-processing methods. They draw on both knowledge-based and frequentist approaches to modeling language. Based on an existing high-performance biomedical concept recognition pipeline and a previously published manually annotated corpus, we apply this hybrid rationalist/empiricist strategy to concept normalization for eight different ontologies. Which approaches did and did not improve precision varied widely between the ontologies.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Boguslav, Mayla and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2018},
	pmid = {29218915},
	pmcid = {PMC5730334},
	keywords = {female first or senior},
	pages = {566--577}
}

@article{cohen_nominalization_2008,
	title = {Nominalization and {Alternations} in {Biomedical} {Language}},
	volume = {3},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2527518/},
	doi = {10.1371/journal.pone.0003158},
	abstract = {Background
This paper presents data on alternations in the argument structure of common domain-specific verbs and their associated verbal nominalizations in the PennBioIE corpus. Alternation is the term in theoretical linguistics for variations in the surface syntactic form of verbs, e.g. the different forms of stimulate in FSH stimulates follicular development and follicular development is stimulated by FSH. The data is used to assess the implications of alternations for biomedical text mining systems and to test the fit of the sublanguage model to biomedical texts.

Methodology/Principal Findings
We examined 1,872 tokens of the ten most common domain-specific verbs or their zero-related nouns in the PennBioIE corpus and labelled them for the presence or absence of three alternations. We then annotated the arguments of 746 tokens of the nominalizations related to these verbs and counted alternations related to the presence or absence of arguments and to the syntactic position of non-absent arguments. We found that alternations are quite common both for verbs and for nominalizations. We also found a previously undescribed alternation involving an adjectival present participle.

Conclusions/Significance
We found that even in this semantically restricted domain, alternations are quite common, and alternations involving nominalizations are exceptionally diverse. Nonetheless, the sublanguage model applies to biomedical language. We also report on a previously undescribed alternation involving an adjectival present participle.},
	number = {9},
	urldate = {2018-01-26},
	journal = {PLoS ONE},
	author = {Cohen, K. Bretonnel and Palmer, Martha and Hunter, Lawrence},
	month = sep,
	year = {2008},
	pmid = {18779866},
	pmcid = {PMC2527518},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/GMKZKGUV/Cohen et al. - 2008 - Nominalization and Alternations in Biomedical Lang.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/AZ2ZWCQH/Cohen et al. - 2008 - Nominalization and Alternations in Biomedical Lang.pdf:application/pdf}
}

@article{morgan_overview_2008,
	title = {Overview of {BioCreative} {II} gene normalization},
	volume = {9},
	issn = {1465-6906},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559987/},
	doi = {10.1186/gb-2008-9-s2-s3},
	abstract = {Background:
The goal of the gene normalization task is to link genes or gene products mentioned in the literature to biological databases. This is a key step in an accurate search of the biological literature. It is a challenging task, even for the human expert; genes are often described rather than referred to by gene symbol and, confusingly, one gene name may refer to different genes (often from different organisms). For BioCreative II, the task was to list the Entrez Gene identifiers for human genes or gene products mentioned in PubMed/MEDLINE abstracts. We selected abstracts associated with articles previously curated for human genes. We provided 281 expert-annotated abstracts containing 684 gene identifiers for training, and a blind test set of 262 documents containing 785 identifiers, with a gold standard created by expert annotators. Inter-annotator agreement was measured at over 90\%.

Results:
Twenty groups submitted one to three runs each, for a total of 54 runs. Three systems achieved F-measures (balanced precision and recall) between 0.80 and 0.81. Combining the system outputs using simple voting schemes and classifiers obtained improved results; the best composite system achieved an F-measure of 0.92 with 10-fold cross-validation. A 'maximum recall' system based on the pooled responses of all participants gave a recall of 0.97 (with precision 0.23), identifying 763 out of 785 identifiers.

Conclusion:
Major advances for the BioCreative II gene normalization task include broader participation (20 versus 8 teams) and a pooled system performance comparable to human experts, at over 90\% agreement. These results show promise as tools to link the literature with biological databases.},
	number = {Suppl 2},
	urldate = {2018-01-26},
	journal = {Genome Biology},
	author = {Morgan, Alexander A and Lu, Zhiyong and Wang, Xinglong and Cohen, Aaron M and Fluck, Juliane and Ruch, Patrick and Divoli, Anna and Fundel, Katrin and Leaman, Robert and Hakenberg, Jörg and Sun, Chengjie and Liu, Heng-hui and Torres, Rafael and Krauthammer, Michael and Lau, William W and Liu, Hongfang and Hsu, Chun-Nan and Schuemie, Martijn and Cohen, K Bretonnel and Hirschman, Lynette},
	year = {2008},
	pmid = {18834494},
	pmcid = {PMC2559987},
	keywords = {reproducibility, female first or senior, normalization, shared tasks},
	pages = {S3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YI5YV4CX/Morgan et al. - 2008 - Overview of BioCreative II gene normalization.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/59F6EA8R/Morgan et al. - 2008 - Overview of BioCreative II gene normalization.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/V4T96CQI/Morgan et al. - 2008 - Overview of BioCreative II gene normalization.pdf:application/pdf}
}

@article{baumgartner_concept_2008,
	title = {Concept recognition for extracting protein interaction relations from biomedical text},
	volume = {9},
	issn = {1465-6906},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559993/},
	doi = {10.1186/gb-2008-9-s2-s9},
	abstract = {Background:
Reliable information extraction applications have been a long sought goal of the biomedical text mining community, a goal that if reached would provide valuable tools to benchside biologists in their increasingly difficult task of assimilating the knowledge contained in the biomedical literature. We present an integrated approach to concept recognition in biomedical text. Concept recognition provides key information that has been largely missing from previous biomedical information extraction efforts, namely direct links to well defined knowledge resources that explicitly cement the concept's semantics. The BioCreative II tasks discussed in this special issue have provided a unique opportunity to demonstrate the effectiveness of concept recognition in the field of biomedical language processing.

Results:
Through the modular construction of a protein interaction relation extraction system, we present several use cases of concept recognition in biomedical text, and relate these use cases to potential uses by the benchside biologist.

Conclusion:
Current information extraction technologies are approaching performance standards at which concept recognition can begin to deliver high quality data to the benchside biologist. Our system is available as part of the BioCreative Meta-Server project and on the internet .},
	number = {Suppl 2},
	urldate = {2018-01-26},
	journal = {Genome Biology},
	author = {Baumgartner, William A and Lu, Zhiyong and Johnson, Helen L and Caporaso, J Gregory and Paquette, Jesse and Lindemann, Anna and White, Elizabeth K and Medvedeva, Olga and Cohen, K Bretonnel and Hunter, Lawrence},
	year = {2008},
	pmid = {18834500},
	pmcid = {PMC2559993},
	pages = {S9},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JH6JC4E2/Baumgartner et al. - 2008 - Concept recognition for extracting protein interac.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/HQQ8PE78/Baumgartner et al. - 2008 - Concept recognition for extracting protein interac.pdf:application/pdf}
}

@article{verspoor_ontology_2009,
	title = {Ontology quality assurance through analysis of term transformations},
	volume = {25},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2687949/},
	doi = {10.1093/bioinformatics/btp195},
	abstract = {Motivation: It is important for the quality of biological ontologies that similar concepts be expressed consistently, or univocally. Univocality is relevant for the usability of the ontology for humans, as well as for computational tools that rely on regularity in the structure of terms. However, in practice terms are not always expressed consistently, and we must develop methods for identifying terms that are not univocal so that they can be corrected., Results: We developed an automated transformation-based clustering methodology for detecting terms that use different linguistic conventions for expressing similar semantics. These term sets represent occurrences of univocality violations. Our method was able to identify 67 examples of univocality violations in the Gene Ontology., Availability: The identified univocality violations are available upon request. We are preparing a release of an open source version of the software to be available at http://bionlp.sourceforge.net., Contact: karin.verspoor@ucdenver.edu},
	number = {12},
	urldate = {2018-01-26},
	journal = {Bioinformatics},
	author = {Verspoor, Karin and Dvorkin, Daniel and Cohen, K. Bretonnel and Hunter, Lawrence},
	month = jun,
	year = {2009},
	pmid = {19478020},
	pmcid = {PMC2687949},
	keywords = {female first or senior},
	pages = {i77--i84},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ML3X2Q7X/Verspoor et al. - 2009 - Ontology quality assurance through analysis of ter.pdf:application/pdf}
}

@article{verspoor_textual_2009,
	title = {The textual characteristics of traditional and {Open} {Access} scientific journals are similar},
	volume = {10},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2714574/},
	doi = {10.1186/1471-2105-10-183},
	abstract = {Background
Recent years have seen an increased amount of natural language processing (NLP) work on full text biomedical journal publications. Much of this work is done with Open Access journal articles. Such work assumes that Open Access articles are representative of biomedical publications in general and that methods developed for analysis of Open Access full text publications will generalize to the biomedical literature as a whole. If this assumption is wrong, the cost to the community will be large, including not just wasted resources, but also flawed science. This paper examines that assumption.

Results
We collected two sets of documents, one consisting only of Open Access publications and the other consisting only of traditional journal publications. We examined them for differences in surface linguistic structures that have obvious consequences for the ease or difficulty of natural language processing and for differences in semantic content as reflected in lexical items. Regarding surface linguistic structures, we examined the incidence of conjunctions, negation, passives, and pronominal anaphora, and found that the two collections did not differ. We also examined the distribution of sentence lengths and found that both collections were characterized by the same mode. Regarding lexical items, we found that the Kullback-Leibler divergence between the two collections was low, and was lower than the divergence between either collection and a reference corpus. Where small differences did exist, log likelihood analysis showed that they were primarily in the area of formatting and in specific named entities.

Conclusion
We did not find structural or semantic differences between the Open Access and traditional journal collections.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Verspoor, Karin and Cohen, K Bretonnel and Hunter, Lawrence},
	month = jun,
	year = {2009},
	pmid = {19527520},
	pmcid = {PMC2714574},
	keywords = {female first or senior},
	pages = {183},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8F499UX8/Verspoor et al. - 2009 - The textual characteristics of traditional and Ope.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/EKY9C9Z5/Verspoor et al. - 2009 - The textual characteristics of traditional and Ope.pdf:application/pdf}
}

@article{wiegers_text_2009,
	title = {Text mining and manual curation of chemical-gene-disease networks for the {Comparative} {Toxicogenomics} {Database} ({CTD})},
	volume = {10},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2768719/},
	doi = {10.1186/1471-2105-10-326},
	abstract = {Background
The Comparative Toxicogenomics Database (CTD) is a publicly available resource that promotes understanding about the etiology of environmental diseases. It provides manually curated chemical-gene/protein interactions and chemical- and gene-disease relationships from the peer-reviewed, published literature. The goals of the research reported here were to establish a baseline analysis of current CTD curation, develop a text-mining prototype from readily available open source components, and evaluate its potential value in augmenting curation efficiency and increasing data coverage.

Results
Prototype text-mining applications were developed and evaluated using a CTD data set consisting of manually curated molecular interactions and relationships from 1,600 documents. Preliminary results indicated that the prototype found 80\% of the gene, chemical, and disease terms appearing in curated interactions. These terms were used to re-rank documents for curation, resulting in increases in mean average precision (63\% for the baseline vs. 73\% for a rule-based re-ranking), and in the correlation coefficient of rank vs. number of curatable interactions per document (baseline 0.14 vs. 0.38 for the rule-based re-ranking).

Conclusion
This text-mining project is unique in its integration of existing tools into a single workflow with direct application to CTD. We performed a baseline assessment of the inter-curator consistency and coverage in CTD, which allowed us to measure the potential of these integrated tools to improve prioritization of journal articles for manual curation. Our study presents a feasible and cost-effective approach for developing a text mining solution to enhance manual curation throughput and efficiency.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Wiegers, Thomas C and Davis, Allan Peter and Cohen, K Bretonnel and Hirschman, Lynette and Mattingly, Carolyn J},
	month = oct,
	year = {2009},
	pmid = {19814812},
	pmcid = {PMC2768719},
	keywords = {female first or senior, curation, IE},
	pages = {326},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YTHWRABI/Wiegers et al. - 2009 - Text mining and manual curation of chemical-gene-d.pdf:application/pdf}
}

@article{arighi_overview_2011,
	title = {Overview of the {BioCreative} {III} {Workshop}},
	volume = {12},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3269932/},
	doi = {10.1186/1471-2105-12-S8-S1},
	abstract = {Background
The overall goal of the BioCreative Workshops is to promote the development of text mining and text processing tools which are useful to the communities of researchers and database curators in the biological sciences. To this end BioCreative I was held in 2004, BioCreative II in 2007, and BioCreative II.5 in 2009. Each of these workshops involved humanly annotated test data for several basic tasks in text mining applied to the biomedical literature. Participants in the workshops were invited to compete in the tasks by constructing software systems to perform the tasks automatically and were given scores based on their performance. The results of these workshops have benefited the community in several ways. They have 1) provided evidence for the most effective methods currently available to solve specific problems; 2) revealed the current state of the art for performance on those problems; 3) and provided gold standard data and results on that data by which future advances can be gauged. This special issue contains overview papers for the three tasks of BioCreative III.

Results
The BioCreative III Workshop was held in September of 2010 and continued the tradition of a challenge evaluation on several tasks judged basic to effective text mining in biology, including a gene normalization (GN) task and two protein-protein interaction (PPI) tasks. In total the Workshop involved the work of twenty-three teams. Thirteen teams participated in the GN task which required the assignment of EntrezGene IDs to all named genes in full text papers without any species information being provided to a system. Ten teams participated in the PPI article classification task (ACT) requiring a system to classify and rank a PubMed® record as belonging to an article either having or not having “PPI relevant” information. Eight teams participated in the PPI interaction method task (IMT) where systems were given full text documents and were required to extract the experimental methods used to establish PPIs and a text segment supporting each such method. Gold standard data was compiled for each of these tasks and participants competed in developing systems to perform the tasks automatically., BioCreative III also introduced a new interactive task (IAT), run as a demonstration task. The goal was to develop an interactive system to facilitate a user’s annotation of the unique database identifiers for all the genes appearing in an article. This task included ranking genes by importance (based preferably on the amount of described experimental information regarding genes). There was also an optional task to assist the user in finding the most relevant articles about a given gene. For BioCreative III, a user advisory group (UAG) was assembled and played an important role 1) in producing some of the gold standard annotations for the GN task, 2) in critiquing IAT systems, and 3) in providing guidance for a future more rigorous evaluation of IAT systems. Six teams participated in the IAT demonstration task and received feedback on their systems from the UAG group. Besides innovations in the GN and PPI tasks making them more realistic and practical and the introduction of the IAT task, discussions were begun on community data standards to promote interoperability and on user requirements and evaluation metrics to address utility and usability of systems.

Conclusions
In this paper we give a brief history of the BioCreative Workshops and how they relate to other text mining competitions in biology. This is followed by a synopsis of the three tasks GN, PPI, and IAT in BioCreative III with figures for best participant performance on the GN and PPI tasks. These results are discussed and compared with results from previous BioCreative Workshops and we conclude that the best performing systems for GN, PPI-ACT and PPI-IMT in realistic settings are not sufficient for fully automatic use. This provides evidence for the importance of interactive systems and we present our vision of how best to construct an interactive system for a GN or PPI like task in the remainder of the paper.},
	number = {Suppl 8},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Arighi, Cecilia N and Lu, Zhiyong and Krallinger, Martin and Cohen, Kevin B and Wilbur, W John and Valencia, Alfonso and Hirschman, Lynette and Wu, Cathy H},
	month = oct,
	year = {2011},
	pmid = {22151647},
	pmcid = {PMC3269932},
	keywords = {female first or senior},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SPAQVHSD/Arighi et al. - 2011 - Overview of the BioCreative III Workshop.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/X2UF3L2P/Arighi et al. - 2011 - Overview of the BioCreative III Workshop.pdf:application/pdf}
}

@article{pestian_sentiment_2012,
	title = {Sentiment {Analysis} of {Suicide} {Notes}: {A} {Shared} {Task}},
	volume = {5},
	issn = {1178-2226},
	shorttitle = {Sentiment {Analysis} of {Suicide} {Notes}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3299408/},
	doi = {10.4137/BII.S9042},
	abstract = {This paper reports on a shared task involving the assignment of emotions to suicide notes. Two features distinguished this task from previous shared tasks in the biomedical domain. One is that it resulted in the corpus of fully anonymized clinical text and annotated suicide notes. This resource is permanently available and will (we hope) facilitate future research. The other key feature of the task is that it required categorization with respect to a large set of labels. The number of participants was larger than in any previous biomedical challenge task. We describe the data production process and the evaluation measures, and give a preliminary analysis of the results. Many systems performed at levels approaching the inter-coder agreement, suggesting that human-like performance on this task is within the reach of currently available technologies.},
	number = {Suppl 1},
	urldate = {2018-01-26},
	journal = {Biomedical Informatics Insights},
	author = {Pestian, John P. and Matykiewicz, Pawel and Linn-Gust, Michelle and South, Brett and Uzuner, Ozlem and Wiebe, Jan and Cohen, K. Bretonnel and Hurdle, John and Brew, Christopher},
	month = jan,
	year = {2012},
	pmid = {22419877},
	pmcid = {PMC3299408},
	pages = {3--16},
	file = {Fulltext:/Users/transfer/Zotero/storage/5DTNRDYJ/Pestian et al. - 2012 - Sentiment analysis of suicide notes A shared task.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/NXMRXKAW/Pestian et al. - 2012 - Sentiment Analysis of Suicide Notes A Shared Task.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6EI3MFD2/BII.html:text/html}
}

@article{hahn_mining_2012,
	title = {Mining the pharmacogenomics literature—a survey of the state of the art},
	volume = {13},
	issn = {1467-5463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3404399/},
	doi = {10.1093/bib/bbs018},
	abstract = {This article surveys efforts on text mining of the pharmacogenomics literature, mainly from the period 2008 to 2011. Pharmacogenomics (or pharmacogenetics) is the field that studies how human genetic variation impacts drug response. Therefore, publications span the intersection of research in genotypes, phenotypes and pharmacology, a topic that has increasingly become a focus of active research in recent years. This survey covers efforts dealing with the automatic recognition of relevant named entities (e.g. genes, gene variants and proteins, diseases and other pathological phenomena, drugs and other chemicals relevant for medical treatment), as well as various forms of relations between them. A wide range of text genres is considered, such as scientific publications (abstracts, as well as full texts), patent texts and clinical narratives. We also discuss infrastructure and resources needed for advanced text analytics, e.g. document corpora annotated with corresponding semantic metadata (gold standards and training data), biomedical terminologies and ontologies providing domain-specific background knowledge at different levels of formality and specificity, software architectures for building complex and scalable text analytics pipelines and Web services grounded to them, as well as comprehensive ways to disseminate and interact with the typically huge amounts of semiformal knowledge structures extracted by text mining tools. Finally, we consider some of the novel applications that have already been developed in the field of pharmacogenomic text mining and point out perspectives for future research.},
	number = {4},
	urldate = {2018-01-26},
	journal = {Briefings in Bioinformatics},
	author = {Hahn, Udo and Cohen, K. Bretonnel and Garten, Yael and Shah, Nigam H.},
	month = jul,
	year = {2012},
	pmid = {22833496},
	pmcid = {PMC3404399},
	pages = {460--494},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3VA4Y8Z8/Hahn et al. - 2012 - Mining the pharmacogenomics literature—a survey of.pdf:application/pdf}
}

@article{verspoor_corpus_2012,
	title = {A corpus of full-text journal articles is a robust evaluation tool for revealing differences in performance of biomedical natural language processing tools},
	volume = {13},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3483229/},
	doi = {10.1186/1471-2105-13-207},
	abstract = {Background
We introduce the linguistic annotation of a corpus of 97 full-text biomedical publications, known as the Colorado Richly Annotated Full Text (CRAFT) corpus. We further assess the performance of existing tools for performing sentence splitting, tokenization, syntactic parsing, and named entity recognition on this corpus.

Results
Many biomedical natural language processing systems demonstrated large differences between their previously published results and their performance on the CRAFT corpus when tested with the publicly available models or rule sets. Trainable systems differed widely with respect to their ability to build high-performing models based on this data.

Conclusions
The finding that some systems were able to train high-performing models based on this corpus is additional evidence, beyond high inter-annotator agreement, that the quality of the CRAFT corpus is high. The overall poor performance of various systems indicates that considerable work needs to be done to enable natural language processing systems to work well when the input is full-text journal articles. The CRAFT corpus provides a valuable resource to the biomedical natural language processing community for evaluation and training of new models for biomedical full text publications.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Verspoor, Karin and Cohen, Kevin Bretonnel and Lanfranchi, Arrick and Warner, Colin and Johnson, Helen L and Roeder, Christophe and Choi, Jinho D and Funk, Christopher and Malenkiy, Yuriy and Eckert, Miriam and Xue, Nianwen and Baumgartner, William A and Bada, Michael and Palmer, Martha and Hunter, Lawrence E},
	month = aug,
	year = {2012},
	pmid = {22901054},
	pmcid = {PMC3483229},
	keywords = {reproducibility, female first or senior},
	pages = {207},
	annote = {Pages 207 in PDF},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/336HVHRV/Verspoor et al. - 2012 - A corpus of full-text journal articles is a robust.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ABNTSU7J/Verspoor et al. - 2012 - A corpus of full-text journal articles is a robust.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BT34K82R/Verspoor et al. - 2012 - A corpus of full-text journal articles is a robust.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GCWZJQAX/1471-2105-13-207.html:text/html}
}

@article{arighi_overview_2013,
	title = {An overview of the {BioCreative} 2012 {Workshop} {Track} {III}: interactive text mining task},
	volume = {2013},
	issn = {1758-0463},
	shorttitle = {An overview of the {BioCreative} 2012 {Workshop} {Track} {III}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3625048/},
	doi = {10.1093/database/bas056},
	abstract = {In many databases, biocuration primarily involves literature curation, which usually involves retrieving relevant articles, extracting information that will translate into annotations and identifying new incoming literature. As the volume of biological literature increases, the use of text mining to assist in biocuration becomes increasingly relevant. A number of groups have developed tools for text mining from a computer science/linguistics perspective, and there are many initiatives to curate some aspect of biology from the literature. Some biocuration efforts already make use of a text mining tool, but there have not been many broad-based systematic efforts to study which aspects of a text mining tool contribute to its usefulness for a curation task. Here, we report on an effort to bring together text mining tool developers and database biocurators to test the utility and usability of tools. Six text mining systems presenting diverse biocuration tasks participated in a formal evaluation, and appropriate biocurators were recruited for testing. The performance results from this evaluation indicate that some of the systems were able to improve efficiency of curation by speeding up the curation task significantly (∼1.7- to 2.5-fold) over manual curation. In addition, some of the systems were able to improve annotation accuracy when compared with the performance on the manually curated set. In terms of inter-annotator agreement, the factors that contributed to significant differences for some of the systems included the expertise of the biocurator on the given curation task, the inherent difficulty of the curation and attention to annotation guidelines. After the task, annotators were asked to complete a survey to help identify strengths and weaknesses of the various systems. The analysis of this survey highlights how important task completion is to the biocurators’ overall experience of a system, regardless of the system’s high score on design, learnability and usability. In addition, strategies to refine the annotation guidelines and systems documentation, to adapt the tools to the needs and query types the end user might have and to evaluate performance in terms of efficiency, user interface, result export and traditional evaluation metrics have been analyzed during this task. This analysis will help to plan for a more intense study in BioCreative IV.},
	urldate = {2018-01-26},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Arighi, Cecilia N. and Carterette, Ben and Cohen, K. Bretonnel and Krallinger, Martin and Wilbur, W. John and Fey, Petra and Dodson, Robert and Cooper, Laurel and Van Slyke, Ceri E. and Dahdul, Wasila and Mabee, Paula and Li, Donghui and Harris, Bethany and Gillespie, Marc and Jimenez, Silvia and Roberts, Phoebe and Matthews, Lisa and Becker, Kevin and Drabkin, Harold and Bello, Susan and Licata, Luana and Chatr-aryamontri, Andrew and Schaeffer, Mary L. and Park, Julie and Haendel, Melissa and Van Auken, Kimberly and Li, Yuling and Chan, Juancarlos and Muller, Hans-Michael and Cui, Hong and Balhoff, James P. and Chi-Yang Wu, Johnny and Lu, Zhiyong and Wei, Chih-Hsuan and Tudor, Catalina O. and Raja, Kalpana and Subramani, Suresh and Natarajan, Jeyakumar and Cejuela, Juan Miguel and Dubey, Pratibha and Wu, Cathy},
	month = jan,
	year = {2013},
	pmid = {23327936},
	pmcid = {PMC3625048},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SZCIIERP/Arighi et al. - 2013 - An overview of the BioCreative 2012 Workshop Track.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XMETSXAJ/Arighi et al. - 2013 - An overview of the BioCreative 2012 Workshop Track.pdf:application/pdf}
}

@article{katayama_biohackathon_2014,
	title = {{BioHackathon} series in 2011 and 2012: penetration of ontology and linked data in life science domains},
	volume = {5},
	issn = {2041-1480},
	shorttitle = {{BioHackathon} series in 2011 and 2012},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3978116/},
	doi = {10.1186/2041-1480-5-5},
	abstract = {The application of semantic technologies to the integration of biological data and the interoperability of bioinformatics analysis and visualization tools has been the common theme of a series of annual BioHackathons hosted in Japan for the past five years. Here we provide a review of the activities and outcomes from the BioHackathons held in 2011 in Kyoto and 2012 in Toyama. In order to efficiently implement semantic technologies in the life sciences, participants formed various sub-groups and worked on the following topics: Resource Description Framework (RDF) models for specific domains, text mining of the literature, ontology development, essential metadata for biological databases, platforms to enable efficient Semantic Web technology development and interoperability, and the development of applications for Semantic Web data. In this review, we briefly introduce the themes covered by these sub-groups. The observations made, conclusions drawn, and software development projects that emerged from these activities are discussed.},
	urldate = {2018-01-26},
	journal = {Journal of Biomedical Semantics},
	author = {Katayama, Toshiaki and Wilkinson, Mark D and Aoki-Kinoshita, Kiyoko F and Kawashima, Shuichi and Yamamoto, Yasunori and Yamaguchi, Atsuko and Okamoto, Shinobu and Kawano, Shin and Kim, Jin-Dong and Wang, Yue and Wu, Hongyan and Kano, Yoshinobu and Ono, Hiromasa and Bono, Hidemasa and Kocbek, Simon and Aerts, Jan and Akune, Yukie and Antezana, Erick and Arakawa, Kazuharu and Aranda, Bruno and Baran, Joachim and Bolleman, Jerven and Bonnal, Raoul JP and Buttigieg, Pier Luigi and Campbell, Matthew P and Chen, Yi-an and Chiba, Hirokazu and Cock, Peter JA and Cohen, K Bretonnel and Constantin, Alexandru and Duck, Geraint and Dumontier, Michel and Fujisawa, Takatomo and Fujiwara, Toyofumi and Goto, Naohisa and Hoehndorf, Robert and Igarashi, Yoshinobu and Itaya, Hidetoshi and Ito, Maori and Iwasaki, Wataru and Kalaš, Matúš and Katoda, Takeo and Kim, Taehong and Kokubu, Anna and Komiyama, Yusuke and Kotera, Masaaki and Laibe, Camille and Lapp, Hilmar and Lütteke, Thomas and Marshall, M Scott and Mori, Takaaki and Mori, Hiroshi and Morita, Mizuki and Murakami, Katsuhiko and Nakao, Mitsuteru and Narimatsu, Hisashi and Nishide, Hiroyo and Nishimura, Yosuke and Nystrom-Persson, Johan and Ogishima, Soichi and Okamura, Yasunobu and Okuda, Shujiro and Oshita, Kazuki and Packer, Nicki H and Prins, Pjotr and Ranzinger, Rene and Rocca-Serra, Philippe and Sansone, Susanna and Sawaki, Hiromichi and Shin, Sung-Ho and Splendiani, Andrea and Strozzi, Francesco and Tadaka, Shu and Toukach, Philip and Uchiyama, Ikuo and Umezaki, Masahito and Vos, Rutger and Whetzel, Patricia L and Yamada, Issaku and Yamasaki, Chisato and Yamashita, Riu and York, William S and Zmasek, Christian M and Kawamoto, Shoko and Takagi, Toshihisa},
	month = feb,
	year = {2014},
	pmid = {24495517},
	pmcid = {PMC3978116},
	pages = {5},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BVQSJ34M/Katayama et al. - 2014 - BioHackathon series in 2011 and 2012 penetration .pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/5PEFHHDB/Katayama et al. - 2014 - BioHackathon series in 2011 and 2012 penetration .pdf:application/pdf}
}

@article{funk_large-scale_2014,
	title = {Large-scale biomedical concept recognition: an evaluation of current automatic annotators and their parameters},
	volume = {15},
	issn = {1471-2105},
	shorttitle = {Large-scale biomedical concept recognition},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4015610/},
	doi = {10.1186/1471-2105-15-59},
	abstract = {Background
Ontological concepts are useful for many different biomedical tasks. Concepts are difficult to recognize in text due to a disconnect between what is captured in an ontology and how the concepts are expressed in text. There are many recognizers for specific ontologies, but a general approach for concept recognition is an open problem.

Results
Three dictionary-based systems (MetaMap, NCBO Annotator, and ConceptMapper) are evaluated on eight biomedical ontologies in the Colorado Richly Annotated Full-Text (CRAFT) Corpus. Over 1,000 parameter combinations are examined, and best-performing parameters for each system-ontology pair are presented.

Conclusions
Baselines for concept recognition by three systems on eight biomedical ontologies are established (F-measures range from 0.14–0.83). Out of the three systems we tested, ConceptMapper is generally the best-performing system; it produces the highest F-measure of seven out of eight ontologies. Default parameters are not ideal for most systems on most ontologies; by changing parameters F-measure can be increased by up to 0.4. Not only are best performing parameters presented, but suggestions for choosing the best parameters based on ontology characteristics are presented.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Funk, Christopher and Baumgartner, William and Garcia, Benjamin and Roeder, Christophe and Bada, Michael and Cohen, K Bretonnel and Hunter, Lawrence E and Verspoor, Karin},
	month = feb,
	year = {2014},
	pmid = {24571547},
	pmcid = {PMC4015610},
	keywords = {female first or senior, normalization},
	pages = {59},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TXWY9EJK/Funk et al. - 2014 - Large-scale biomedical concept recognition an eva.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/X8FHKU4U/Funk et al. - 2014 - Large-scale biomedical concept recognition an eva.pdf:application/pdf}
}

@article{cohen_high-precision_2011,
	title = {{HIGH}-{PRECISION} {BIOLOGICAL} {EVENT} {EXTRACTION}: {EFFECTS} {OF} {SYSTEM} {AND} {OF} {DATA}},
	volume = {27},
	issn = {0824-7935},
	shorttitle = {{HIGH}-{PRECISION} {BIOLOGICAL} {EVENT} {EXTRACTION}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4414063/},
	doi = {10.1111/j.1467-8640.2011.00405.x},
	abstract = {We approached the problems of event detection, argument identification, and negation and speculation detection in the BioNLP’09 information extraction challenge through concept recognition and analysis. Our methodology involved using the OpenDMAP semantic parser with manually written rules. The original OpenDMAP system was updated for this challenge with a broad ontology defined for the events of interest, new linguistic patterns for those events, and specialized coordination handling. We achieved state-of-the-art precision for two of the three tasks, scoring the highest of 24 teams at precision of 71.81 on Task 1 and the highest of 6 teams at precision of 70.97 on Task 2. We provide a detailed analysis of the training data and show that a number of trigger words were ambiguous as to event type, even when their arguments are constrained by semantic class. The data is also shown to have a number of missing annotations. Analysis of a sampling of the comparatively small number of false positives returned by our system shows that major causes of this type of error were failing to recognize second themes in two-theme events, failing to recognize events when they were the arguments to other events, failure to recognize nontheme arguments, and sentence segmentation errors. We show that specifically handling coordination had a small but important impact on the overall performance of the system. The OpenDMAP system and the rule set are available at http://bionlp.sourceforge.net.},
	number = {4},
	urldate = {2018-01-26},
	journal = {Computational intelligence},
	author = {Cohen, K. Bretonnel and Verspoor, Karin and Johnson, Helen L. and Roeder, Chris and Ogren, Philip V. and Baumgartner, William A. and White, Elizabeth and Tipney, Hannah and Hunter, Lawrence},
	month = nov,
	year = {2011},
	pmid = {25937701},
	pmcid = {PMC4414063},
	pages = {681--701},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZUZ5K3ZF/PMC4414063.html:text/html;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/86CD4RCL/Cohen et al. - 2011 - HIGH-PRECISION BIOLOGICAL EVENT EXTRACTION EFFECT.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/VIDDAMIW/j.1467-8640.2011.00405.html:text/html}
}

@article{kim_introduction_2015,
	title = {Introduction to the {Biomedical} {Linked} {Annotation} {Hackathon} ({BLAH}) 2015 {Symposium}},
	volume = {9},
	issn = {1753-6561},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4613566/},
	doi = {10.1186/1753-6561-9-S5-A1},
	number = {Suppl 5},
	urldate = {2018-01-26},
	journal = {BMC Proceedings},
	author = {Kim, Jin-Dong and Cohen, Kevin Bretonnel and Collier, Nigel and Lu, Zhiyong and Stenetorp, Pontus},
	month = aug,
	year = {2015},
	pmid = {null},
	pmcid = {PMC4613566},
	pages = {A1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/A6LEM78D/Kim et al. - 2015 - Introduction to the Biomedical Linked Annotation H.pdf:application/pdf}
}

@article{funk_gene_2016,
	title = {Gene {Ontology} synonym generation rules lead to increased performance in biomedical concept recognition},
	volume = {7},
	issn = {2041-1480},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5018193/},
	doi = {10.1186/s13326-016-0096-7},
	abstract = {Background
Gene Ontology (GO) terms represent the standard for annotation and representation of molecular functions, biological processes and cellular compartments, but a large gap exists between the way concepts are represented in the ontology and how they are expressed in natural language text. The construction of highly specific GO terms is formulaic, consisting of parts and pieces from more simple terms.

Results
We present two different types of manually generated rules to help capture the variation of how GO terms can appear in natural language text. The first set of rules takes into account the compositional nature of GO and recursively decomposes the terms into their smallest constituent parts. The second set of rules generates derivational variations of these smaller terms and compositionally combines all generated variants to form the original term. By applying both types of rules, new synonyms are generated for two-thirds of all GO terms and an increase in F-measure performance for recognition of GO on the CRAFT corpus from 0.498 to 0.636 is observed. Additionally, we evaluated the combination of both types of rules over one million full text documents from Elsevier; manual validation and error analysis show we are able to recognize GO concepts with reasonable accuracy (88 \%) based on random sampling of annotations.

Conclusions
In this work we present a set of simple synonym generation rules that utilize the highly compositional and formulaic nature of the Gene Ontology concepts. We illustrate how the generated synonyms aid in improving recognition of GO concepts on two different biomedical corpora. We discuss other applications of our rules for GO ontology quality assurance, explore the issue of overgeneration, and provide examples of how similar methodologies could be applied to other biomedical terminologies. Additionally, we provide all generated synonyms for use by the text-mining community.

Electronic supplementary material
The online version of this article (doi:10.1186/s13326-016-0096-7) contains supplementary material, which is available to authorized users.},
	number = {1},
	urldate = {2018-01-26},
	journal = {Journal of Biomedical Semantics},
	author = {Funk, Christopher S. and Cohen, K. Bretonnel and Hunter, Lawrence E. and Verspoor, Karin M.},
	month = sep,
	year = {2016},
	pmid = {27613112},
	pmcid = {PMC5018193},
	keywords = {female first or senior, normalization},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/N3F9RWVX/Funk et al. - 2016 - Gene Ontology synonym generation rules lead to inc.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TEF6X6JF/Funk et al. - 2016 - Gene Ontology synonym generation rules lead to inc.pdf:application/pdf}
}

@article{cohen_coreference_2017,
	title = {Coreference annotation and resolution in the {Colorado} {Richly} {Annotated} {Full} {Text} ({CRAFT}) corpus of biomedical journal articles},
	volume = {18},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5561560/},
	doi = {10.1186/s12859-017-1775-9},
	abstract = {Background
Coreference resolution is the task of finding strings in text that have the same referent as other strings. Failures of coreference resolution are a common cause of false negatives in information extraction from the scientific literature. In order to better understand the nature of the phenomenon of coreference in biomedical publications and to increase performance on the task, we annotated the Colorado Richly Annotated Full Text (CRAFT) corpus with coreference relations.

Results
The corpus was manually annotated with coreference relations, including identity and appositives for all coreferring base noun phrases. The OntoNotes annotation guidelines, with minor adaptations, were used. Interannotator agreement ranges from 0.480 (entity-based CEAF) to 0.858 (Class-B3), depending on the metric that is used to assess it. The resulting corpus adds nearly 30,000 annotations to the previous release of the CRAFT corpus. Differences from related projects include a much broader definition of markables, connection to extensive annotation of several domain-relevant semantic classes, and connection to complete syntactic annotation. Tool performance was benchmarked on the data. A publicly available out-of-the-box, general-domain coreference resolution system achieved an F-measure of 0.14 (B3), while a simple domain-adapted rule-based system achieved an F-measure of 0.42. An ensemble of the two reached F of 0.46. Following the IDENTITY chains in the data would add 106,263 additional named entities in the full 97-paper corpus, for an increase of 76\% percent in the semantic classes of the eight ontologies that have been annotated in earlier versions of the CRAFT corpus.

Conclusions
The project produced a large data set for further investigation of coreference and coreference resolution in the scientific literature. The work raised issues in the phenomenon of reference in this domain and genre, and the paper proposes that many mentions that would be considered generic in the general domain are not generic in the biomedical domain due to their referents to specific classes in domain-specific ontologies. The comparison of the performance of a publicly available and well-understood coreference resolution system with a domain-adapted system produced results that are consistent with the notion that the requirements for successful coreference resolution in this genre are quite different from those of the general domain, and also suggest that the baseline performance difference is quite large.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Cohen, K. Bretonnel and Lanfranchi, Arrick and Choi, Miji Joo-young and Bada, Michael and Baumgartner, William A. and Panteleyeva, Natalya and Verspoor, Karin and Palmer, Martha and Hunter, Lawrence E.},
	month = aug,
	year = {2017},
	pmid = {28818042},
	pmcid = {PMC5561560},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/49U87PMA/Cohen et al. - 2017 - Coreference annotation and resolution in the Color.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/X86U5IHP/Cohen et al. - 2017 - Coreference annotation and resolution in the Color.pdf:application/pdf}
}

@article{boguslav_improving_2018-2,
	title = {Improving precision in concept normalization},
	volume = {23},
	issn = {2335-6936},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5730334/},
	abstract = {Most natural language processing applications exhibit a trade-off between precision and recall. In some use cases for natural language processing, there are reasons to prefer to tilt that trade-off toward high precision. Relying on the Zipfian distribution of false positive results, we describe a strategy for increasing precision, using a variety of both pre-processing and post-processing methods. They draw on both knowledge-based and frequentist approaches to modeling language. Based on an existing high-performance biomedical concept recognition pipeline and a previously published manually annotated corpus, we apply this hybrid rationalist/empiricist strategy to concept normalization for eight different ontologies. Which approaches did and did not improve precision varied widely between the ontologies.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Boguslav, Mayla and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2018},
	pmid = {29218915},
	pmcid = {PMC5730334},
	pages = {566--577},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BEVC7PVB/Boguslav et al. - 2018 - Improving precision in concept normalization.pdf:application/pdf}
}

@article{cohen_empirical_2005,
	title = {Empirical data on corpus design and usage in biomedical natural language processing},
	volume = {2005},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1560643/},
	abstract = {This paper describes the designs of six publicly available biomedical corpora. We
then present usage data for the six corpora. We show that corpora
that are carefully annotated with respect to structural and linguistic
characteristics and that are distributed in standard formats are
more widely used than corpora that are not. These findings have implications
for the design of the next generation of biomedical corpora.},
	urldate = {2018-01-26},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Cohen, K. Bretonnel and Ogren, Philip V. and Fox, Lynne and Hunter, Lawrence},
	year = {2005},
	pmid = {16779021},
	pmcid = {PMC1560643},
	pages = {156--160},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8X8A26UH/Cohen et al. - 2005 - Empirical data on corpus design and usage in biome.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PAV7CXCM/Cohen et al. - 2005 - Empirical data on corpus design and usage in biome.pdf:application/pdf}
}

@article{hunter_biomedical_2006,
	title = {Biomedical {Language} {Processing}: {Perspective} {What}’s {Beyond} {PubMed}?},
	volume = {21},
	issn = {1097-2765},
	shorttitle = {Biomedical {Language} {Processing}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1702322/},
	doi = {10.1016/j.molcel.2006.02.012},
	number = {5},
	urldate = {2018-01-26},
	journal = {Molecular cell},
	author = {Hunter, Lawrence and Cohen, K. Bretonnel},
	month = mar,
	year = {2006},
	pmid = {16507357},
	pmcid = {PMC1702322},
	pages = {589--594},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KD5QNF2A/Hunter and Cohen - 2006 - Biomedical Language Processing Perspective What’s.pdf:application/pdf}
}

@article{baumgartner_open-source_2008,
	title = {An open-source framework for large-scale, flexible evaluation of biomedical text mining systems},
	volume = {3},
	issn = {1747-5333},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2276192/},
	doi = {10.1186/1747-5333-3-1},
	abstract = {Background
Improved evaluation methodologies have been identified as a necessary prerequisite to the improvement of text mining theory and practice. This paper presents a publicly available framework that facilitates thorough, structured, and large-scale evaluations of text mining technologies. The extensibility of this framework and its ability to uncover system-wide characteristics by analyzing component parts as well as its usefulness for facilitating third-party application integration are demonstrated through examples in the biomedical domain.

Results
Our evaluation framework was assembled using the Unstructured Information Management Architecture. It was used to analyze a set of gene mention identification systems involving 225 combinations of system, evaluation corpus, and correctness measure. Interactions between all three were found to affect the relative rankings of the systems. A second experiment evaluated gene normalization system performance using as input 4,097 combinations of gene mention systems and gene mention system-combining strategies. Gene mention system recall is shown to affect gene normalization system performance much more than does gene mention system precision, and high gene normalization performance is shown to be achievable with remarkably low levels of gene mention system precision.

Conclusion
The software presented in this paper demonstrates the potential for novel discovery resulting from the structured evaluation of biomedical language processing systems, as well as the usefulness of such an evaluation framework for promoting collaboration between developers of biomedical language processing technologies. The code base is available as part of the BioNLP UIMA Component Repository on SourceForge.net.},
	urldate = {2018-01-26},
	journal = {Journal of Biomedical Discovery and Collaboration},
	author = {Baumgartner, William A and Cohen, K Bretonnel and Hunter, Lawrence},
	month = jan,
	year = {2008},
	pmid = {18230184},
	pmcid = {PMC2276192},
	keywords = {reproducibility, NER},
	pages = {1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/NUDCVRWA/Baumgartner et al. - 2008 - An open-source framework for large-scale, flexible.pdf:application/pdf}
}

@article{baumgartner_manual_2007,
	title = {Manual curation is not sufficient for annotation of genomic databases},
	volume = {23},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516305/},
	doi = {10.1093/bioinformatics/btm229},
	abstract = {Motivation
Knowledge base construction has been an area of intense activity and great importance in the growth of computational biology. However, there is little or no history of work on the subject of evaluation of knowledge bases, either with respect to their contents or with respect to the processes by which they are constructed. This article proposes the application of a metric from software engineering known as the found/fixed graph to the problem of evaluating the processes by which genomic knowledge bases are built, as well as the completeness of their contents.

Results
Well-understood patterns of change in the found/fixed graph are found to occur in two large publicly available knowledge bases. These patterns suggest that the current manual curation processes will take far too long to complete the annotations of even just the most important model organisms, and that at their current rate of production, they will never be sufficient for completing the annotation of all currently available proteomes.

Contact

            larry.hunter@uchsc.edu},
	number = {13},
	urldate = {2018-01-26},
	journal = {Bioinformatics (Oxford, England)},
	author = {Baumgartner, William A. and Cohen, K. Bretonnel and Fox, Lynne M. and Acquaah-Mensah, George and Hunter, Lawrence},
	month = jul,
	year = {2007},
	pmid = {17646325},
	pmcid = {PMC2516305},
	pages = {i41--i48},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/J9DX6KPM/Baumgartner et al. - 2007 - Manual curation is not sufficient for annotation o.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VCZ2DIJV/Baumgartner et al. - 2007 - Manual curation is not sufficient for annotation o.pdf:application/pdf}
}

@article{cohen_parenthetically_2011,
	title = {Parenthetically {Speaking}: {Classifying} the {Contents} of {Parentheses} for {Text} {Mining}},
	volume = {2011},
	issn = {1942-597X},
	shorttitle = {Parenthetically {Speaking}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3243264/},
	abstract = {The contents of parentheses in biomedical text have many potential uses in text mining applications. However, making use of them requires the ability to determine what class of contents they are. A system that automatically classifies parenthesized text into one of 20 categories is presented and evaluated here. It performs at a micro-averaged accuracy of 68\% and a macro-averaged accuracy of 60\% on an annotated corpus. The application is available as a Java class and as a Perl module.},
	urldate = {2018-01-26},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Cohen, K. Bretonnel and Christiansen, Thomas and Hunter, Lawrence E.},
	year = {2011},
	pmid = {22195078},
	pmcid = {PMC3243264},
	keywords = {NER},
	pages = {267--272},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XJQRF285/Cohen et al. - 2011 - Parenthetically Speaking Classifying the Contents.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7HAJ8VQQ/Cohen et al. - 2011 - Parenthetically Speaking Classifying the Contents.pdf:application/pdf}
}

@article{kano_u-compare_2011,
	title = {U-{Compare} bio-event meta-service: compatible {BioNLP} event extraction services},
	volume = {12},
	issn = {1471-2105},
	shorttitle = {U-{Compare} bio-event meta-service},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3299809/},
	doi = {10.1186/1471-2105-12-481},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Kano, Yoshinobu and Björne, Jari and Ginter, Filip and Salakoski, Tapio and Buyko, Ekaterina and Hahn, Udo and Cohen, K Bretonnel and Verspoor, Karin and Roeder, Christophe and Hunter, Lawrence E and Kilicoglu, Halil and Bergler, Sabine and Van Landeghem, Sofie and Van Parys, Thomas and Van de Peer, Yves and Miwa, Makoto and Ananiadou, Sophia and Neves, Mariana and Pascual-Montano, Alberto and Özgür, Arzucan and Radev, Dragomir R and Riedel, Sebastian and Sætre, Rune and Chun, Hong-Woo and Kim, Jin-Dong and Pyysalo, Sampo and Ohta, Tomoko and Tsujii, Jun'ichi},
	month = dec,
	year = {2011},
	pmid = {22177292},
	pmcid = {PMC3299809},
	keywords = {reproducibility},
	pages = {481},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TZ77CYL9/Kano et al. - 2011 - U-Compare bio-event meta-service compatible BioNL.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VN9IK74F/Kano et al. - 2011 - U-Compare bio-event meta-service compatible BioNL.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/5WJA37HI/Kano et al. - 2011 - U-Compare bio-event meta-service compatible BioNL.pdf:application/pdf}
}

@article{bada_concept_2012,
	title = {Concept annotation in the {CRAFT} corpus},
	volume = {13},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3476437/},
	doi = {10.1186/1471-2105-13-161},
	abstract = {Background
Manually annotated corpora are critical for the training and evaluation of automated methods to identify concepts in biomedical text.

Results
This paper presents the concept annotations of the Colorado Richly Annotated Full-Text (CRAFT) Corpus, a collection of 97 full-length, open-access biomedical journal articles that have been annotated both semantically and syntactically to serve as a research resource for the biomedical natural-language-processing (NLP) community. CRAFT identifies all mentions of nearly all concepts from nine prominent biomedical ontologies and terminologies: the Cell Type Ontology, the Chemical Entities of Biological Interest ontology, the NCBI Taxonomy, the Protein Ontology, the Sequence Ontology, the entries of the Entrez Gene database, and the three subontologies of the Gene Ontology. The first public release includes the annotations for 67 of the 97 articles, reserving two sets of 15 articles for future text-mining competitions (after which these too will be released). Concept annotations were created based on a single set of guidelines, which has enabled us to achieve consistently high interannotator agreement.

Conclusions
As the initial 67-article release contains more than 560,000 tokens (and the full set more than 790,000 tokens), our corpus is among the largest gold-standard annotated biomedical corpora. Unlike most others, the journal articles that comprise the corpus are drawn from diverse biomedical disciplines and are marked up in their entirety. Additionally, with a concept-annotation count of nearly 100,000 in the 67-article subset (and more than 140,000 in the full collection), the scale of conceptual markup is also among the largest of comparable corpora. The concept annotations of the CRAFT Corpus have the potential to significantly advance biomedical text mining by providing a high-quality gold standard for NLP systems. The corpus, annotation guidelines, and other associated resources are freely available at http://bionlp-corpora.sourceforge.net/CRAFT/index.shtml.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Bada, Michael and Eckert, Miriam and Evans, Donald and Garcia, Kristin and Shipley, Krista and Sitnikov, Dmitry and Baumgartner, William A and Cohen, K Bretonnel and Verspoor, Karin and Blake, Judith A and Hunter, Lawrence E},
	month = jul,
	year = {2012},
	pmid = {22776079},
	pmcid = {PMC3476437},
	pages = {161},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/HAKYQUZ3/Bada et al. - 2012 - Concept annotation in the CRAFT corpus.pdf:application/pdf}
}

@article{wu_biocreative-2012_2012,
	title = {{BioCreative}-2012 {Virtual} {Issue}},
	volume = {2012},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3514749/},
	doi = {10.1093/database/bas049},
	urldate = {2018-01-26},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Wu, Cathy H. and Arighi, Cecilia N. and Cohen, Kevin B. and Hirschman, Lynette and Krallinger, Martin and Lu, Zhiyong and Mattingly, Carolyn and Valencia, Alfonso and Wiegers, Thomas C. and John Wilbur, W.},
	month = dec,
	year = {2012},
	pmid = {23221175},
	pmcid = {PMC3514749},
	keywords = {shared tasks, evaluation},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7DR4MX8F/Wu et al. - 2012 - BioCreative-2012 Virtual Issue.pdf:application/pdf}
}

@article{cohen_chapter_2013,
	title = {Chapter 16: {Text} {Mining} for {Translational} {Bioinformatics}},
	volume = {9},
	issn = {1553-734X},
	shorttitle = {Chapter 16},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3635962/},
	doi = {10.1371/journal.pcbi.1003044},
	abstract = {Text mining for translational bioinformatics is a new field with tremendous research potential. It is a subfield of biomedical natural language processing that concerns itself directly with the problem of relating basic biomedical research to clinical practice, and vice versa. Applications of text mining fall both into the category of T1 translational research—translating basic science results into new interventions—and T2 translational research, or translational research for public health. Potential use cases include better phenotyping of research subjects, and pharmacogenomic research. A variety of methods for evaluating text mining applications exist, including corpora, structured test suites, and post hoc judging. Two basic principles of linguistic structure are relevant for building text mining applications. One is that linguistic structure consists of multiple levels. The other is that every level of linguistic structure is characterized by ambiguity. There are two basic approaches to text mining: rule-based, also known as knowledge-based; and machine-learning-based, also known as statistical. Many systems are hybrids of the two approaches. Shared tasks have had a strong effect on the direction of the field. Like all translational bioinformatics software, text mining software for translational bioinformatics can be considered health-critical and should be subject to the strictest standards of quality assurance and software testing.},
	number = {4},
	urldate = {2018-01-26},
	journal = {PLoS Computational Biology},
	author = {Cohen, K. Bretonnel and Hunter, Lawrence E.},
	month = apr,
	year = {2013},
	pmid = {23633944},
	pmcid = {PMC3635962},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RNBS8YHF/Cohen and Hunter - 2013 - Chapter 16 Text Mining for Translational Bioinfor.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MURC6UEW/Cohen and Hunter - 2013 - Chapter 16 Text Mining for Translational Bioinfor.pdf:application/pdf}
}

@article{li_mining_2013,
	title = {Mining {FDA} drug labels for medical conditions},
	volume = {13},
	issn = {1472-6947},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3646673/},
	doi = {10.1186/1472-6947-13-53},
	abstract = {Background
Cincinnati Children’s Hospital Medical Center (CCHMC) has built the initial Natural Language Processing (NLP) component to extract medications with their corresponding medical conditions (Indications, Contraindications, Overdosage, and Adverse Reactions) as triples of medication-related information ([(1) drug name]-[(2) medical condition]-[(3) LOINC section header]) for an intelligent database system, in order to improve patient safety and the quality of health care. The Food and Drug Administration’s (FDA) drug labels are used to demonstrate the feasibility of building the triples as an intelligent database system task.

Methods
This paper discusses a hybrid NLP system, called AutoMCExtractor, to collect medical conditions (including disease/disorder and sign/symptom) from drug labels published by the FDA. Altogether, 6,611 medical conditions in a manually-annotated gold standard were used for the system evaluation. The pre-processing step extracted the plain text from XML file and detected eight related LOINC sections (e.g. Adverse Reactions, Warnings and Precautions) for medical condition extraction. Conditional Random Fields (CRF) classifiers, trained on token, linguistic, and semantic features, were then used for medical condition extraction. Lastly, dictionary-based post-processing corrected boundary-detection errors of the CRF step. We evaluated the AutoMCExtractor on manually-annotated FDA drug labels and report the results on both token and span levels.

Results
Precision, recall, and F-measure were 0.90, 0.81, and 0.85, respectively, for the span level exact match; for the token-level evaluation, precision, recall, and F-measure were 0.92, 0.73, and 0.82, respectively.

Conclusions
The results demonstrate that (1) medical conditions can be extracted from FDA drug labels with high performance; and (2) it is feasible to develop a framework for an intelligent database system.},
	urldate = {2018-01-26},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Li, Qi and Deleger, Louise and Lingren, Todd and Zhai, Haijun and Kaiser, Megan and Stoutenborough, Laura and Jegga, Anil G and Cohen, Kevin Bretonnel and Solti, Imre},
	month = apr,
	year = {2013},
	pmid = {23617267},
	pmcid = {PMC3646673},
	keywords = {NER},
	pages = {53},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/4FBQTWBZ/Li et al. - 2013 - Mining FDA drug labels for medical conditions.pdf:application/pdf}
}

@article{comeau_bioc:_2013,
	title = {{BioC}: a minimalist approach to interoperability for biomedical text processing},
	volume = {2013},
	issn = {1758-0463},
	shorttitle = {{BioC}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3889917/},
	doi = {10.1093/database/bat064},
	abstract = {A vast amount of scientific information is encoded in natural language text, and the quantity of such text has become so great that it is no longer economically feasible to have a human as the first step in the search process. Natural language processing and text mining tools have become essential to facilitate the search for and extraction of information from text. This has led to vigorous research efforts to create useful tools and to create humanly labeled text corpora, which can be used to improve such tools. To encourage combining these efforts into larger, more powerful and more capable systems, a common interchange format to represent, store and exchange the data in a simple manner between different language processing systems and text mining tools is highly desirable. Here we propose a simple extensible mark-up language format to share text documents and annotations. The proposed annotation approach allows a large number of different annotations to be represented including sentences, tokens, parts of speech, named entities such as genes or diseases and relationships between named entities. In addition, we provide simple code to hold this data, read it from and write it back to extensible mark-up language files and perform some sample processing. We also describe completed as well as ongoing work to apply the approach in several directions. Code and data are available at http://bioc.sourceforge.net/., Database URL:
http://bioc.sourceforge.net/},
	urldate = {2018-01-26},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Comeau, Donald C. and Islamaj Doğan, Rezarta and Ciccarese, Paolo and Cohen, Kevin Bretonnel and Krallinger, Martin and Leitner, Florian and Lu, Zhiyong and Peng, Yifan and Rinaldi, Fabio and Torii, Manabu and Valencia, Alfonso and Verspoor, Karin and Wiegers, Thomas C. and Wu, Cathy H. and Wilbur, W. John},
	month = sep,
	year = {2013},
	pmid = {24048470},
	pmcid = {PMC3889917},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KZ69GKKP/Comeau et al. - 2013 - BioC a minimalist approach to interoperability fo.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WJTYQHHY/Comeau et al. - 2013 - BioC a minimalist approach to interoperability fo.pdf:application/pdf}
}

@article{funk_combining_2014,
	title = {{COMBINING} {HETEROGENOUS} {DATA} {FOR} {PREDICTION} {OF} {DISEASE} {RELATED} {AND} {PHARMACOGENES}},
	issn = {2335-6936},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3910248/},
	abstract = {Identifying genetic variants that affect drug response or play a role in disease is an important task for clinicians and researchers. Before individual variants can be explored efficiently for effect on drug response or disease relationships, specific candidate genes must be identified. While many methods rank candidate genes through the use of sequence features and network topology, only a few exploit the information contained in the biomedical literature. In this work, we train and test a classifier on known pharmacogenes from PharmGKB and present a classifier that predicts pharmacogenes on a genome-wide scale using only Gene Ontology annotations and simple features mined from the biomedical literature. Performance of F=0.86, AUC=0.860 is achieved. The top 10 predicted genes are analyzed. Additionally, a set of enriched pharmacogenic Gene Ontology concepts is produced.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {FUNK, CHRISTOPHER S. and HUNTER, LAWRENCE E. and COHEN, K. BRETONNEL},
	year = {2014},
	pmid = {24297559},
	pmcid = {PMC3910248},
	pages = {328--339},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/QBG6ML3H/FUNK et al. - 2014 - COMBINING HETEROGENOUS DATA FOR PREDICTION OF DISE.pdf:application/pdf}
}

@article{arighi_biocreative-iv_2014,
	title = {{BioCreative}-{IV} virtual issue},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4030502/},
	doi = {10.1093/database/bau039},
	urldate = {2018-01-26},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Arighi, Cecilia N. and Wu, Cathy H. and Cohen, Kevin B. and Hirschman, Lynette and Krallinger, Martin and Valencia, Alfonso and Lu, Zhiyong and Wilbur, John W. and Wiegers, Thomas C.},
	month = may,
	year = {2014},
	pmid = {24852177},
	pmcid = {PMC4030502},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/IVDLDAJN/Arighi et al. - 2014 - BioCreative-IV virtual issue.pdf:application/pdf}
}

@article{kim_pubannotation-query:_2015,
	title = {{PubAnnotation}-query: a search tool for corpora with multi-layers of annotation},
	volume = {9},
	issn = {1753-6561},
	shorttitle = {{PubAnnotation}-query},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4582920/},
	doi = {10.1186/1753-6561-9-S5-A3},
	number = {Suppl 5},
	urldate = {2018-01-26},
	journal = {BMC Proceedings},
	author = {Kim, Jin-Dong and Cohen, Kevin Bretonnel and Kim, Jung-jae},
	month = aug,
	year = {2015},
	pmid = {null},
	pmcid = {PMC4582920},
	pages = {A3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XQML9MBB/Kim et al. - 2015 - PubAnnotation-query a search tool for corpora wit.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/V48IT9ZA/Kim et al. - 2015 - PubAnnotation-query a search tool for corpora wit.pdf:application/pdf}
}

@article{cohen_methodological_2016,
	title = {Methodological {Issues} in {Predicting} {Pediatric} {Epilepsy} {Surgery} {Candidates} {Through} {Natural} {Language} {Processing} and {Machine} {Learning}},
	volume = {8},
	issn = {1178-2226},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4876984/},
	doi = {10.4137/BII.S38308},
	abstract = {Objective: We describe the development and evaluation of a system that uses machine learning and natural language processing techniques to identify potential candidates for surgical intervention for drug-resistant pediatric epilepsy. The data are comprised of free-text clinical notes extracted from the electronic health record (EHR). Both known clinical outcomes from the EHR and manual chart annotations provide gold standards for the patient’s status. The following hypotheses are then tested: 1) machine learning methods can identify epilepsy surgery candidates as well as physicians do and 2) machine learning methods can identify candidates earlier than physicians do. These hypotheses are tested by systematically evaluating the effects of the data source, amount of training data, class balance, classification algorithm, and feature set on classifier performance. The results support both hypotheses, with F-measures ranging from 0.71 to 0.82. The feature set, classification algorithm, amount of training data, class balance, and gold standard all significantly affected classification performance. It was further observed that classification performance was better than the highest agreement between two annotators, even at one year before documented surgery referral. The results demonstrate that such machine learning methods can contribute to predicting pediatric epilepsy surgery candidates and reducing lag time to surgery referral.},
	urldate = {2018-01-26},
	journal = {Biomedical Informatics Insights},
	author = {Cohen, Kevin Bretonnel and Glass, Benjamin and Greiner, Hansel M. and Holland-Bouley, Katherine and Standridge, Shannon and Arya, Ravindra and Faist, Robert and Morita, Diego and Mangano, Francesco and Connolly, Brian and Glauser, Tracy and Pestian, John},
	month = may,
	year = {2016},
	pmid = {27257386},
	pmcid = {PMC4876984},
	keywords = {reproducibility},
	pages = {11--18},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZIHXAWDI/Cohen et al. - 2016 - Methodological Issues in Predicting Pediatric Epil.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YK756IV5/Cohen et al. - 2016 - Methodological Issues in Predicting Pediatric Epil.pdf:application/pdf}
}

@article{neveol_clinical_2016,
	title = {Clinical {Information} {Extraction} at the {CLEF} {eHealth} {Evaluation} lab 2016},
	volume = {1609},
	issn = {1613-0073},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5756095/},
	abstract = {This paper reports on Task 2 of the 2016 CLEF eHealth evaluation lab which extended the previous information extraction tasks of ShARe/CLEF eHealth evaluation labs. The task continued with named entity recognition and normalization in French narratives, as offered in CLEF eHealth 2015. Named entity recognition involved ten types of entities including disorders that were defined according to Semantic Groups in the Unified Medical Language System® (UMLS®), which was also used for normalizing the entities. In addition, we introduced a large-scale classification task in French death certificates, which consisted of extracting causes of death as coded in the International Classification of Diseases, tenth revision (ICD10). Participant systems were evaluated against a blind reference standard of 832 titles of scientific articles indexed in MEDLINE, 4 drug monographs published by the European Medicines Agency (EMEA) and 27,850 death certificates using Precision, Recall and F-measure. In total, seven teams participated, including five in the entity recognition and normalization task, and five in the death certificate coding task. Three teams submitted their systems to our newly offered reproducibility track. For entity recognition, the highest performance was achieved on the EMEA corpus, with an overall F-measure of 0.702 for plain entities recognition and 0.529 for normalized entity recognition. For entity normalization, the highest performance was achieved on the MEDLINE corpus, with an overall F-measure of 0.552. For death certificate coding, the highest performance was 0.848 F-measure.},
	urldate = {2018-01-26},
	journal = {CEUR workshop proceedings},
	author = {Névéol, Aurélie and Cohen, K. Bretonnel and Grouin, Cyril and Hamon, Thierry and Lavergne, Thomas and Kelly, Liadh and Goeuriot, Lorraine and Rey, Grégoire and Robert, Aude and Tannier, Xavier and Zweigenbaum, Pierre},
	month = sep,
	year = {2016},
	pmid = {29308065},
	pmcid = {PMC5756095},
	keywords = {female first or senior},
	pages = {28--42},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7NJ5UKRQ/Névéol et al. - 2016 - Clinical Information Extraction at the CLEF eHealt.pdf:application/pdf}
}

@article{kinoshita_biocreative_2005,
	title = {{BioCreAtIvE} {Task}1A: entity identification with a stochastic tagger},
	volume = {6},
	issn = {1471-2105},
	shorttitle = {{BioCreAtIvE} {Task}1A},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1869018/},
	doi = {10.1186/1471-2105-6-S1-S4},
	abstract = {Background
Our approach to Task 1A was inspired by Tanabe and Wilbur's ABGene system [,]. Like Tanabe and Wilbur, we approached the problem as one of part-of-speech tagging, adding a GENE tag to the standard tag set. Where their system uses the Brill tagger, we used TnT, the Trigrams 'n' Tags HMM-based part-of-speech tagger []. Based on careful error analysis, we implemented a set of post-processing rules to correct both false positives and false negatives. We participated in both the open and the closed divisions; for the open division, we made use of data from NCBI.

Results
Our base system without post-processing achieved a precision and recall of 68.0\% and 77.2\%, respectively, giving an F-measure of 72.3\%. The full system with post-processing achieved a precision and recall of 80.3\% and 80.5\% giving an F-measure of 80.4\%. We achieved a slight improvement (F-measure = 80.9\%) by employing a dictionary-based post-processing step for the open division. We placed third in both the open and the closed division.

Conclusion
Our results show that a part-of-speech tagger can be augmented with post-processing rules resulting in an entity identification system that competes well with other approaches.},
	number = {Suppl 1},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Kinoshita, Shuhei and Cohen, K Bretonnel and Ogren, Philip V and Hunter, Lawrence},
	month = may,
	year = {2005},
	pmid = {15960838},
	pmcid = {PMC1869018},
	keywords = {NER},
	pages = {S4},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JZ9EQTHY/Kinoshita et al. - 2005 - BioCreAtIvE Task1A entity identification with a s.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/GZVBHF6S/Kinoshita et al. - 2005 - BioCreAtIvE Task1A entity identification with a s.pdf:application/pdf}
}

@article{johnson_corpus_2007,
	title = {Corpus {Refactoring}: a {Feasibility} {Study}},
	volume = {2},
	issn = {1747-5333},
	shorttitle = {Corpus {Refactoring}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2072937/},
	doi = {10.1186/1747-5333-2-4},
	abstract = {Background
Most biomedical corpora have not been used outside of the lab that created them, despite the fact that the availability of the gold-standard evaluation data that they provide is one of the rate-limiting factors for the progress of biomedical text mining. Data suggest that one major factor affecting the use of a corpus outside of its home laboratory is the format in which it is distributed. This paper tests the hypothesis that corpus refactoring – changing the format of a corpus without altering its semantics – is a feasible goal, namely that it can be accomplished with a semi-automatable process and in a time-effcient way. We used simple text processing methods and limited human validation to convert the Protein Design Group corpus into two new formats: WordFreak and embedded XML. We tracked the total time expended and the success rates of the automated steps.

Results
The refactored corpus is available for download at the BioNLP SourceForge website http://bionlp.sourceforge.net. The total time expended was just over three person-weeks, consisting of about 102 hours of programming time (much of which is one-time development cost) and 20 hours of manual validation of automatic outputs. Additionally, the steps required to refactor any corpus are presented.

Conclusion
We conclude that refactoring of publicly available corpora is a technically and economically feasible method for increasing the usage of data already available for evaluating biomedical language processing systems.},
	urldate = {2018-01-26},
	journal = {Journal of Biomedical Discovery and Collaboration},
	author = {Johnson, Helen L and Baumgartner, William A and Krallinger, Martin and Cohen, K Bretonnel and Hunter, Lawrence},
	month = sep,
	year = {2007},
	pmid = {17854502},
	pmcid = {PMC2072937},
	keywords = {female first or senior},
	pages = {4},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CZ9Y366N/Johnson et al. - 2007 - Corpus Refactoring a Feasibility Study.pdf:application/pdf}
}

@article{cohen_getting_2008,
	title = {Getting {Started} in {Text} {Mining}},
	volume = {4},
	issn = {1553-734X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2217579/},
	doi = {10.1371/journal.pcbi.0040020},
	number = {1},
	urldate = {2018-01-26},
	journal = {PLoS Computational Biology},
	author = {Cohen, K. Bretonnel and Hunter, Lawrence},
	month = jan,
	year = {2008},
	pmid = {18225946},
	pmcid = {PMC2217579},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CIRE4NIF/Cohen and Hunter - 2008 - Getting Started in Text Mining.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U97MBQ83/Cohen and Hunter - 2008 - Getting Started in Text Mining.pdf:application/pdf}
}

@article{hunter_opendmap:_2008,
	title = {{OpenDMAP}: {An} open source, ontology-driven concept analysis engine, with applications to capturing knowledge regarding protein transport, protein interactions and cell-type-specific gene expression},
	volume = {9},
	issn = {1471-2105},
	shorttitle = {{OpenDMAP}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2275248/},
	doi = {10.1186/1471-2105-9-78},
	abstract = {Background
Information extraction (IE) efforts are widely acknowledged to be important in harnessing the rapid advance of biomedical knowledge, particularly in areas where important factual information is published in a diverse literature. Here we report on the design, implementation and several evaluations of OpenDMAP, an ontology-driven, integrated concept analysis system. It significantly advances the state of the art in information extraction by leveraging knowledge in ontological resources, integrating diverse text processing applications, and using an expanded pattern language that allows the mixing of syntactic and semantic elements and variable ordering.

Results
OpenDMAP information extraction systems were produced for extracting protein transport assertions (transport), protein-protein interaction assertions (interaction) and assertions that a gene is expressed in a cell type (expression). Evaluations were performed on each system, resulting in F-scores ranging from .26 – .72 (precision .39 – .85, recall .16 – .85). Additionally, each of these systems was run over all abstracts in MEDLINE, producing a total of 72,460 transport instances, 265,795 interaction instances and 176,153 expression instances. 

Conclusion
OpenDMAP advances the performance standards for extracting protein-protein interaction predications from the full texts of biomedical research articles. Furthermore, this level of performance appears to generalize to other information extraction tasks, including extracting information about predicates of more than two arguments. The output of the information extraction system is always constructed from elements of an ontology, ensuring that the knowledge representation is grounded with respect to a carefully constructed model of reality. The results of these efforts can be used to increase the efficiency of manual curation efforts and to provide additional features in systems that integrate multiple sources for information extraction. The open source OpenDMAP code library is freely available at},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Hunter, Lawrence and Lu, Zhiyong and Firby, James and Baumgartner, William A and Johnson, Helen L and Ogren, Philip V and Cohen, K Bretonnel},
	month = jan,
	year = {2008},
	pmid = {18237434},
	pmcid = {PMC2275248},
	pages = {78},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/D3RWCGUC/Hunter et al. - 2008 - OpenDMAP An open source, ontology-driven concept .pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/4LWVRETJ/Hunter et al. - 2008 - OpenDMAP An open source, ontology-driven concept .pdf:application/pdf}
}

@article{ogren_compositional_2004,
	title = {{THE} {COMPOSITIONAL} {STRUCTURE} {OF} {GENE} {ONTOLOGY} {TERMS}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2490823/},
	abstract = {An analysis of the term names in the Gene Ontology reveals the prevalence of substring relations between terms: 65.3\% of all GO terms contain another GO term as a proper substring. This substring relation often coincides with a derivational relationship between the terms. For example, the term regulation of cell proliferation (GO:0042127) is derived from the term cell proliferation (GO:0008283) by addition of the phrase regulation of. Further, we note that particular substrings which are not themselves GO terms (e.g. regulation of in the preceding example) recur frequently and in consistent subtrees of the ontology, and that these frequently occurring substrings often indicate interesting semantic relationships between the related terms. We describe the extent of these phenomena—substring relations between terms, and the recurrence of derivational phrases such as regulation of—and propose that these phenomena can be exploited in various ways to make the information in GO more computationally accessible, to construct a conceptually richer representation of the data encoded in the ontology, and to assist in the analysis of natural language texts.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {OGREN, P. V. and COHEN, K. B. and ACQUAAH-MENSAH, G. K. and EBERLEIN, J. and HUNTER, L.},
	year = {2004},
	pmid = {14992505},
	pmcid = {PMC2490823},
	pages = {214--225},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YK6C8HRQ/OGREN et al. - 2004 - THE COMPOSITIONAL STRUCTURE OF GENE ONTOLOGY TERMS.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/5UVS3HGZ/OGREN et al. - 2004 - THE COMPOSITIONAL STRUCTURE OF GENE ONTOLOGY TERMS.pdf:application/pdf}
}

@article{zweigenbaum_frontiers_2007,
	title = {Frontiers of biomedical text mining: current progress},
	volume = {8},
	issn = {1467-5463},
	shorttitle = {Frontiers of biomedical text mining},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516302/},
	doi = {10.1093/bib/bbm045},
	abstract = {It is now almost 15 years since the publication of the first paper on text mining in the genomics domain, and decades since the first paper on text mining in the medical domain. Enormous progress has been made in the areas of information retrieval, evaluation methodologies and resource construction. Some problems, such as abbreviation-handling, can essentially be considered solved problems, and others, such as identification of gene mentions in text, seem likely to be solved soon. However, a number of problems at the frontiers of biomedical text mining continue to present interesting challenges and opportunities for great improvements and interesting research. In this article we review the current state of the art in biomedical text mining or ‘BioNLP’ in general, focusing primarily on papers published within the past year.},
	number = {5},
	urldate = {2018-01-26},
	journal = {Briefings in bioinformatics},
	author = {Zweigenbaum, Pierre and Demner-Fushman, Dina and Yu, Hong and Cohen, Kevin B.},
	month = sep,
	year = {2007},
	pmid = {17977867},
	pmcid = {PMC2516302},
	pages = {358--375},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/T45P7Q4M/Zweigenbaum et al. - 2007 - Frontiers of biomedical text mining current progr.pdf:application/pdf}
}

@article{caporaso_mutationfinder:_2007,
	title = {{MutationFinder}: a high-performance system for extracting point mutation mentions from text},
	volume = {23},
	issn = {1367-4803},
	shorttitle = {{MutationFinder}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516306/},
	doi = {10.1093/bioinformatics/btm235},
	abstract = {Summary
Discussion of point mutations is ubiquitous in biomedical literature, and manually compiling databases or literature on mutations in specific genes or proteins is tedious. We present an open-source, rule-based system, MutationFinder, for extracting point mutation mentions from text. On blind test data, it achieves nearly perfect precision and a markedly improved recall over a baseline.

Availability
MutationFinder, along with a high-quality gold standard data set, and a scoring script for mutation extraction systems have been made publicly available. Implementations, source code and unit tests are available in Python, Perl and Java. MutationFinder can be used as a stand-alone script, or imported by other applications.

Project URL

            http://bionlp.sourceforge.net
          

Contact

            gregcaporaso@gmail.com},
	number = {14},
	urldate = {2018-01-26},
	journal = {Bioinformatics (Oxford, England)},
	author = {Caporaso, J. Gregory and Baumgartner, William A. and Randolph, David A. and Cohen, K. Bretonnel and Hunter, Lawrence},
	month = jul,
	year = {2007},
	pmid = {17495998},
	pmcid = {PMC2516306},
	keywords = {NER},
	pages = {1862--1865},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CITVF7E5/Caporaso et al. - 2007 - MutationFinder a high-performance system for extr.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/J4GWXKK8/Caporaso et al. - 2007 - MutationFinder a high-performance system for extr.pdf:application/pdf}
}

@article{caporaso_intrinsic_2008-1,
	title = {{INTRINSIC} {EVALUATION} {OF} {TEXT} {MINING} {TOOLS} {MAY} {NOT} {PREDICT} {PERFORMANCE} {ON} {REALISTIC} {TASKS}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2517250/},
	abstract = {Biomedical text mining and other automated techniques are beginning to achieve performance which suggests that they could be applied to aid database curators. However, few studies have evaluated how these systems might work in practice. In this article we focus on the problem of annotating mutations in Protein Data Bank (PDB) entries, and evaluate the relationship between performance of two automated techniques, a text-mining-based approach (MutationFinder) and an alignment-based approach, in intrinsic versus extrinsic evaluations. We find that high performance on gold standard data (an intrinsic evaluation) does not necessarily translate to high performance for database annotation (an extrinsic evaluation). We show that this is in part a result of lack of access to the full text of journal articles, which appears to be critical for comprehensive database annotation by text mining. Additionally, we evaluate the accuracy and completeness of manually annotated mutation data in the PDB, and find that it is far from perfect. We conclude that currently the most cost-effective and reliable approach for database annotation might incorporate manual and automatic annotation methods.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {CAPORASO, J. GREGORY and DESHPANDE, NITA and FINK, J. LYNN and BOURNE, PHILIP E. and COHEN, K. BRETONNEL and HUNTER, LAWRENCE},
	year = {2008},
	pmid = {18229722},
	pmcid = {PMC2517250},
	keywords = {reproducibility},
	pages = {640--651},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/LN7UC5Z2/CAPORASO et al. - 2008 - INTRINSIC EVALUATION OF TEXT MINING TOOLS MAY NOT .pdf:application/pdf}
}

@article{demner-fushman_themes_2008,
	title = {Themes in biomedical natural language processing: {BioNLP}08},
	volume = {9},
	issn = {1471-2105},
	shorttitle = {Themes in biomedical natural language processing},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2586759/},
	doi = {10.1186/1471-2105-9-S11-S1},
	number = {Suppl 11},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Demner-Fushman, Dina and Ananiadou, Sophia and Cohen, K Bretonnel and Pestian, John and Tsujii, Jun'ichi and Webber, Bonnie},
	month = nov,
	year = {2008},
	pmid = {19025685},
	pmcid = {PMC2586759},
	keywords = {female first or senior},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7XJUHSRA/Demner-Fushman et al. - 2008 - Themes in biomedical natural language processing .pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TMPZKDTC/Demner-Fushman et al. - 2008 - Themes in biomedical natural language processing .pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3SJR4W8C/Demner-Fushman et al. - 2008 - Themes in biomedical natural language processing .pdf:application/pdf}
}

@article{lu_generif_2007,
	title = {{GeneRIF} {QUALITY} {ASSURANCE} {AS} {SUMMARY} {REVISION}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2652871/},
	abstract = {Like the primary scientific literature, GeneRIFs exhibit both growth and obsolescence. NLM’s control over the contents of the Entrez Gene database provides a mechanism for dealing with obsolete data: GeneRIFs are removed from the database when they are found to be of low quality. However, the rapid and extensive growth of Entrez Gene makes manual location of low-quality GeneRIFs problematic. This paper presents a system that takes advantage of the summary-like quality of GeneRIFs to detect low-quality GeneRIFs via a summary revision approach, achieving precision of 89\% and recall of 77\%. Aspects of the system have been adopted by NLM as a quality assurance mechanism.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {LU, ZHIYONG and COHEN, K. BRETONNEL and HUNTER, LAWRENCE},
	year = {2007},
	pmid = {17990498},
	pmcid = {PMC2652871},
	pages = {269--280},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TJZXC77N/LU et al. - 2007 - GeneRIF QUALITY ASSURANCE AS SUMMARY REVISION.pdf:application/pdf}
}

@article{lu_finding_2006,
	title = {{FINDING} {GENERIFS} {VIA} {GENE} {ONTOLOGY} {ANNOTATIONS}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2652876/},
	abstract = {A Gene Reference Into Function (GeneRIF) is a concise phrase describing a function of a gene in the Entrez Gene database. Applying techniques from the area of natural language processing known as automatic summarization, it is possible to link the Entrez Gene database, the Gene Ontology, and the biomedical literature. A system was implemented that automatically suggests a sentence from a PubMed/MEDLINE abstract as a candidate GeneRIF by exploiting a gene’s GO annotations along with location features and cue words. Results suggest that the method can significantly increase the number of GeneRIF annotations in Entrez Gene, and that it produces qualitatively more useful GeneRIFs than other methods.},
	urldate = {2018-01-26},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {LU, ZHIYONG and COHEN, K. BRETONNEL and HUNTER, LAWRENCE},
	year = {2006},
	pmid = {17094227},
	pmcid = {PMC2652876},
	pages = {52--63},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/UVNHIR68/LU et al. - 2006 - FINDING GENERIFS VIA GENE ONTOLOGY ANNOTATIONS.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3PMYKS6K/LU et al. - 2006 - FINDING GENERIFS VIA GENE ONTOLOGY ANNOTATIONS.pdf:application/pdf}
}

@article{kano_u-compare:_2009,
	title = {U-{Compare}: share and compare text mining tools with {UIMA}},
	volume = {25},
	issn = {1367-4803},
	shorttitle = {U-{Compare}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2712335/},
	doi = {10.1093/bioinformatics/btp289},
	abstract = {Summary: Due to the increasing number of text mining resources (tools and corpora) available to biologists, interoperability issues between these resources are becoming significant obstacles to using them effectively. UIMA, the Unstructured Information Management Architecture, is an open framework designed to aid in the construction of more interoperable tools. U-Compare is built on top of the UIMA framework, and provides both a concrete framework for out-of-the-box text mining and a sophisticated evaluation platform allowing users to run specific tools on any target text, generating both detailed statistics and instance-based visualizations of outputs. U-Compare is a joint project, providing the world's largest, and still growing, collection of UIMA-compatible resources. These resources, originally developed by different groups for a variety of domains, include many famous tools and corpora. U-Compare can be launched straight from the web, without needing to be manually installed. All U-Compare components are provided ready-to-use and can be combined easily via a drag-and-drop interface without any programming. External UIMA components can also simply be mixed with U-Compare components, without distinguishing between locally and remotely deployed resources., Availability: http://u-compare.org/, Contact: kano@is.s.u-tokyo.ac.jp},
	number = {15},
	urldate = {2018-01-26},
	journal = {Bioinformatics},
	author = {Kano, Yoshinobu and Baumgartner, William A. and McCrohon, Luke and Ananiadou, Sophia and Cohen, K. Bretonnel and Hunter, Lawrence and Tsujii, Jun'ichi},
	month = aug,
	year = {2009},
	pmid = {19414535},
	pmcid = {PMC2712335},
	keywords = {reproducibility},
	pages = {1997--1998},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/M3WTFDP3/Kano et al. - 2009 - U-Compare share and compare text mining tools wit.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/K5URD747/Kano et al. - 2009 - U-Compare share and compare text mining tools wit.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RVZLLFXL/Kano et al. - 2009 - U-Compare share and compare text mining tools wit.pdf:application/pdf}
}

@article{verspoor_exploring_2010,
	title = {Exploring species-based strategies for gene normalization},
	volume = {7},
	issn = {1545-5963},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2929766/},
	doi = {10.1109/TCBB.2010.48},
	abstract = {We introduce a system developed for the BioCreativeII.5 community evaluation of information extraction of proteins and protein interactions. The paper focuses primarily on the gene normalization task of recognizing protein mentions in text and mapping them to the appropriate database identifiers based on contextual clues. We outline a “fuzzy” dictionary lookup approach to protein mention detection that matches regularized text to similarly-regularized dictionary entries. We describe several different strategies for gene normalization that focus on species or organism mentions in the text, both globally throughout the document and locally in the immediate vicinity of a protein mention, and present the results of experimentation with a series of system variations that explore the effectiveness of the various normalization strategies, as well as the role of external knowledge sources. While our system was neither the best nor the worst performing system in the evaluation, the gene normalization strategies show promise and the system affords the opportunity to explore some of the variables affecting performance on the BCII.5 tasks.},
	number = {3},
	urldate = {2018-01-26},
	journal = {IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM},
	author = {Verspoor, Karin and Roeder, Christophe and Johnson, Helen L. and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2010},
	pmid = {20671318},
	pmcid = {PMC2929766},
	keywords = {female first or senior},
	pages = {462--471},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KGB7NBE8/Verspoor et al. - 2010 - Exploring species-based strategies for gene normal.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TAI5UC92/Verspoor et al. - 2010 - Exploring species-based strategies for gene normal.pdf:application/pdf}
}

@article{cohen_integrating_2010,
	title = {Integrating text mining into high-throughput assay analysis},
	volume = {11},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2956390/},
	doi = {10.1186/1471-2105-11-S5-O3},
	number = {Suppl 5},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Cohen, K Bretonnel},
	month = oct,
	year = {2010},
	pmid = {null},
	pmcid = {PMC2956390},
	pages = {O3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/2WBD37L2/Cohen - 2010 - Integrating text mining into high-throughput assay.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MF46GJ3J/Cohen - 2010 - Integrating text mining into high-throughput assay.pdf:application/pdf}
}

@article{cohen_structural_2010,
	title = {The structural and content aspects of abstracts versus bodies of full text journal articles are different},
	volume = {11},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3098079/},
	doi = {10.1186/1471-2105-11-492},
	abstract = {Background
An increase in work on the full text of journal articles and the growth of PubMedCentral have the opportunity to create a major paradigm shift in how biomedical text mining is done. However, until now there has been no comprehensive characterization of how the bodies of full text journal articles differ from the abstracts that until now have been the subject of most biomedical text mining research.

Results
We examined the structural and linguistic aspects of abstracts and bodies of full text articles, the performance of text mining tools on both, and the distribution of a variety of semantic classes of named entities between them. We found marked structural differences, with longer sentences in the article bodies and much heavier use of parenthesized material in the bodies than in the abstracts. We found content differences with respect to linguistic features. Three out of four of the linguistic features that we examined were statistically significantly differently distributed between the two genres. We also found content differences with respect to the distribution of semantic features. There were significantly different densities per thousand words for three out of four semantic classes, and clear differences in the extent to which they appeared in the two genres. With respect to the performance of text mining tools, we found that a mutation finder performed equally well in both genres, but that a wide variety of gene mention systems performed much worse on article bodies than they did on abstracts. POS tagging was also more accurate in abstracts than in article bodies.

Conclusions
Aspects of structure and content differ markedly between article abstracts and article bodies. A number of these differences may pose problems as the text mining field moves more into the area of processing full-text articles. However, these differences also present a number of opportunities for the extraction of data types, particularly that found in parenthesized text, that is present in article bodies but not in article abstracts.},
	urldate = {2018-01-26},
	journal = {BMC Bioinformatics},
	author = {Cohen, K Bretonnel and Johnson, Helen L and Verspoor, Karin and Roeder, Christophe and Hunter, Lawrence E},
	month = sep,
	year = {2010},
	pmid = {20920264},
	pmcid = {PMC3098079},
	pages = {492},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8AM7CIT5/Cohen et al. - 2010 - The structural and content aspects of abstracts ve.pdf:application/pdf}
}

@inproceedings{noauthor_notitle_nodate-1
}

@inproceedings{noauthor_notitle_nodate-2
}

@inproceedings{noauthor_notitle_nodate-3
}

@article{bose_delineation_1975,
	title = {Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution},
	volume = {66},
	issn = {1090-2104},
	language = {eng},
	number = {4},
	journal = {Biochemical and Biophysical Research Communications},
	author = {Bose, K. S. and Sarma, R. H.},
	month = oct,
	year = {1975},
	pmid = {2},
	pages = {1173--1179}
}

@article{yilmaz_testicular_2015,
	title = {Testicular torsion in a patient with {Cohen} syndrome},
	volume = {41},
	issn = {2149-3235},
	doi = {10.5152/tud.2015.27136},
	abstract = {Cohen syndrome is an extremely rare autosomal recessive disorder. A 12-year-old boy with Cohen syndrome applied to a primary health care center because of severe pain in the left groin and was diagnosed with epididymo-orchitis. Despite the administered the antibiotic treatment, pain increased. Therefore, the family brought the patient to the emergency department 16 h after the first diagnosis. The patient had mild mental retardation, myopia, and craniofacial dysmorphism, which are components of Cohen syndrome. There was no blood flow on the left testicle at color Doppler ultrasonography. Further, scrotal exploration was performed because of a high risk of torsion. The left testicle was torsioned, and the color was dark blue. Revascularization could not be achieved by detorsion; left orchiectomy and right testicular fixation were then conducted. In conclusion, to the best of our knowledge, this is the first reported case of testicular torsion in Cohen syndrome. If a patient with this syndrome has acute groin pain, testicular torsion should be immediately ruled out with Doppler ultrasonography. These patients may not clearly and correctly express themselves because of mild mental retardation. Moreover, detailed genitourinary, particularly testicular examination may clarify the omitted pathologies and make them well known in future in this syndrome.},
	language = {eng},
	number = {1},
	journal = {Turkish Journal of Urology},
	author = {Yılmaz, Ömer and Yeşildal, Cumhur and Malkoç, Ercan and Soydan, Hasan},
	month = mar,
	year = {2015},
	pmid = {26328200},
	pmcid = {PMC4548649},
	pages = {51--52},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/5U7SVQM4/Yılmaz et al. - 2015 - Testicular torsion in a patient with Cohen syndrom.pdf:application/pdf}
}

@article{de_la_clergerie_passage_nodate,
	title = {{PASSAGE}},
	author = {de la Clergerie, Éric and Hamon, Olivier and Mostefa, Djamel and Ayache, Christelle and Paroubek, Patrick and Vilnat, Anne}
}

@inproceedings{diaz_analysis_2015,
	title = {An analysis of biomedical tokenization: {Problems} and strategies},
	shorttitle = {An analysis of biomedical tokenization},
	booktitle = {Proceedings of the {Sixth} {International} {Workshop} on {Health} {Text} {Mining} and {Information} {Analysis}},
	author = {Díaz, Noa P. Cruz and López, Manuel Maña},
	year = {2015},
	keywords = {female first or senior, tokenization},
	pages = {40--49},
	file = {Fulltext:/Users/transfer/Zotero/storage/4CSKQR62/Díaz and López - 2015 - An analysis of biomedical tokenization Problems a.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/L8P6VBW5/Díaz and López - 2015 - An analysis of biomedical tokenization Problems a.pdf:application/pdf}
}

@inproceedings{arens_preliminary_2004,
	title = {A preliminary look into the use of named entity information for bioscience text tokenization},
	booktitle = {Proceedings of the {Student} {Research} {Workshop} at {HLT}-{NAACL} 2004},
	publisher = {Association for Computational Linguistics},
	author = {Arens, Robert},
	year = {2004},
	pages = {37--42},
	file = {Fulltext:/Users/transfer/Zotero/storage/5A9RE26Z/Arens - 2004 - A preliminary look into the use of named entity in.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/BAVCPDDA/citation.html:text/html}
}

@inproceedings{witte_fuzzy_2003,
	title = {Fuzzy coreference resolution for summarization},
	booktitle = {Proceedings of 2003 {International} {Symposium} on {Reference} {Resolution} and {Its} {Applications} to {Question} {Answering} and {Summarization} ({ARQAS})},
	author = {Witte, René and Bergler, Sabine},
	year = {2003},
	pages = {43--50},
	file = {Fulltext:/Users/transfer/Zotero/storage/VH4FP2DK/Witte and Bergler - 2003 - Fuzzy coreference resolution for summarization.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/7S8CKK2L/Witte and Bergler - 2003 - Fuzzy coreference resolution for summarization.pdf:application/pdf}
}

@article{pustejovsky_lexical_1993,
	title = {Lexical semantic techniques for corpus analysis},
	volume = {19},
	number = {2},
	journal = {Computational Linguistics},
	author = {Pustejovsky, James and Anick, Peter and Bergler, Sabine},
	year = {1993},
	keywords = {female first or senior},
	pages = {331--358},
	file = {Fulltext:/Users/transfer/Zotero/storage/CEK8RUZ5/Pustejovsky et al. - 1993 - Lexical semantic techniques for corpus analysis.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/5YFQWQNC/citation.html:text/html}
}

@article{kilicoglu_recognizing_2008,
	title = {Recognizing speculative language in biomedical research articles: a linguistically motivated perspective},
	volume = {9},
	shorttitle = {Recognizing speculative language in biomedical research articles},
	number = {11},
	journal = {BMC bioinformatics},
	author = {Kilicoglu, Halil and Bergler, Sabine},
	year = {2008},
	keywords = {female first or senior},
	pages = {S10},
	file = {Fulltext:/Users/transfer/Zotero/storage/CLKHTUTX/1471-2105-9-S11-S10.html:text/html;Snapshot:/Users/transfer/Zotero/storage/ZL87R8PS/1471-2105-9-S11-S10.html:text/html}
}

@article{bergler_evidential_1993,
	title = {Evidential analysis of reported speech.},
	author = {Bergler, Sabine},
	year = {1993},
	keywords = {female first or senior},
	file = {Snapshot:/Users/transfer/Zotero/storage/85BDJDHZ/item.html:text/html}
}

@inproceedings{anick_lexical_1991,
	title = {Lexical structures for linguistic inference},
	booktitle = {Workshop of {SIGLEX} ({Special} {Interest} {Group} within {ACL} on the {Lexicon})},
	publisher = {Springer},
	author = {Anick, Peter and Bergler, Sabine},
	year = {1991},
	keywords = {female first or senior},
	pages = {121--135},
	file = {Fulltext:/Users/transfer/Zotero/storage/6E3WSR24/Anick and Bergler - 1991 - Lexical structures for linguistic inference.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SYUVSDVV/3-540-55801-2_31.html:text/html}
}

@inproceedings{andreevskaia_can_2005,
	title = {Can shallow predicate argument structures determine entailment},
	booktitle = {Proceedings of the {First} {PASCAL} {Challenges} {Workshop} on {Recognising} {Textual} {Entailment}, {Southampton}, {UK}},
	author = {Andreevskaia, Alina and Li, Zhuoyan and Bergler, Sabine},
	year = {2005},
	keywords = {female first or senior},
	pages = {45--48},
	file = {Fulltext:/Users/transfer/Zotero/storage/3NMBU8Q3/Andreevskaia et al. - 2005 - Can shallow predicate argument structures determin.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/BR2JNVFC/Andreevskaia et al. - 2005 - Can shallow predicate argument structures determin.pdf:application/pdf}
}

@inproceedings{bergler_semantics_1991,
	title = {The semantics of collocational patterns for reporting verbs},
	booktitle = {Proceedings of the fifth conference on {European} chapter of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bergler, Sabine},
	year = {1991},
	keywords = {female first or senior},
	pages = {216--221},
	file = {Fulltext:/Users/transfer/Zotero/storage/SZGYCJ8Y/Bergler - 1991 - The semantics of collocational patterns for report.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ZTVFUTBV/citation.html:text/html}
}

@book{pustejovsky_lexical_1992,
	title = {Lexical semantics and knowledge representation},
	publisher = {Springer},
	author = {Pustejovsky, James and Bergler, Sabine},
	year = {1992},
	keywords = {female first or senior},
	file = {Fulltext:/Users/transfer/Zotero/storage/WMQXW7NI/Pustejovsky and Bergler - 1992 - Lexical semantics and knowledge representation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ENBLHCPG/Pustejovsky and Bergler - 1992 - Lexical semantics and knowledge representation.pdf:application/pdf}
}

@inproceedings{pustejovsky_acquisition_1987,
	title = {The {Acquisition} of {Conceptual} {Structure} for the {Lexicon}.},
	booktitle = {{AAAI}},
	author = {Pustejovsky, James and Bergler, Sabine},
	year = {1987},
	keywords = {female first or senior},
	pages = {566--570},
	file = {Snapshot:/Users/transfer/Zotero/storage/J8XA6WSN/aaai87-101.html:text/html}
}

@article{bergler_lexical_1995,
	title = {From lexical semantics to text analysis},
	journal = {Computational Lexical Semantics, Cambridge University Press, New York, NY},
	author = {Bergler, Sabine},
	year = {1995},
	keywords = {female first or senior}
}

@article{kilicoglu_effective_2011,
	title = {Effective {Bio}-event extraction using trigger words and syntactic dependencies},
	volume = {27},
	number = {4},
	journal = {Computational Intelligence},
	author = {Kilicoglu, Halil and Bergler, Sabine},
	year = {2011},
	keywords = {female first or senior},
	pages = {583--609},
	file = {Fulltext:/Users/transfer/Zotero/storage/4FQ7BBY8/Kilicoglu and Bergler - 2011 - Effective Bio-event extraction using trigger words.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/UI9JIRVW/Kilicoglu and Bergler - 2011 - Effective Bio-event extraction using trigger words:}
}

@inproceedings{schuman_postnominal_2006,
	title = {Postnominal prepositional phrase attachment in proteomics},
	booktitle = {Proceedings of the {Workshop} on {Linking} {Natural} {Language} {Processing} and {Biology}: {Towards} {Deeper} {Biological} {Literature} {Analysis}},
	publisher = {Association for Computational Linguistics},
	author = {Schuman, Jonathan and Bergler, Sabine},
	year = {2006},
	keywords = {female first or senior},
	pages = {82--89},
	file = {Fulltext:/Users/transfer/Zotero/storage/JCT2DJ83/Schuman and Bergler - 2006 - Postnominal prepositional phrase attachment in pro.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CE79GX83/citation.html:text/html}
}

@inproceedings{witte_erss_2005,
	title = {{ERSS} 2005: {Coreference}-based summarization reloaded},
	shorttitle = {{ERSS} 2005},
	booktitle = {{DUC} 2005 {Document} {Understanding} {Workshop}, {Canada}},
	author = {Witte, René and Krestel, Ralf and Bergler, Sabine},
	year = {2005},
	file = {Fulltext:/Users/transfer/Zotero/storage/KK4KE4N7/Witte et al. - 2005 - ERSS 2005 Coreference-based summarization reloade.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/5DZAL5ZA/Witte et al. - 2005 - ERSS 2005 Coreference-based summarization reloade.pdf:application/pdf}
}

@inproceedings{bergler_towards_1997,
	title = {Towards reliable partial anaphora resolution},
	booktitle = {Proceedings of a {Workshop} on {Operational} {Factors} in {Practical}, {Robust} {Anaphora} {Resolution} for {Unrestricted} {Texts}},
	publisher = {Association for Computational Linguistics},
	author = {Bergler, Sabine},
	year = {1997},
	keywords = {female first or senior},
	pages = {62--66},
	file = {Fulltext:/Users/transfer/Zotero/storage/83PG6Q82/Bergler - 1997 - Towards reliable partial anaphora resolution.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/WUKJC7MG/citation.html:text/html}
}

@article{krestel_predicate-argument_2010,
	title = {Predicate-argument extractor (pax)},
	journal = {New Challenges For NLP Frameworks Programme},
	author = {Krestel, Ralf and Witte, René and Bergler, Sabine},
	year = {2010},
	keywords = {female first or senior},
	pages = {51},
	file = {Fulltext:/Users/transfer/Zotero/storage/4PWDXAJP/Krestel et al. - 2010 - Predicate-argument extractor (pax).pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GXXFRQFL/Krestel et al. - 2010 - Predicate-argument extractor (pax).pdf:application/pdf}
}

@inproceedings{kilicoglu_high-precision_2010,
	title = {A high-precision approach to detecting hedges and their scopes},
	booktitle = {Proceedings of the fourteenth conference on computational natural language learning–{Shared} task},
	author = {Kilicoglu, Halil and Bergler, Sabine},
	year = {2010},
	keywords = {female first or senior},
	pages = {70--77},
	file = {Fulltext:/Users/transfer/Zotero/storage/R6NWVXQV/Kilicoglu and Bergler - 2010 - A high-precision approach to detecting hedges and .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/FLMZ6IPG/Kilicoglu and Bergler - 2010 - A high-precision approach to detecting hedges and .pdf:application/pdf}
}

@inproceedings{rosenberg_uconcordia:_2012,
	title = {Uconcordia: {Clac} negation focus detection at* sem 2012},
	shorttitle = {Uconcordia},
	booktitle = {Proceedings of the {First} {Joint} {Conference} on {Lexical} and {Computational} {Semantics}-{Volume} 1: {Proceedings} of the main conference and the shared task, and {Volume} 2: {Proceedings} of the {Sixth} {International} {Workshop} on {Semantic} {Evaluation}},
	publisher = {Association for Computational Linguistics},
	author = {Rosenberg, Sabine and Bergler, Sabine},
	year = {2012},
	keywords = {female first or senior},
	pages = {294--300},
	file = {Fulltext:/Users/transfer/Zotero/storage/UNZT6QFH/Rosenberg and Bergler - 2012 - Uconcordia Clac negation focus detection at sem .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/T3TBJN54/citation.html:text/html}
}

@inproceedings{bergler_semantic_1993,
	title = {Semantic dimensions in the field of reporting verbs},
	booktitle = {Proceedings of the ninth annual conference of the {University} of {Waterloo} {Centre} for the {New} {Oxford} {English} {Dictionary} and {Text} {Research}},
	author = {Bergler, Sabine},
	year = {1993},
	keywords = {female first or senior},
	pages = {1--11},
	file = {Fulltext:/Users/transfer/Zotero/storage/WPZ2XBEI/Bergler - 1993 - Semantic dimensions in the field of reporting verb.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/RG59T232/Bergler - 1993 - Semantic dimensions in the field of reporting verb.pdf:application/pdf}
}

@inproceedings{kilicoglu_biological_2012,
	title = {Biological event composition},
	volume = {13},
	booktitle = {{BMC} bioinformatics},
	publisher = {BioMed Central},
	author = {Kilicoglu, Halil and Bergler, Sabine},
	year = {2012},
	pages = {S7},
	file = {Fulltext:/Users/transfer/Zotero/storage/BWYWI7Z6/1471-2105-13-S11-S7.html:text/html;Snapshot:/Users/transfer/Zotero/storage/IFERZ548/1471-2105-13-S11-S7.html:text/html}
}

@inproceedings{bergler_coreference_1996,
	title = {Coreference patterns in the wall street journal},
	booktitle = {Synchronic corpus linguistics. {Papers} from the sixteenth {International} {Conference} on {English} {Language} {Research} on {Computerized} {Corpora} (1CAME 16). {Rodopi}},
	publisher = {Citeseer},
	author = {Bergler, Sabine and Knoll, Sonja},
	year = {1996},
	keywords = {female first or senior},
	file = {Snapshot:/Users/transfer/Zotero/storage/J7LAEZ7B/summary.html:text/html}
}

@inproceedings{krestel_believe_2009,
	title = {Believe {It} or {Not}: {Solving} the {TAC} 2009 {Textual} {Entailment} {Tasks} through an {Artificial} {Believer} {System}.},
	shorttitle = {Believe {It} or {Not}},
	booktitle = {{TAC}},
	author = {Krestel, Ralf and Witte, René and Bergler, Sabine},
	year = {2009},
	keywords = {female first or senior},
	file = {Fulltext:/Users/transfer/Zotero/storage/V5RVJWZ8/Krestel et al. - 2009 - Believe It or Not Solving the TAC 2009 Textual En.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HEY79YJY/Krestel et al. - 2009 - Believe It or Not Solving the TAC 2009 Textual En.pdf:application/pdf}
}

@article{rosenberg_clac_2012,
	title = {{CLaC} {Labs}: {Processing} modality and negation},
	shorttitle = {{CLaC} {Labs}},
	journal = {Working Notes for QA4MRE Pilot Task at CLEF},
	author = {Rosenberg, Sabine and Kilicoglu, Halil and Bergler, Sabine},
	year = {2012},
	keywords = {female first or senior}
}

@incollection{bergler_metonymy_2013,
	title = {Metonymy and metaphor: boundary cases and the role of a generative lexicon},
	shorttitle = {Metonymy and metaphor},
	booktitle = {Advances in generative lexicon theory},
	publisher = {Springer},
	author = {Bergler, Sabine},
	year = {2013},
	keywords = {female first or senior},
	pages = {127--145},
	file = {Fulltext:/Users/transfer/Zotero/storage/FXLE8WCR/Bergler - 2013 - Metonymy and metaphor boundary cases and the role.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XUG9ZXFP/978-94-007-5189-7_6.html:text/html}
}

@book{alagar_incompleteness_2012,
	title = {Incompleteness and {Uncertainty} in {Information} {Systems}: {Proceedings} of the {SOFTEKS} {Workshop} on {Incompleteness} and {Uncertainty} in {Information} {Systems}, {Concordia} {University}, {Montreal}, {Canada}, 8–9 {October} 1993},
	shorttitle = {Incompleteness and {Uncertainty} in {Information} {Systems}},
	publisher = {Springer Science \& Business Media},
	author = {Alagar, Vangalur S. and Bergler, Sabine and Dong, Fang Qing},
	year = {2012},
	file = {Snapshot:/Users/transfer/Zotero/storage/USGPDLNK/books.html:text/html}
}

@inproceedings{andreevskaia_semantic_2006,
	title = {Semantic {Tagging} at the {Sense} {Level}.},
	booktitle = {{AAAI}},
	author = {Andreevskaia, Alina and Bergler, Sabine},
	year = {2006},
	keywords = {female first or senior}
}

@inproceedings{bergler_bioki:_2006,
	title = {{BioKI}: {Enzymes}: an adaptable system to locate low-frequency information in full-text proteomics articles},
	shorttitle = {{BioKI}},
	booktitle = {Proceedings of the {Workshop} on {Linking} {Natural} {Language} {Processing} and {Biology}: {Towards} {Deeper} {Biological} {Literature} {Analysis}},
	publisher = {Association for Computational Linguistics},
	author = {Bergler, Sabine and Schuman, Jonathan and Dubuc, Julien and Lebedev, Alexandr},
	year = {2006},
	keywords = {female first or senior},
	pages = {91--92},
	file = {Fulltext:/Users/transfer/Zotero/storage/LCLN6GIH/Bergler et al. - 2006 - BioKI Enzymes an adaptable system to locate low-.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GMUML5ET/citation.html:text/html}
}

@inproceedings{lamjiri_indexing_2007,
	title = {Indexing low frequency information for question answering},
	booktitle = {Large {Scale} {Semantic} {Access} to {Content} ({Text}, {Image}, {Video}, and {Sound})},
	publisher = {LE CENTRE DE HAUTES ETUDES INTERNATIONALES D'INFORMATIQUE DOCUMENTAIRE},
	author = {Lamjiri, Abolfazl Keighobadi and Dubuc, Julien and Kosseim, Leila and Bergler, Sabine},
	year = {2007},
	keywords = {female first or senior},
	pages = {659--664},
	file = {Fulltext:/Users/transfer/Zotero/storage/CIQGNWL8/Lamjiri et al. - 2007 - Indexing low frequency information for question an.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3FWGZ8PS/citation.html:text/html}
}

@inproceedings{dubuc_structure-aware_2010,
	title = {Structure-aware topic clustering in social media},
	booktitle = {Proceedings of the 10th {ACM} symposium on {Document} engineering},
	publisher = {ACM},
	author = {Dubuc, Julien and Bergler, Sabine},
	year = {2010},
	keywords = {female first or senior},
	pages = {247--250},
	file = {Snapshot:/Users/transfer/Zotero/storage/CVAHYF2Z/citation.html:text/html}
}

@inproceedings{powell_monitoring_2016,
	title = {Monitoring {Discussion} of {Vaccine} {Adverse} {Events} in the {Media}: {Opportunities} from the {Vaccine} {Sentimeter}.},
	shorttitle = {Monitoring {Discussion} of {Vaccine} {Adverse} {Events} in the {Media}},
	booktitle = {{AAAI} {Workshop}: {WWW} and {Population} {Health} {Intelligence}},
	author = {Powell, Guido and Zinszer, Kate and Dhananjay, Jahnavi and Bahk, Chi and Madoff, Lawrence C. and Brownstein, John S. and Bergler, Sabine and Buckeridge, David L.},
	year = {2016},
	file = {Snapshot:/Users/transfer/Zotero/storage/3EVD2YYH/12412.html:text/html}
}

@inproceedings{ozdemir_comparative_2015,
	title = {A {Comparative} {Study} of {Different} {Sentiment} {Lexica} for {Sentiment} {Analysis} of {Tweets}},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing}},
	author = {Ozdemir, Canberk and Bergler, Sabine},
	year = {2015},
	keywords = {female first or senior},
	pages = {488--496},
	file = {Fulltext:/Users/transfer/Zotero/storage/397HWGBV/Ozdemir and Bergler - 2015 - A Comparative Study of Different Sentiment Lexica .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HGIMLE7Q/Ozdemir and Bergler - 2015 - A Comparative Study of Different Sentiment Lexica .pdf:application/pdf}
}

@inproceedings{damova_inferences_1998,
	title = {Inferences between aspectual verbs and events},
	booktitle = {Proceedings of {EESSLI}'98 {Workshop}-{Lexical} {Semantics} in {Context}},
	author = {Damova, Mariana and Bergler, Sabine},
	year = {1998},
	keywords = {female first or senior},
	file = {Fulltext:/Users/transfer/Zotero/storage/6Q6VA79T/Damova and Bergler - 1998 - Inferences between aspectual verbs and events.ps:application/postscript;Snapshot:/Users/transfer/Zotero/storage/3IWDLPJR/Damova and Bergler - 1998 - Inferences between aspectual verbs and events.ps:application/postscript}
}

@book{bergler_horst_2012,
	title = {Hörst du?-tu portes la mémoire: die literarische {Verarbeitung} von {Gedächtnis} und {Erinnerung} in ausgewählten {Werken} von {Doron} {Rabinovici} und {Cécile} {Wajsbrot}},
	shorttitle = {Hörst du?},
	publisher = {na},
	author = {Bergler, Sabine},
	year = {2012},
	keywords = {female first or senior},
	file = {Fulltext:/Users/transfer/Zotero/storage/IQLLNUUF/Bergler - 2012 - Hörst du-tu portes la mémoire die literarische V.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/A92S86XU/Bergler - 2012 - Hörst du-tu portes la mémoire die literarische V.pdf:application/pdf}
}

@article{andreevskaia_shallow_nodate,
	title = {Shallow {Semantics} for {Textual} {Entailment} {Determination}},
	author = {Andreevskaia, Alina and Li, Zhuoyan and Bergler, Sabine},
	keywords = {female first or senior}
}

@incollection{andreevskaia_partial_2006,
	title = {Partial predicate argument structure matching for entailment determination},
	booktitle = {Machine {Learning} {Challenges}. {Evaluating} {Predictive} {Uncertainty}, {Visual} {Object} {Classification}, and {Recognising} {Tectual} {Entailment}},
	publisher = {Springer},
	author = {Andreevskaia, Alina and Li, Zhuoyan and Bergler, Sabine},
	year = {2006},
	keywords = {female first or senior},
	pages = {332--343},
	file = {Snapshot:/Users/transfer/Zotero/storage/JJLY2UQN/10.html:text/html}
}

@inproceedings{schuman_role_2008,
	title = {The role of nominalizations in prepositional phrase attachment in {GENIA}},
	booktitle = {Conference of the {Canadian} {Society} for {Computational} {Studies} of {Intelligence}},
	publisher = {Springer},
	author = {Schuman, Jonathan and Bergler, Sabine},
	year = {2008},
	keywords = {female first or senior},
	pages = {271--282},
	file = {Snapshot:/Users/transfer/Zotero/storage/TNP69EL9/978-3-540-68825-9_26.html:text/html}
}

@phdthesis{bergler_horst_2012-1,
	type = {{PhD} {Thesis}},
	title = {Hörst du?-tu portes la mémoire},
	shorttitle = {Hörst du?},
	school = {uniwien},
	author = {Bergler, Sabine},
	year = {2012},
	keywords = {female first or senior},
	file = {Fulltext:/Users/transfer/Zotero/storage/BP54STU2/Bergler - 2012 - Hörst du-tu portes la mémoire.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/KTXRFPWZ/19282.html:text/html}
}

@article{zweigenbaum_apports_2008,
	title = {Apports de la linguistique dans les systèmes de recherche d'informations précises},
	volume = {13},
	number = {1},
	journal = {Revue française de linguistique appliquée},
	author = {Zweigenbaum, Pierre and Grau, Brigitte and Ligozat, Anne-Laure and Robba, Isabelle and Rosset, Sophie and Tannier, Xavier and Vilnat, Anne and Bellot, Patrice},
	year = {2008},
	keywords = {francais, France},
	pages = {41--62},
	file = {Fulltext:/Users/transfer/Zotero/storage/ACPXUCTA/article.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7NKVICI2/resume.html:text/html}
}

@article{grouin_mesures_2011,
	title = {Mesures d’évaluation pour entités nommées structurées},
	journal = {Évaluation des méthodes d’Extraction de Connaissances dans les Données, Brest, France},
	author = {Grouin, Cyril and Galibert, Olivier and Rosset, Sophie and Quintard, Ludovic and Zweigenbaum, Pierre},
	year = {2011},
	keywords = {francais, France, NER},
	file = {Fulltext:/Users/transfer/Zotero/storage/9SSQUIHG/Grouin et al. - 2011 - Mesures d’évaluation pour entités nommées structur.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/R8EKSWZX/Grouin et al. - 2011 - Mesures d’évaluation pour entités nommées structur.pdf:application/pdf}
}

@book{nouvel_les_2015,
	title = {Les entités nommées pour le traitement automatique des langues},
	number = {EPFL-BOOK-221390},
	publisher = {ISTE editions},
	author = {Nouvel, Damien and Ehrmann, Maud and Rosset, Sophie},
	year = {2015},
	keywords = {female first or senior, francais, France, NER},
	file = {Snapshot:/Users/transfer/Zotero/storage/IXCRAE87/221390.pdf:application/pdf}
}

@article{grouin_acces_2011,
	title = {Accès au contenu sémantique en langue de spécialité: extraction des prescriptions et concepts médicaux},
	shorttitle = {Accès au contenu sémantique en langue de spécialité},
	journal = {Actes des conférences TALN 2011 et Recital 2011},
	author = {Grouin, Cyril and Deléger, Louise and Cartoni, Bruno and Rosset, Sophie and Zweigenbaum, Pierre},
	year = {2011},
	keywords = {francais, France, NER},
	pages = {109},
	file = {Fulltext:/Users/transfer/Zotero/storage/SUAEH7VP/Grouin et al. - 2011 - Accès au contenu sémantique en langue de spécialit.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/974AQ68T/Grouin et al. - 2011 - Accès au contenu sémantique en langue de spécialit.pdf:application/pdf}
}

@inproceedings{dutrey_quel_2012,
	title = {Quel est l'apport de la détection d'entités nommées pour l'extraction d'information en domaine restreint?({What} is the contribution of named entities detection for information extraction in restric-ted domain?)[in {French}]},
	shorttitle = {Quel est l'apport de la détection d'entités nommées pour l'extraction d'information en domaine restreint?},
	booktitle = {Proceedings of the {Joint} {Conference} {JEP}-{TALN}-{RECITAL} 2012, volume 2: {TALN}},
	author = {Dutrey, Camille and Clavel, Chloé and Rosset, Sophie and Vasilescu, Ioana and Adda-Decker, Martine},
	year = {2012},
	keywords = {ethics, francais, France, NER},
	pages = {359--366},
	file = {Fulltext:/Users/transfer/Zotero/storage/9CAEJZZJ/Dutrey et al. - 2012 - Quel est l'apport de la détection d'entités nommée.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/4GK6FE3E/Dutrey et al. - 2012 - Quel est l'apport de la détection d'entités nommée.pdf:application/pdf}
}

@inproceedings{el_maarouf_extraction_2011,
	title = {Extraction de patrons sémantiques appliquée à la classification d'{Entités} {Nommées}},
	booktitle = {{TALN}'2011},
	author = {El Maarouf, Ismaïl and Villaneau, Jeanne and Rosset, Sophie},
	year = {2011},
	keywords = {francais, France, NER},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZYBDGFQ2/El Maarouf et al. - 2011 - Extraction de patrons sémantiques appliquée à la c.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GGVY2768/hal-01214224.html:text/html}
}

@article{bernard_etude_2010,
	title = {Etude des caractéristiques des collections de documents pour les évaluations de systeme de questions-réponses},
	journal = {Mons, Belgique},
	author = {Bernard, Guillaume and Adda-Decker, Martine and Rosset, Sophie},
	year = {2010},
	keywords = {female first or senior},
	pages = {305},
	file = {Fulltext:/Users/transfer/Zotero/storage/PUW73256/Bernard et al. - 2010 - Etude des caractéristiques des collections de docu.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/EKYJLR79/Bernard et al. - 2010 - Etude des caractéristiques des collections de docu.pdf:application/pdf}
}

@article{zweigenbaum_extraction_nodate,
	title = {Extraction des relations temporelles entre concepts médicaux et expressions temporelles: vers une meilleure représentation du séjour hospitalier des patients},
	shorttitle = {Extraction des relations temporelles entre concepts médicaux et expressions temporelles},
	author = {ZWEIGENBAUM, Pierre and GRABAR, Natalia and HAMON, Thierry and ROSSET, Sophie and TANNIER, Xavier and GROUIN, Cyril},
	keywords = {francais, France},
	file = {Fulltext:/Users/transfer/Zotero/storage/NGGNQ54X/ZWEIGENBAUM et al. - Extraction des relations temporelles entre concept.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/TK4TNLG9/ZWEIGENBAUM et al. - Extraction des relations temporelles entre concept.pdf:application/pdf}
}

@inproceedings{zweigenbaum_resolution_2012,
	title = {Résolution des coréférences dans des comptes rendus cliniques. {Une} expérimentation issue du défi i2b2/{VA} 2011},
	booktitle = {{RFIA} 2012 ({Reconnaissance} des {Formes} et {Intelligence} {Artificielle})},
	author = {Zweigenbaum, Pierre and Wisniewski, Guillaume and Marco, Dinarelli and Grouin, Cyril and Rosset, Sophie},
	year = {2012},
	keywords = {francais, France},
	pages = {978--2},
	file = {Fulltext:/Users/transfer/Zotero/storage/JXH7WSMF/Zweigenbaum et al. - 2012 - Résolution des coréférences dans des comptes rendu.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/WK35JYCA/hal-00656514.html:text/html}
}

@inproceedings{grouin_identification_nodate,
	title = {Identification de facteurs de risque pour des patients diabétiques à partir de comptes-rendus cliniques par des approches hybrides},
	booktitle = {Actes de la 22e conférence sur le {Traitement} {Automatique} des {Langues} {Naturelles}},
	publisher = {Association pour le Traitement Automatique des Langues},
	author = {Grouin, Cyril and Moriceau, Véronique and Rosset, Sophie and Zweigenbaum, Pierre},
	keywords = {francais, France, NER},
	pages = {25--36},
	file = {Fulltext:/Users/transfer/Zotero/storage/C4JAUXLX/Grouin et al. - Identification de facteurs de risque pour des pati.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ASI53DL3/Grouin et al. - Identification de facteurs de risque pour des pati.pdf:application/pdf}
}

@article{paroubek_principles_2007,
	title = {Principles of evaluation in natural language processing},
	volume = {48},
	number = {1},
	journal = {Traitement Automatique des Langues},
	author = {Paroubek, Patrick and Chaudiron, Stéphane and Hirschman, Lynette},
	year = {2007},
	keywords = {reproducibility, female first or senior, francais, France, review, evaluation},
	pages = {7--31},
	file = {Fulltext:/Users/transfer/Zotero/storage/8SFDA32R/Paroubek et al. - 2007 - Principles of evaluation in natural language proce.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/Z9IXNU78/hal-00502700.html:text/html}
}

@article{clark_automatic_2017,
	title = {Automatic classification of {RDoC} positive valence severity with a neural network},
	volume = {75S},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2017.07.005},
	abstract = {OBJECTIVE: Our objective was to develop a machine learning-based system to determine the severity of Positive Valance symptoms for a patient, based on information included in their initial psychiatric evaluation. Severity was rated on an ordinal scale of 0-3 as follows: 0 (absent=no symptoms), 1 (mild=modest significance), 2 (moderate=requires treatment), 3 (severe=causes substantial impairment) by experts.
MATERIALS AND METHODS: We treated the task of assigning Positive Valence severity as a text classification problem. During development, we experimented with regularized multinomial logistic regression classifiers, gradient boosted trees, and feedforward, fully-connected neural networks. We found both regularization and feature selection via mutual information to be very important in preventing models from overfitting the data. Our best configuration was a neural network with three fully connected hidden layers with rectified linear unit activations.
RESULTS: Our best performing system achieved a score of 77.86\%. The evaluation metric is an inverse normalization of the Mean Absolute Error presented as a percentage number between 0 and 100, where 100 means the highest performance. Error analysis showed that 90\% of the system errors involved neighboring severity categories.
CONCLUSION: Machine learning text classification techniques with feature selection can be trained to recognize broad differences in Positive Valence symptom severity with a modest amount of training data (in this case 600 documents, 167 of which were unannotated). An increase in the amount of annotated data can increase accuracy of symptom severity classification by several percentage points. Additional features and/or a larger training corpus may further improve accuracy.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Clark, Cheryl and Wellner, Ben and Davis, Rachel and Aberdeen, John and Hirschman, Lynette},
	month = nov,
	year = {2017},
	pmid = {28694118},
	pmcid = {PMC5705444},
	keywords = {female first or senior},
	pages = {S120--S128}
}

@misc{noauthor_automatic_nodate,
	title = {Automatic classification of {RDoC} positive valence severity with a neural network - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046417301612?via%3Dihub},
	urldate = {2018-02-16},
	file = {Automatic classification of RDoC positive valence severity with a neural network - ScienceDirect:/Users/transfer/Zotero/storage/96LVCDJK/S1532046417301612.html:text/html}
}

@article{hirschman_text_2012,
	title = {Text mining for the biocuration workflow},
	volume = {2012},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3328793/},
	doi = {10.1093/database/bas020},
	abstract = {Molecular biology has become heavily dependent on biological knowledge encoded in expert curated biological databases. As the volume of biological literature increases, biocurators need help in keeping up with the literature; (semi-) automated aids for biocuration would seem to be an ideal application for natural language processing and text mining. However, to date, there have been few documented successes for improving biocuration throughput using text mining. Our initial investigations took place for the workshop on ‘Text Mining for the BioCuration Workflow’ at the third International Biocuration Conference (Berlin, 2009). We interviewed biocurators to obtain workflows from eight biological databases. This initial study revealed high-level commonalities, including (i) selection of documents for curation; (ii) indexing of documents with biologically relevant entities (e.g. genes); and (iii) detailed curation of specific relations (e.g. interactions); however, the detailed workflows also showed many variabilities. Following the workshop, we conducted a survey of biocurators. The survey identified biocurator priorities, including the handling of full text indexed with biological entities and support for the identification and prioritization of documents for curation. It also indicated that two-thirds of the biocuration teams had experimented with text mining and almost half were using text mining at that time. Analysis of our interviews and survey provide a set of requirements for the integration of text mining into the biocuration workflow. These can guide the identification of common needs across curated databases and encourage joint experimentation involving biocurators, text mining developers and the larger biomedical research community.},
	urldate = {2018-02-16},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Hirschman, Lynette and Burns, Gully A. P. C and Krallinger, Martin and Arighi, Cecilia and Cohen, K. Bretonnel and Valencia, Alfonso and Wu, Cathy H. and Chatr-Aryamontri, Andrew and Dowell, Karen G. and Huala, Eva and Lourenço, Anália and Nash, Robert and Veuthey, Anne-Lise and Wiegers, Thomas and Winter, Andrew G.},
	month = apr,
	year = {2012},
	pmid = {22513129},
	pmcid = {PMC3328793},
	keywords = {female first or senior, curation},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/96MNEHCR/Hirschman et al. - 2012 - Text mining for the biocuration workflow.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VGAUD8VD/Hirschman et al. - 2012 - Text mining for the biocuration workflow.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/GGL2XV36/Hirschman et al. - 2012 - Text mining for the biocuration workflow.pdf:application/pdf}
}

@article{colosimo_nephele:_2011,
	title = {Nephele: genotyping via complete composition vectors and {MapReduce}},
	volume = {6},
	issn = {1751-0473},
	shorttitle = {Nephele},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3182884/},
	doi = {10.1186/1751-0473-6-13},
	abstract = {Background
Current sequencing technology makes it practical to sequence many samples of a given organism, raising new challenges for the processing and interpretation of large genomics data sets with associated metadata. Traditional computational phylogenetic methods are ideal for studying the evolution of gene/protein families and using those to infer the evolution of an organism, but are less than ideal for the study of the whole organism mainly due to the presence of insertions/deletions/rearrangements. These methods provide the researcher with the ability to group a set of samples into distinct genotypic groups based on sequence similarity, which can then be associated with metadata, such as host information, pathogenicity, and time or location of occurrence. Genotyping is critical to understanding, at a genomic level, the origin and spread of infectious diseases. Increasingly, genotyping is coming into use for disease surveillance activities, as well as for microbial forensics. The classic genotyping approach has been based on phylogenetic analysis, starting with a multiple sequence alignment. Genotypes are then established by expert examination of phylogenetic trees. However, these traditional single-processor methods are suboptimal for rapidly growing sequence datasets being generated by next-generation DNA sequencing machines, because they increase in computational complexity quickly with the number of sequences.

Results
Nephele is a suite of tools that uses the complete composition vector algorithm to represent each sequence in the dataset as a vector derived from its constituent k-mers by passing the need for multiple sequence alignment, and affinity propagation clustering to group the sequences into genotypes based on a distance measure over the vectors. Our methods produce results that correlate well with expert-defined clades or genotypes, at a fraction of the computational cost of traditional phylogenetic methods run on traditional hardware. Nephele can use the open-source Hadoop implementation of MapReduce to parallelize execution using multiple compute nodes. We were able to generate a neighbour-joined tree of over 10,000 16S samples in less than 2 hours.

Conclusions
We conclude that using Nephele can substantially decrease the processing time required for generating genotype trees of tens to hundreds of organisms at genome scale sequence coverage.},
	urldate = {2018-02-16},
	journal = {Source Code for Biology and Medicine},
	author = {Colosimo, Marc E and Peterson, Matthew W and Mardis, Scott and Hirschman, Lynette},
	month = aug,
	year = {2011},
	pmid = {21851626},
	pmcid = {PMC3182884},
	keywords = {female first or senior},
	pages = {13},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/I9WIQUD3/Colosimo et al. - 2011 - Nephele genotyping via complete composition vecto.pdf:application/pdf}
}

@article{hirschman_habitat-lite:_2008,
	title = {Habitat-{Lite}: {A} {GSC} {Case} {Study} {Based} on {Free} {Text} {Terms} for {Environmental} {Metadata}},
	volume = {12},
	shorttitle = {Habitat-{Lite}},
	url = {http://online.liebertpub.com/doi/abs/10.1089/omi.2008.0016},
	doi = {10.1089/omi.2008.0016},
	abstract = {There is an urgent need to capture metadata on the rapidly growing number of genomic, metagenomic and related sequences, such as 16S ribosomal genes. This need is a major focus within the Genomic Standards Consortium (GSC), and Habitat is a key metadata descriptor in the proposed “Minimum Information about a Genome Sequence” (MIGS) specification. The goal of the work described here is to provide a light-weight, easy-to-use (small) set of terms (“Habitat-Lite”) that captures high-level information about habitat while preserving a mapping to the recently launched Environment Ontology (EnvO). Our motivation for building Habitat-Lite is to meet the needs of multiple users, such as annotators curating these data, database providers hosting the data, and biologists and bioinformaticians alike who need to search and employ such data in comparative analyses. Here, we report a case study based on semiautomated identification of terms from GenBank and GOLD. We estimate that the terms in the initial version of Habitat-Lite would provide useful labels for over 60\% of the kinds of information found in the GenBank isolation\_source field, and around 85\% of the terms in the GOLD habitat field. We present a revised version of Habitat-Lite defined within the EnvO Environmental Ontology through a new category, EnvO-Lite-GSC. We invite the community's feedback on its further development to provide a minimum list of terms to capture high-level habitat information and to provide classification bins needed for future studies.},
	number = {2},
	urldate = {2018-02-16},
	journal = {OMICS: A Journal of Integrative Biology},
	author = {Hirschman, Lynette and Clark, Cheryl and Cohen, K. Bretonnel and Mardis, Scott and Luciano, Joanne and Kottmann, Renzo and Cole, James and Markowitz, Victor and Kyrpides, Nikos and Morrison, Norman and Schriml, Lynn M. and Field, Dawn},
	month = apr,
	year = {2008},
	keywords = {female first or senior, ontology},
	pages = {129--136},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/VX5W25UP/Hirschman et al. - 2008 - Habitat-Lite A GSC Case Study Based on Free Text .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ED32CDSH/omi.2008.html:text/html}
}

@article{wellner_rapidly_2007,
	title = {Rapidly {Retargetable} {Approaches} to {De}-identification in {Medical} {Records}},
	volume = {14},
	issn = {1067-5027},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1975794/},
	doi = {10.1197/jamia.M2435},
	abstract = {Objective
This paper describes a successful approach to de-identification that was developed to participate in a recent AMIA-sponsored challenge evaluation.

Method
Our approach focused on rapid adaptation of existing toolkits for named entity recognition using two existing toolkits, Carafe and LingPipe.

Results
The “out of the box” Carafe system achieved a very good score (phrase F-measure of 0.9664) with only four hours of work to adapt it to the de-identification task. With further tuning, we were able to reduce the token-level error term by over 36\% through task-specific feature engineering and the introduction of a lexicon, achieving a phrase F-measure of 0.9736.

Conclusions
We were able to achieve good performance on the de-identification task by the rapid retargeting of existing toolkits. For the Carafe system, we developed a method for tuning the balance of recall vs. precision, as well as a confidence score that correlated well with the measured F-score.},
	number = {5},
	urldate = {2018-02-16},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Wellner, Ben and Huyck, Matt and Mardis, Scott and Aberdeen, John and Morgan, Alex and Peshkin, Leonid and Yeh, Alex and Hitzeman, Janet and Hirschman, Lynette},
	year = {2007},
	pmid = {17600096},
	pmcid = {PMC1975794},
	keywords = {reproducibility, female first or senior, NER},
	pages = {564--573},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RC9JQD6X/Wellner et al. - 2007 - Rapidly Retargetable Approaches to De-identificati.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/LT6J47JB/Wellner et al. - 2007 - Rapidly Retargetable Approaches to De-identificati.pdf:application/pdf}
}

@article{hirschman_rutabaga_2002,
	title = {Rutabaga by any other name: extracting biological names},
	volume = {35},
	issn = {1532-0464},
	shorttitle = {Rutabaga by any other name},
	abstract = {As the pace of biological research accelerates, biologists are becoming increasingly reliant on computers to manage the information explosion. Biologists communicate their research findings by relying on precise biological terms; these terms then provide indices into the literature and across the growing number of biological databases. This article examines emerging techniques to access biological resources through extraction of entity names and relations among them. Information extraction has been an active area of research in natural language processing and there are promising results for information extraction applied to news stories, e.g., balanced precision and recall in the 93-95\% range for identifying person, organization and location names. But these results do not seem to transfer directly to biological names, where results remain in the 75-80\% range. Multiple factors may be involved, including absence of shared training and test sets for rigorous measures of progress, lack of annotated training data specific to biological tasks, pervasive ambiguity of terms, frequent introduction of new terms, and a mismatch between evaluation tasks as defined for news and real biological problems. We present evidence from a simple lexical matching exercise that illustrates some specific problems encountered when identifying biological names. We conclude by outlining a research agenda to raise performance of named entity tagging to a level where it can be used to perform tasks of biological importance.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	author = {Hirschman, Lynette and Morgan, Alexander A. and Yeh, Alexander S.},
	month = aug,
	year = {2002},
	pmid = {12755519},
	keywords = {female first or senior, NER},
	pages = {247--259}
}

@article{hirschman_crowdsourcing_2016,
	title = {Crowdsourcing and curation: perspectives from biology and natural language processing},
	volume = {2016},
	issn = {1758-0463},
	shorttitle = {Crowdsourcing and curation},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4976298/},
	doi = {10.1093/database/baw115},
	abstract = {Crowdsourcing is increasingly utilized for performing tasks in both natural language processing and biocuration. Although there have been many applications of crowdsourcing in these fields, there have been fewer high-level discussions of the methodology and its applicability to biocuration. This paper explores crowdsourcing for biocuration through several case studies that highlight different ways of leveraging ‘the crowd’; these raise issues about the kind(s) of expertise needed, the motivations of participants, and questions related to feasibility, cost and quality. The paper is an outgrowth of a panel session held at BioCreative V (Seville, September 9–11, 2015). The session consisted of four short talks, followed by a discussion. In their talks, the panelists explored the role of expertise and the potential to improve crowd performance by training; the challenge of decomposing tasks to make them amenable to crowdsourcing; and the capture of biological data and metadata through community editing., Database URL:
http://www.mitre.org/publications/technical-papers/crowdsourcing-and-curation-perspectives},
	urldate = {2018-02-16},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Hirschman, Lynette and Fort, Karën and Boué, Stéphanie and Kyrpides, Nikos and Islamaj Doğan, Rezarta and Cohen, Kevin Bretonnel},
	month = aug,
	year = {2016},
	pmid = {27504010},
	pmcid = {PMC4976298},
	keywords = {reproducibility, female first or senior, curation},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/L7RQ5AGE/Hirschman et al. - 2016 - Crowdsourcing and curation perspectives from biol.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PJW8PX27/Hirschman et al. - 2016 - Crowdsourcing and curation perspectives from biol.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MB252W34/Hirschman et al. - 2016 - Crowdsourcing and curation perspectives from biol.pdf:application/pdf}
}

@article{burger_hybrid_2014,
	title = {Hybrid curation of gene–mutation relations combining automated extraction and crowdsourcing},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4170591/},
	doi = {10.1093/database/bau094},
	abstract = {Background: This article describes capture of biological information using a hybrid approach that combines natural language processing to extract biological entities and crowdsourcing with annotators recruited via Amazon Mechanical Turk to judge correctness of candidate biological relations. These techniques were applied to extract gene– mutation relations from biomedical abstracts with the goal of supporting production scale capture of gene–mutation–disease findings as an open source resource for personalized medicine. Results: The hybrid system could be configured to provide good performance for gene–mutation extraction (precision ∼82\%; recall ∼70\% against an expert-generated gold standard) at a cost of \$0.76 per abstract. This demonstrates that crowd labor platforms such as Amazon Mechanical Turk can be used to recruit quality annotators, even in an application requiring subject matter expertise; aggregated Turker judgments for gene–mutation relations exceeded 90\% accuracy. Over half of the precision errors were due to mismatches against the gold standard hidden from annotator view (e.g. incorrect EntrezGene identifier or incorrect mutation position extracted), or incomplete task instructions (e.g. the need to exclude nonhuman mutations). Conclusions: The hybrid curation model provides a readily scalable cost-effective approach to curation, particularly if coupled with expert human review to filter precision errors. We plan to generalize the framework and make it available as open source software., Database URL:
http://www.mitre.org/publications/technical-papers/hybrid-curation-of-gene-mutation-relations-combining-automated},
	urldate = {2018-02-16},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Burger, John D. and Doughty, Emily and Khare, Ritu and Wei, Chih-Hsuan and Mishra, Rajashree and Aberdeen, John and Tresner-Kirsch, David and Wellner, Ben and Kann, Maricel G. and Lu, Zhiyong and Hirschman, Lynette},
	month = sep,
	year = {2014},
	pmid = {25246425},
	pmcid = {PMC4170591},
	keywords = {female first or senior, curation, IE},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/HMUBXAQS/Burger et al. - 2014 - Hybrid curation of gene–mutation relations combini.pdf:application/pdf}
}

@article{yeh_biocreative_2005,
	title = {{BioCreAtIvE} {Task} 1A: gene mention finding evaluation},
	volume = {6},
	issn = {1471-2105},
	shorttitle = {{BioCreAtIvE} {Task} 1A},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1869012/},
	doi = {10.1186/1471-2105-6-S1-S2},
	abstract = {Background
The biological research literature is a major repository of knowledge. As the amount of literature increases, it will get harder to find the information of interest on a particular topic. There has been an increasing amount of work on text mining this literature, but comparing this work is hard because of a lack of standards for making comparisons. To address this, we worked with colleagues at the Protein Design Group, CNB-CSIC, Madrid to develop BioCreAtIvE (Critical Assessment for Information Extraction in Biology), an open common evaluation of systems on a number of biological text mining tasks. We report here on task 1A, which deals with finding mentions of genes and related entities in text. "Finding mentions" is a basic task, which can be used as a building block for other text mining tasks. The task makes use of data and evaluation software provided by the (US) National Center for Biotechnology Information (NCBI).

Results
15 teams took part in task 1A. A number of teams achieved scores over 80\% F-measure (balanced precision and recall). The teams that tried to use their task 1A systems to help on other BioCreAtIvE tasks reported mixed results.

Conclusion
The 80\% plus F-measure results are good, but still somewhat lag the best scores achieved in some other domains such as newswire, due in part to the complexity and length of gene names, compared to person or organization names in newswire.},
	number = {Suppl 1},
	urldate = {2018-02-16},
	journal = {BMC Bioinformatics},
	author = {Yeh, Alexander and Morgan, Alexander and Colosimo, Marc and Hirschman, Lynette},
	month = may,
	year = {2005},
	pmid = {15960832},
	pmcid = {PMC1869012},
	keywords = {NER, shared tasks},
	pages = {S2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DA6E57QU/Yeh et al. - 2005 - BioCreAtIvE Task 1A gene mention finding evaluati.pdf:application/pdf}
}

@article{colosimo_data_2005,
	title = {Data preparation and interannotator agreement: {BioCreAtIvE} {Task} 1B},
	volume = {6},
	issn = {1471-2105},
	shorttitle = {Data preparation and interannotator agreement},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1869005/},
	doi = {10.1186/1471-2105-6-S1-S12},
	abstract = {Background
We prepared and evaluated training and test materials for an assessment of text mining methods in molecular biology. The goal of the assessment was to evaluate the ability of automated systems to generate a list of unique gene identifiers from PubMed abstracts for the three model organisms Fly, Mouse, and Yeast. This paper describes the preparation and evaluation of answer keys for training and testing. These consisted of lists of normalized gene names found in the abstracts, generated by adapting the gene list for the full journal articles found in the model organism databases. For the training dataset, the gene list was pruned automatically to remove gene names not found in the abstract; for the testing dataset, it was further refined by manual annotation by annotators provided with guidelines. A critical step in interpreting the results of an assessment is to evaluate the quality of the data preparation. We did this by careful assessment of interannotator agreement and the use of answer pooling of participant results to improve the quality of the final testing dataset.

Results
Interannotator analysis on a small dataset showed that our gene lists for Fly and Yeast were good (87\% and 91\% three-way agreement) but the Mouse gene list had many conflicts (mostly omissions), which resulted in errors (69\% interannotator agreement). By comparing and pooling answers from the participant systems, we were able to add an additional check on the test data; this allowed us to find additional errors, especially in Mouse. This led to 1\% change in the Yeast and Fly "gold standard" answer keys, but to an 8\% change in the mouse answer key.

Conclusion
We found that clear annotation guidelines are important, along with careful interannotator experiments, to validate the generated gene lists. Also, abstracts alone are a poor resource for identifying genes in paper, containing only a fraction of genes mentioned in the full text (25\% for Fly, 36\% for Mouse). We found that there are intrinsic differences between the model organism databases related to the number of synonymous terms and also to curation criteria. Finally, we found that answer pooling was much faster and allowed us to identify more conflicting genes than interannotator analysis.},
	number = {Suppl 1},
	urldate = {2018-02-16},
	journal = {BMC Bioinformatics},
	author = {Colosimo, Marc E and Morgan, Alexander A and Yeh, Alexander S and Colombe, Jeffrey B and Hirschman, Lynette},
	month = may,
	year = {2005},
	pmid = {15960824},
	pmcid = {PMC1869005},
	keywords = {female first or senior, annotation},
	pages = {S12},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/V3GV8ZF2/Colosimo et al. - 2005 - Data preparation and interannotator agreement Bio.pdf:application/pdf}
}

@article{hirschman_experiment_1981,
	title = {An experiment in automated health care evaluation from narrative medical records},
	volume = {14},
	issn = {0010-4809},
	language = {eng},
	number = {5},
	journal = {Computers and Biomedical Research, an International Journal},
	author = {Hirschman, L. and Story, G. and Marsh, E. and Lyman, M. and Sager, N.},
	month = oct,
	year = {1981},
	pmid = {7273723},
	keywords = {female first or senior},
	pages = {447--463}
}

@misc{noauthor_overview_nodate,
	title = {Overview of the interactive task in {BioCreative} {V}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5009325/},
	urldate = {2018-02-16},
	file = {Overview of the interactive task in BioCreative V:/Users/transfer/Zotero/storage/L35NXJFT/PMC5009325.html:text/html}
}

@article{wang_overview_2016,
	title = {Overview of the interactive task in {BioCreative} {V}},
	volume = {2016},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5009325/},
	doi = {10.1093/database/baw119},
	abstract = {Fully automated text mining (TM) systems promote efficient literature searching, retrieval, and review but are not sufficient to produce ready-to-consume curated documents. These systems are not meant to replace biocurators, but instead to assist them in one or more literature curation steps. To do so, the user interface is an important aspect that needs to be considered for tool adoption. The BioCreative Interactive task (IAT) is a track designed for exploring user-system interactions, promoting development of useful TM tools, and providing a communication channel between the biocuration and the TM communities. In BioCreative V, the IAT track followed a format similar to previous interactive tracks, where the utility and usability of TM tools, as well as the generation of use cases, have been the focal points. The proposed curation tasks are user-centric and formally evaluated by biocurators. In BioCreative V IAT, seven TM systems and 43 biocurators participated. Two levels of user participation were offered to broaden curator involvement and obtain more feedback on usability aspects. The full level participation involved training on the system, curation of a set of documents with and without TM assistance, tracking of time-on-task, and completion of a user survey. The partial level participation was designed to focus on usability aspects of the interface and not the performance per se. In this case, biocurators navigated the system by performing pre-designed tasks and then were asked whether they were able to achieve the task and the level of difficulty in completing the task. In this manuscript, we describe the development of the interactive task, from planning to execution and discuss major findings for the systems tested., Database URL:
http://www.biocreative.org},
	urldate = {2018-02-16},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Wang, Qinghua and S. Abdul, Shabbir and Almeida, Lara and Ananiadou, Sophia and Balderas-Martínez, Yalbi I. and Batista-Navarro, Riza and Campos, David and Chilton, Lucy and Chou, Hui-Jou and Contreras, Gabriela and Cooper, Laurel and Dai, Hong-Jie and Ferrell, Barbra and Fluck, Juliane and Gama-Castro, Socorro and George, Nancy and Gkoutos, Georgios and Irin, Afroza K. and Jensen, Lars J. and Jimenez, Silvia and Jue, Toni R. and Keseler, Ingrid and Madan, Sumit and Matos, Sérgio and McQuilton, Peter and Milacic, Marija and Mort, Matthew and Natarajan, Jeyakumar and Pafilis, Evangelos and Pereira, Emiliano and Rao, Shruti and Rinaldi, Fabio and Rothfels, Karen and Salgado, David and Silva, Raquel M. and Singh, Onkar and Stefancsik, Raymund and Su, Chu-Hsien and Subramani, Suresh and Tadepally, Hamsa D. and Tsaprouni, Loukia and Vasilevsky, Nicole and Wang, Xiaodong and Chatr-Aryamontri, Andrew and Laulederkind, Stanley J. F. and Matis-Mitchell, Sherri and McEntyre, Johanna and Orchard, Sandra and Pundir, Sangya and Rodriguez-Esteban, Raul and Van Auken, Kimberly and Lu, Zhiyong and Schaeffer, Mary and Wu, Cathy H. and Hirschman, Lynette and Arighi, Cecilia N.},
	month = sep,
	year = {2016},
	pmid = {27589961},
	pmcid = {PMC5009325},
	keywords = {reproducibility, female first or senior, shared tasks},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/448N7IKB/Wang et al. - 2016 - Overview of the interactive task in BioCreative V.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/GMTTDNIH/Wang et al. - 2016 - Overview of the interactive task in BioCreative V.pdf:application/pdf}
}

@article{carrell_hiding_2013,
	title = {Hiding in plain sight: use of realistic surrogates to reduce exposure of protected health information in clinical text},
	volume = {20},
	issn = {1067-5027},
	shorttitle = {Hiding in plain sight},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3638183/},
	doi = {10.1136/amiajnl-2012-001034},
	abstract = {Objective
Secondary use of clinical text is impeded by a lack of highly effective, low-cost de-identification methods. Both, manual and automated methods for removing protected health information, are known to leave behind residual identifiers. The authors propose a novel approach for addressing the residual identifier problem based on the theory of Hiding In Plain Sight (HIPS).

Materials and Methods
HIPS relies on obfuscation to conceal residual identifiers. According to this theory, replacing the detected identifiers with realistic but synthetic surrogates should collectively render the few ‘leaked’ identifiers difficult to distinguish from the synthetic surrogates. The authors conducted a pilot study to test this theory on clinical narrative, de-identified by an automated system. Test corpora included 31 oncology and 50 family practice progress notes read by two trained chart abstractors and an informaticist.

Results
Experimental results suggest approximately 90\% of residual identifiers can be effectively concealed by the HIPS approach in text containing average and high densities of personal identifying information.

Discussion
This pilot test suggests HIPS is feasible, but requires further evaluation. The results need to be replicated on larger corpora of diverse origin under a range of detection scenarios. Error analyses also suggest areas where surrogate generation techniques can be refined to improve efficacy.

Conclusions
If these results generalize to existing high-performing de-identification systems with recall rates of 94–98\%, HIPS could increase the effective de-identification rates of these systems to levels above 99\% without further advancements in system recall. Additional and more rigorous assessment of the HIPS approach is warranted.},
	number = {2},
	urldate = {2018-02-16},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Carrell, David and Malin, Bradley and Aberdeen, John and Bayer, Samuel and Clark, Cheryl and Wellner, Ben and Hirschman, Lynette},
	year = {2013},
	pmid = {22771529},
	pmcid = {PMC3638183},
	keywords = {female first or senior},
	pages = {342--348},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SLRDAYS3/Carrell et al. - 2013 - Hiding in plain sight use of realistic surrogates.pdf:application/pdf}
}

@article{aberdeen_mitre_2010,
	title = {The {MITRE} {Identification} {Scrubber} {Toolkit}: {Design}, training, and assessment},
	volume = {79},
	issn = {1386-5056},
	shorttitle = {The {MITRE} {Identification} {Scrubber} {Toolkit}},
	url = {http://www.sciencedirect.com/science/article/pii/S1386505610001681},
	doi = {10.1016/j.ijmedinf.2010.09.007},
	abstract = {Purpose
Medical records must often be stripped of patient identifiers, or de-identified, before being shared. De-identification by humans is time-consuming, and existing software is limited in its generality. The open source MITRE Identification Scrubber Toolkit (MIST) provides an environment to support rapid tailoring of automated de-identification to different document types, using automatically learned classifiers to de-identify and protect sensitive information.
Methods
MIST was evaluated with four classes of patient records from the Vanderbilt University Medical Center: discharge summaries, laboratory reports, letters, and order summaries. We trained and tested MIST on each class of record separately, as well as on pooled sets of records. We measured precision, recall, F-measure and accuracy at the word level for the detection of patient identifiers as designated by the HIPAA Safe Harbor Rule.
Results
MIST was applied to medical records that differed in the amounts and types of protected health information (PHI): lab reports contained only two types of PHI (dates, names) compared to discharge summaries, which were much richer. Performance of the de-identification tool depended on record class; F-measure results were 0.996 for order summaries, 0.996 for discharge summaries, 0.943 for letters and 0.934 for laboratory reports. Experiments suggest the tool requires several hundred training exemplars to reach an F-measure of at least 0.9.
Conclusions
The MIST toolkit makes possible the rapid tailoring of automated de-identification to particular document types and supports the transition of the de-identification software to medical end users, avoiding the need for developers to have access to original medical records. We are making the MIST toolkit available under an open source license to encourage its application to diverse data sets at multiple institutions.},
	number = {12},
	urldate = {2018-02-16},
	journal = {International Journal of Medical Informatics},
	author = {Aberdeen, John and Bayer, Samuel and Yeniterzi, Reyyan and Wellner, Ben and Clark, Cheryl and Hanauer, David and Malin, Bradley and Hirschman, Lynette},
	month = dec,
	year = {2010},
	keywords = {female first or senior, NER},
	pages = {849--859},
	file = {ScienceDirect Full Text PDF:/Users/transfer/Zotero/storage/HLKCRXAQ/Aberdeen et al. - 2010 - The MITRE Identification Scrubber Toolkit Design,.pdf:application/pdf;ScienceDirect Snapshot:/Users/transfer/Zotero/storage/XHZDFHQ6/S1386505610001681.html:text/html}
}

@article{carrell_is_2016,
	title = {Is the {Juice} {Worth} the {Squeeze}? {Costs} and {Benefits} of {Multiple} {Human} {Annotators} for {Clinical} {Text} {De}-identification},
	volume = {55},
	issn = {0026-1270},
	shorttitle = {Is the {Juice} {Worth} the {Squeeze}?},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5194214/},
	doi = {10.3414/ME15-01-0122},
	abstract = {Background
Clinical text contains valuable information but must be de-identified before it can be used for secondary purposes. Accurate annotation of personally identifiable information (PII) is essential to the development of automated de-identification systems and to manual redaction of PII. Yet the accuracy of annotations may vary considerably across individual annotators and annotation is costly. As such, the marginal benefit of incorporating additional annotators has not been well characterized.

Objectives
This study models the costs and benefits of incorporating increasing numbers of independent human annotators to identify the instances of PII in a corpus. We used a corpus with gold standard annotations to evaluate the performance of teams of annotators of increasing size.

Methods
Four annotators independently identified PII in a 100-document corpus consisting of randomly selected clinical notes from Family Practice clinics in a large integrated health care system. These annotations were pooled and validated to generate a gold standard corpus for evaluation.

Results
Recall rates for all PII types ranged from 0.90 to 0.98 for individual annotators to 0.998 to 1.0 for teams of three, when measured against the gold standard. Median cost per PII instance discovered during corpus annotation ranged from \$0.71 for an individual annotator to \$377 for annotations discovered only by a fourth annotator.

Conclusions
Incorporating a second annotator into a PII annotation process reduces unredacted PII and improves the quality of annotations to 0.99 recall, yielding clear benefit at reasonable cost; the cost advantages of annotation teams larger than two diminish rapidly.},
	number = {4},
	urldate = {2018-02-16},
	journal = {Methods of information in medicine},
	author = {Carrell, D. S. and Cronkite, D. J. and Malin, B. A. and Aberdeen, J. S. and Hirschman, L.},
	month = aug,
	year = {2016},
	pmid = {27405787},
	pmcid = {PMC5194214},
	keywords = {female first or senior, annotation},
	pages = {356--364},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/23XAN5CT/Carrell et al. - 2016 - Is the Juice Worth the Squeeze Costs and Benefits.pdf:application/pdf}
}

@article{hanauer_bootstrapping_2013,
	title = {Bootstrapping a de-identification system for narrative patient records: {Cost}-performance tradeoffs},
	volume = {82},
	issn = {1386-5056},
	shorttitle = {Bootstrapping a de-identification system for narrative patient records},
	url = {http://www.sciencedirect.com/science/article/pii/S1386505613000634},
	doi = {10.1016/j.ijmedinf.2013.03.005},
	abstract = {Purpose
We describe an experiment to build a de-identification system for clinical records using the open source MITRE Identification Scrubber Toolkit (MIST). We quantify the human annotation effort needed to produce a system that de-identifies at high accuracy.
Methods
Using two types of clinical records (history and physical notes, and social work notes), we iteratively built statistical de-identification models by annotating 10 notes, training a model, applying the model to another 10 notes, correcting the model's output, and training from the resulting larger set of annotated notes. This was repeated for 20 rounds of 10 notes each, and then an additional 6 rounds of 20 notes each, and a final round of 40 notes. At each stage, we measured precision, recall, and F-score, and compared these to the amount of annotation time needed to complete the round.
Results
After the initial 10-note round (33min of annotation time) we achieved an F-score of 0.89. After just over 8h of annotation time (round 21) we achieved an F-score of 0.95. Number of annotation actions needed, as well as time needed, decreased in later rounds as model performance improved. Accuracy on history and physical notes exceeded that of social work notes, suggesting that the wider variety and contexts for protected health information (PHI) in social work notes is more difficult to model.
Conclusions
It is possible, with modest effort, to build a functioning de-identification system de novo using the MIST framework. The resulting system achieved performance comparable to other high-performing de-identification systems.},
	number = {9},
	urldate = {2018-02-16},
	journal = {International Journal of Medical Informatics},
	author = {Hanauer, David and Aberdeen, John and Bayer, Samuel and Wellner, Benjamin and Clark, Cheryl and Zheng, Kai and Hirschman, Lynette},
	month = sep,
	year = {2013},
	keywords = {female first or senior, NER},
	pages = {821--831},
	file = {ScienceDirect Full Text PDF:/Users/transfer/Zotero/storage/LNTXKNL2/Hanauer et al. - 2013 - Bootstrapping a de-identification system for narra.pdf:application/pdf;ScienceDirect Snapshot:/Users/transfer/Zotero/storage/EV5H53CG/S1386505613000634.html:text/html}
}

@article{lu_biocuration_2012,
	title = {Biocuration workflows and text mining: overview of the {BioCreative} 2012 {Workshop} {Track} {II}},
	volume = {2012},
	issn = {1758-0463},
	shorttitle = {Biocuration workflows and text mining},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3500522/},
	doi = {10.1093/database/bas043},
	abstract = {Manual curation of data from the biomedical literature is a rate-limiting factor for many expert curated databases. Despite the continuing advances in biomedical text mining and the pressing needs of biocurators for better tools, few existing text-mining tools have been successfully integrated into production literature curation systems such as those used by the expert curated databases. To close this gap and better understand all aspects of literature curation, we invited submissions of written descriptions of curation workflows from expert curated databases for the BioCreative 2012 Workshop Track II. We received seven qualified contributions, primarily from model organism databases. Based on these descriptions, we identified commonalities and differences across the workflows, the common ontologies and controlled vocabularies used and the current and desired uses of text mining for biocuration. Compared to a survey done in 2009, our 2012 results show that many more databases are now using text mining in parts of their curation workflows. In addition, the workshop participants identified text-mining aids for finding gene names and symbols (gene indexing), prioritization of documents for curation (document triage) and ontology concept assignment as those most desired by the biocurators., Database URL:
http://www.biocreative.org/tasks/bc-workshop-2012/workflow/},
	urldate = {2018-02-16},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Lu, Zhiyong and Hirschman, Lynette},
	month = nov,
	year = {2012},
	pmid = {23160416},
	pmcid = {PMC3500522},
	keywords = {female first or senior, curation, review},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/2NT63QVU/Lu and Hirschman - 2012 - Biocuration workflows and text mining overview of.pdf:application/pdf}
}

@article{chapman_overcoming_2011,
	title = {Overcoming barriers to {NLP} for clinical text: the role of shared tasks and the need for additional creative solutions},
	volume = {18},
	issn = {1067-5027},
	shorttitle = {Overcoming barriers to {NLP} for clinical text},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3168329/},
	doi = {10.1136/amiajnl-2011-000465},
	number = {5},
	urldate = {2018-02-16},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Chapman, Wendy W and Nadkarni, Prakash M and Hirschman, Lynette and D'Avolio, Leonard W and Savova, Guergana K and Uzuner, Ozlem},
	year = {2011},
	pmid = {21846785},
	pmcid = {PMC3168329},
	keywords = {female first or senior, shared tasks},
	pages = {540--543},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/G3IRYVP7/Chapman et al. - 2011 - Overcoming barriers to NLP for clinical text the .pdf:application/pdf}
}

@article{clark_mitre_2011,
	title = {{MITRE} system for clinical assertion status classification},
	volume = {18},
	issn = {1067-5027},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3168316/},
	doi = {10.1136/amiajnl-2011-000164},
	abstract = {Objective
To describe a system for determining the assertion status of medical problems mentioned in clinical reports, which was entered in the 2010 i2b2/VA community evaluation ‘Challenges in natural language processing for clinical data’ for the task of classifying assertions associated with problem concepts extracted from patient records.

Materials and methods
A combination of machine learning (conditional random field and maximum entropy) and rule-based (pattern matching) techniques was used to detect negation, speculation, and hypothetical and conditional information, as well as information associated with persons other than the patient.

Results
The best submission obtained an overall micro-averaged F-score of 0.9343.

Conclusions
Using semantic attributes of concepts and information about document structure as features for statistical classification of assertions is a good way to leverage rule-based and statistical techniques. In this task, the choice of features may be more important than the choice of classifier algorithm.},
	number = {5},
	urldate = {2018-02-16},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Clark, Cheryl and Aberdeen, John and Coarr, Matt and Tresner-Kirsch, David and Wellner, Ben and Yeh, Alexander and Hirschman, Lynette},
	year = {2011},
	pmid = {21515542},
	pmcid = {PMC3168316},
	keywords = {female first or senior, IE},
	pages = {563--567},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/UPAAQEQS/Clark et al. - 2011 - MITRE system for clinical assertion status classif.pdf:application/pdf}
}

@article{krallinger_linking_2008,
	title = {Linking genes to literature: text mining, information extraction, and retrieval applications for biology},
	volume = {9},
	issn = {1465-6906},
	shorttitle = {Linking genes to literature},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559992/},
	doi = {10.1186/gb-2008-9-s2-s8},
	abstract = {Efficient access to information contained in online scientific literature collections is essential for life science research, playing a crucial role from the initial stage of experiment planning to the final interpretation and communication of the results. The biological literature also constitutes the main information source for manual literature curation used by expert-curated databases. Following the increasing popularity of web-based applications for analyzing biological data, new text-mining and information extraction strategies are being implemented. These systems exploit existing regularities in natural language to extract biologically relevant information from electronic texts automatically. The aim of the BioCreative challenge is to promote the development of such tools and to provide insight into their performance. This review presents a general introduction to the main characteristics and applications of currently available text-mining systems for life sciences in terms of the following: the type of biological information demands being addressed; the level of information granularity of both user queries and results; and the features and methods commonly exploited by these applications. The current trend in biomedical text mining points toward an increasing diversification in terms of application types and techniques, together with integration of domain-specific resources such as ontologies. Additional descriptions of some of the systems discussed here are available on the internet .},
	number = {Suppl 2},
	urldate = {2018-02-16},
	journal = {Genome Biology},
	author = {Krallinger, Martin and Valencia, Alfonso and Hirschman, Lynette},
	year = {2008},
	pmid = {18834499},
	pmcid = {PMC2559992},
	keywords = {female first or senior, curation, IE, review},
	pages = {S8},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SWIIVKTF/Krallinger et al. - 2008 - Linking genes to literature text mining, informat.pdf:application/pdf}
}

@article{hirschman_overview_2005,
	title = {Overview of {BioCreAtIvE} task 1B: normalized gene lists},
	volume = {6 Suppl 1},
	issn = {1471-2105},
	shorttitle = {Overview of {BioCreAtIvE} task 1B},
	doi = {10.1186/1471-2105-6-S1-S11},
	abstract = {BACKGROUND: Our goal in BioCreAtIve has been to assess the state of the art in text mining, with emphasis on applications that reflect real biological applications, e.g., the curation process for model organism databases. This paper summarizes the BioCreAtIvE task 1B, the "Normalized Gene List" task, which was inspired by the gene list supplied for each curated paper in a model organism database. The task was to produce the correct list of unique gene identifiers for the genes and gene products mentioned in sets of abstracts from three model organisms (Yeast, Fly, and Mouse).
RESULTS: Eight groups fielded systems for three data sets (Yeast, Fly, and Mouse). For Yeast, the top scoring system (out of 15) achieved 0.92 F-measure (harmonic mean of precision and recall); for Mouse and Fly, the task was more difficult, due to larger numbers of genes, more ambiguity in the gene naming conventions (particularly for Fly), and complex gene names (for Mouse). For Fly, the top F-measure was 0.82 out of 11 systems and for Mouse, it was 0.79 out of 16 systems.
CONCLUSION: This assessment demonstrates that multiple groups were able to perform a real biological task across a range of organisms. The performance was dependent on the organism, and specifically on the naming conventions associated with each organism. These results hold out promise that the technology can provide partial automation of the curation process in the near future.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Hirschman, Lynette and Colosimo, Marc and Morgan, Alexander and Yeh, Alexander},
	year = {2005},
	pmid = {15960823},
	pmcid = {PMC1869004},
	keywords = {female first or senior, normalization, shared tasks},
	pages = {S11}
}

@article{hirschman_overview_2005-1,
	title = {Overview of {BioCreAtIvE}: critical assessment of information extraction for biology},
	volume = {6},
	issn = {1471-2105},
	shorttitle = {Overview of {BioCreAtIvE}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1869002/},
	doi = {10.1186/1471-2105-6-S1-S1},
	abstract = {Background
The goal of the first BioCreAtIvE challenge (Critical Assessment of Information Extraction in Biology) was to provide a set of common evaluation tasks to assess the state of the art for text mining applied to biological problems. The results were presented in a workshop held in Granada, Spain March 28–31, 2004. The articles collected in this BMC Bioinformatics supplement entitled "A critical assessment of text mining methods in molecular biology" describe the BioCreAtIvE tasks, systems, results and their independent evaluation.

Results
BioCreAtIvE focused on two tasks. The first dealt with extraction of gene or protein names from text, and their mapping into standardized gene identifiers for three model organism databases (fly, mouse, yeast). The second task addressed issues of functional annotation, requiring systems to identify specific text passages that supported Gene Ontology annotations for specific proteins, given full text articles.

Conclusion
The first BioCreAtIvE assessment achieved a high level of international participation (27 groups from 10 countries). The assessment provided state-of-the-art performance results for a basic task (gene name finding and normalization), where the best systems achieved a balanced 80\% precision / recall or better, which potentially makes them suitable for real applications in biology. The results for the advanced task (functional annotation from free text) were significantly lower, demonstrating the current limitations of text-mining approaches where knowledge extrapolation and interpretation are required. In addition, an important contribution of BioCreAtIvE has been the creation and release of training and test data sets for both tasks. There are 22 articles in this special issue, including six that provide analyses of results or data quality for the data sets, including a novel inter-annotator consistency assessment for the test set used in task 2.},
	number = {Suppl 1},
	urldate = {2018-02-16},
	journal = {BMC Bioinformatics},
	author = {Hirschman, Lynette and Yeh, Alexander and Blaschke, Christian and Valencia, Alfonso},
	month = may,
	year = {2005},
	pmid = {15960821},
	pmcid = {PMC1869002},
	keywords = {female first or senior, shared tasks, review},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TLR4RSXX/Hirschman et al. - 2005 - Overview of BioCreAtIvE critical assessment of in.pdf:application/pdf}
}

@article{story_data_1982,
	title = {Data base design for natural language medical data},
	volume = {6},
	issn = {0148-5598},
	language = {eng},
	number = {1},
	journal = {Journal of Medical Systems},
	author = {Story, G. and Hirschman, L.},
	month = feb,
	year = {1982},
	pmid = {7069313},
	keywords = {female first or senior, IE},
	pages = {77--88}
}

@article{altman_statistics_1980,
	title = {Statistics and ethics in medical research. {Misuse} of statistics is unethical.},
	volume = {281},
	issn = {0007-1447},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1714517/},
	number = {6249},
	urldate = {2018-02-17},
	journal = {British Medical Journal},
	author = {Altman, D G},
	month = nov,
	year = {1980},
	pmid = {7427629},
	pmcid = {PMC1714517},
	keywords = {ethics},
	pages = {1182--1184},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/QEFX5Q6N/Altman - 1980 - Statistics and ethics in medical research. Misuse .pdf:application/pdf}
}

@article{cohen_critical_2006,
	title = {A critical review of {PASBio}'s argument structures for biomedical verbs},
	volume = {7},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1764449/},
	doi = {10.1186/1471-2105-7-S3-S5},
	abstract = {Background
Propositional representations of biomedical knowledge are a critical component of most aspects of semantic mining in biomedicine. However, the proper set of propositions has yet to be determined. Recently, the PASBio project proposed a set of propositions and argument structures for biomedical verbs. This initial set of representations presents an opportunity for evaluating the suitability of predicate-argument structures as a scheme for representing verbal semantics in the biomedical domain. Here, we quantitatively evaluate several dimensions of the initial PASBio propositional structure repository.

Results
We propose a number of metrics and heuristics related to arity, role labelling, argument realization, and corpus coverage for evaluating large-scale predicate-argument structure proposals. We evaluate the metrics and heuristics by applying them to PASBio 1.0.

Conclusion
PASBio demonstrates the suitability of predicate-argument structures for representing aspects of the semantics of biomedical verbs. Metrics related to theta-criterion violations and to the distribution of arguments are able to detect flaws in semantic representations, given a set of predicate-argument structures and a relatively small corpus annotated with them.},
	number = {Suppl 3},
	urldate = {2018-02-17},
	journal = {BMC Bioinformatics},
	author = {Cohen, K Bretonnel and Hunter, Lawrence},
	month = nov,
	year = {2006},
	pmid = {17134478},
	pmcid = {PMC1764449},
	pages = {S5},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZFYR7K3K/Cohen and Hunter - 2006 - A critical review of PASBio's argument structures .pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MLN2WWA9/Cohen and Hunter - 2006 - A critical review of PASBio's argument structures .pdf:application/pdf}
}

@inproceedings{banko_scaling_2001,
	address = {Stroudsburg, PA, USA},
	series = {{ACL} '01},
	title = {Scaling to {Very} {Very} {Large} {Corpora} for {Natural} {Language} {Disambiguation}},
	url = {https://doi.org/10.3115/1073012.1073017},
	doi = {10.3115/1073012.1073017},
	abstract = {The amount of readily available on-line text has reached hundreds of billions of words and continues to grow. Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less. In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used. We are fortunate that for this particular application, correctly labeled training data is free. Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost.},
	urldate = {2018-02-17},
	booktitle = {Proceedings of the 39th {Annual} {Meeting} on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Banko, Michele and Brill, Eric},
	year = {2001},
	pages = {26--33},
	file = {ACM Full Text PDF:/Users/transfer/Zotero/storage/BZB6CVZZ/Banko and Brill - 2001 - Scaling to Very Very Large Corpora for Natural Lan.pdf:application/pdf}
}

@article{akkasi_chemtok:_2016,
	title = {{ChemTok}: {A} {New} {Rule} {Based} {Tokenizer} for {Chemical} {Named} {Entity} {Recognition}},
	volume = {2016},
	issn = {2314-6133},
	shorttitle = {{ChemTok}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4749772/},
	doi = {10.1155/2016/4248026},
	abstract = {Named Entity Recognition (NER) from text constitutes the first step in many text mining applications. The most important preliminary step for NER systems using machine learning approaches is tokenization where raw text is segmented into tokens. This study proposes an enhanced rule based tokenizer, ChemTok, which utilizes rules extracted mainly from the train data set. The main novelty of ChemTok is the use of the extracted rules in order to merge the tokens split in the previous steps, thus producing longer and more discriminative tokens. ChemTok is compared to the tokenization methods utilized by ChemSpot and tmChem. Support Vector Machines and Conditional Random Fields are employed as the learning algorithms. The experimental results show that the classifiers trained on the output of ChemTok outperforms all classifiers trained on the output of the other two tokenizers in terms of classification performance, and the number of incorrectly segmented entities.},
	urldate = {2018-02-17},
	journal = {BioMed Research International},
	author = {Akkasi, Abbas and Varoğlu, Ekrem and Dimililer, Nazife},
	year = {2016},
	pmid = {26942193},
	pmcid = {PMC4749772},
	keywords = {tokenization},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XAKHAHZD/Akkasi et al. - 2016 - ChemTok A New Rule Based Tokenizer for Chemical N.pdf:application/pdf}
}

@article{barrett_building_2011,
	title = {Building a biomedical tokenizer using the token lattice design pattern and the adapted {Viterbi} algorithm},
	volume = {12},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3111587/},
	doi = {10.1186/1471-2105-12-S3-S1},
	abstract = {Background
Tokenization is an important component of language processing yet there is no widely accepted tokenization method for English texts, including biomedical texts. Other than rule based techniques, tokenization in the biomedical domain has been regarded as a classification task. Biomedical classifier-based tokenizers either split or join textual objects through classification to form tokens. The idiosyncratic nature of each biomedical tokenizer’s output complicates adoption and reuse. Furthermore, biomedical tokenizers generally lack guidance on how to apply an existing tokenizer to a new domain (subdomain). We identify and complete a novel tokenizer design pattern and suggest a systematic approach to tokenizer creation. We implement a tokenizer based on our design pattern that combines regular expressions and machine learning. Our machine learning approach differs from the previous split-join classification approaches. We evaluate our approach against three other tokenizers on the task of tokenizing biomedical text.

Results
Medpost and our adapted Viterbi tokenizer performed best with a 92.9\% and 92.4\% accuracy respectively.

Conclusions
Our evaluation of our design pattern and guidelines supports our claim that the design pattern and guidelines are a viable approach to tokenizer construction (producing tokenizers matching leading custom-built tokenizers in a particular domain). Our evaluation also demonstrates that ambiguous tokenizations can be disambiguated through POS tagging. In doing so, POS tag sequences and training data have a significant impact on proper text tokenization.},
	number = {Suppl 3},
	urldate = {2018-02-17},
	journal = {BMC Bioinformatics},
	author = {Barrett, Neil and Weber-Jahnke, Jens},
	month = jun,
	year = {2011},
	pmid = {21658288},
	pmcid = {PMC3111587},
	keywords = {tokenization},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U77KLZKU/Barrett and Weber-Jahnke - 2011 - Building a biomedical tokenizer using the token la.pdf:application/pdf}
}

@article{barrett_token_2014,
	title = {A token centric part-of-speech tagger for biomedical text},
	volume = {61},
	issn = {0933-3657},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365714000359},
	doi = {10.1016/j.artmed.2014.03.005},
	abstract = {Objective
Difficulties with part-of-speech (POS) tagging of biomedical text is accessing and annotating appropriate training corpora. These difficulties may result in POS taggers trained on corpora that differ from the tagger's target biomedical text (cross-domain tagging). In such cases where training and target corpora differ tagging accuracy decreases. This paper presents a POS tagger for cross-domain tagging called TcT.
Methods and material
TcT estimates a tag's likelihood for a given token by combining token collocation probabilities and the token's tag probabilities calculated using a Naive Bayes classifier. We compared TcT to three POS taggers used in the biomedical domain (mxpost, Brill and TnT). We trained each tagger on a non-biomedical corpus and evaluated it on biomedical corpora.
Results
TcT was more accurate in cross-domain tagging than mxpost, Brill and TnT (respective averages 83.9, 81.0, 79.5 and 78.8).
Conclusion
Our analysis of tagger performance suggests that lexical differences between corpora have more effect on tagging accuracy than originally considered by previous research work. Biomedical POS tagging algorithms may be modified to improve their cross-domain tagging accuracy without requiring extra training or large training data sets. Future work should reexamine POS tagging methods for biomedical text. This differs from the work to date that has focused on retraining existing POS taggers.},
	number = {1},
	urldate = {2018-02-17},
	journal = {Artificial Intelligence in Medicine},
	author = {Barrett, Neil and Weber-Jahnke, Jens},
	month = may,
	year = {2014},
	keywords = {tokenization},
	pages = {11--20},
	file = {ScienceDirect Snapshot:/Users/transfer/Zotero/storage/XUQ3M8VS/S0933365714000359.html:text/html}
}

@article{font-clos_log-log_2015,
	title = {Log-{Log} {Convexity} of {Type}-{Token} {Growth} in {Zipf}'s {Systems}},
	volume = {114},
	issn = {1079-7114},
	doi = {10.1103/PhysRevLett.114.238701},
	abstract = {It is traditionally assumed that Zipf's law implies the power-law growth of the number of different elements with the total number of elements in a system-the so-called Heaps' law. We show that a careful definition of Zipf's law leads to the violation of Heaps' law in random systems, with growth curves that have a convex shape in log-log scale. These curves fulfill universal data collapse that only depends on the value of Zipf's exponent. We observe that real books behave very much in the same way as random systems, despite the presence of burstiness in word occurrence. We advance an explanation for this unexpected correspondence.},
	language = {eng},
	number = {23},
	journal = {Physical Review Letters},
	author = {Font-Clos, Francesc and Corral, Álvaro},
	month = jun,
	year = {2015},
	pmid = {26196834},
	keywords = {tokenization},
	pages = {238701}
}

@article{liu_automatic_2015,
	title = {Automatic {De}-identification of {Electronic} {Medical} {Records} using {Token}-level and {Character}-level {Conditional} {Random} {Fields}},
	volume = {58},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4988843/},
	doi = {10.1016/j.jbi.2015.06.009},
	abstract = {De-identification, identifying and removing all protected health information (PHI) present in clinical data including electronic medical records (EMRs), is a critical step in making clinical data publicly available. The 2014 i2b2 (Center of Informatics for Integrating Biology and Bedside) clinical natural language processing (NLP) challenge sets up a track for de-identification (track 1). In this study, we propose a hybrid system based on both machine learning and rule approaches for the de-identification track. In our system, PHI instances are first identified by two (token-level and character-level) conditional random fields (CRFs) and a rule-based classifier, and then are merged by some rules. Experiments conducted on the i2b2 corpus show that our system submitted for the challenge achieves the highest micro F-scores of 94.64\%, 91.24\% and 91.63\% under the “token”, “strict” and “relaxed” criteria respectively, which is among top-ranked systems of the 2014 i2b2 challenge. After integrating some refined localization dictionaries, our system is further improved with F-scores of 94.83\%, 91.57\% and 91.95\% under the “token”, “strict” and “relaxed” criteria respectively.,},
	number = {Suppl},
	urldate = {2018-02-17},
	journal = {Journal of biomedical informatics},
	author = {Liu, Zengjian and Chen, Yangxin and Tang, Buzhou and Wang, Xiaolong and Chen, Qingcai and Li, Haodi and Wang, Jingfeng and Deng, Qiwen and Zhu, Suisong},
	month = dec,
	year = {2015},
	pmid = {26122526},
	pmcid = {PMC4988843},
	keywords = {tokenization},
	pages = {S47--S52},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3HSNLLG8/Liu et al. - 2015 - Automatic De-identification of Electronic Medical .pdf:application/pdf}
}

@article{dai_recognition_2015,
	title = {Recognition and {Evaluation} of {Clinical} {Section} {Headings} in {Clinical} {Documents} {Using} {Token}-{Based} {Formulation} with {Conditional} {Random} {Fields}},
	volume = {2015},
	issn = {2314-6133},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4563061/},
	doi = {10.1155/2015/873012},
	abstract = {Electronic health record (EHR) is a digital data format that collects electronic health information about an individual patient or population. To enhance the meaningful use of EHRs, information extraction techniques have been developed to recognize clinical concepts mentioned in EHRs. Nevertheless, the clinical judgment of an EHR cannot be known solely based on the recognized concepts without considering its contextual information. In order to improve the readability and accessibility of EHRs, this work developed a section heading recognition system for clinical documents. In contrast to formulating the section heading recognition task as a sentence classification problem, this work proposed a token-based formulation with the conditional random field (CRF) model. A standard section heading recognition corpus was compiled by annotators with clinical experience to evaluate the performance and compare it with sentence classification and dictionary-based approaches. The results of the experiments showed that the proposed method achieved a satisfactory F-score of 0.942, which outperformed the sentence-based approach and the best dictionary-based system by 0.087 and 0.096, respectively. One important advantage of our formulation over the sentence-based approach is that it presented an integrated solution without the need to develop additional heuristics rules for isolating the headings from the surrounding section contents.},
	urldate = {2018-02-17},
	journal = {BioMed Research International},
	author = {Dai, Hong-Jie and Syed-Abdul, Shabbir and Chen, Chih-Wei and Wu, Chieh-Chen},
	year = {2015},
	pmid = {26380302},
	pmcid = {PMC4563061},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RVDXZVUG/Dai et al. - 2015 - Recognition and Evaluation of Clinical Section Hea.pdf:application/pdf}
}

@article{rehman_morpheme_2013,
	title = {Morpheme {Matching} {Based} {Text} {Tokenization} for a {Scarce} {Resourced} {Language}},
	volume = {8},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3749178/},
	doi = {10.1371/journal.pone.0068178},
	abstract = {Text tokenization is a fundamental pre-processing step for almost all the information processing applications. This task is nontrivial for the scarce resourced languages such as Urdu, as there is inconsistent use of space between words. In this paper a morpheme matching based approach has been proposed for Urdu text tokenization, along with some other algorithms to solve the additional issues of boundary detection of compound words, affixation, reduplication, names and abbreviations. This study resulted into 97.28\% precision, 93.71\% recall, and 95.46\% F1-measure; while tokenizing a corpus of 57000 words by using a morpheme list with 6400 entries.},
	number = {8},
	urldate = {2018-02-17},
	journal = {PLoS ONE},
	author = {Rehman, Zobia and Anwar, Waqas and Bajwa, Usama Ijaz and Xuan, Wang and Chaoying, Zhou},
	month = aug,
	year = {2013},
	pmid = {23990871},
	pmcid = {PMC3749178},
	keywords = {tokenization},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/6IIEZZFI/Rehman et al. - 2013 - Morpheme Matching Based Text Tokenization for a Sc.pdf:application/pdf}
}

@article{macrae_predictors_2015,
	title = {Predictors of token-to-token inconsistency in preschool children with typical speech-language development},
	volume = {29},
	issn = {1464-5076},
	doi = {10.3109/02699206.2015.1063085},
	abstract = {The purpose of this study was to examine potential concurrent predictors and replicate rates of token-to-token inconsistency (inconsistency in repeated productions of the same word) in 43 children with typical speech-language development, ages 2;6 to 4;2. A standard linear regression was used to determine which variables, if any, among age, expressive and receptive vocabulary, and speech sound production abilities predicted token-to-token inconsistency. Inconsistency rates in children from one research site, reported elsewhere, were compared to rates in children from a second research site. The results revealed that expressive vocabulary was the only significant predictor of token-to-token inconsistency in these children. Furthermore, inconsistency rates were similarly high across the two research sites. The findings are discussed in terms of their implications for our theoretical understanding of token-to-token inconsistency and its role in the differential diagnosis of speech sound disorders in children.},
	language = {eng},
	number = {12},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Macrae, Toby and Sosa, Anna V.},
	year = {2015},
	pmid = {26308586},
	keywords = {tokenization},
	pages = {922--937}
}

@article{endress_influence_2011,
	title = {The influence of type and token frequency on the acquisition of affixation patterns: implications for language processing},
	volume = {37},
	issn = {1939-1285},
	shorttitle = {The influence of type and token frequency on the acquisition of affixation patterns},
	doi = {10.1037/a0020210},
	abstract = {Rules, and exceptions to such rules, are ubiquitous in many domains, including language. Here we used simple artificial grammars to investigate the influence of 2 factors on the acquisition of rules and their exceptions, namely type frequency (the relative numbers of different exceptions to different regular items) and token frequency (the number of exception tokens relative to the number of regular tokens). We familiarized participants to either a prefixation pattern (where regulars started with /ZaI/ and exceptions ended with /ZaI/) or a suffixation pattern (where regulars ended with /ZaI/ and exceptions started with /ZaI/). We show that the type and the token frequency of regular items and exceptions influence in different ways what participants can learn. For the exceptions to be learned, they have to occur sufficiently often so that participants can memorize them; this can be achieved by a high token frequency. However, a high token frequency of the exceptions also impaired the acquisition of the regular pattern. In contrast, the type frequency of the patterns seemed to determine whether the regular pattern could be learned: When the type frequency of the regular items was sufficiently high, participants successfully learned the regular pattern even when the exceptions were played so often that 66\% of the familiarization items were exceptions. We discuss these findings in the context of general learning mechanisms and the role they may play in language acquisition.},
	language = {eng},
	number = {1},
	journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
	author = {Endress, Ansgar D. and Hauser, Marc D.},
	month = jan,
	year = {2011},
	pmid = {20804286},
	keywords = {tokenization},
	pages = {77--95}
}

@article{lazaro_written_2016,
	title = {Written {Type} and {Token} {Frequency} {Measures} of {Fifty} {Spanish} {Derivational} {Morphemes}},
	volume = {19},
	issn = {1988-2904},
	doi = {10.1017/sjp.2016.75},
	abstract = {Several databases of written language exist in Spanish that manage important information on the lexical and sublexical characteristics of words. However, there is no database with information on the productivity and frequency of use of derivational suffixes: sublexical units with an essential role in the formation of orthographic representations and lexical access. This work examines these two measures, known as type and token frequencies, for a series of 50 derivational suffixes and their corresponding orthographic endings. Derivational suffixes are differentiated from orthographic endings by eliminating pseudoaffixed words from the list of orthographic endings (cerveza [beer] is a simple word despite its ending in -eza). We provide separate data for child and adult populations, using two databases commonly accessed by psycholinguists conducting research in Spanish. We describe the filtering process used to obtain descriptive data that will provide information for future research on token and type frequencies of morphemes. This database is an important development for researchers focusing on the role of morphology in lexical acquisition and access.},
	language = {eng},
	journal = {The Spanish Journal of Psychology},
	author = {Lázaro, Miguel and Acha, Joana and Illera, Víctor and Sainz, Javier S.},
	month = nov,
	year = {2016},
	pmid = {27821213},
	keywords = {tokenization},
	pages = {E75}
}

@article{boyer_automated_2015,
	title = {Automated {Detection} of {Health} {Websites}' {HONcode} {Conformity}: {Can} {N}-gram {Tokenization} {Replace} {Stemming}?},
	volume = {216},
	issn = {0926-9630},
	shorttitle = {Automated {Detection} of {Health} {Websites}' {HONcode} {Conformity}},
	abstract = {Authors evaluated supervised automatic classification algorithms for determination of health related web-page compliance with individual HONcode criteria of conduct using varying length character n-gram vectors to represent healthcare web page documents. The training/testing collection comprised web page fragments extracted by HONcode experts during the manual certification process. The authors compared automated classification performance of n-gram tokenization to the automated classification performance of document words and Porter-stemmed document words using a Naive Bayes classifier and DF (document frequency) dimensionality reduction metrics. The study attempted to determine whether the automated, language-independent approach might safely replace word-based classification. Using 5-grams as document features, authors also compared the baseline DF reduction function to Chi-square and Z-score dimensionality reductions. Overall study results indicate that n-gram tokenization provided a potentially viable alternative to document word stemming.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Boyer, Célia and Dolamic, Ljiljana and Grabar, Natalia},
	year = {2015},
	pmid = {26262363},
	pages = {1064}
}

@article{richards_type/token_1987,
	title = {Type/{Token} {Ratios}: what do they really tell us?},
	volume = {14},
	issn = {0305-0009},
	shorttitle = {Type/{Token} {Ratios}},
	language = {eng},
	number = {2},
	journal = {Journal of Child Language},
	author = {Richards, B.},
	month = jun,
	year = {1987},
	pmid = {3611238},
	keywords = {tokenization},
	pages = {201--209}
}

@article{manschreck_formal_1981,
	title = {Formal thought disorder, the type-token ratio and disturbed voluntary motor movement in schizophrenia},
	volume = {139},
	issn = {0007-1250},
	abstract = {Little work has been done to determine objective, reliable differences in formal characteristics of the actual utterances of thought-disordered and non-thought-disordered subjects. The type-token ratio (TTR), a quantitative measure of repetition in language, correlated highly with clinical judgments of thought disorder when spoken language was examined, and statistically differentiated thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. Elicited and spontaneous motor abnormalities were associated with reduced TTRs both in schizophrenics and in affective subjects with motor disturbance. The TTR is a reliable, objective indicator of language deviance and thought disorder, and strongly associated with motor disturbances.},
	language = {eng},
	journal = {The British Journal of Psychiatry: The Journal of Mental Science},
	author = {Manschreck, T. C. and Maher, B. A. and Ader, D. N.},
	month = jul,
	year = {1981},
	pmid = {6117348},
	keywords = {tokenization},
	pages = {7--15}
}

@article{hess_sample_1986,
	title = {Sample size and type-token ratios for oral language of preschool children},
	volume = {29},
	issn = {0022-4685},
	abstract = {This study investigated the stability of five type-token ratios (TTRs) in 50-utterance oral language samples segmented into nine lengths. The samples were obtained from 83 children, 3, 4, and 5 years of age. The five TTRs included the basic type-token ratio, the corrected type-token ratio, the root type-token ratio, the bilogarithmic type-token ratio, and the Characteristic K. The sample segment sizes consisted of the first, second, third, and fourth 50-word segments; the first and second 100-word segments; the first 150-word segment; the first 200-word segment; and the total 50-utterance sample. Based on the results of this study, TTR measures on the language of young children should not be compared for samples that differ in number of words. Further, TTR measures for sample size of 50 and 100 words have reliabilities that are judged to be inadequate for research or clinical purposes. The size of the language sample needed for minimum reliability of .70 is 350 words. Greater reliability requires larger word-sample size.},
	language = {eng},
	number = {1},
	journal = {Journal of Speech and Hearing Research},
	author = {Hess, C. W. and Sefton, K. M. and Landry, R. G.},
	month = mar,
	year = {1986},
	pmid = {3702374},
	keywords = {reproducibility, tokenization},
	pages = {129--134}
}

@article{tomanek_reappraisal_2007,
	title = {A reappraisal of sentence and token splitting for life sciences documents},
	volume = {129},
	issn = {0926-9630},
	abstract = {Natural language processing of real-world documents requires several low-level tasks such as splitting a piece of text into its constituent sentences, and splitting each sentence into its constituent tokens to be performed by some preprocessor (prior to linguistic analysis). While this task is often considered as unsophisticated clerical work, in the life sciences domain it poses enormous problems due to complex naming conventions. In this paper, we first introduce an annotation framework for sentence and token splitting underlying a newly constructed sentence- and token-tagged biomedical text corpus. This corpus serves as a training environment and test bed for machine-learning based sentence and token splitters using Conditional Random Fields (CRFs). Our evaluation experiments reveal that CRFs with a rich feature set substantially increase sentence and token detection performance.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Tomanek, Katrin and Wermter, Joachim and Hahn, Udo},
	year = {2007},
	pmid = {17911772},
	keywords = {female first or senior, tokenization},
	pages = {524--528}
}

@misc{noauthor_ios_nodate,
	title = {{IOS} {Press} {Ebooks} - {A} {Reappraisal} of {Sentence} and {Token} {Splitting} for {Life} {Sciences} {Documents}},
	url = {http://ebooks.iospress.nl/publication/11031},
	urldate = {2018-02-17},
	keywords = {tokenization},
	file = {IOS Press Ebooks - A Reappraisal of Sentence and Token Splitting for Life Sciences Documents:/Users/transfer/Zotero/storage/KICQDLLH/11031.html:text/html}
}

@article{baracchini_[language_1970,
	title = {[{Language} in mental retardates: the {Type}-{Token} ratio]},
	volume = {16},
	issn = {0035-6336},
	shorttitle = {[{Language} in mental retardates},
	language = {ita},
	number = {2},
	journal = {Rivista Di Neurobiologia: Organo Ufficiale Della Societa Dei Neurologi, Neuroradiologi E Neurochirurghi Ospedalieri},
	author = {Baracchini, G. and Bickel, J. and Bertocchini, M.},
	month = jun,
	year = {1970},
	pmid = {5505861},
	keywords = {tokenization},
	pages = {235--240}
}

@article{de_renzi_token_1962,
	title = {The token test: {A} sensitive test to detect receptive disturbances in aphasics},
	volume = {85},
	issn = {0006-8950},
	shorttitle = {The token test},
	language = {eng},
	journal = {Brain: A Journal of Neurology},
	author = {De Renzi, E. and Vignolo, L. A.},
	month = dec,
	year = {1962},
	pmid = {14026018},
	keywords = {tokenization},
	pages = {665--678}
}

@article{moscoso_del_prado_martin_type_2004,
	title = {Do type and token effects reflect different mechanisms? {Connectionist} modeling of {Dutch} past-tense formation and final devoicing},
	volume = {90},
	issn = {0093-934X},
	shorttitle = {Do type and token effects reflect different mechanisms?},
	doi = {10.1016/j.bandl.2003.12.002},
	abstract = {In this paper, we show that both token and type-based effects in lexical processing can result from a single, token-based, system, and therefore, do not necessarily reflect different levels of processing. We report three Simple Recurrent Networks modeling Dutch past-tense formation. These networks show token-based frequency effects and type-based analogical effects closely matching the behavior of human participants when producing past-tense forms for both existing verbs and pseudo-verbs. The third network covers the full vocabulary of Dutch, without imposing predefined linguistic structure on the input or output words.},
	language = {eng},
	number = {1-3},
	journal = {Brain and Language},
	author = {Moscoso del Prado Martín, Fermín and Ernestus, Mirjam and Harald Baayen, R.},
	month = sep,
	year = {2004},
	pmid = {15172546},
	keywords = {tokenization},
	pages = {287--298}
}

@inproceedings{sogaard_whats_2014,
	title = {What's in a p-value in {NLP}?},
	booktitle = {Proceedings of the eighteenth conference on computational natural language learning},
	author = {Søgaard, Anders and Johannsen, Anders and Plank, Barbara and Hovy, Dirk and Alonso, Héctor Martínez},
	year = {2014},
	keywords = {reproducibility, stats},
	pages = {1--10},
	file = {Fulltext:/Users/transfer/Zotero/storage/RKSI55DA/Søgaard et al. - 2014 - What's in a p-value in NLP.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/8AS7T8FI/Søgaard et al. - 2014 - What's in a p-value in NLP.pdf:application/pdf}
}

@article{church_how_2013,
	title = {How many multiword expressions do people know?},
	volume = {10},
	number = {2},
	journal = {ACM Transactions on Speech and Language Processing (TSLP)},
	author = {Church, Kenneth},
	year = {2013},
	pages = {4},
	file = {Fulltext:/Users/transfer/Zotero/storage/C9ACRVZK/Church - 2013 - How many multiword expressions do people know.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MSBDK8YD/citation.html:text/html}
}

@inproceedings{church_one_1995,
	title = {One term or two?},
	booktitle = {Proceedings of the 18th annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {ACM},
	author = {Church, Kenneth Ward},
	year = {1995},
	keywords = {tokenization},
	pages = {310--318},
	file = {Fulltext:/Users/transfer/Zotero/storage/FYY5IXU9/Church - 1995 - One term or two.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ZTSPNXYI/citation.html:text/html}
}

@incollection{church_inverse_1999,
	title = {Inverse document frequency (idf): {A} measure of deviations from poisson},
	shorttitle = {Inverse document frequency (idf)},
	booktitle = {Natural language processing using very large corpora},
	publisher = {Springer},
	author = {Church, Kenneth and Gale, William},
	year = {1999},
	pages = {283--295},
	file = {Fulltext:/Users/transfer/Zotero/storage/GQ7E8H2T/Church and Gale - 1999 - Inverse document frequency (idf) A measure of dev.pdf:application/pdf;Fulltext:/Users/transfer/Zotero/storage/TC44PJBV/Church and Gale - 1999 - Inverse document frequency (idf) A measure of dev.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/G8EDYSCR/978-94-017-2390-9_18.html:text/html}
}

@article{church_pendulum_2011,
	title = {A pendulum swung too far},
	volume = {6},
	number = {5},
	journal = {Linguistic Issues in Language Technology},
	author = {Church, Kenneth},
	year = {2011},
	pages = {1--27},
	file = {Fulltext:/Users/transfer/Zotero/storage/GLJVTAD7/Church - 2011 - A pendulum swung too far.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LHS6QHQG/Church - 2011 - A pendulum swung too far.pdf:application/pdf}
}

@article{church_next_2016,
	title = {The next generation},
	volume = {22},
	number = {6},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth Ward},
	year = {2016},
	pages = {977--980},
	file = {Fulltext:/Users/transfer/Zotero/storage/G8Y54LGB/Church - 2016 - The next generation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/V7IN4VPL/5A007435473C0C8A441AC76B16C10EA5.html:text/html}
}

@inproceedings{umemura_empirical_2000,
	title = {Empirical term weighting and expansion frequency},
	booktitle = {Proceedings of the 2000 {Joint} {SIGDAT} conference on {Empirical} methods in natural language processing and very large corpora: held in conjunction with the 38th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}-{Volume} 13},
	publisher = {Association for Computational Linguistics},
	author = {Umemura, Kyoji and Church, Kenneth W.},
	year = {2000},
	pages = {117--123},
	file = {Fulltext:/Users/transfer/Zotero/storage/2KUQDGIP/Umemura and Church - 2000 - Empirical term weighting and expansion frequency.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/A4TX7MBL/citation.html:text/html}
}

@article{church_reviewing_2005,
	title = {Reviewing the reviewers},
	volume = {31},
	number = {4},
	journal = {Computational Linguistics},
	author = {Church, Kenneth},
	year = {2005},
	pages = {575--578},
	file = {Fulltext:/Users/transfer/Zotero/storage/NNMHJCNL/Church - 2005 - Reviewing the reviewers.pdf:application/pdf;Fulltext:/Users/transfer/Zotero/storage/X3DSZMHK/Church - 2005 - Reviewing the reviewers.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XJDF9JQX/Church - 2005 - Reviewing the reviewers.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GFBQ2WZM/Church - 2005 - Reviewing the reviewers.pdf:application/pdf}
}

@article{church_emerging_2017,
	title = {Emerging trends: {Inflation}},
	volume = {23},
	shorttitle = {Emerging trends},
	number = {5},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth},
	year = {2017},
	pages = {807--812},
	file = {Fulltext:/Users/transfer/Zotero/storage/JAQQDTWT/Church - 2017 - Emerging trends Inflation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/W34X7MVV/66B6A22C42CF2342989F492101E80C23.html:text/html}
}

@article{church_emerging_2017-1,
	title = {Emerging trends: {I} did it, {I} did it, {I} did it, but...},
	volume = {23},
	shorttitle = {Emerging trends},
	number = {3},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth Ward},
	year = {2017},
	pages = {473--480},
	file = {Fulltext:/Users/transfer/Zotero/storage/2RFFZR2G/Church - 2017 - Emerging trends I did it, I did it, I did it, but.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YFEUTZRX/E04A550C6DFF0154C684888B7B9F68EA.html:text/html}
}

@article{church_word2vec_2017,
	title = {Word2Vec},
	volume = {23},
	number = {1},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth Ward},
	year = {2017},
	pages = {155--162},
	file = {Fulltext:/Users/transfer/Zotero/storage/Z97DIRNC/Church - 2017 - Word2Vec.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/9BM3EJXI/B84AE4446BD47F48847B4904F0B36E0B.html:text/html}
}

@article{church_poisson_1995,
	title = {Poisson mixtures},
	volume = {1},
	issn = {1469-8110, 1351-3249},
	url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/poisson-mixtures/52E7F9429D0EC03EEC6674E071727B64},
	doi = {10.1017/S1351324900000139},
	abstract = {AbstractShannon (1948) showed that a wide range of practical problems can be reduced to the problem of estimating probability distributions of words and ngrams in text. It has become standard practice in text compression, speech recognition, information retrieval and many other applications of Shannon's theory to introduce a “bag-of-words” assumption. But obviously, word rates vary from genre to genre, author to author, topic to topic, document to document, section to section, and paragraph to paragraph. The proposed Poisson mixture captures much of this heterogeneous structure by allowing the Poisson parameter θ to vary over documents subject to a density function φ. φ is intended to capture dependencies on hidden variables such genre, author, topic, etc. (The Negative Binomial is a well-known special case where φ is a Г distribution.) Poisson mixtures fit the data better than standard Poissons, producing more accurate estimates of the variance over documents (σ2), entropy (H), inverse document frequency (IDF), and adaptation (Pr(x ≥ 2/x ≥ 1)).},
	language = {en},
	number = {2},
	urldate = {2018-02-17},
	journal = {Natural Language Engineering},
	author = {Church, Kenneth W. and Gale, William A.},
	month = jun,
	year = {1995},
	pages = {163--190},
	file = {Snapshot:/Users/transfer/Zotero/storage/3R6MKG32/52E7F9429D0EC03EEC6674E071727B64.html:text/html}
}

@article{haas_last_1968,
	title = {The last words of {Biloxi}},
	volume = {34},
	number = {2},
	journal = {International Journal of American Linguistics},
	author = {Haas, Mary R.},
	year = {1968},
	pages = {77--84},
	file = {Snapshot:/Users/transfer/Zotero/storage/8QKL8LNU/465000.html:text/html}
}

@article{kilgarriff_googleology_2007,
	title = {Googleology is bad science},
	volume = {33},
	number = {1},
	journal = {Computational linguistics},
	author = {Kilgarriff, Adam},
	year = {2007},
	keywords = {reproducibility},
	pages = {147--151},
	file = {Fulltext:/Users/transfer/Zotero/storage/YIVYA5G3/Kilgarriff - 2007 - Googleology is bad science.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SDNSP4NP/Kilgarriff - 2007 - Googleology is bad science.pdf:application/pdf}
}

@article{wintner_what_2009,
	title = {What science underlies natural language engineering?},
	volume = {35},
	number = {4},
	journal = {Computational Linguistics},
	author = {Wintner, Shuly},
	year = {2009},
	pages = {641--644},
	file = {Fulltext:/Users/transfer/Zotero/storage/C2ENI6VJ/Wintner - 2009 - What science underlies natural language engineerin.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/M3VCWC9C/Wintner - 2009 - What science underlies natural language engineerin.pdf:application/pdf}
}

@article{reiter_shrinking_2007,
	title = {The shrinking horizons of computational linguistics},
	volume = {33},
	number = {2},
	journal = {Computational Linguistics},
	author = {Reiter, Ehud},
	year = {2007},
	pages = {283--287},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZTP8TW43/Reiter - 2007 - The shrinking horizons of computational linguistic.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/NDLI6MWT/Reiter - 2007 - The shrinking horizons of computational linguistic.pdf:application/pdf}
}

@article{fort_amazon_2011,
	title = {Amazon mechanical turk: {Gold} mine or coal mine?},
	volume = {37},
	shorttitle = {Amazon mechanical turk},
	number = {2},
	journal = {Computational Linguistics},
	author = {Fort, Karën and Adda, Gilles and Cohen, K. Bretonnel},
	year = {2011},
	keywords = {female first or senior},
	pages = {413--420},
	file = {Fulltext:/Users/transfer/Zotero/storage/LJSEULAV/Fort et al. - 2011 - Amazon mechanical turk Gold mine or coal mine.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/B7JP74M4/Fort et al. - 2011 - Amazon mechanical turk Gold mine or coal mine.pdf:application/pdf}
}

@article{krahmer_what_2010,
	title = {What computational linguists can learn from psychologists (and vice versa)},
	volume = {36},
	number = {2},
	journal = {Computational linguistics},
	author = {Krahmer, Emiel},
	year = {2010},
	pages = {285--294},
	file = {Fulltext:/Users/transfer/Zotero/storage/YK5YR3ST/Krahmer - 2010 - What computational linguists can learn from psycho.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/8Y292YUZ/Krahmer - 2010 - What computational linguists can learn from psycho.pdf:application/pdf}
}

@article{pedersen_empiricism_2008,
	title = {Empiricism is not a matter of faith},
	volume = {34},
	number = {3},
	journal = {Computational Linguistics},
	author = {Pedersen, Ted},
	year = {2008},
	keywords = {reproducibility, rep},
	pages = {465--470},
	file = {Fulltext:/Users/transfer/Zotero/storage/VPG5CRPN/Pedersen - 2008 - Empiricism is not a matter of faith.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/AIZ9RAY7/citation.html:text/html}
}

@article{jones_computational_2007,
	title = {Computational linguistics: what about the linguistics?},
	volume = {33},
	shorttitle = {Computational linguistics},
	number = {3},
	journal = {Computational linguistics},
	author = {Jones, Karen Spärck},
	year = {2007},
	keywords = {female first or senior},
	pages = {437--441},
	file = {Fulltext:/Users/transfer/Zotero/storage/QL72HB2Q/Jones - 2007 - Computational linguistics what about the linguist.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6NFYXEKA/Jones - 2007 - Computational linguistics what about the linguist.pdf:application/pdf}
}

@article{bird_natural_2009,
	title = {Natural language processing and linguistic fieldwork},
	volume = {35},
	number = {3},
	journal = {Computational linguistics},
	author = {Bird, Steven},
	year = {2009},
	pages = {469--474},
	file = {Fulltext:/Users/transfer/Zotero/storage/T4RH4I2I/Bird - 2009 - Natural language processing and linguistic fieldwo.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6YFLTRNT/Bird - 2009 - Natural language processing and linguistic fieldwo.pdf:application/pdf}
}

@article{rosenfeld_two_2000,
	title = {Two decades of statistical language modeling: {Where} do we go from here?},
	volume = {88},
	shorttitle = {Two decades of statistical language modeling},
	number = {8},
	journal = {Proceedings of the IEEE},
	author = {Rosenfeld, Ronald},
	year = {2000},
	pages = {1270--1278},
	file = {Fulltext:/Users/transfer/Zotero/storage/YWI7P5NB/Rosenfeld - 2000 - Two decades of statistical language modeling Wher.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3UFPHZ4R/880083.html:text/html}
}

@article{steedman_becoming_2008,
	title = {On becoming a discipline},
	volume = {34},
	number = {1},
	journal = {Computational Linguistics},
	author = {Steedman, Mark},
	year = {2008},
	pages = {137--144},
	file = {Fulltext:/Users/transfer/Zotero/storage/MTY66PXV/Steedman - 2008 - On becoming a discipline.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/7ZYJ723H/Steedman - 2008 - On becoming a discipline.pdf:application/pdf}
}

@inproceedings{hall_less_2014,
	title = {Less grammar, more features},
	volume = {1},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	author = {Hall, David and Durrett, Greg and Klein, Dan},
	year = {2014},
	pages = {228--237},
	file = {Fulltext:/Users/transfer/Zotero/storage/WVB8GBIK/Hall et al. - 2014 - Less grammar, more features.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/Z2G8MASH/Hall et al. - 2014 - Less grammar, more features.pdf:application/pdf}
}

@inproceedings{smeaton_information_1997,
	title = {Information retrieval: {Still} butting heads with natural language processing?},
	shorttitle = {Information retrieval},
	booktitle = {International {Summer} {School} on {Information} {Extraction}},
	publisher = {Springer},
	author = {Smeaton, Alan F.},
	year = {1997},
	pages = {115--138},
	file = {Fulltext:/Users/transfer/Zotero/storage/5PGHH2V5/Smeaton - 1997 - Information retrieval Still butting heads with na.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/NBGFK3IM/3-540-63438-X_7.html:text/html}
}

@article{smith_linguistic_2011,
	title = {Linguistic structure prediction},
	volume = {4},
	number = {2},
	journal = {Synthesis lectures on human language technologies},
	author = {Smith, Noah A.},
	year = {2011},
	pages = {1--274},
	file = {Fulltext:/Users/transfer/Zotero/storage/K6VTZ65D/Smith - 2011 - Linguistic structure prediction.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3DM62UWU/S00361ED1V01Y201105HLT013.html:text/html}
}

@article{jelinek_dawn_2009,
	title = {The dawn of statistical {ASR} and {MT}},
	volume = {35},
	number = {4},
	journal = {Computational Linguistics},
	author = {Jelinek, Frederick},
	year = {2009},
	pages = {483--494},
	file = {Fulltext:/Users/transfer/Zotero/storage/45AHSRYE/Jelinek - 2009 - The dawn of statistical ASR and MT.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/NQ3PWYAH/citation.html:text/html}
}

@article{alviar_recent_2008,
	title = {Recent advances in computational linguistics and their application to {Biblical} studies},
	volume = {54},
	number = {1},
	journal = {New Testament Studies},
	author = {Alviar, J. Jose},
	year = {2008},
	pages = {139--159},
	file = {Snapshot:/Users/transfer/Zotero/storage/4EE77UNN/15DB6C331FB84E8D9E6640AE1DFAE073.html:text/html}
}

@article{bodenreider_ontology-epistemology_2004,
	title = {The {Ontology}-{Epistemology} {Divide}: {A} {Case} {Study} in {Medical} {Terminology}},
	volume = {2004},
	shorttitle = {The {Ontology}-{Epistemology} {Divide}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4346778/},
	abstract = {Medical terminology collects and organizes the many different kinds of terms employed in the biomedical domain both by practitioners and also in the course of biomedical research. In addition to serving as labels for biomedical classes, these names reflect the organizational principles of biomedical vocabularies and ontologies. Some names represent invariant features (classes, universals) of biomedical reality (i.e., they are a matter for ontology). Other names, however, convey also how this reality is perceived, measured, and understood by health professionals (i.e., they belong to the domain of epistemology). We analyze terms from several biomedical vocabularies in order to throw light on the interactions between ontological and epistemological components of these terminologies. We identify four cases: 1) terms containing classification criteria, 2) terms reflecting detectability, modality, uncertainty, and vagueness, 3) terms created in order to obtain a complete partition of a given domain, and 4) terms reflecting mere fiat boundaries. We show that epistemology-loaded terms are pervasive in biomedical vocabularies, that the “classes” they name often do not comply with sound classification principles, and that they are therefore likely to cause problems in the evolution and alignment of terminologies and associated ontologies.},
	urldate = {2018-02-21},
	journal = {Formal ontology in information systems : proceedings of the ... International Conference. FOIS (Conference)},
	author = {BODENREIDER, Olivier and SMITH, Barry and BURGUN, Anita},
	year = {2004},
	pmid = {25745641},
	pmcid = {PMC4346778},
	pages = {185--195},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/M6L8WMX4/BODENREIDER et al. - 2004 - The Ontology-Epistemology Divide A Case Study in .pdf:application/pdf}
}

@article{marwede_epistemological-ontological_2005,
	title = {The epistemological-ontological divide in clinical radiology},
	volume = {116},
	issn = {0926-9630},
	abstract = {Medical ontologies like GALEN, the FMA or SNOMED represent a kind of "100\% certain" medical knowledge which is not inherent to all medical sub-domains. Clinical radiology uses computerized imaging techniques to make the human body visible and interprets the imaging findings in a clinical context delivering a textual report. For clinical radiology few standardized vocabularies are available. We examined the definitions given in the glossary of terms for thoracic radiology published by the Fleischner Society. We further classified these terms with regard to their definitions in terms of (a) describing visible structures on the image itself, (b) referring to ontological entities of the body (anatomical or pathological), and (c) terms imposing knowledge on structures visible on the image, epistemologically representing ontological entities of the body. Each ontological/epistemological definition was rated on a scale of vague/weak-sound/strong and put in context with the evaluation comments for the use of the terms given in the glossary itself. The result of this distinction shows that clinical radiology uses many terms referring to ontological entities valid for representation in a medical ontology. However, many epistemological terms exist in the terminology which impose epistemological knowledge on ontological entities. The analysis of the evaluation comments reveals that terms classified as sound (ontologically) and strong (epistemologically) are evaluated higher than terms bearing vague or weak definitions. On the basis of this, we argue that the distinction between ontological and epistemological definitions is necessary in order to construct epistemologically-sensitive application ontologies for medical sub-domains, like clinical radiology, where knowledge is fragmented in terms of description, inferred from a description, concluded on the basis of imaging, or other additional information with varying degrees of certainty.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Marwede, Dirk and Fielding, Matthew},
	year = {2005},
	pmid = {16160348},
	pages = {749--754}
}

@article{schulz_bridging_2010,
	title = {Bridging the semantics gap between terminologies, ontologies, and information models},
	volume = {160},
	issn = {0926-9630},
	abstract = {SNOMED CT and other biomedical vocabularies provide semantic identifiers for all kinds of linguistic expressions, many of which cannot be considered terms in a strict sense. We analyzed such "non-terms" in SNOMED CT and concluded that many of them cannot be interpreted as directly referring to objects or processes, but rather to information entities. Discussing two approaches to represent information entities, viz. the OBO Information artifact ontology (IAO) and the HL7 v3 Reference Information Model (RIM), we propose an integrative solution for representing information entities in SNOMED CT, in a way that is still compatible with RIM and the IAO and uses moderately enhanced description logics.},
	language = {eng},
	number = {Pt 2},
	journal = {Studies in Health Technology and Informatics},
	author = {Schulz, Stefan and Schober, Daniel and Daniel, Christel and Jaulent, Marie-Christine},
	year = {2010},
	pmid = {20841834},
	keywords = {female first or senior},
	pages = {1000--1004},
	file = {SHTI160-1000.pdf:/Users/transfer/Zotero/storage/XWVREKGT/SHTI160-1000.pdf:application/pdf}
}

@article{richard_patient_2017,
	title = {From {Patient} {Discharge} {Summaries} to an {Ontology} for {Psychiatry}},
	volume = {245},
	issn = {0926-9630},
	abstract = {Psychiatry aims at detecting symptoms, providing diagnoses and treating mental disorders. We developed ONTOPSYCHIA, an ontology for psychiatry in three modules: social and environmental factors of mental disorders, mental disorders, and treatments. The use of ONTOPSYCHIA, associated with dedicated tools, will facilitate semantic research in Patient Discharge Summaries (PDS). To develop the first module of the ontology we propose a PDS text analysis in order to explicit psychiatry concepts. We decided to set aside classifications during the construction of the modu le, to focus only on the information contained in PDS (bottom-up approach) and to return to domain classifications solely for the enrichment phase (top-down approach). Then, we focused our work on the development of the LOVMI methodology (Les Ontologies Validées par Méthode Interactive - Ontologies Validated by Interactive Method), which aims to provide a methodological framework to validate the structure and the semantic of an ontology.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Richard, Marion and Aimé, Xavier and Jaulent, Marie-Christine and Krebs, Marie-Odile and Charlet, Jean},
	year = {2017},
	pmid = {29295236},
	pages = {930--934}
}

@article{pares_towards_2014,
	title = {Towards an automatic harmonization of the representation of medical reports to assess their similarities},
	volume = {205},
	issn = {0926-9630},
	abstract = {Numerous hospitals contain unexploited knowledge deposits. These often take the form of unstructured records with heterogeneous content, which, at various levels of those organizations, register past cases. Those records are for instance patient medical records. Accessing the knowledge and experience they gather would help us to handle present cases. We present here a method to normalize textual reports in foetopathology in order to constitute a proper case base that will be the target of case-based reasoning techniques. Statistics of noise and silence generated by this method on 10 cases are presented.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Parès, Yves and Aimé, Xavier and Charlet, Jean and Jaulent, Marie-Christine},
	year = {2014},
	pmid = {25160309},
	pages = {858--862}
}

@article{baneyx_methodology_2006,
	title = {Methodology to build medical ontology from textual resources},
	issn = {1942-597X},
	abstract = {In the medical field, it is now established that the maintenance of unambiguous thesauri goes through ontologies. Our research task is to help pneumologists code acts and diagnoses with a software that represents medical knowledge through a domain ontology. In this paper, we describe our general methodology aimed at knowledge engineers in order to build various types of medical ontologies based on terminology extraction from texts. The hypothesis is to apply natural language processing tools to textual patient discharge summaries to develop the resources needed to build an ontology in pneumology. Results indicate that the joint use of distributional analysis and lexico-syntactic patterns performed satisfactorily for building such ontologies.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Baneyx, Audrey and Charlet, Jean and Jaulent, Marie-Christine},
	year = {2006},
	pmid = {17238295},
	pmcid = {PMC1839277},
	pages = {21--25}
}

@article{baneyx_building_2007,
	title = {Building an ontology of pulmonary diseases with natural language processing tools using textual corpora},
	volume = {76},
	issn = {1386-5056},
	doi = {10.1016/j.ijmedinf.2006.05.031},
	abstract = {Pathologies and acts are classified in thesauri to help physicians to code their activity. In practice, the use of thesauri is not sufficient to reduce variability in coding and thesauri are not suitable for computer processing. We think the automation of the coding task requires a conceptual modeling of medical items: an ontology. Our task is to help lung specialists code acts and diagnoses with software that represents medical knowledge of this concerned specialty by an ontology. The objective of the reported work was to build an ontology of pulmonary diseases dedicated to the coding process. To carry out this objective, we develop a precise methodological process for the knowledge engineer in order to build various types of medical ontologies. This process is based on the need to express precisely in natural language the meaning of each concept using differential semantics principles. A differential ontology is a hierarchy of concepts and relationships organized according to their similarities and differences. Our main research hypothesis is to apply natural language processing tools to corpora to develop the resources needed to build the ontology. We consider two corpora, one composed of patient discharge summaries and the other being a teaching book. We propose to combine two approaches to enrich the ontology building: (i) a method which consists of building terminological resources through distributional analysis and (ii) a method based on the observation of corpus sequences in order to reveal semantic relationships. Our ontology currently includes 1550 concepts and the software implementing the coding process is still under development. Results show that the proposed approach is operational and indicates that the combination of these methods and the comparison of the resulting terminological structures give interesting clues to a knowledge engineer for the building of an ontology.},
	language = {eng},
	number = {2-3},
	journal = {International Journal of Medical Informatics},
	author = {Baneyx, Audrey and Charlet, Jean and Jaulent, Marie-Christine},
	month = mar,
	year = {2007},
	pmid = {16797227},
	pages = {208--215}
}

@article{charlet_building_2006,
	title = {Building medical ontologies by terminology extraction from texts: an experiment for the intensive care units},
	volume = {36},
	issn = {0010-4825},
	shorttitle = {Building medical ontologies by terminology extraction from texts},
	doi = {10.1016/j.compbiomed.2005.04.012},
	abstract = {In many medical fields, maintenance, comparison and aggregation of unambiguous terminologies go through formal specialized clinical terminologies: ontologies. We describe a methodology to build medical ontology from textual reports using a natural language processing tool, the SYNTEX software. The methodology is illustrated in the surgical intensive care medical domain. We have tested the possibility for an expert to build a sizeable ontology in a reasonable time. The quality of the ontology has been evaluated according to its capacity to cover the ICD-10 terminology in the field. Finally, the methodology itself is discussed.},
	language = {eng},
	number = {7-8},
	journal = {Computers in Biology and Medicine},
	author = {Charlet, Jean and Bachimont, Bruno and Jaulent, Marie-Christine},
	month = aug,
	year = {2006},
	pmid = {16198328},
	pages = {857--870}
}

@article{baneyx_building_2005,
	title = {Building medical ontologies based on terminology extraction from texts: an experimentation in pneumology},
	volume = {116},
	issn = {0926-9630},
	shorttitle = {Building medical ontologies based on terminology extraction from texts},
	abstract = {Pathologies and acts are classified in thesauri to help physicians to code their activity. In practice, the use of thesauri is not sufficient to reduce variability in coding and thesauri do not fit computer processing. We think the automation of the coding task requires a conceptual modelling of medical items: an ontology. Our objective is to help pneumologists code acts and diagnoses with a software that represents medical knowledge by an ontology of the concerned specialty. The main research hypothesis is to apply natural language processing tools to corpora to develop the resources needed to build the ontology. In this paper, our objective is twofold: we have to build the ontology of pneumology and we want to develop a methodology for the knowledge engineer to build various types of medical ontologies based on terminology extraction from texts.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Baneyx, Audrey and Charlet, Jean and Jaulent, Marie-Christine},
	year = {2005},
	pmid = {16160333},
	pages = {659--664}
}

@article{le_moigno_terminology_2002,
	title = {Terminology extraction from text to build an ontology in surgical intensive care},
	issn = {1531-605X},
	abstract = {In many medical fields, the maintenance of unabiguous terminologies, the comparison and aggregation of different terminologies go through the building of formal specialized clinical terminologies, the ontologies. In this paper, we describe the building of an ontology in the surgical intensive care medical domain. We considered textual reports as the main source of information and a natural language processing tool, the SYNTEX software, is used to build the ontology. We have tested the possibility for an expert to build a sizeable ontology in a reasonable time. The quality of the ontology has been evaluated according to its capacity to cover the ICD-10 terminology in the field. Examples of coding activity with the ontology are proposed and discussed.},
	language = {eng},
	journal = {Proceedings. AMIA Symposium},
	author = {Le Moigno, Sophie and Charlet, Jean and Bourigault, Didier and Degoulet, Patrice and Jaulent, Marie-Christine},
	year = {2002},
	pmid = {12463860},
	pmcid = {PMC2244325},
	pages = {430--434}
}

@article{lehmann_troubled_2016,
	title = {Troubled {Waters}: {Navigating} {Unintended} {Consequences} of {Health} {Information} {Technology}},
	issn = {0943-4747},
	shorttitle = {Troubled {Waters}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5171549/},
	doi = {10.15265/IY-2016-056},
	abstract = {Objectives
To provide an introduction to the 2016 IMIA Yearbook of Medical Informatics by the editors.

Methods
We present a brief overview of the 2016 special topic “Unintended consequences of Health IT: new problems, new solutions”, we review our choice of special topic section editors, and discuss the transitions in the editorial team for next year.

Results
This edition of the Yearbook acknowledges the fact that implementation and use of Health Information Technology (HIT) may result in unintended consequences, which may lead to both adverse and sometimes beneficial outcomes. However to date, in the literature, undesired outcomes are emphasized with a focus on the complex causes and the many sources that may generate them. The growing awareness of the importance of HIT’s unintended consequences and their increasing documentation reflect a wider acceptance of HIT by users (more use generating more consequences) and and a new type of users (a shift from early adopters to late adopters and laggards), whith great expectations regarding the improvement of care quality through HIT solutions. Different points of view on new problems and new solutions of unintended consequences of Health IT are presented through the keynote paper, survey papers, and the working group contributions.

Conclusions
The regular 2016 issue of the IMIA yearbook focuses on new unintended consequences of Health IT – brought on by wider adoption and different types of users as well as solutions to addressing them.},
	number = {1},
	urldate = {2018-02-21},
	journal = {Yearbook of Medical Informatics},
	author = {Lehmann, C. U. and Séroussi, B. and Jaulent, M.-C.},
	month = nov,
	year = {2016},
	pmid = {27830225},
	pmcid = {PMC5171549},
	pages = {5--6},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/S9RHTGGQ/Lehmann et al. - 2016 - Troubled Waters Navigating Unintended Consequence.pdf:application/pdf}
}

@inproceedings{noauthor_structural_nodate,
	title = {Structural ambiguity and conceptual information retrieval},
	file = {Y95-1015 (2).pdf:/Users/transfer/Zotero/storage/76Z3WI7Z/Y95-1015 (2).pdf:application/pdf}
}

@inproceedings{tomanek_sentence_2007,
	title = {Sentence and token splitting based on conditional random fields},
	volume = {49},
	booktitle = {Proceedings of the 10th {Conference} of the {Pacific} {Association} for {Computational} {Linguistics}},
	author = {Tomanek, Katrin and Wermter, Joachim and Hahn, Udo},
	year = {2007},
	pages = {57},
	file = {Fulltext:/Users/transfer/Zotero/storage/7TRTD3WR/Tomanek et al. - 2007 - Sentence and token splitting based on conditional .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3ZZ5BL69/Tomanek et al. - 2007 - Sentence and token splitting based on conditional .pdf:application/pdf}
}

@inproceedings{tomanek_reappraisal_2007-1,
	title = {A reappraisal of sentence and token splitting for life sciences documents},
	booktitle = {Medinfo 2007: {Proceedings} of the 12th {World} {Congress} on {Health} ({Medical}) {Informatics}; {Building} {Sustainable} {Health} {Systems}},
	publisher = {IOS Press},
	author = {Tomanek, Katrin and Wermter, Joachim and Hahn, Udo},
	year = {2007},
	pages = {524},
	file = {Snapshot:/Users/transfer/Zotero/storage/ABH4EMXB/documentSummary\;dn=771702544377115\;res=IELHEA.html:text/html}
}

@article{blankenship_linguistic_1962,
	title = {A linguistic analysis of oral and written style},
	volume = {48},
	number = {4},
	journal = {Quarterly Journal of Speech},
	author = {Blankenship, Jane},
	year = {1962},
	pages = {419--422},
	file = {Snapshot:/Users/transfer/Zotero/storage/6Z2ZUR8K/00335636209382571.html:text/html}
}

@article{grefenstette_what_1994,
	title = {What is a word, what is a sentence?: problems of {Tokenisation}},
	shorttitle = {What is a word, what is a sentence?},
	author = {Grefenstette, Gregory and Tapanainen, Pasi},
	year = {1994},
	file = {Fulltext:/Users/transfer/Zotero/storage/SUGV3JH2/Grefenstette and Tapanainen - 1994 - What is a word, what is a sentence problems of T.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XICDN3EH/Grefenstette and Tapanainen - 1994 - What is a word, what is a sentence problems of T.pdf:application/pdf}
}

@inproceedings{silla_analysis_2004,
	title = {An analysis of sentence boundary detection systems for {English} and {Portuguese} documents},
	booktitle = {International {Conference} on {Intelligent} {Text} {Processing} and {Computational} {Linguistics}},
	publisher = {Springer},
	author = {Silla, Carlos N. and Kaestner, Celso AA},
	year = {2004},
	keywords = {tokenization},
	pages = {135--141},
	file = {Fulltext:/Users/transfer/Zotero/storage/RJ5WLIVZ/Silla and Kaestner - 2004 - An analysis of sentence boundary detection systems.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/QL2XLJEE/978-3-540-24630-5_16.html:text/html}
}

@inproceedings{walker_sentence_2001,
	title = {Sentence boundary detection: {A} comparison of paradigms for improving {MT} quality},
	volume = {58},
	shorttitle = {Sentence boundary detection},
	booktitle = {Proceedings of the {MT} {Summit} {VIII}},
	author = {Walker, Daniel J. and Clements, David E. and Darwin, Maki and Amtrup, Jan W.},
	year = {2001},
	file = {Fulltext:/Users/transfer/Zotero/storage/CCMV2SEZ/Walker et al. - 2001 - Sentence boundary detection A comparison of parad.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/AW7U7ISV/Walker et al. - 2001 - Sentence boundary detection A comparison of parad.pdf:application/pdf}
}

@article{yule_sentence-length_1939,
	title = {On sentence-length as a statistical characteristic of style in prose: {With} application to two cases of disputed authorship},
	volume = {30},
	shorttitle = {On sentence-length as a statistical characteristic of style in prose},
	number = {3/4},
	journal = {Biometrika},
	author = {Yule, G. Udny},
	year = {1939},
	pages = {363--390},
	file = {Snapshot:/Users/transfer/Zotero/storage/E53DLD8U/2332655.html:text/html}
}

@inproceedings{aroonmanakun_thoughts_2007,
	title = {Thoughts on word and sentence segmentation in {Thai}},
	booktitle = {Proceedings of the {Seventh} {Symposium} on {Natural} language {Processing}, {Pattaya}, {Thailand}, {December} 13–15},
	author = {Aroonmanakun, Wirote},
	year = {2007},
	pages = {85--90},
	file = {Fulltext:/Users/transfer/Zotero/storage/NXD6GZD6/Aroonmanakun - 2007 - Thoughts on word and sentence segmentation in Thai.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SYQMSK9G/Aroonmanakun - 2007 - Thoughts on word and sentence segmentation in Thai.pdf:application/pdf}
}

@inproceedings{choi_advances_2000,
	title = {Advances in domain independent linear text segmentation},
	booktitle = {Proceedings of the 1st {North} {American} chapter of the {Association} for {Computational} {Linguistics} conference},
	publisher = {Association for Computational Linguistics},
	author = {Choi, Freddy YY},
	year = {2000},
	keywords = {tokenization},
	pages = {26--33},
	file = {Fulltext:/Users/transfer/Zotero/storage/5SXYPXLV/Choi - 2000 - Advances in domain independent linear text segment.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PUK9NFZ2/citation.html:text/html}
}

@article{danielson_computer_1963,
	title = {Computer automation of two readability formulas},
	volume = {40},
	number = {2},
	journal = {Journalism Quarterly},
	author = {Danielson, Wayne A. and Bryan, Sam Dunn},
	year = {1963},
	pages = {201--206},
	file = {Snapshot:/Users/transfer/Zotero/storage/7RC479AB/107769906304000207.html:text/html}
}

@inproceedings{habert_towards_1998,
	title = {Towards tokenization evaluation},
	volume = {98},
	booktitle = {Proceedings of {LREC}},
	author = {Habert, Benoit and Adda, Gilles and Adda-Decker, M. and de Marëuil, P. Boula and Ferrari, Silvana and Ferret, O. and Illouz, Gabriel and Paroubek, P.},
	year = {1998},
	keywords = {tokenization, francais, France},
	pages = {427--431},
	file = {Fulltext:/Users/transfer/Zotero/storage/WM96MFSC/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf;Fulltext:/Users/transfer/Zotero/storage/ABB6K7X3/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf;habert-et-al98b.pdf:/Users/transfer/Zotero/storage/ACAJP9LV/habert-et-al98b.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/Z9XMAKV3/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6ZXHCDQU/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf}
}

@inproceedings{chanod_non-deterministic_1996,
	title = {A non-deterministic tokeniser for finite-state parsing},
	booktitle = {{ECAI}-96 workshop on {Extended} {Finite} {State} {Models} of {Language}, {Budapest}},
	author = {Chanod, Jean-Pierre and Tapanainen, Pasi},
	year = {1996},
	keywords = {tokenization},
	file = {Fulltext:/Users/transfer/Zotero/storage/HL8UKFSY/Chanod and Tapanainen - 1996 - A non-deterministic tokeniser for finite-state par.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/Q6ZH2IU3/Chanod and Tapanainen - 1996 - A non-deterministic tokeniser for finite-state par.pdf:application/pdf}
}

@book{fish_how_2011,
	title = {How to write a sentence},
	publisher = {HarperCollins},
	author = {Fish, Stanley},
	year = {2011},
	file = {Fulltext:/Users/transfer/Zotero/storage/Z5SUKWBP/Fish - 2011 - How to write a sentence.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/I24U49NE/Fish - 2011 - How to write a sentence.pdf:application/pdf}
}

@article{mccray_nature_1998,
	title = {The nature of lexical knowledge},
	volume = {37},
	journal = {Methods of Information in Medicine},
	author = {McCray, Alexa T.},
	year = {1998},
	pages = {353--360},
	file = {Fulltext:/Users/transfer/Zotero/storage/PYFCTZ72/McCray - 1998 - The nature of lexical knowledge.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PSAHGRAL/McCray - 1998 - The nature of lexical knowledge.pdf:application/pdf}
}

@article{spencer_differences_1973,
	title = {Differences between linguists and nonlinguists in intuitions of grammaticality-acceptability},
	volume = {2},
	number = {2},
	journal = {Journal of psycholinguistic research},
	author = {Spencer, Nancy Jane},
	year = {1973},
	pages = {83--98},
	file = {Snapshot:/Users/transfer/Zotero/storage/BW8V9BYX/BF01067203.html:text/html}
}

@inproceedings{grefenstette_corpus-based_1995,
	title = {Corpus-based method for automatic identification of support verbs for nominalizations},
	booktitle = {Proceedings of the seventh conference on {European} chapter of the {Association} for {Computational} {Linguistics}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Grefenstette, Gregory and Teufel, Simone},
	year = {1995},
	pages = {98--103},
	file = {Fulltext:/Users/transfer/Zotero/storage/Q5IDBCCC/Grefenstette and Teufel - 1995 - Corpus-based method for automatic identification o.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MWAQW3EF/citation.html:text/html}
}

@article{read_sentence_2012,
	title = {Sentence boundary detection: {A} long solved problem?},
	shorttitle = {Sentence boundary detection},
	journal = {Proceedings of COLING 2012: Posters},
	author = {Read, Jonathon and Dridan, Rebecca and Oepen, Stephan and Solberg, Lars Jørgen},
	year = {2012},
	pages = {985--994},
	file = {Fulltext:/Users/transfer/Zotero/storage/BZRZHP9S/Read et al. - 2012 - Sentence boundary detection A long solved problem.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YSNQJDHF/Read et al. - 2012 - Sentence boundary detection A long solved problem.pdf:application/pdf}
}

@inproceedings{boyd_scientific_1980,
	title = {Scientific realism and naturalistic epistemology},
	volume = {1980},
	booktitle = {{PSA}: {Proceedings} of the biennial meeting of the {Philosophy} of {Science} {Association}},
	publisher = {Philosophy of Science Association},
	author = {Boyd, Richard},
	year = {1980},
	pages = {613--662},
	file = {192615.pdf:/Users/transfer/Zotero/storage/PS8KDEE5/192615.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PR85YGP8/psaprocbienmeetp.1980.2.html:text/html}
}

@article{boyd_realism_1991,
	title = {Realism, anti-foundationalism and the enthusiasm for natural kinds},
	volume = {61},
	number = {1-2},
	journal = {Philosophical studies},
	author = {Boyd, Richard},
	year = {1991},
	pages = {127--148}
}

@article{boyd_how_1988,
	title = {How to be a moral realist},
	journal = {Contemporary Materialism},
	author = {Boyd, Richard N.},
	year = {1988},
	pages = {307},
	file = {Fulltext:/Users/transfer/Zotero/storage/D5ZADK3D/Boyd - 1988 - How to be a moral realist.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YV376WAW/books.html:text/html}
}

@article{boyd_current_1983,
	title = {On the current status of the issue of scientific realism},
	volume = {19},
	number = {1-3},
	journal = {Erkenntnis},
	author = {Boyd, Richard N.},
	year = {1983},
	pages = {45--90}
}

@article{boyd_realism_1973,
	title = {Realism, underdetermination, and a causal theory of evidence},
	journal = {Nous},
	author = {Boyd, Richard N.},
	year = {1973},
	pages = {1--12},
	file = {Snapshot:/Users/transfer/Zotero/storage/8WZYE8UU/2216179.html:text/html}
}

@article{salmasian_medication-indication_2015,
	title = {Medication-indication knowledge bases: a systematic review and critical appraisal},
	volume = {22},
	issn = {1527-974X},
	shorttitle = {Medication-indication knowledge bases},
	doi = {10.1093/jamia/ocv129},
	abstract = {OBJECTIVE: Medication-indication information is a key part of the information needed for providing decision support for and promoting appropriate use of medications. However, this information is not readily available to end users, and a lot of the resources only contain this information in unstructured form (free text). A number of public knowledge bases (KBs) containing structured medication-indication information have been developed over the years, but a direct comparison of these resources has not yet been conducted.
MATERIAL AND METHODS: We conducted a systematic review of the literature to identify all medication-indication KBs and critically appraised these resources in terms of their scope as well as their support for complex indication information.
RESULTS: We identified 7 KBs containing medication-indication data. They notably differed from each other in terms of their scope, coverage for on- or off-label indications, source of information, and choice of terminologies for representing the knowledge. The majority of KBs had issues with granularity of the indications as well as with representing duration of therapy, primary choice of treatment, and comedications or comorbidities.
DISCUSSION AND CONCLUSION: This is the first study directly comparing public KBs of medication indications. We identified several gaps in the existing resources, which can motivate future research.},
	language = {eng},
	number = {6},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Salmasian, Hojjat and Tran, Tran H. and Chase, Herbert S. and Friedman, Carol},
	month = nov,
	year = {2015},
	pmid = {26335981},
	pmcid = {PMC5009909},
	keywords = {female first or senior},
	pages = {1261--1270}
}

@article{salmasian_deriving_2013,
	title = {Deriving comorbidities from medical records using natural language processing},
	volume = {20},
	issn = {1527-974X},
	doi = {10.1136/amiajnl-2013-001889},
	abstract = {Extracting comorbidity information is crucial for phenotypic studies because of the confounding effect of comorbidities. We developed an automated method that accurately determines comorbidities from electronic medical records. Using a modified version of the Charlson comorbidity index (CCI), two physicians created a reference standard of comorbidities by manual review of 100 admission notes. We processed the notes using the MedLEE natural language processing system, and wrote queries to extract comorbidities automatically from its structured output. Interrater agreement for the reference set was very high (97.7\%). Our method yielded an F1 score of 0.761 and the summed CCI score was not different from the reference standard (p=0.329, power 80.4\%). In comparison, obtaining comorbidities from claims data yielded an F1 score of 0.741, due to lower sensitivity (66.1\%). Because CCI has previously been validated as a predictor of mortality and readmission, our method could allow automated prediction of these outcomes.},
	language = {eng},
	number = {e2},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Salmasian, Hojjat and Freedberg, Daniel E. and Friedman, Carol},
	month = dec,
	year = {2013},
	pmid = {24177145},
	pmcid = {PMC3861932},
	keywords = {female first or senior},
	pages = {e239--242}
}

@article{friedman_natural_2013,
	title = {Natural language processing: state of the art and prospects for significant progress, a workshop sponsored by the {National} {Library} of {Medicine}},
	volume = {46},
	issn = {1532-0480},
	shorttitle = {Natural language processing},
	doi = {10.1016/j.jbi.2013.06.004},
	abstract = {Natural language processing (NLP) is crucial for advancing healthcare because it is needed to transform relevant information locked in text into structured data that can be used by computer processes aimed at improving patient care and advancing medicine. In light of the importance of NLP to health, the National Library of Medicine (NLM) recently sponsored a workshop to review the state of the art in NLP focusing on text in English, both in biomedicine and in the general language domain. Specific goals of the NLM-sponsored workshop were to identify the current state of the art, grand challenges and specific roadblocks, and to identify effective use and best practices. This paper reports on the main outcomes of the workshop, including an overview of the state of the art, strategies for advancing the field, and obstacles that need to be addressed, resulting in recommendations for a research agenda intended to advance the field.},
	language = {eng},
	number = {5},
	journal = {Journal of Biomedical Informatics},
	author = {Friedman, Carol and Rindflesch, Thomas C. and Corn, Milton},
	month = oct,
	year = {2013},
	pmid = {23810857},
	keywords = {female first or senior},
	pages = {765--773}
}

@article{haerian_methods_2012,
	title = {Methods for identifying suicide or suicidal ideation in {EHRs}},
	volume = {2012},
	issn = {1942-597X},
	abstract = {Electronic health records contain important data elements for detection of novel adverse drug reactions, genotype/phenotype identification and psychosocial factor analysis, and the role of each of these as risk factors for suicidality warrants further investigation. Suicide and suicidal ideation are documented in clinical narratives. The specific purpose of this study was to define an algorithm for automated detection of this serious event. We found that ICD-9 E-Codes had the lowest positive predictive value: 0.55 (90\% CI: 0.42-0.67), while combining ICD-9 and NLP had the best PPV: 0.97 (90\% CI: 0.92-0.99). A qualitative analysis and classification of the types of errors by ICD-9 and NLP automated coding compared to manual review are also discussed.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Haerian, K. and Salmasian, H. and Friedman, C.},
	year = {2012},
	pmid = {23304402},
	pmcid = {PMC3540459},
	keywords = {female first or senior},
	pages = {1244--1253}
}

@article{xu_combining_2012,
	title = {Combining corpus-derived sense profiles with estimated frequency information to disambiguate clinical abbreviations},
	volume = {2012},
	issn = {1942-597X},
	abstract = {Abbreviations are widely used in clinical notes and are often ambiguous. Word sense disambiguation (WSD) for clinical abbreviations therefore is a critical task for many clinical natural language processing (NLP) systems. Supervised machine learning based WSD methods are known for their high performance. However, it is time consuming and costly to construct annotated samples for supervised WSD approaches and sense frequency information is often ignored by these methods. In this study, we proposed a profile-based method that used dictated discharge summaries as an external source to automatically build sense profiles and applied them to disambiguate abbreviations in hospital admission notes via the vector space model. Our evaluation using a test set containing 2,386 annotated instances from 13 ambiguous abbreviations in admission notes showed that the profile-based method performed better than two baseline methods and achieved a best average precision of 0.792. Furthermore, we developed a strategy to combine sense frequency information estimated from a clustering analysis with the profile-based method. Our results showed that the combined approach largely improved the performance and achieved a highest precision of 0.875 on the same test set, indicating that integrating sense frequency information with local context is effective for clinical abbreviation disambiguation.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Xu, Hua and Stetson, Peter D. and Friedman, Carol},
	year = {2012},
	pmid = {23304376},
	pmcid = {PMC3540457},
	keywords = {female first or senior},
	pages = {1004--1013}
}

@article{salmasian_automated_2013,
	title = {An automated tool for detecting medication overuse based on the electronic health records},
	volume = {22},
	issn = {1099-1557},
	doi = {10.1002/pds.3387},
	abstract = {PURPOSE: Medication overuse is a serious concern in healthcare as it leads to increased expenditures, side effects, and morbidities. Identifying overuse is only possible through excluding appropriate indications that are primarily mentioned in unstructured notes. We developed a framework for automatic identification of medication overuse and applied it to proton pump inhibitors (PPIs).
METHODS: We first created an indications knowledge base using data from drug labels, clinical guidelines, expert opinion, and other sources. We also obtained the list of current problems for 200 randomly selected inpatients who received PPIs using a natural language processing system and the discharge summaries of those patients. These problems were checked against the indications knowledge base to identify overuse candidates. Two gastroenterologists manually reviewed the notes and identified cases of overuse. Results from the automated framework were compared with the manual review.
RESULTS: Reviewers had high interrater reliability in finding indications (agreement = 92.1\%, Cohen's κ = 0.773). In 137 notes included in the final analysis, our system identified indications with a sensitivity of 74\% (95\%CI = 59-86) and specificity of 95\% (95\%CI = 87-98). In cases of appropriate use where the automated system also found one or more indications, it always included the correct indication.
CONCLUSIONS: We created an automated system that can identify established indications of medication use in electronic health records with high accuracy. It can provide clinical decision support for identifying potential overuse of PPIs and could be useful for reducing overuse and encouraging better documentation of indications.},
	language = {eng},
	number = {2},
	journal = {Pharmacoepidemiology and Drug Safety},
	author = {Salmasian, Hojjat and Freedberg, Daniel E. and Abrams, Julian A. and Friedman, Carol},
	month = feb,
	year = {2013},
	pmid = {23233423},
	pmcid = {PMC3566345},
	keywords = {female first or senior},
	pages = {183--189}
}

@article{xu_new_2012,
	title = {A new clustering method for detecting rare senses of abbreviations in clinical notes},
	volume = {45},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2012.06.003},
	abstract = {Abbreviations are widely used in clinical documents and they are often ambiguous. Building a list of possible senses (also called sense inventory) for each ambiguous abbreviation is the first step to automatically identify correct meanings of abbreviations in given contexts. Clustering based methods have been used to detect senses of abbreviations from a clinical corpus [1]. However, rare senses remain challenging and existing algorithms are not good enough to detect them. In this study, we developed a new two-phase clustering algorithm called Tight Clustering for Rare Senses (TCRS) and applied it to sense generation of abbreviations in clinical text. Using manually annotated sense inventories from a set of 13 ambiguous clinical abbreviations, we evaluated and compared TCRS with the existing Expectation Maximization (EM) clustering algorithm for sense generation, at two different levels of annotation cost (10 vs. 20 instances for each abbreviation). Our results showed that the TCRS-based method could detect 85\% senses on average; while the EM-based method found only 75\% senses, when similar annotation effort (about 20 instances) was used. Further analysis demonstrated that the improvement by the TCRS method was mainly from additionally detected rare senses, thus indicating its usefulness for building more complete sense inventories of clinical abbreviations.},
	language = {eng},
	number = {6},
	journal = {Journal of Biomedical Informatics},
	author = {Xu, Hua and Wu, Yonghui and Elhadad, Noémie and Stetson, Peter D. and Friedman, Carol},
	month = dec,
	year = {2012},
	pmid = {22742938},
	pmcid = {PMC3729222},
	keywords = {female first or senior},
	pages = {1075--1083}
}

@article{haerian_detection_2012,
	title = {Detection of pharmacovigilance-related adverse events using electronic health records and automated methods},
	volume = {92},
	issn = {1532-6535},
	doi = {10.1038/clpt.2012.54},
	abstract = {Electronic health records (EHRs) are an important source of data for detection of adverse drug reactions (ADRs). However, adverse events are frequently due not to medications but to the patients' underlying conditions. Mining to detect ADRs from EHR data must account for confounders. We developed an automated method using natural-language processing (NLP) and a knowledge source to differentiate cases in which the patient's disease is responsible for the event rather than a drug. Our method was applied to 199,920 hospitalization records, concentrating on two serious ADRs: rhabdomyolysis (n = 687) and agranulocytosis (n = 772). Our method automatically identified 75\% of the cases, those with disease etiology. The sensitivity and specificity were 93.8\% (confidence interval: 88.9-96.7\%) and 91.8\% (confidence interval: 84.0-96.2\%), respectively. The method resulted in considerable saving of time: for every 1 h spent in development, there was a saving of at least 20 h in manual review. The review of the remaining 25\% of the cases therefore became more feasible, allowing us to identify the medications that had caused the ADRs.},
	language = {eng},
	number = {2},
	journal = {Clinical Pharmacology and Therapeutics},
	author = {Haerian, K. and Varn, D. and Vaidya, S. and Ena, L. and Chase, H. S. and Friedman, C.},
	month = aug,
	year = {2012},
	pmid = {22713699},
	pmcid = {PMC3685297},
	keywords = {female first or senior},
	pages = {228--234}
}

@article{li_determining_2011,
	title = {Determining the reasons for medication prescriptions in the {EHR} using knowledge and natural language processing},
	volume = {2011},
	issn = {1942-597X},
	abstract = {Knowledge of medication indications is significant for automatic applications aimed at improving patient safety, such as computerized physician order entry and clinical decision support systems. The Electronic Health Record (EHR) contains pertinent information related to patient safety such as information related to appropriate prescribing. However, the reasons for medication prescriptions are usually not explicitly documented in the patient record. This paper describes a method that determines the reasons for medication uses based on information occurring in outpatient notes. The method utilizes drug-indication knowledge that we acquired, and natural language processing. Evaluation showed the method obtained a sensitivity of 62.8\%, specificity of 93.9\%, precision of 90\% and F-measure of 73.9\%. This pilot study demonstrated that linking external drug indication knowledge to the EHR for determining the reasons for medication use was promising, but also revealed some challenges. Future work will focus on increasing the accuracy and coverage of the indication knowledge and evaluating its performance using a much larger set of drugs frequently used in the outpatient population.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Li, Ying and Salmasian, Hojjat and Harpaz, Rave and Chase, Herbert and Friedman, Carol},
	year = {2011},
	pmid = {22195134},
	pmcid = {PMC3243251},
	keywords = {female first or senior},
	pages = {768--776}
}

@article{fan_deriving_2011,
	title = {Deriving a probabilistic syntacto-semantic grammar for biomedicine based on domain-specific terminologies},
	volume = {44},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2011.04.006},
	abstract = {Biomedical natural language processing (BioNLP) is a useful technique that unlocks valuable information stored in textual data for practice and/or research. Syntactic parsing is a critical component of BioNLP applications that rely on correctly determining the sentence and phrase structure of free text. In addition to dealing with the vast amount of domain-specific terms, a robust biomedical parser needs to model the semantic grammar to obtain viable syntactic structures. With either a rule-based or corpus-based approach, the grammar engineering process requires substantial time and knowledge from experts, and does not always yield a semantically transferable grammar. To reduce the human effort and to promote semantic transferability, we propose an automated method for deriving a probabilistic grammar based on a training corpus consisting of concept strings and semantic classes from the Unified Medical Language System (UMLS), a comprehensive terminology resource widely used by the community. The grammar is designed to specify noun phrases only due to the nominal nature of the majority of biomedical terminological concepts. Evaluated on manually parsed clinical notes, the derived grammar achieved a recall of 0.644, precision of 0.737, and average cross-bracketing of 0.61, which demonstrated better performance than a control grammar with the semantic information removed. Error analysis revealed shortcomings that could be addressed to improve performance. The results indicated the feasibility of an approach which automatically incorporates terminology semantics in the building of an operational grammar. Although the current performance of the unsupervised solution does not adequately replace manual engineering, we believe once the performance issues are addressed, it could serve as an aide in a semi-supervised solution.},
	language = {eng},
	number = {5},
	journal = {Journal of Biomedical Informatics},
	author = {Fan, Jung-Wei and Friedman, Carol},
	month = oct,
	year = {2011},
	pmid = {21549857},
	pmcid = {PMC3172402},
	keywords = {female first or senior},
	pages = {805--814}
}

@article{wang_selecting_2010,
	title = {Selecting information in electronic health records for knowledge acquisition},
	volume = {43},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2010.03.011},
	abstract = {Knowledge acquisition of relations between biomedical entities is critical for many automated biomedical applications, including pharmacovigilance and decision support. Automated acquisition of statistical associations from biomedical and clinical documents has shown some promise. However, acquisition of clinically meaningful relations (i.e. specific associations) remains challenging because textual information is noisy and co-occurrence does not typically determine specific relations. In this work, we focus on acquisition of two types of relations from clinical reports: disease-manifestation related symptom (MRS) and drug-adverse drug event (ADE), and explore the use of filtering by sections of the reports to improve performance. Evaluation indicated that applying the filters improved recall (disease-MRS: from 0.85 to 0.90; drug-ADE: from 0.43 to 0.75) and precision (disease-MRS: from 0.82 to 0.92; drug-ADE: from 0.16 to 0.31). This preliminary study demonstrates that selecting information in narrative electronic reports based on the sections improves the detection of disease-MRS and drug-ADE types of relations. Further investigation of complementary methods, such as more sophisticated statistical methods, more complex temporal models and use of information from other knowledge sources, is needed.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	author = {Wang, Xiaoyan and Chase, Herbert and Markatou, Marianthi and Hripcsak, George and Friedman, Carol},
	month = aug,
	year = {2010},
	pmid = {20362071},
	pmcid = {PMC2902678},
	keywords = {female first or senior},
	pages = {595--601}
}

@article{wang_characterizing_2009,
	title = {Characterizing environmental and phenotypic associations using information theory and electronic health records},
	volume = {10 Suppl 9},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-10-S9-S13},
	abstract = {BACKGROUND: The availability of up-to-date, executable, evidence-based medical knowledge is essential for many clinical applications, such as pharmacovigilance, but executable knowledge is costly to obtain and update. Automated acquisition of environmental and phenotypic associations in biomedical and clinical documents using text mining has showed some success. The usefulness of the association knowledge is limited, however, due to the fact that the specific relationships between clinical entities remain unknown. In particular, some associations are indirect relations due to interdependencies among the data.
RESULTS: In this work, we develop methods using mutual information (MI) and its property, the data processing inequality (DPI), to help characterize associations that were generated based on use of natural language processing to encode clinical information in narrative patient records followed by statistical methods. Evaluation based on a random sample consisting of two drugs and two diseases indicates an overall precision of 81\%.
CONCLUSION: This preliminary study demonstrates that the proposed method is effective for helping to characterize phenotypic and environmental associations obtained from clinical reports.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Wang, Xiaoyan and Hripcsak, George and Friedman, Carol},
	month = sep,
	year = {2009},
	pmid = {19761567},
	pmcid = {PMC2745684},
	keywords = {female first or senior},
	pages = {S13}
}

@article{wang_active_2009,
	title = {Active computerized pharmacovigilance using natural language processing, statistics, and electronic health records: a feasibility study},
	volume = {16},
	issn = {1067-5027},
	shorttitle = {Active computerized pharmacovigilance using natural language processing, statistics, and electronic health records},
	doi = {10.1197/jamia.M3028},
	abstract = {OBJECTIVE It is vital to detect the full safety profile of a drug throughout its market life. Current pharmacovigilance systems still have substantial limitations, however. The objective of our work is to demonstrate the feasibility of using natural language processing (NLP), the comprehensive Electronic Health Record (EHR), and association statistics for pharmacovigilance purposes. DESIGN Narrative discharge summaries were collected from the Clinical Information System at New York Presbyterian Hospital (NYPH). MedLEE, an NLP system, was applied to the collection to identify medication events and entities which could be potential adverse drug events (ADEs). Co-occurrence statistics with adjusted volume tests were used to detect associations between the two types of entities, to calculate the strengths of the associations, and to determine their cutoff thresholds. Seven drugs/drug classes (ibuprofen, morphine, warfarin, bupropion, paroxetine, rosiglitazone, ACE inhibitors) with known ADEs were selected to evaluate the system. RESULTS One hundred thirty-two potential ADEs were found to be associated with the 7 drugs. Overall recall and precision were 0.75 and 0.31 for known ADEs respectively. Importantly, qualitative evaluation using historic roll back design suggested that novel ADEs could be detected using our system. CONCLUSIONS This study provides a framework for the development of active, high-throughput and prospective systems which could potentially unveil drug safety profiles throughout their entire market life. Our results demonstrate that the framework is feasible although there are some challenging issues. To the best of our knowledge, this is the first study using comprehensive unstructured data from the EHR for pharmacovigilance.},
	language = {eng},
	number = {3},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Wang, Xiaoyan and Hripcsak, George and Markatou, Marianthi and Friedman, Carol},
	month = jun,
	year = {2009},
	pmid = {19261932},
	pmcid = {PMC2732239},
	keywords = {female first or senior},
	pages = {328--337}
}

@article{fan_generating_2009,
	title = {Generating quality word sense disambiguation test sets based on {MeSH} indexing},
	volume = {2009},
	issn = {1942-597X},
	abstract = {Word sense disambiguation (WSD) determines the correct meaning of a word that has more than one meaning, and is a critical step in biomedical natural language processing, as interpretation of information in text can be correct only if the meanings of their component terms are correctly identified first. Quality evaluation sets are important to WSD because they can be used as representative samples for developing automatic programs and as referees for comparing different WSD programs. To help create quality test sets for WSD, we developed a MeSH-based automatic sense-tagging method that preferentially annotates terms being topical of the text. Preliminary results were promising and revealed important issues to be addressed in biomedical WSD research. We also suggest that, by cross-validating with 2 or 3 annotators, the method should be able to efficiently generate quality WSD test sets. Online supplement is available at: http://www.dbmi.columbia.edu/{\textasciitilde}juf7002/AMIA09.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Fan, Jung-Wei and Friedman, Carol},
	month = nov,
	year = {2009},
	pmid = {20351846},
	pmcid = {PMC2815444},
	keywords = {female first or senior},
	pages = {183--187}
}

@article{xu_methods_2009,
	title = {Methods for building sense inventories of abbreviations in clinical notes},
	volume = {16},
	issn = {1067-5027},
	doi = {10.1197/jamia.M2927},
	abstract = {OBJECTIVE: To develop methods for building corpus-specific sense inventories of abbreviations occurring in clinical documents.
DESIGN: A corpus of internal medicine admission notes was collected and instances of each clinical abbreviation in the corpus were clustered to different sense clusters. One instance from each cluster was manually annotated to generate a final list of senses. Two clustering-based methods (Expectation Maximization--EM and Farthest First--FF) and one random sampling method for sense detection were evaluated using a set of 12 clinical abbreviations.
MEASUREMENTS: The clustering-based sense detection methods were evaluated using a set of clinical abbreviations that were manually sense annotated. "Sense Completeness" and "Annotation Cost" were used to measure the performance of different methods. Clustering error rates were also reported for different clustering algorithms.
RESULTS: A clustering-based semi-automated method was developed to build corpus-specific sense inventories for abbreviations in hospital admission notes. Evaluation demonstrated that this method could largely reduce manual annotation cost and increase the completeness of sense inventories when compared with a manual annotation method using random samples.
CONCLUSION: The authors developed an effective clustering-based method for building corpus-specific sense inventories for abbreviations in a clinical corpus. To the best of the authors knowledge, this is the first time clustering technologies have been used to help building sense inventories of abbreviations in clinical text. The results demonstrated that the clustering-based method performed better than the manual annotation method using random samples for the task of building sense inventories of clinical abbreviations.},
	language = {eng},
	number = {1},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Xu, Hua and Stetson, Peter D. and Friedman, Carol},
	month = feb,
	year = {2009},
	pmid = {18952935},
	pmcid = {PMC2605589},
	keywords = {female first or senior},
	pages = {103--108}
}

@article{sam_information-theoretic_2007,
	title = {Information-theoretic classification of {SNOMED} improves the organization of context-sensitive excerpts from {Cochrane} reviews},
	issn = {1942-597X},
	abstract = {The emphasis on evidence based medicine (EBM) has placed increased focus on finding timely answers to clinical questions in presence of patients. Using a combination of natural language processing for the generation of clinical excerpts and information theoretic distance based clustering, we evaluated multiple approaches for the efficient presentation of context-sensitive EBM excerpts.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Sam, Lee and Borlawsky, Tara and Tao, Ying and Li, Jianrong and Friedman, Carol and Smith, Barry and Lussier, Yves A.},
	month = oct,
	year = {2007},
	pmid = {18694197},
	pmcid = {PMC2655812},
	keywords = {female first or senior},
	pages = {1100}
}

@article{xu_study_2007,
	title = {A study of abbreviations in clinical notes},
	issn = {1942-597X},
	abstract = {Various natural language processing (NLP) systems have been developed to unlock patient information from narrative clinical notes in order to support knowledge based applications such as error detection, surveillance and decision support. In many clinical notes, abbreviations are widely used without mention of their definitions, which is very different from the use of abbreviations in the biomedical literature. Thus, it is critical, but more challenging, for NLP systems to correctly interpret abbreviations in these notes. In this paper we describe a study of a two-step model for building a clinical abbreviation database: first, abbreviations in a text corpus were detected and then a sense inventory was built for those that were found. Four detection methods were developed and evaluated. Results showed that the best detection method had a precision of 91.4\% and recall of 80.3\%. A simple method was used to build sense inventories from two different knowledge sources: the Unified Medical Language System (UMLS) and a MEDLINE abbreviation database (ADAM). Evaluation showed the inventory from the UMLS appeared to be the more appropriate of the two for defining the sense of abbreviations, but was not ideal. It covered 35\% of the senses and had an ambiguity rate of 40\% for those that were covered. However, annotation by domain experts appears necessary for uncovered abbreviations and to determine the correct senses.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Xu, Hua and Stetson, Peter D. and Friedman, Carol},
	month = oct,
	year = {2007},
	pmid = {18693951},
	pmcid = {PMC2655910},
	keywords = {female first or senior},
	pages = {821--825}
}

@article{fan_combining_2007,
	title = {Combining contextual and lexical features to classify {UMLS} concepts},
	issn = {1942-597X},
	abstract = {Semantic classification is important for biomedical terminologies and the many applications that depend on them. Previously we developed two classifiers for 8 broad clinically relevant classes to reclassify and validate UMLS concepts. We found them to be complementary, and then combined them using a manual approach. In this paper, we extended the classifiers by adding an "other" class to categorize concepts not belonging to any of the 8 classes. In addition, we focused on automating the method for combining the two classifiers by training a meta-classifier that performs dynamic combination to exploit the strength of each classifier. The automated method performed as well as manual combination, achieving classification accuracy of about 0.81.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Fan, Jung-Wei and Friedman, Carol},
	month = oct,
	year = {2007},
	pmid = {18693832},
	pmcid = {PMC2655898},
	keywords = {female first or senior},
	pages = {231--235}
}

@article{chen_detection_2007,
	title = {Detection of practice pattern trends through {Natural} {Language} {Processing} of clinical narratives and biomedical literature},
	issn = {1942-597X},
	abstract = {Clinical knowledge, best evidence, and practice patterns evolve over time. The ability to track these changes and study practice trends may be valuable for performance measurement and quality improvement efforts. The goal of this study was to assess the feasibility and validity of methods to generate and compare trends in biomedical literature and clinical narrative. We focused on the challenge of detecting trends in medication usage over time for two diseases: HIV/AIDS and asthma. Information about disease-specific medications in published randomized control trials and discharge summaries at NewYork-Presbyterian Hospital over a ten-year period were extracted using Natural Language Processing. This paper reports on the ability of our semi-automated process to discover disease-drug practice pattern trends and interpretation of findings across the biomedical and clinical text sources.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Chen, Elizabeth S. and Stetson, Peter D. and Lussier, Yves A. and Markatou, Marianthi and Hripcsak, George and Friedman, Carol},
	month = oct,
	year = {2007},
	pmid = {18693810},
	pmcid = {PMC2655911},
	keywords = {female first or senior},
	pages = {120--124}
}

@article{fan_semantic_2008,
	title = {Semantic reclassification of the {UMLS} concepts},
	volume = {24},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btn343},
	abstract = {Accurate semantic classification is valuable for text mining and knowledge-based tasks that perform inference based on semantic classes. To benefit applications using the semantic classification of the Unified Medical Language System (UMLS) concepts, we automatically reclassified the concepts based on their lexical and contextual features. The new classification is useful for auditing the original UMLS semantic classification and for building biomedical text mining applications.
AVAILABILITY: http://www.dbmi.columbia.edu/{\textasciitilde}juf7002/reclassify\_production},
	language = {eng},
	number = {17},
	journal = {Bioinformatics (Oxford, England)},
	author = {Fan, Jung-Wei and Friedman, Carol},
	month = sep,
	year = {2008},
	pmid = {18625612},
	pmcid = {PMC2519163},
	keywords = {female first or senior},
	pages = {1971--1973}
}

@article{chen_automated_2008,
	title = {Automated acquisition of disease drug knowledge from biomedical and clinical documents: an initial study},
	volume = {15},
	issn = {1067-5027},
	shorttitle = {Automated acquisition of disease drug knowledge from biomedical and clinical documents},
	doi = {10.1197/jamia.M2401},
	abstract = {OBJECTIVE: Explore the automated acquisition of knowledge in biomedical and clinical documents using text mining and statistical techniques to identify disease-drug associations.
DESIGN: Biomedical literature and clinical narratives from the patient record were mined to gather knowledge about disease-drug associations. Two NLP systems, BioMedLEE and MedLEE, were applied to Medline articles and discharge summaries, respectively. Disease and drug entities were identified using the NLP systems in addition to MeSH annotations for the Medline articles. Focusing on eight diseases, co-occurrence statistics were applied to compute and evaluate the strength of association between each disease and relevant drugs.
RESULTS: Ranked lists of disease-drug pairs were generated and cutoffs calculated for identifying stronger associations among these pairs for further analysis. Differences and similarities between the text sources (i.e., biomedical literature and patient record) and annotations (i.e., MeSH and NLP-extracted UMLS concepts) with regards to disease-drug knowledge were observed.
CONCLUSION: This paper presents a method for acquiring disease-specific knowledge and a feasibility study of the method. The method is based on applying a combination of NLP and statistical techniques to both biomedical and clinical documents. The approach enabled extraction of knowledge about the drugs clinicians are using for patients with specific diseases based on the patient record, while it is also acquired knowledge of drugs frequently involved in controlled trials for those same diseases. In comparing the disease-drug associations, we found the results to be appropriate: the two text sources contained consistent as well as complementary knowledge, and manual review of the top five disease-drug associations by a medical expert supported their correctness across the diseases.},
	language = {eng},
	number = {1},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Chen, Elizabeth S. and Hripcsak, George and Xu, Hua and Markatou, Marianthi and Friedman, Carol},
	month = feb,
	year = {2008},
	pmid = {17947625},
	pmcid = {PMC2274872},
	keywords = {female first or senior},
	pages = {87--98}
}

@article{fan_using_2007,
	title = {Using distributional analysis to semantically classify {UMLS} concepts},
	volume = {129},
	issn = {0926-9630},
	abstract = {The UMLS is a widely used and comprehensive knowledge source in the biomedical domain. It specifies biomedical concepts and their semantic categories, and therefore is valuable for Natural Language Processing (NLP) and other knowledge-based systems. However, the UMLS semantic classification is not always accurate, which adversely affects performance of these systems. Therefore, it is desirable to automatically validate, or, when necessary, to semantically reclassify UMLS concepts. We applied a distributional similarity method based on syntactic dependencies and -skew divergence to classify concepts in the T033 Finding class in order to determine which ones were biologic functions or disorders. A gold standard of 100 randomly sampled concepts was created that was based on a majority annotation of three experts. Precision of 0.54 and recall of 0.654 was achieved by the top prediction; precision of 0.64 and recall of 0.769 was achieved by the top 2 predictions. Error analysis revealed problems in the current method, and provided insight into future improvements.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Fan, Jung-Wei and Xu, Hua and Friedman, Carol},
	year = {2007},
	pmid = {17911771},
	keywords = {female first or senior},
	pages = {519--523}
}

@article{fan_using_2007-1,
	title = {Using contextual and lexical features to restructure and validate the classification of biomedical concepts},
	volume = {8},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-8-264},
	abstract = {BACKGROUND: Biomedical ontologies are critical for integration of data from diverse sources and for use by knowledge-based biomedical applications, especially natural language processing as well as associated mining and reasoning systems. The effectiveness of these systems is heavily dependent on the quality of the ontological terms and their classifications. To assist in developing and maintaining the ontologies objectively, we propose automatic approaches to classify and/or validate their semantic categories. In previous work, we developed an approach using contextual syntactic features obtained from a large domain corpus to reclassify and validate concepts of the Unified Medical Language System (UMLS), a comprehensive resource of biomedical terminology. In this paper, we introduce another classification approach based on words of the concept strings and compare it to the contextual syntactic approach.
RESULTS: The string-based approach achieved an error rate of 0.143, with a mean reciprocal rank of 0.907. The context-based and string-based approaches were found to be complementary, and the error rate was reduced further by applying a linear combination of the two classifiers. The advantage of combining the two approaches was especially manifested on test data with sufficient contextual features, achieving the lowest error rate of 0.055 and a mean reciprocal rank of 0.969.
CONCLUSION: The lexical features provide another semantic dimension in addition to syntactic contextual features that support the classification of ontological concepts. The classification errors of each dimension can be further reduced through appropriate combination of the complementary classifiers.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Fan, Jung-Wei and Xu, Hua and Friedman, Carol},
	month = jul,
	year = {2007},
	pmid = {17650333},
	pmcid = {PMC2014782},
	keywords = {female first or senior},
	pages = {264}
}

@article{tao_information_2007,
	title = {Information theory applied to the sparse gene ontology annotation network to predict novel gene function},
	volume = {23},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btm195},
	abstract = {MOTIVATION: Despite advances in the gene annotation process, the functions of a large portion of gene products remain insufficiently characterized. In addition, the in silico prediction of novel Gene Ontology (GO) annotations for partially characterized gene functions or processes is highly dependent on reverse genetic or functional genomic approaches. To our knowledge, no prediction method has been demonstrated to be highly accurate for sparsely annotated GO terms (those associated to fewer than 10 genes).
RESULTS: We propose a novel approach, information theory-based semantic similarity (ITSS), to automatically predict molecular functions of genes based on existing GO annotations. Using a 10-fold cross-validation, we demonstrate that the ITSS algorithm obtains prediction accuracies (precision 97\%, recall 77\%) comparable to other machine learning algorithms when compared in similar conditions over densely annotated portions of the GO datasets. This method is able to generate highly accurate predictions in sparsely annotated portions of GO, where previous algorithms have failed. As a result, our technique generates an order of magnitude more functional predictions than previous methods. A 10-fold cross validation demonstrated a precision of 90\% at a recall of 36\% for the algorithm over sparsely annotated networks of the recent GO annotations (about 1400 GO terms and 11,000 genes in Homo sapiens). To our knowledge, this article presents the first historical rollback validation for the predicted GO annotations, which may represent more realistic conditions than more widely used cross-validation approaches. By manually assessing a random sample of 100 predictions conducted in a historical rollback evaluation, we estimate that a minimum precision of 51\% (95\% confidence interval: 43-58\%) can be achieved for the human GO Annotation file dated 2003.
AVAILABILITY: The program is available on request. The 97,732 positive predictions of novel gene annotations from the 2005 GO Annotation dataset and other supplementary information is available at http://phenos.bsd.uchicago.edu/ITSS/.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {13},
	journal = {Bioinformatics (Oxford, England)},
	author = {Tao, Ying and Sam, Lee and Li, Jianrong and Friedman, Carol and Lussier, Yves A.},
	month = jul,
	year = {2007},
	pmid = {17646340},
	pmcid = {PMC2882681},
	keywords = {female first or senior},
	pages = {i529--538}
}

@article{fan_semantic_2007,
	title = {Semantic classification of biomedical concepts using distributional similarity},
	volume = {14},
	issn = {1067-5027},
	doi = {10.1197/jamia.M2314},
	abstract = {OBJECTIVE: To develop an automated, high-throughput, and reproducible method for reclassifying and validating ontological concepts for natural language processing applications.
DESIGN: We developed a distributional similarity approach to classify the Unified Medical Language System (UMLS) concepts. Classification models were built for seven broad biomedically relevant semantic classes created by grouping subsets of the UMLS semantic types. We used contextual features based on syntactic properties obtained from two different large corpora and used alpha-skew divergence as the similarity measure.
MEASUREMENTS: The testing sets were automatically generated based on the changes by the National Library of Medicine to the semantic classification of concepts from the UMLS 2005AA to the 2006AA release. Error rates were calculated and a misclassification analysis was performed.
RESULTS: The estimated lowest error rates were 0.198 and 0.116 when considering the correct classification to be covered by our top prediction and top 2 predictions, respectively.
CONCLUSION: The results demonstrated that the distributional similarity approach can recommend high level semantic classification suitable for use in natural language processing.},
	language = {eng},
	number = {4},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Fan, Jung-Wei and Friedman, Carol},
	month = aug,
	year = {2007},
	pmid = {17460124},
	pmcid = {PMC2244895},
	keywords = {female first or senior},
	pages = {467--477}
}

@article{xu_gene_2007,
	title = {Gene symbol disambiguation using knowledge-based profiles},
	volume = {23},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btm056},
	abstract = {MOTIVATION: The ambiguity of biomedical entities, particularly of gene symbols, is a big challenge for text-mining systems in the biomedical domain. Existing knowledge sources, such as Entrez Gene and the MEDLINE database, contain information concerning the characteristics of a particular gene that could be used to disambiguate gene symbols.
RESULTS: For each gene, we create a profile with different types of information automatically extracted from related MEDLINE abstracts and readily available annotated knowledge sources. We apply the gene profiles to the disambiguation task via an information retrieval method, which ranks the similarity scores between the context where the ambiguous gene is mentioned, and candidate gene profiles. The gene profile with the highest similarity score is then chosen as the correct sense. We evaluated the method on three automatically generated testing sets of mouse, fly and yeast organisms, respectively. The method achieved the highest precision of 93.9\% for the mouse, 77.8\% for the fly and 89.5\% for the yeast.
AVAILABILITY: The testing data sets and disambiguation programs are available at http://www.dbmi.columbia.edu/{\textasciitilde}hux7002/gsd2006},
	language = {eng},
	number = {8},
	journal = {Bioinformatics (Oxford, England)},
	author = {Xu, Hua and Fan, Jung-Wei and Hripcsak, George and Mendonça, Eneida A. and Markatou, Marianthi and Friedman, Carol},
	month = apr,
	year = {2007},
	pmid = {17314123},
	keywords = {female first or senior},
	pages = {1015--1022}
}

@article{xu_natural_2006,
	title = {A natural language processing ({NLP}) tool to assist in the curation of the laboratory {Mouse} {Tumor} {Biology} {Database}},
	issn = {1942-597X},
	abstract = {A substantial effort of the biological community involves the development of model organism databases containing key genomic information concerning specific organisms. This paper describes a developing natural language processing (NLP) tool, which is aimed at assisting curators of the Mouse Tumor Biology (MTB) Database of the Mouse Genome Informatics (MGI) group by helping them quickly find key information in the articles.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Xu, Hua and Krupke, Debra and Blake, Judith and Friedman, Carol},
	year = {2006},
	pmid = {17238769},
	pmcid = {PMC1839428},
	keywords = {female first or senior},
	pages = {1150}
}

@article{silfen_zebrahunter:_2006,
	title = {{ZebraHunter}: searching rare medical diagnoses and retrieving relevant citations},
	issn = {1942-597X},
	shorttitle = {{ZebraHunter}},
	abstract = {The clinicopathological conferences and case reports that are published in the medical literature contain rare and complex medical cases that are of general interest to the medical community. We present ZebraHunter, an information retrieval resource that allows clinicians to input clinical findings, search for rare diseases (medical zebras), and fetch the associated citations.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Silfen, Eric Z. and Patel, Chintan and Mendonça, Eneida and Friedman, Carol},
	year = {2006},
	pmid = {17238713},
	pmcid = {PMC1839437},
	keywords = {female first or senior},
	pages = {1094}
}

@article{chen_disseminating_2006,
	title = {Disseminating natural language processed clinical narratives},
	issn = {1942-597X},
	abstract = {Through Natural Language Processing (NLP) techniques, information can be extracted from clinical narratives for a variety of applications (e.g., patient management). While the complex and nested output of NLP systems can be expressed in standard formats, such as the eXtensible Markup Language (XML), these representations may not be directly suitable for certain end-users or applications. The availability of a âeuro tabular' format that simplifies the content and structure of NLP output may facilitate the dissemination and use by users who are more familiar with common spreadsheet, database, or statistical tools. In this paper, we describe the knowledge-based design of a tabular representation for NLP output and development of a transformation program for the structured output of MedLEE, an NLP system at our institution. Through an evaluation, we found that the simplified tabular format is comparable to existing more complex NLP formats in effectiveness for identifying clinical conditions in narrative reports.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Chen, Elizabeth S. and Hripcsak, George and Friedman, Carol},
	year = {2006},
	pmid = {17238316},
	pmcid = {PMC1839529},
	keywords = {female first or senior},
	pages = {126--130}
}

@article{lussier_phenogo:_2006,
	title = {{PhenoGO}: assigning phenotypic context to gene ontology annotations with natural language processing},
	issn = {2335-6936},
	shorttitle = {{PhenoGO}},
	abstract = {Natural language processing (NLP) is a high throughput technology because it can process vast quantities of text within a reasonable time period. It has the potential to substantially facilitate biomedical research by extracting, linking, and organizing massive amounts of information that occur in biomedical journal articles as well as in textual fields of biological databases. Until recently, much of the work in biological NLP and text mining has revolved around recognizing the occurrence of biomolecular entities in articles, and in extracting particular relationships among the entities. Now, researchers have recognized a need to link the extracted information to ontologies or knowledge bases, which is a more difficult task. One such knowledge base is Gene Ontology annotations (GOA), which significantly increases semantic computations over the function, cellular components and processes of genes. For multicellular organisms, these annotations can be refined with phenotypic context, such as the cell type, tissue, and organ because establishing phenotypic contexts in which a gene is expressed is a crucial step for understanding the development and the molecular underpinning of the pathophysiology of diseases. In this paper, we propose a system, PhenoGO, which automatically augments annotations in GOA with additional context. PhenoGO utilizes an existing NLP system, called BioMedLEE, an existing knowledge-based phenotype organizer system (PhenOS) in conjunction with MeSH indexing and established biomedical ontologies. More specifically, PhenoGO adds phenotypic contextual information to existing associations between gene products and GO terms as specified in GOA. The system also maps the context to identifiers that are associated with different biomedical ontologies, including the UMLS, Cell Ontology, Mouse Anatomy, NCBI taxonomy, GO, and Mammalian Phenotype Ontology. In addition, PhenoGO was evaluated for coding of anatomical and cellular information and assigning the coded phenotypes to the correct GOA; results obtained show that PhenoGO has a precision of 91\% and recall of 92\%, demonstrating that the PhenoGO NLP system can accurately encode a large number of anatomical and cellular ontologies to GO annotations. The PhenoGO Database may be accessed at the following URL: http://www.phenoGO.org},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Lussier, Yves and Borlawsky, Tara and Rappaport, Daniel and Liu, Yang and Friedman, Carol},
	year = {2006},
	pmid = {17094228},
	pmcid = {PMC2906243},
	keywords = {female first or senior},
	pages = {64--75}
}

@article{tulipano_natural_2007,
	title = {Natural language processing and visualization in the molecular imaging domain},
	volume = {40},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2006.08.002},
	abstract = {Molecular imaging is at the crossroads of genomic sciences and medical imaging. Information within the molecular imaging literature could be used to link to genomic and imaging information resources and to organize and index images in a way that is potentially useful to researchers. A number of natural language processing (NLP) systems are available to automatically extract information from genomic literature. One existing NLP system, known as BioMedLEE, automatically extracts biological information consisting of biomolecular substances and phenotypic data. This paper focuses on the adaptation, evaluation, and application of BioMedLEE to the molecular imaging domain. In order to adapt BioMedLEE for this domain, we extend an existing molecular imaging terminology and incorporate it into BioMedLEE. BioMedLEE's performance is assessed with a formal evaluation study. The system's performance, measured as recall and precision, is 0.74 (95\% CI: [.70-.76]) and 0.70 (95\% CI [.63-.76]), respectively. We adapt a JAVA viewer known as PGviewer for the simultaneous visualization of images with NLP extracted information.},
	language = {eng},
	number = {3},
	journal = {Journal of Biomedical Informatics},
	author = {Tulipano, P. Karina and Tao, Ying and Millar, William S. and Zanzonico, Pat and Kolbert, Katherine and Xu, Hua and Yu, Hong and Chen, Lifeng and Lussier, Yves A. and Friedman, Carol},
	month = jun,
	year = {2007},
	pmid = {17084109},
	keywords = {female first or senior},
	pages = {270--281}
}

@article{friedman_bio-ontology_2006,
	title = {Bio-{Ontology} and text: bridging the modeling gap},
	volume = {22},
	issn = {1367-4811},
	shorttitle = {Bio-{Ontology} and text},
	doi = {10.1093/bioinformatics/btl405},
	abstract = {MOTIVATION: Natural language processing (NLP) techniques are increasingly being used in biology to automate the capture of new biological discoveries in text, which are being reported at a rapid rate. Yet, information represented in NLP data structures is classically very different from information organized with ontologies as found in model organisms or genetic databases. To facilitate the computational reuse and integration of information buried in unstructured text with that of genetic databases, we propose and evaluate a translational schema that represents a comprehensive set of phenotypic and genetic entities, as well as their closely related biomedical entities and relations as expressed in natural language. In addition, the schema connects different scales of biological information, and provides mappings from the textual information to existing ontologies, which are essential in biology for integration, organization, dissemination and knowledge management of heterogeneous phenotypic information. A common comprehensive representation for otherwise heterogeneous phenotypic and genetic datasets, such as the one proposed, is critical for advancing systems biology because it enables acquisition and reuse of unprecedented volumes of diverse types of knowledge and information from text.
RESULTS: A novel representational schema, PGschema, was developed that enables translation of phenotypic, genetic and their closely related information found in textual narratives to a well-defined data structure comprising phenotypic and genetic concepts from established ontologies along with modifiers and relationships. Evaluation for coverage of a selected set of entities showed that 90\% of the information could be represented (95\% confidence interval: 86-93\%; n = 268). Moreover, PGschema can be expressed automatically in an XML format using natural language techniques to process the text. To our knowledge, we are providing the first evaluation of a translational schema for NLP that contains declarative knowledge about genes and their associated biomedical data (e.g. phenotypes).
AVAILABILITY: http://zellig.cpmc.columbia.edu/PGschema},
	language = {eng},
	number = {19},
	journal = {Bioinformatics (Oxford, England)},
	author = {Friedman, Carol and Borlawsky, Tara and Shagina, Lyudmila and Xing, H. Rosie and Lussier, Yves A.},
	month = oct,
	year = {2006},
	pmid = {16870928},
	pmcid = {PMC2879055},
	keywords = {female first or senior},
	pages = {2421--2429}
}

@article{xu_machine_2006,
	title = {Machine learning and word sense disambiguation in the biomedical domain: design and evaluation issues},
	volume = {7},
	issn = {1471-2105},
	shorttitle = {Machine learning and word sense disambiguation in the biomedical domain},
	doi = {10.1186/1471-2105-7-334},
	abstract = {BACKGROUND: Word sense disambiguation (WSD) is critical in the biomedical domain for improving the precision of natural language processing (NLP), text mining, and information retrieval systems because ambiguous words negatively impact accurate access to literature containing biomolecular entities, such as genes, proteins, cells, diseases, and other important entities. Automated techniques have been developed that address the WSD problem for a number of text processing situations, but the problem is still a challenging one. Supervised WSD machine learning (ML) methods have been applied in the biomedical domain and have shown promising results, but the results typically incorporate a number of confounding factors, and it is problematic to truly understand the effectiveness and generalizability of the methods because these factors interact with each other and affect the final results. Thus, there is a need to explicitly address the factors and to systematically quantify their effects on performance.
RESULTS: Experiments were designed to measure the effect of "sample size" (i.e. size of the datasets), "sense distribution" (i.e. the distribution of the different meanings of the ambiguous word) and "degree of difficulty" (i.e. the measure of the distances between the meanings of the senses of an ambiguous word) on the performance of WSD classifiers. Support Vector Machine (SVM) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations: BPD, BSA, PCA, and RSV, which were chosen because of varying degrees of differences in their respective senses. Results showed that: 1) increasing the sample size generally reduced the error rate, but this was limited mainly to well-separated senses (i.e. cases where the distances between the senses were large); in difficult cases an unusually large increase in sample size was needed to increase performance slightly, which was impractical, 2) the sense distribution did not have an effect on performance when the senses were separable, 3) when there was a majority sense of over 90\%, the WSD classifier was not better than use of the simple majority sense, 4) error rates were proportional to the similarity of senses, and 5) there was no statistical difference between results when using a 5-fold or 10-fold cross-validation method. Other issues that impact performance are also enumerated.
CONCLUSION: Several different independent aspects affect performance when using ML techniques for WSD. We found that combining them into one single result obscures understanding of the underlying methods. Although we studied only four abbreviations, we utilized a well-established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics. The results of our experiments show that in order to understand the performance of these ML methods it is critical that papers report on the baseline performance, the distribution and sample size of the senses in the datasets, and the standard deviation or confidence intervals. In addition, papers should also characterize the difficulty of the WSD task, the WSD situations addressed and not addressed, as well as the ML methods and features used. This should lead to an improved understanding of the generalizablility and the limitations of the methodology.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Xu, Hua and Markatou, Marianthi and Dimova, Rositsa and Liu, Hongfang and Friedman, Carol},
	month = jul,
	year = {2006},
	pmid = {16822321},
	pmcid = {PMC1550263},
	keywords = {female first or senior},
	pages = {334}
}

@article{liu_quantitative_2006,
	title = {Quantitative assessment of dictionary-based protein named entity tagging},
	volume = {13},
	issn = {1067-5027},
	doi = {10.1197/jamia.M2085},
	abstract = {OBJECTIVE: Natural language processing (NLP) approaches have been explored to manage and mine information recorded in biological literature. A critical step for biological literature mining is biological named entity tagging (BNET) that identifies names mentioned in text and normalizes them with entries in biological databases. The aim of this study was to provide quantitative assessment of the complexity of BNET on protein entities through BioThesaurus, a thesaurus of gene/protein names for UniProt knowledgebase (UniProtKB) entries that was acquired using online resources.
METHODS: We evaluated the complexity through several perspectives: ambiguity (i.e., the number of genes/proteins represented by one name), synonymy (i.e., the number of names associated with the same gene/protein), and coverage (i.e., the percentage of gene/protein names in text included in the thesaurus). We also normalized names in BioThesaurus and measures were obtained twice, once before normalization and once after.
RESULTS: The current version of BioThesaurus has over 2.6 million names or 2.1 million normalized names covering more than 1.8 million UniProtKB entries. The average synonymy is 3.53 (2.86 after normalization), ambiguity is 2.31 before normalization and 2.32 after, while the coverage is 94.0\% based on the BioCreAtive data set comprising MEDLINE abstracts containing genes/proteins.
CONCLUSION: The study indicated that names for genes/proteins are highly ambiguous and there are usually multiple names for the same gene or protein. It also demonstrated that most gene/protein names appearing in text can be found in BioThesaurus.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Liu, Hongfang and Hu, Zhang-Zhi and Torii, Manabu and Wu, Cathy and Friedman, Carol},
	month = oct,
	year = {2006},
	pmid = {16799122},
	pmcid = {PMC1561801},
	keywords = {female first or senior},
	pages = {497--507}
}

@article{kukafka_human_2006,
	title = {Human and automated coding of rehabilitation discharge summaries according to the {International} {Classification} of {Functioning}, {Disability}, and {Health}},
	volume = {13},
	issn = {1067-5027},
	doi = {10.1197/jamia.M2107},
	abstract = {OBJECTIVE: The International Classification of Functioning, Disability, and Health (ICF) is designed to provide a common language and framework for describing health and health-related states. The goal of this research was to investigate human and automated coding of functional status information using the ICF framework.
DESIGN: The authors extended an existing natural language processing (NLP) system to encode rehabilitation discharge summaries according to the ICF.
MEASUREMENTS: The authors conducted a formal evaluation, comparing the coding performed by expert coders, non-expert coders, and the NLP system.
RESULTS: Automated coding can be used to assign codes using the ICF, with results similar to those obtained by human coders, at least for the selection of ICF code and assignment of the performance qualifier. Coders achieved high agreement on ICF code assignment.
CONCLUSION: This research is a key next step in the development of the ICF as a sensitive and universal classification of functional status information. It is worthwhile to continue to investigate automated ICF coding.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Kukafka, Rita and Bales, Michael E. and Burkhardt, Ann and Friedman, Carol},
	month = oct,
	year = {2006},
	pmid = {16799117},
	pmcid = {PMC1561799},
	keywords = {female first or senior},
	pages = {508--515}
}

@article{tulipano_natural_2005,
	title = {Natural language processing in the molecular imaging domain},
	issn = {1942-597X},
	abstract = {Molecular imaging represents the intersection between imaging and genomic sciences. There has been a surge in research literature and information in both sciences. Information contained within molecular imaging literature could be used to 1) link to genomic and imaging information resources and 2) to organize and index images. This research focuses on the adaptation, evaluation, and application of BioMedLEE, a natural language processing system (NLP), in the automated extraction of information from molecular imaging abstracts.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Tulipano, P. Karina and Tao, Ying and Zanzonico, Pat and Kolbert, Katherine and Lussier, Yves and Friedman, Carol},
	year = {2005},
	pmid = {16779429},
	pmcid = {PMC1560602},
	keywords = {female first or senior},
	pages = {1143}
}

@article{bales_extending_2005,
	title = {Extending a medical language processing system to the functional status domain},
	issn = {1942-597X},
	abstract = {The World Health Organization's International Classification of Functioning, Disability, and Health (ICF) provides a common framework for describing functional status information (FSI) in health records. Given the expense of manual coding, we are investigating the use of natural language processing (NLP) for automated FSI coding. We used an existing NLP system that was originally designed to encode clinical information. The system's lexicon and coding table were modified and preprocessing and postprocessing programs were created, allowing for automated assignment of selected ICF codes.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Bales, Michael and Kukafka, Rita and Burkhardt, Ann and Friedman, Carol},
	year = {2005},
	pmid = {16779175},
	pmcid = {PMC1560823},
	keywords = {female first or senior},
	pages = {888}
}

@article{zhou_terminology_2006,
	title = {Terminology model discovery using natural language processing and visualization techniques},
	volume = {39},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2005.10.006},
	abstract = {Medical terminologies are important for unambiguous encoding and exchange of clinical information. The traditional manual method of developing terminology models is time-consuming and limited in the number of phrases that a human developer can examine. In this paper, we present an automated method for developing medical terminology models based on natural language processing (NLP) and information visualization techniques. Surgical pathology reports were selected as the testing corpus for developing a pathology procedure terminology model. The use of a general NLP processor for the medical domain, MedLEE, provides an automated method for acquiring semantic structures from a free text corpus and sheds light on a new high-throughput method of medical terminology model development. The use of an information visualization technique supports the summarization and visualization of the large quantity of semantic structures generated from medical documents. We believe that a general method based on NLP and information visualization will facilitate the modeling of medical terminologies.},
	language = {eng},
	number = {6},
	journal = {Journal of Biomedical Informatics},
	author = {Zhou, Li and Tao, Ying and Cimino, James J. and Chen, Elizabeth S. and Liu, Hongfang and Lussier, Yves A. and Hripcsak, George and Friedman, Carol},
	month = dec,
	year = {2006},
	pmid = {16360342},
	keywords = {female first or senior},
	pages = {626--636}
}

@article{bales_qualitative_2006,
	title = {Qualitative assessment of the {International} {Classification} of {Functioning}, {Disability}, and {Health} with respect to the desiderata for controlled medical vocabularies},
	volume = {75},
	issn = {1386-5056},
	doi = {10.1016/j.ijmedinf.2005.07.026},
	abstract = {BACKGROUND: The International Classification of Functioning, Disability, and Health (ICF), a classification system published in 2001 by the World Health Organization (WHO), provides a common language and framework for describing functional status information (FSI) in health records.
METHODS: Informed by ongoing research in coding FSI in patient records, this paper qualitatively assesses the ICF framework with respect to the desiderata for controlled medical vocabularies, an enumerated a list of desirable qualities for controlled medical vocabularies proposed by Cimino [J.J. Cimino, Desiderata for controlled medical vocabularies in the twenty-first century, Meth. Inform. Med. 37 (1998) 394-403].
RESULTS: The ICF satisfies 5 of the 12 desiderata. Five points were not satisfied and two points could not be evaluated.
CONCLUSION: The ICF is a rich source of relevant terms, concepts, and relationships, but it was not developed in consideration of requirements for formal terminologies. Therefore, it could serve as a base from which to develop a formal terminology of functioning and disability. This assessment is a key next step in the development of the ICF as a sensitive, universal measure of functional status.},
	language = {eng},
	number = {5},
	journal = {International Journal of Medical Informatics},
	author = {Bales, Michael E. and Kukafka, Rita and Burkhardt, Ann and Friedman, Carol},
	month = may,
	year = {2006},
	pmid = {16122973},
	keywords = {female first or senior},
	pages = {384--395}
}

@article{mendonca_extracting_2005,
	title = {Extracting information on pneumonia in infants using natural language processing of radiology reports},
	volume = {38},
	issn = {1532-0464},
	doi = {10.1016/j.jbi.2005.02.003},
	abstract = {Natural language processing (NLP) is critical for improvement of the healthcare process because it can encode clinical data in patient documents. Many clinical applications such as decision support require coded data to function appropriately. However, in order to be applicable for healthcare, performance must be adequate. A valuable automated application is the detection of infectious diseases, such as surveillance of pneumonia in newborns (e.g., neonates) because the disease produces significant rates of morbidity and mortality, and manual surveillance is challenging. Studies have demonstrated that automated surveillance using NLP is a useful adjunct to manual surveillance and an effective tool for infection control practitioners. This paper presents a study evaluating the feasibility of an NLP-based monitoring system to screen for healthcare-associated pneumonia in neonates. We estimated sensitivity, specificity, and positive predictive value by comparing results with clinicians' judgments. Sensitivity was 71\% and specificity was 99\%. Our results demonstrated that the automated method was feasible.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	author = {Mendonça, Eneida A. and Haas, Janet and Shagina, Lyudmila and Larson, Elaine and Friedman, Carol},
	month = aug,
	year = {2005},
	pmid = {16084473},
	keywords = {female first or senior},
	pages = {314--321}
}

@article{chen_extracting_2004,
	title = {Extracting phenotypic information from the literature via natural language processing},
	volume = {107},
	issn = {0926-9630},
	abstract = {In recent years, the amount of biomedical knowledge has been increasing exponentially. Several Natural Language Processing (NLP) systems have been developed to help researchers extract, encode and organize new information automatically from textual literature or narrative reports. Some of these systems focus on extracting biological entities or molecular interactions while others retrieve and encode clinical information. To exploit gene functions in the post-genome era, it is necessary to extract phenotypic information automatically from the literature as well. However, few NLP projects have focused on this. We present the development of a system called BioMedLEE that extracts a broad variety of phenotypic information from the biomedical literature. The system was developed by adapting MedLEE, an existing clinical information extraction NLP engine. A feasibility evaluation study of BioMedLEE was performed using 300 randomly chosen journal titles. Results showed that experts achieved an average precision rate of 65.4\%, (95\%CI: [58.0\%, 72.8\%]) and a recall rate of 73.0\%, (95\%CI: [66.2\%, 80.0\%]). BioMedLEE had 64.0\% precision and 77.1\% recall respectively, according to expert agreements.},
	language = {eng},
	number = {Pt 2},
	journal = {Studies in Health Technology and Informatics},
	author = {Chen, Lifeng and Friedman, Carol},
	year = {2004},
	pmid = {15360914},
	keywords = {female first or senior},
	pages = {758--762}
}

@article{liu_cliniviewer:_2004,
	title = {{CliniViewer}: a tool for viewing electronic medical records based on natural language processing and {XML}},
	volume = {107},
	issn = {0926-9630},
	shorttitle = {{CliniViewer}},
	abstract = {With the evolving use of computers in healthcare, the electronic medical record (EMR) is becoming more and more popular. A tool is needed that would enable physicians to accurately and efficiently access clinical information in multiple medical records associated with a particular patient. Both natural language processing (NLP) and the eXtensible Markup Language (XML) have been used in the clinical domain for capturing, representing, and utilizing clinical information and both have shown great potential. In this paper, we demonstrate another use of XML and NLP through CliniViewer, a tool that organizes and presents the clinical information in multiple records. We also describe the flexibility and capability provided when combining XML and NLP to summarize, navigate, and conceptualize structured information. The tool has been fully implemented and tested using patients with multiple discharge summaries.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Liu, Hongfang and Friedman, Carol},
	year = {2004},
	pmid = {15360891},
	keywords = {female first or senior},
	pages = {639--643}
}

@article{xu_facilitating_2004,
	title = {Facilitating cancer research using natural language processing of pathology reports},
	volume = {107},
	issn = {0926-9630},
	abstract = {Many ongoing clinical research projects, such as projects involving studies associated with cancer, involve manual capture of information in surgical pathology reports so that the information can be used to determine the eligibility of recruited patients for the study and to provide other information, such as cancer prognosis. Natural language processing (NLP) systems offer an alternative to automated coding, but pathology reports have certain features that are difficult for NLP systems. This paper describes how a preprocessor was integrated with an existing NLP system (MedLEE) in order to reduce modification to the NLP system and to improve performance. The work was done in conjunction with an ongoing clinical research project that assesses disparities and risks of developing breast cancer for minority women. An evaluation of the system was performed using manually coded data from the research project's database as a gold standard. The evaluation outcome showed that the extended NLP system had a sensitivity of 90.6\% and a precision of 91.6\%. Results indicated that this system performed satisfactorily for capturing information for the cancer research project.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Xu, Hua and Anderson, Kristin and Grann, Victor R. and Friedman, Carol},
	year = {2004},
	pmid = {15360876},
	keywords = {female first or senior},
	pages = {565--572}
}

@article{bakken_comparison_2004,
	title = {A comparison of semantic categories of the {ISO} reference terminology models for nursing and the {MedLEE} natural language processing system},
	volume = {107},
	issn = {0926-9630},
	abstract = {Natural language processing (NLP) systems have demonstrated utility in parsing narrative texts for purposes such as surveillance and decision support. However, there has been little work related to NLP of nursing narratives. The purpose of this study was to compare the semantic categories of a NLP system (Medical Language Extraction and Encoding [MedLEE] system) with the semantic domains, categories, and attributes of the International Standards Organization(ISO) reference terminology models for nursing diagnoses and nursing actions. All but two MedLEE diagnosis and procedure-related semantic categories mapped to ISO models. In some instances, we found exact correspondence between the semantic structures of MedLEE and the ISO models. In other situations (e.g. aspects of site or location), the ISO model was not as granular as MedLEE. For clinical procedure and non-invasive examination, two ISO nursing action model components (action and target) were required to represent the MedLEE semantic category. The ISO model requires additional specification of selected semantic categories for the abstract semantic domains in order to achieve the objective of using NLP to parse and encode data from nursing narratives. Our analysis also suggests areas for extension of MedLEE.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Bakken, Suzanne and Hyun, Sookyung and Friedman, Carol and Johnson, Stephen},
	year = {2004},
	pmid = {15360857},
	keywords = {female first or senior},
	pages = {472--476}
}

@article{chen_gene_2005,
	title = {Gene name ambiguity of eukaryotic nomenclatures},
	volume = {21},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/bth496},
	abstract = {MOTIVATION: With more and more scientific literature published online, the effective management and reuse of this knowledge has become problematic. Natural language processing (NLP) may be a potential solution by extracting, structuring and organizing biomedical information in online literature in a timely manner. One essential task is to recognize and identify genomic entities in text. 'Recognition' can be accomplished using pattern matching and machine learning. But for 'identification' these techniques are not adequate. In order to identify genomic entities, NLP needs a comprehensive resource that specifies and classifies genomic entities as they occur in text and that associates them with normalized terms and also unique identifiers so that the extracted entities are well defined. Online organism databases are an excellent resource to create such a lexical resource. However, gene name ambiguity is a serious problem because it affects the appropriate identification of gene entities. In this paper, we explore the extent of the problem and suggest ways to address it.
RESULTS: We obtained gene information from 21 organisms and quantified naming ambiguities within species, across species, with English words and with medical terms. When the case (of letters) was retained, official symbols displayed negligible intra-species ambiguity (0.02\%) and modest ambiguities with general English words (0.57\%) and medical terms (1.01\%). In contrast, the across-species ambiguity was high (14.20\%). The inclusion of gene synonyms increased intra-species ambiguity substantially and full names contributed greatly to gene-medical-term ambiguity. A comprehensive lexical resource that covers gene information for the 21 organisms was then created and used to identify gene names by using a straightforward string matching program to process 45,000 abstracts associated with the mouse model organism while ignoring case and gene names that were also English words. We found that 85.1\% of correctly retrieved mouse genes were ambiguous with other gene names. When gene names that were also English words were included, 233\% additional 'gene' instances were retrieved, most of which were false positives. We also found that authors prefer to use synonyms (74.7\%) to official symbols (17.7\%) or full names (7.6\%) in their publications.
CONTACT: lifeng.chen@dbmi.columbia.edu},
	language = {eng},
	number = {2},
	journal = {Bioinformatics (Oxford, England)},
	author = {Chen, Lifeng and Liu, Hongfang and Friedman, Carol},
	month = jan,
	year = {2005},
	pmid = {15333458},
	keywords = {female first or senior, normalization},
	pages = {248--256}
}

@article{friedman_automated_2004,
	title = {Automated encoding of clinical documents based on natural language processing},
	volume = {11},
	issn = {1067-5027},
	doi = {10.1197/jamia.M1552},
	abstract = {OBJECTIVE: The aim of this study was to develop a method based on natural language processing (NLP) that automatically maps an entire clinical document to codes with modifiers and to quantitatively evaluate the method.
METHODS: An existing NLP system, MedLEE, was adapted to automatically generate codes. The method involves matching of structured output generated by MedLEE consisting of findings and modifiers to obtain the most specific code. Recall and precision applied to Unified Medical Language System (UMLS) coding were evaluated in two separate studies. Recall was measured using a test set of 150 randomly selected sentences, which were processed using MedLEE. Results were compared with a reference standard determined manually by seven experts. Precision was measured using a second test set of 150 randomly selected sentences from which UMLS codes were automatically generated by the method and then validated by experts.
RESULTS: Recall of the system for UMLS coding of all terms was .77 (95\% CI.72-.81), and for coding terms that had corresponding UMLS codes recall was .83 (.79-.87). Recall of the system for extracting all terms was .84 (.81-.88). Recall of the experts ranged from .69 to .91 for extracting terms. The precision of the system was .89 (.87-.91), and precision of the experts ranged from .61 to .91.
CONCLUSION: Extraction of relevant clinical information and UMLS coding were accomplished using a method based on NLP. The method appeared to be comparable to or better than six experts. The advantage of the method is that it maps text to codes along with other related information, rendering the coded output suitable for effective retrieval.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Friedman, Carol and Shagina, Lyudmila and Lussier, Yves and Hripcsak, George},
	month = oct,
	year = {2004},
	pmid = {15187068},
	pmcid = {PMC516246},
	keywords = {female first or senior},
	pages = {392--402}
}

@article{liu_multi-aspect_2004,
	title = {A multi-aspect comparison study of supervised word sense disambiguation},
	volume = {11},
	issn = {1067-5027},
	doi = {10.1197/jamia.M1533},
	abstract = {OBJECTIVE: The aim of this study was to investigate relations among different aspects in supervised word sense disambiguation (WSD; supervised machine learning for disambiguating the sense of a term in a context) and compare supervised WSD in the biomedical domain with that in the general English domain.
METHODS: The study involves three data sets (a biomedical abbreviation data set, a general biomedical term data set, and a general English data set). The authors implemented three machine-learning algorithms, including (1) naïve Bayes (NBL) and decision lists (TDLL), (2) their adaptation of decision lists (ODLL), and (3) their mixed supervised learning (MSL). There were six feature representations (various combinations of collocations, bag of words, oriented bag of words, etc.) and five window sizes (2, 4, 6, 8, and 10).
RESULTS: Supervised WSD is suitable only when there are enough sense-tagged instances with at least a few dozens of instances for each sense. Collocations combined with neighboring words are appropriate selections for the context. For terms with unrelated biomedical senses, a large window size such as the whole paragraph should be used, while for general English words a moderate window size between 4 and 10 should be used. The performance of the authors' implementation of decision list classifiers for abbreviations was better than that of traditional decision list classifiers. However, the opposite held for the other two sets. Also, the authors' mixed supervised learning was stable and generally better than others for all sets.
CONCLUSION: From this study, it was found that different aspects of supervised WSD depend on each other. The experiment method presented in the study can be used to select the best supervised WSD classifier for each ambiguous term.},
	language = {eng},
	number = {4},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Liu, Hongfang and Teller, Virginia and Friedman, Carol},
	month = aug,
	year = {2004},
	pmid = {15064284},
	pmcid = {PMC436083},
	keywords = {female first or senior},
	pages = {320--331}
}

@article{rzhetsky_geneways:_2004,
	title = {{GeneWays}: a system for extracting, analyzing, visualizing, and integrating molecular pathway data},
	volume = {37},
	issn = {1532-0464},
	shorttitle = {{GeneWays}},
	doi = {10.1016/j.jbi.2003.10.001},
	abstract = {The immense growth in the volume of research literature and experimental data in the field of molecular biology calls for efficient automatic methods to capture and store information. In recent years, several groups have worked on specific problems in this area, such as automated selection of articles pertinent to molecular biology, or automated extraction of information using natural-language processing, information visualization, and generation of specialized knowledge bases for molecular biology. GeneWays is an integrated system that combines several such subtasks. It analyzes interactions between molecular substances, drawing on multiple sources of information to infer a consensus view of molecular networks. GeneWays is designed as an open platform, allowing researchers to query, review, and critique stored information.},
	language = {eng},
	number = {1},
	journal = {Journal of Biomedical Informatics},
	author = {Rzhetsky, Andrey and Iossifov, Ivan and Koike, Tomohiro and Krauthammer, Michael and Kra, Pauline and Morris, Mitzi and Yu, Hong and Duboué, Pablo Ariel and Weng, Wubin and Wilbur, W. John and Hatzivassiloglou, Vasileios and Friedman, Carol},
	month = feb,
	year = {2004},
	pmid = {15016385},
	keywords = {female first or senior},
	pages = {43--53}
}

@article{tuason_biological_2004,
	title = {Biological nomenclatures: a source of lexical knowledge and ambiguity},
	issn = {2335-6936},
	shorttitle = {Biological nomenclatures},
	abstract = {There has been increased work in developing automated systems that involve natural language processing (NLP) to recognize and extract genomic information from the literature. Recognition and identification of biological entities is a critical step in this process. NLP systems generally rely on nomenclatures and ontological specifications as resources for determining the names of the entities, assigning semantic categories that are consistent with the corresponding ontology, and assignment of identifiers that map to well-defined entities within a particular nomenclature. Although nomenclatures and ontologies are valuable for text processing systems, they were developed to aid researchers and are heterogeneous in structure and semantics. A uniform resource that is automatically generated from diverse resources, and that is designed for NLP purposes would be a useful tool for the field, and would further database interoperability. This paper presents work towards this goal. We have automatically created lexical resources from four model organism nomenclature systems (mouse, fly, worm, and yeast), and have studied performance of the resources within an existing NLP system, GENIES. Using nomenclatures is not straightforward because issues concerning ambiguity, synonymy, and name variations are quite challenging. In this paper we focus mainly on ambiguity. We determined that the number of ambiguous gene names within the individual nomenclatures, across the four nomenclatures, and with general English ranged from 0\%-10.18\%, 1.187\%-20.30\%, and 0\%-2.49\% respectively. When actually processing text, we found the rate of ambiguous occurrences (not counting ambiguities stemming from English words) to range from 2.4\%-32.9\% depending on the organisms considered.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Tuason, O. and Chen, L. and Liu, H. and Blake, J. A. and Friedman, C.},
	year = {2004},
	pmid = {14992507},
	keywords = {female first or senior},
	pages = {238--249}
}

@article{xu_facilitating_2003,
	title = {Facilitating research in pathology using natural language processing},
	issn = {1942-597X},
	abstract = {Clinical research projects frequently rely on manual extraction of information from pathology reports, which is a costly and time-consuming process. This paper describes use of a natural language processing (NLP) system to automatically extract and structure information in textual pathology reports that is needed for clinical research.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Xu, Hua and Friedman, Carol},
	year = {2003},
	pmid = {14728560},
	pmcid = {PMC1480292},
	keywords = {female first or senior},
	pages = {1057}
}

@article{friedman_vocabulary_2003,
	title = {A vocabulary development and visualization tool based on natural language processing and the mining of textual patient reports},
	volume = {36},
	issn = {1532-0464},
	abstract = {Medical terminologies are critical for automated healthcare systems. Some terminologies, such as the UMLS and SNOMED are comprehensive, whereas others specialize in limited domains (i.e., BIRADS) or are developed for specific applications. An important feature of a terminology is comprehensive coverage of relevant clinical terms and ease of use by users, which include computerized applications. We have developed a method for facilitating vocabulary development and maintenance that is based on utilization of natural language processing to mine large collections of clinical reports in order to obtain information on terminology as expressed by physicians. Once the reports are processed and the terms structured and collected into an XML representational schema, it is possible to determine information about terms, such as frequency of occurrence, compositionality, relations to other terms (such as modifiers), and correspondence to a controlled vocabulary. This paper describes the method and discusses how it can be used as a tool to help vocabulary builders navigate through the terms physicians use, visualize their relations to other terms via a flexible viewer, and determine their correspondence to a controlled vocabulary.},
	language = {eng},
	number = {3},
	journal = {Journal of Biomedical Informatics},
	author = {Friedman, Carol and Liu, Hongfang and Shagina, Lyudmila},
	month = jun,
	year = {2003},
	pmid = {14615228},
	keywords = {female first or senior},
	pages = {189--201}
}

@article{friedman_two_2002,
	title = {Two biomedical sublanguages: a description based on the theories of {Zellig} {Harris}},
	volume = {35},
	issn = {1532-0464},
	shorttitle = {Two biomedical sublanguages},
	abstract = {Natural language processing (NLP) systems have been developed to provide access to the tremendous body of data and knowledge that is available in the biomedical domain in the form of natural language text. These NLP systems are valuable because they can encode and amass the information in the text so that it can be used by other automated processes to improve patient care and our understanding of disease processes and treatments. Zellig Harris proposed a theory of sublanguage that laid the foundation for natural language processing in specialized domains. He hypothesized that the informational content and structure form a specialized language that can be delineated in the form of a sublanguage grammar. The grammar can then be used by a language processor to capture and encode the salient information and relations in text. In this paper, we briefly summarize his language and sublanguage theories. In addition, we summarize our prior research, which is associated with the sublanguage grammars we developed for two different biomedical domains. These grammars illustrate how Harris' theories provide a basis for the development of language processing systems in the biomedical domain. The two domains and their associated sublanguages discussed are: the clinical domain, where the text consists of patient reports, and the biomolecular domain, where the text consists of complete journal articles.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	author = {Friedman, Carol and Kra, Pauline and Rzhetsky, Andrey},
	month = aug,
	year = {2002},
	pmid = {12755517},
	keywords = {female first or senior},
	pages = {222--235}
}

@article{liu_mining_2003,
	title = {Mining terminological knowledge in large biomedical corpora},
	issn = {2335-6936},
	abstract = {Terminological knowledge of the biomedical domain is important for natural language processing (NLP) and information retrieval (IR) applications, and a number of terminological knowledge sources, such as LocusLink, GeneBank, and the UMLS, already exist. However, because of the tremendous amount of research activity in the field, new terms and symbols are continually being created, many of which are published in the literature, but are not available in any of the other resources. Therefore, effective mining of the literature for new terminology is critical for furthering NLP and IR applications. Abbreviations are widely used in the biomedical domain, and the understanding of abbreviations requires a terminological knowledge base that consists of abbreviations with their associated senses. In previous work, several methods have been developed for automatic construction of abbreviation knowledge bases from parenthetical expressions. However, these methods pair abbreviations and their expansions based on manually crafted patterns or rules. In this paper, we propose an automatic method, which is not based on patterns or rules but is based on the use of collocations, to extract a set of related terms from parenthetical expressions including abbreviations associated with their expansions and other types of related terms such as synonyms, or hyponyms etc. Our method is based on the observation that terms associated with parenthetical expressions i) are usually related, and ii) are often collocations because they tend to co-occur more often than expected by chance. Our method was applied to the collection of MEDLINE abstracts. The method and the results were evaluated using two collections: Berman's handcrafted abbreviation list and the LocusLink collection.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Liu, Hongfang and Friedman, Carol},
	year = {2003},
	pmid = {12603046},
	keywords = {female first or senior},
	pages = {415--426}
}

@article{yu_automatic_2002,
	title = {Automatic extraction of gene and protein synonyms from {MEDLINE} and journal articles},
	issn = {1531-605X},
	abstract = {Genes and proteins are often associated with multiple names, and more names are added as new functional or structural information is discovered. Because authors often alternate between these synonyms, information retrieval and extraction benefits from identifying these synonymous names. We have developed a method to extract automatically synonymous gene and protein names from MEDLINE and journal articles. We first identified patterns authors use to list synonymous gene and protein names. We developed SGPE (for synonym extraction of gene and protein names), a software program that recognizes the patterns and extracts from MEDLINE abstracts and full-text journal articles candidate synonymous terms. SGPE then applies a sequence of filters that automatically screen out those terms that are not gene and protein names. We evaluated our method to have an overall precision of 71\% on both MEDLINE and journal articles, and 90\% precision on the more suitable full-text articles alone},
	language = {eng},
	journal = {Proceedings. AMIA Symposium},
	author = {Yu, Hong and Hatzivassiloglou, Vasileios and Friedman, Carol and Rzhetsky, Andrey and Wilbur, W. John},
	year = {2002},
	pmid = {12463959},
	pmcid = {PMC2244511},
	keywords = {female first or senior},
	pages = {919--923}
}

@article{liu_study_2001,
	title = {A study of abbreviations in the {UMLS}},
	issn = {1531-605X},
	abstract = {Abbreviations are widely used in medicine. The understanding of abbreviations is important for medical language processing and information retrieval systems. The Unified Medical Language System (UMLS) contains a large number of abbreviations. We hypothesized that extracting and studying the UMLS abbreviations can be helpful for understanding the characteristics of abbreviations in medicine. In this paper, we describe a method for extracting abbreviations from the UMLS. We evaluated the method and studied the ambiguous nature of the abbreviations. In addition, the coverage of the UMLS abbreviations in medical reports was studied. Using our method, we extracted 163,666 unique (abbreviation, full form) pairs from the UMLS with a precision of 97.5\%, and a recall of 96\%. The UMLS abbreviations were highly ambiguous: 33.1\% of abbreviations with six characters or less had multiple meanings; the average number of different full forms for all abbreviations with six characters or less was 2.28. The coverage of the UMLS abbreviations in medical reports was over 66\%.},
	language = {eng},
	journal = {Proceedings. AMIA Symposium},
	author = {Liu, H. and Lussier, Y. A. and Friedman, C.},
	year = {2001},
	pmid = {11825217},
	pmcid = {PMC2243414},
	keywords = {female first or senior},
	pages = {393--397}
}

@article{friedman_genies:_2001,
	title = {{GENIES}: a natural-language processing system for the extraction of molecular pathways from journal articles},
	volume = {17 Suppl 1},
	issn = {1367-4803},
	shorttitle = {{GENIES}},
	abstract = {Systems that extract structured information from natural language passages have been highly successful in specialized domains. The time is opportune for developing analogous applications for molecular biology and genomics. We present a system, GENIES, that extracts and structures information about cellular pathways from the biological literature in accordance with a knowledge model that we developed earlier. We implemented GENIES by modifying an existing medical natural language processing system, MedLEE, and performed a preliminary evaluation study. Our results demonstrate the value of the underlying techniques for the purpose of acquiring valuable knowledge from biological journals.},
	language = {eng},
	journal = {Bioinformatics (Oxford, England)},
	author = {Friedman, C. and Kra, P. and Yu, H. and Krauthammer, M. and Rzhetsky, A.},
	year = {2001},
	pmid = {11472995},
	keywords = {female first or senior},
	pages = {S74--82}
}

@article{ribeiro_why_2016,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2018-02-24},
	journal = {arXiv:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.04938},
	keywords = {reproducibility, ML},
	file = {arXiv\:1602.04938 PDF:/Users/transfer/Zotero/storage/7M6SWV7J/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf;arXiv.org Snapshot:/Users/transfer/Zotero/storage/N5NP3Q23/1602.html:text/html}
}

@book{jezek_lexicon:_2016,
	title = {The lexicon: {An} introduction},
	shorttitle = {The lexicon},
	publisher = {Oxford University Press},
	author = {Ježek, Elisabetta},
	year = {2016},
	file = {Snapshot:/Users/transfer/Zotero/storage/ITTFZCHH/books.html:text/html}
}

@article{pustejovsky_semantic_2008,
	title = {Semantic coercion in language: {Beyond} distributional analysis},
	volume = {20},
	shorttitle = {Semantic coercion in language},
	number = {1},
	journal = {Italian Journal of Linguistics},
	author = {Pustejovsky, James and Jezek, Elisabetta},
	year = {2008},
	pages = {175--208},
	file = {Fulltext:/Users/transfer/Zotero/storage/67Z8NX8V/Pustejovsky and Jezek - 2008 - Semantic coercion in language Beyond distribution.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/S2Z8J6KN/Pustejovsky and Jezek - 2008 - Semantic coercion in language Beyond distribution.pdf:application/pdf}
}

@article{chen_searching_2017,
	title = {Searching for suicide-related information on {Chinese} websites},
	volume = {258},
	issn = {1872-7123},
	doi = {10.1016/j.psychres.2017.08.087},
	abstract = {Growing concerns about cyber-suicide have prompted many studies on suicide information available on the web. However, very few studies have considered non-English websites. We aimed to analyze online suicide-related information accessed through Chinese-language websites. We used Taiwan's two most popular search engines (Google and Yahoo) to explore the results returned from six suicide-related search terms in March 2016. The first three pages listing the results from each search were analyzed and rated based on the attitude towards suicide (pro-suicide, anti-suicide, neutral/mixed, not a suicide site, or error). Comparisons across different search terms were also performed. In all, 375 linked webpages were included; 16.3\% of the webpages were pro-suicide and 41.3\% were anti-suicide. The majority of the pro-suicide sites were user-generated webpages (96.7\%). Searches using the keywords 'ways to kill yourself' (31.7\%) and 'painless suicide' (28.3\%) generated much larger numbers of harmful webpages than the term 'suicide' (4.3\%). We conclude that collaborative efforts with internet service providers and search engines to improve the ranking of anti-suicide webpages and websites and implement online suicide reporting guidelines are highly encouraged.},
	language = {eng},
	journal = {Psychiatry Research},
	author = {Chen, Ying-Yeh and Hung, Galen Chin-Lun and Cheng, Qijin and Tsai, Chi-Wei and Wu, Kevin Chien-Chang},
	month = dec,
	year = {2017},
	pmid = {28886904},
	pages = {506--510}
}

@article{cheng_assessing_2017,
	title = {Assessing {Suicide} {Risk} and {Emotional} {Distress} in {Chinese} {Social} {Media}: {A} {Text} {Mining} and {Machine} {Learning} {Study}},
	volume = {19},
	issn = {1438-8871},
	shorttitle = {Assessing {Suicide} {Risk} and {Emotional} {Distress} in {Chinese} {Social} {Media}},
	doi = {10.2196/jmir.7276},
	abstract = {BACKGROUND: Early identification and intervention are imperative for suicide prevention. However, at-risk people often neither seek help nor take professional assessment. A tool to automatically assess their risk levels in natural settings can increase the opportunity for early intervention.
OBJECTIVE: The aim of this study was to explore whether computerized language analysis methods can be utilized to assess one's suicide risk and emotional distress in Chinese social media.
METHODS: A Web-based survey of Chinese social media (ie, Weibo) users was conducted to measure their suicide risk factors including suicide probability, Weibo suicide communication (WSC), depression, anxiety, and stress levels. Participants' Weibo posts published in the public domain were also downloaded with their consent. The Weibo posts were parsed and fitted into Simplified Chinese-Linguistic Inquiry and Word Count (SC-LIWC) categories. The associations between SC-LIWC features and the 5 suicide risk factors were examined by logistic regression. Furthermore, the support vector machine (SVM) model was applied based on the language features to automatically classify whether a Weibo user exhibited any of the 5 risk factors.
RESULTS: A total of 974 Weibo users participated in the survey. Those with high suicide probability were marked by a higher usage of pronoun (odds ratio, OR=1.18, P=.001), prepend words (OR=1.49, P=.02), multifunction words (OR=1.12, P=.04), a lower usage of verb (OR=0.78, P{\textless}.001), and a greater total word count (OR=1.007, P=.008). Second-person plural was positively associated with severe depression (OR=8.36, P=.01) and stress (OR=11, P=.005), whereas work-related words were negatively associated with WSC (OR=0.71, P=.008), severe depression (OR=0.56, P=.005), and anxiety (OR=0.77, P=.02). Inconsistently, third-person plural was found to be negatively associated with WSC (OR=0.02, P=.047) but positively with severe stress (OR=41.3, P=.04). Achievement-related words were positively associated with depression (OR=1.68, P=.003), whereas health- (OR=2.36, P=.004) and death-related (OR=2.60, P=.01) words positively associated with stress. The machine classifiers did not achieve satisfying performance in the full sample set but could classify high suicide probability (area under the curve, AUC=0.61, P=.04) and severe anxiety (AUC=0.75, P{\textless}.001) among those who have exhibited WSC.
CONCLUSIONS: SC-LIWC is useful to examine language markers of suicide risk and emotional distress in Chinese social media and can identify characteristics different from previous findings in the English literature. Some findings are leading to new hypotheses for future verification. Machine classifiers based on SC-LIWC features are promising but still require further optimization for application in real life.},
	language = {eng},
	number = {7},
	journal = {Journal of Medical Internet Research},
	author = {Cheng, Qijin and Li, Tim Mh and Kwok, Chi-Leung and Zhu, Tingshao and Yip, Paul Sf},
	month = jul,
	year = {2017},
	pmid = {28694239},
	pmcid = {PMC5525005},
	pages = {e243}
}

@article{guan_[pilot_2015,
	title = {[{A} pilot study of differences in behavioral and linguistic characteristics between {Sina} suicide microblog users and {Sina} microblog users without suicide idea]},
	volume = {36},
	issn = {0254-6450},
	abstract = {OBJECTIVE: To investigate how suicide microblog users in China "act" and "speak" differently from other microblog users without suicide idea.
METHODS: The suicide group consisted of 31 Chinese microblog users identified as suicide via online information provided by a Sina microblog user, and the control group consisted of 30 active microblog users without suicide idea screened by using suicide-related psychological scales. The differences in 10 microblog use behavioral characteristics and 88 linguistic characteristics between the suicide group and the control group were compared with normality test and rank sum test respectively.
RESULTS: In the behavioral characteristics, the suicide group used hyperlinks and "@" less frequently than the control group [0.04 (0.04) vs. 0.06 (0.04), P=0.029; 0.60 (0.27) vs. 0.69 (0.18), P=0.028], and was more self-focused [0.47 (0.25) vs. 0.30 (0.10), P=0.010]. In the linguistic characteristics, the suicide group showed less frequency in using measure word, work related word and apostrophe than the control group (P{\textless}0.05), and showed more frequency in using pronoun, personal pronoun, third person singular, non-specific pronoun, word expressing social experience, word expressing anxiety, word expressing exclusion, sexual word, religious word, second person singular, human being related word, negative emotion related word, anger related word, sadness or death related word (P{\textless}0.05).
CONCLUSION: Suicides seemed to interact less with others, showed more self-concern and more negative expressions, use more cognitively exclusive, death-related, religion-related words, and use less work-related words. The results of this study might be helpful for the research on suicide among netizen.},
	language = {chi},
	number = {5},
	journal = {Zhonghua Liu Xing Bing Xue Za Zhi = Zhonghua Liuxingbingxue Zazhi},
	author = {Guan, Li and Hao, Bibo and Liu, Tianli and Cheng, Qijin and Yip, Paul Siu Fai and Zhu, Tingshao},
	month = may,
	year = {2015},
	pmid = {26080626},
	keywords = {mental\_health},
	pages = {421--425}
}

@article{liu_assessing_2014,
	title = {Assessing suicide attempts and depression among {Chinese} speakers over the {Internet}},
	volume = {35},
	issn = {2151-2396},
	doi = {10.1027/0227-5910/a000261},
	abstract = {BACKGROUND: In populations where mental health resources are scarce or unavailable, or where stigma prevents help-seeking, the Internet may be a way to identify and reach at-risk persons using self-report validated screening tools as well as to characterize individuals seeking health information online.
AIMS: We examined the feasibility of delivering an Internet-based Chinese-language depression and suicide screener and described its users.
METHOD: An Internet-based depression and suicide screener was created and advertised primarily through Google AdWords. Participants completed a suicide and depression screening measure and received individualized feedback, which, if necessary, included the suggestion to seek additional mental health resources.
RESULTS: In 7 months, 11,631 individuals visited the site; 4,709 provided valid information. Nearly half reported a current major depressive episode (MDE) and 18.3\% a recent suicide attempt; however, over 75\% reported never having sought help, including 77.7\% of those with MDEs and 75.9\% of those reporting a suicide attempt. As participants found the site by searching for depression information online, results may not generalize to the entire Chinese-speaking population.
CONCLUSION: Online screening can feasibly identify and reach many at-risk Chinese-speaking persons. It may provide resources to those with limited access to services or to those reluctant to seek such services.},
	language = {eng},
	number = {5},
	journal = {Crisis},
	author = {Liu, Nancy H. and Contreras, Omar and Muñoz, Ricardo F. and Leykin, Yan},
	year = {2014},
	pmid = {25115490},
	pmcid = {PMC4689579},
	pages = {322--329}
}

@article{quan_unsupervised_2014,
	title = {An unsupervised text mining method for relation extraction from biomedical literature},
	volume = {9},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0102039},
	abstract = {The wealth of interaction information provided in biomedical articles motivated the implementation of text mining approaches to automatically extract biomedical relations. This paper presents an unsupervised method based on pattern clustering and sentence parsing to deal with biomedical relation extraction. Pattern clustering algorithm is based on Polynomial Kernel method, which identifies interaction words from unlabeled data; these interaction words are then used in relation extraction between entity pairs. Dependency parsing and phrase structure parsing are combined for relation extraction. Based on the semi-supervised KNN algorithm, we extend the proposed unsupervised approach to a semi-supervised approach by combining pattern clustering, dependency parsing and phrase structure parsing rules. We evaluated the approaches on two different tasks: (1) Protein-protein interactions extraction, and (2) Gene-suicide association extraction. The evaluation of task (1) on the benchmark dataset (AImed corpus) showed that our proposed unsupervised approach outperformed three supervised methods. The three supervised methods are rule based, SVM based, and Kernel based separately. The proposed semi-supervised approach is superior to the existing semi-supervised methods. The evaluation on gene-suicide association extraction on a smaller dataset from Genetic Association Database and a larger dataset from publicly available PubMed showed that the proposed unsupervised and semi-supervised methods achieved much higher F-scores than co-occurrence based method.},
	language = {eng},
	number = {7},
	journal = {PloS One},
	author = {Quan, Changqin and Wang, Meng and Ren, Fuji},
	year = {2014},
	pmid = {25036529},
	pmcid = {PMC4103846},
	keywords = {IE},
	pages = {e102039}
}

@article{li_temporal_2014,
	title = {Temporal and computerized psycholinguistic analysis of the blog of a {Chinese} adolescent suicide},
	volume = {35},
	issn = {2151-2396},
	doi = {10.1027/0227-5910/a000248},
	abstract = {BACKGROUND: Text analysis of personal documents provides insight into the cognition of those who complete suicide. Many personal documents are digitalized and easily found on the Internet, which can be used to advance suicide research.
AIMS: (1) To examine the temporal relationships between posting intensity and language use to sketch the suicidal process of a young man on the basis of his blog entries. (2) To investigate whether digitalized personal documents and paper documents of suicide cases have similar or different language patterns.
METHOD: Firstly, 193 blog entries of a 13-year-old boy posted during the year prior to his suicide were analyzed using the Chinese Linguistic Inquiry and Word Count (CLIWC) program. The temporal relationships between posting intensity and language use were illustrated by time series visualization. Secondly, the findings of this case study were compared with previous case studies from a systematic search of three Ovid databases.
RESULTS: Posting frequency and language use in the blog helped sketch the suicidal process of the young boy. In this case study, the ratio of positive to negative emotion words was associated with the posting trend. Progressive self-referencing appeared to be a primary predictive sign of suicide. However, the comparison did not show other clearly consistent patterns.
CONCLUSION: Digitalized personal documents, when interpreted with other information of the individual, provide insight into the suicidal process of completed suicides. This study extends the findings of psycholinguistic analyses of suicides to the Chinese social context and online document form.},
	language = {eng},
	number = {3},
	journal = {Crisis},
	author = {Li, Tim M. H. and Chau, Michael and Yip, Paul S. F. and Wong, Paul W. C.},
	year = {2014},
	pmid = {24698727},
	pages = {168--175}
}

@misc{noauthor_suicide_nodate,
	title = {Suicide notes: what do they tell us? - {Ho} - 1998 - {Acta} {Psychiatrica} {Scandinavica} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0447.1998.tb10121.x/abstract;jsessionid=D54424594BD81F0D3ABA9A3191161AD2.f04t02},
	urldate = {2018-02-26},
	file = {Suicide notes\: what do they tell us? - Ho - 1998 - Acta Psychiatrica Scandinavica - Wiley Online Library:/Users/transfer/Zotero/storage/QN8DC9V3/abstract\;jsessionid=D54424594BD81F0D3ABA9A3191161AD2.html:text/html}
}

@article{chia_suicide_1979,
	title = {Suicide letters},
	volume = {8},
	issn = {0304-4602},
	abstract = {This is a study of 266 suicide letters collected over a period of 8 years (1969-1976). In the study of completed suicide cases, there are few sources of data available. A critical research may question the reliability of the study of suicide letters. In this paper the author tries to answer some of the many questions which might be posed. It is however felt that the study of suicide letters does help us to understand the mental state of suicidal victims prior to their acts. The study of suicide letter is one of the prerequisites to the understanding of this complicated human behaviour.},
	language = {eng},
	number = {3},
	journal = {Annals of the Academy of Medicine, Singapore},
	author = {Chia, B. H. and Tsoi, W. F.},
	month = jul,
	year = {1979},
	pmid = {547873},
	pages = {298--300}
}

@article{waters_suicide_2017,
	title = {Suicide voices: testimonies of trauma in the {French} workplace},
	volume = {43},
	issn = {1468-215X},
	shorttitle = {Suicide voices},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5378294/},
	doi = {10.1136/medhum-2016-011013},
	abstract = {Workplace suicide has become an urgent social concern internationally with rising numbers of employees choosing to kill themselves in the face of extreme pressures at work. Yet, research on this phenomenon is hampered by fragmentary statistical data and the sheer contentiousness of this issue. This paper presents the preliminary findings of a research project on workplace suicides in France, where there has been a ‘suicide epidemic’ across a wide range of companies. I draw on an analysis of suicide letters linked to 23 suicide cases across three French companies during the period 2005–2015. My methodological approach is informed by the work of suicide sociologist, Jack D Douglas, who emphasised the importance of narrative, testimony and voice to our understanding of the causes of suicide. Douglas argued that an analysis of the ‘social meanings’ of suicide should start with a consideration of the motivations attributed to self-killing by suicidal individuals themselves and those close to them. Why does work or conditions of work push some individuals to take their own lives? What can the ‘suicide voices’ articulated in recent testimonies tell us about the causes of workplace suicide? In this paper, I treat suicide letters as a unique mode of testimony that can reveal some of the profound effects of workplace transformations on subjective, intimate and lived experiences of work. By examining French suicide testimonies, my aim is to deepen our understanding of the nature and causes of suicide in today’s globalised workplaces.},
	number = {1},
	urldate = {2018-02-26},
	journal = {Medical humanities},
	author = {Waters, Sarah},
	month = mar,
	year = {2017},
	pmid = {27613808},
	pmcid = {PMC5378294},
	pages = {24--29},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/78VIWSAW/Waters - 2017 - Suicide voices testimonies of trauma in the Frenc.pdf:application/pdf}
}

@inproceedings{losada_test_2016,
	title = {A test collection for research on depression and language use},
	booktitle = {International {Conference} of the {Cross}-{Language} {Evaluation} {Forum} for {European} {Languages}},
	publisher = {Springer},
	author = {Losada, David E. and Crestani, Fabio},
	year = {2016},
	pages = {28--39},
	file = {Fulltext:/Users/transfer/Zotero/storage/3V59HWBY/Losada and Crestani - 2016 - A test collection for research on depression and l.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GW92MXUB/978-3-319-44564-9_3.html:text/html}
}

@inproceedings{resnik_beyond_2015,
	title = {Beyond {LDA}: exploring supervised topic modeling for depression-related language in {Twitter}},
	shorttitle = {Beyond {LDA}},
	booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
	author = {Resnik, Philip and Armstrong, William and Claudino, Leonardo and Nguyen, Thang and Nguyen, Viet-An and Boyd-Graber, Jordan},
	year = {2015},
	pages = {99--107},
	file = {Fulltext:/Users/transfer/Zotero/storage/BYQ7VQ7U/Resnik et al. - 2015 - Beyond LDA exploring supervised topic modeling fo.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HDNTSAPH/Resnik et al. - 2015 - Beyond LDA exploring supervised topic modeling fo.pdf:application/pdf}
}

@inproceedings{schwartz_predicting_2016,
	title = {Predicting individual well-being through the language of social media},
	booktitle = {Biocomputing 2016: {Proceedings} of the {Pacific} {Symposium}},
	publisher = {World Scientific},
	author = {Schwartz, H. Andrew and Sap, Maarten and Kern, Margaret L. and Eichstaedt, Johannes C. and Kapelner, Adam and Agrawal, Megha and Blanco, Eduardo and Dziurzynski, Lukasz and Park, Gregory and Stillwell, David},
	year = {2016},
	pages = {516--527},
	file = {Fulltext:/Users/transfer/Zotero/storage/H8BQFJ6Q/Schwartz et al. - 2016 - Predicting individual well-being through the langu.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/A3YG6SFJ/9789814749411_0047.html:text/html}
}

@inproceedings{preotiuc-pietro_mental_2015,
	title = {Mental illness detection at the {World} {Well}-{Being} {Project} for the {CLPsych} 2015 shared task},
	booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
	author = {Preoţiuc-Pietro, Daniel and Sap, Maarten and Schwartz, H. Andrew and Ungar, Lyle},
	year = {2015},
	pages = {40--45},
	file = {Fulltext:/Users/transfer/Zotero/storage/WRVRMK6J/Preoţiuc-Pietro et al. - 2015 - Mental illness detection at the World Well-Being P.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/KJ4A5Q5K/Preoţiuc-Pietro et al. - 2015 - Mental illness detection at the World Well-Being P.pdf:application/pdf}
}

@inproceedings{coppersmith_quantifying_2015,
	title = {Quantifying suicidal ideation via language usage on social media},
	booktitle = {Joint {Statistics} {Meetings} {Proceedings}, {Statistical} {Computing} {Section}, {JSM}},
	author = {Coppersmith, Glen and Leary, Ryan and Whyne, Eric and Wood, Tony},
	year = {2015},
	file = {Fulltext:/Users/transfer/Zotero/storage/INUENBM3/Coppersmith et al. - 2015 - Quantifying suicidal ideation via language usage o.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/JNLTI8DG/Coppersmith et al. - 2015 - Quantifying suicidal ideation via language usage o.pdf:application/pdf}
}

@inproceedings{coppersmith_exploratory_2016,
	title = {Exploratory analysis of social media prior to a suicide attempt},
	booktitle = {Proceedings of the {Third} {Workshop} on {Computational} {Lingusitics} and {Clinical} {Psychology}},
	author = {Coppersmith, Glen and Ngo, Kim and Leary, Ryan and Wood, Anthony},
	year = {2016},
	pages = {106--117},
	file = {Fulltext:/Users/transfer/Zotero/storage/R4B26TWW/Coppersmith et al. - 2016 - Exploratory analysis of social media prior to a su.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/8IRWXM6H/Coppersmith et al. - 2016 - Exploratory analysis of social media prior to a su.pdf:application/pdf}
}

@inproceedings{resnik_university_2015,
	title = {The {University} of {Maryland} {CLPsych} 2015 shared task system},
	booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
	author = {Resnik, Philip and Armstrong, William and Claudino, Leonardo and Nguyen, Thang},
	year = {2015},
	pages = {54--60},
	file = {Fulltext:/Users/transfer/Zotero/storage/XSBUGIAI/Resnik et al. - 2015 - The University of Maryland CLPsych 2015 shared tas.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CLLWRHAK/Resnik et al. - 2015 - The University of Maryland CLPsych 2015 shared tas.pdf:application/pdf}
}

@inproceedings{milne_clpsych_2016,
	title = {Clpsych 2016 shared task: {Triaging} content in online peer-support forums},
	shorttitle = {Clpsych 2016 shared task},
	booktitle = {Proceedings of the {Third} {Workshop} on {Computational} {Lingusitics} and {Clinical} {Psychology}},
	author = {Milne, David N. and Pink, Glen and Hachey, Ben and Calvo, Rafael A.},
	year = {2016},
	pages = {118--127},
	file = {Fulltext:/Users/transfer/Zotero/storage/P597TKCW/Milne et al. - 2016 - Clpsych 2016 shared task Triaging content in onli.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/JFQH36UN/Milne et al. - 2016 - Clpsych 2016 shared task Triaging content in onli.pdf:application/pdf}
}

@inproceedings{pedersen_screening_2015,
	title = {Screening twitter users for depression and ptsd with lexical decision lists},
	booktitle = {Proceedings of the 2nd workshop on computational linguistics and clinical psychology: from linguistic signal to clinical reality},
	author = {Pedersen, Ted},
	year = {2015},
	pages = {46--53},
	file = {Fulltext:/Users/transfer/Zotero/storage/SW5K6AEL/Pedersen - 2015 - Screening twitter users for depression and ptsd wi.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3YX9RYCS/Pedersen - 2015 - Screening twitter users for depression and ptsd wi.pdf:application/pdf}
}

@article{braithwaite_validating_2016,
	title = {Validating machine learning algorithms for {Twitter} data against established measures of suicidality},
	volume = {3},
	number = {2},
	journal = {JMIR mental health},
	author = {Braithwaite, Scott R. and Giraud-Carrier, Christophe and West, Josh and Barnes, Michael D. and Hanson, Carl Lee},
	year = {2016},
	file = {Fulltext:/Users/transfer/Zotero/storage/TVKNMXXB/PMC4886102.html:text/html;Snapshot:/Users/transfer/Zotero/storage/BWAJDW64/PMC4886102.html:text/html}
}

@article{nadeem_identifying_2016,
	title = {Identifying depression on {Twitter}},
	journal = {arXiv preprint arXiv:1607.07384},
	author = {Nadeem, Moin},
	year = {2016},
	file = {Fulltext:/Users/transfer/Zotero/storage/9PKHNNV7/Nadeem - 2016 - Identifying depression on Twitter.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XYCVWXWQ/1607.html:text/html}
}

@article{mowery_understanding_2017,
	title = {Understanding depressive symptoms and psychosocial stressors on {Twitter}: a corpus-based study},
	volume = {19},
	shorttitle = {Understanding depressive symptoms and psychosocial stressors on {Twitter}},
	number = {2},
	journal = {Journal of medical Internet research},
	author = {Mowery, Danielle and Smith, Hilary and Cheney, Tyler and Stoddard, Greg and Coppersmith, Glen and Bryan, Craig and Conway, Mike},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/75IP5P7U/PMC5350450.html:text/html;Snapshot:/Users/transfer/Zotero/storage/ZVGSH2JT/PMC5350450.html:text/html}
}

@article{wongkoblap_researching_2017,
	title = {Researching mental health disorders in the era of social media: {Systematic} review},
	volume = {19},
	shorttitle = {Researching mental health disorders in the era of social media},
	number = {6},
	journal = {Journal of medical Internet research},
	author = {Wongkoblap, Akkapon and Vadillo, Miguel A. and Curcin, Vasa},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/GJ9PB6IJ/PMC5509952.html:text/html;Snapshot:/Users/transfer/Zotero/storage/T4H7DFKT/PMC5509952.html:text/html}
}

@article{guntuku_detecting_2017,
	title = {Detecting depression and mental illness on social media: an integrative review},
	volume = {18},
	shorttitle = {Detecting depression and mental illness on social media},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Guntuku, Sharath Chandra and Yaden, David B. and Kern, Margaret L. and Ungar, Lyle H. and Eichstaedt, Johannes C.},
	year = {2017},
	pages = {43--49},
	file = {Fulltext:/Users/transfer/Zotero/storage/XL32AP4I/Guntuku et al. - 2017 - Detecting depression and mental illness on social .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/9I8F8TE7/S2352154617300384.html:text/html}
}

@inproceedings{pink_classification_2016,
	title = {Classification of mental health forum posts},
	booktitle = {Proceedings of the {Third} {Workshop} on {Computational} {Lingusitics} and {Clinical} {Psychology}},
	author = {Pink, Glen and Radford, Will and Hachey, Ben},
	year = {2016},
	pages = {180--182},
	file = {Fulltext:/Users/transfer/Zotero/storage/CV6TFTFL/Pink et al. - 2016 - Classification of mental health forum posts.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/C37GP2TZ/Pink et al. - 2016 - Classification of mental health forum posts.pdf:application/pdf}
}

@article{calvo_natural_2017,
	title = {Natural language processing in mental health applications using non-clinical texts},
	volume = {23},
	number = {5},
	journal = {Natural Language Engineering},
	author = {Calvo, Rafael A. and Milne, David N. and Hussain, M. Sazzad and Christensen, Helen},
	year = {2017},
	pages = {649--685},
	file = {Fulltext:/Users/transfer/Zotero/storage/PHHIXQ7G/Calvo et al. - 2017 - Natural language processing in mental health appli.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6NG9EM48/32645FFCFD37C67DA62CA06DB66EB2F4.html:text/html}
}

@article{amir_quantifying_2017,
	title = {Quantifying {Mental} {Health} from {Social} {Media} with {Neural} {User} {Embeddings}},
	journal = {arXiv preprint arXiv:1705.00335},
	author = {Amir, Silvio and Coppersmith, Glen and Carvalho, Paula and Silva, Mário J. and Wallace, Byron C.},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/6S9C5QDV/Amir et al. - 2017 - Quantifying Mental Health from Social Media with N.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3DVS5MH7/1705.html:text/html}
}

@article{benton_multi-task_2017,
	title = {Multi-task learning for mental health using social media text},
	journal = {arXiv preprint arXiv:1712.03538},
	author = {Benton, Adrian and Mitchell, Margaret and Hovy, Dirk},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/NY3V9FI9/Benton et al. - 2017 - Multi-task learning for mental health using social.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/I7CBLBH4/1712.html:text/html}
}

@article{gonzalez-hernandez_capturing_2017,
	title = {Capturing the patient’s perspective: a review of advances in natural language processing of health-related text},
	volume = {26},
	shorttitle = {Capturing the patient’s perspective},
	number = {01},
	journal = {Yearbook of medical informatics},
	author = {Gonzalez-Hernandez, G. and Sarker, A. and O’Connor, K. and Savova, G.},
	year = {2017},
	keywords = {female first or senior},
	pages = {214--227},
	file = {Fulltext:/Users/transfer/Zotero/storage/RS2MYD24/Gonzalez-Hernandez et al. - 2017 - Capturing the patient’s perspective a review of a.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/V34IDSKA/Gonzalez-Hernandez et al. - 2017 - Capturing the patient’s perspective a review of a.pdf:application/pdf}
}

@article{elibol_cross-corpora_2016,
	title = {Cross-corpora unsupervised learning of trajectories in autism spectrum disorders},
	volume = {17},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Elibol, Huseyin Melih and Nguyen, Vincent and Linderman, Scott and Johnson, Matthew and Hashmi, Amna and Doshi-Velez, Finale},
	year = {2016},
	pages = {4597--4634},
	file = {Fulltext:/Users/transfer/Zotero/storage/Z7UHHSF8/Elibol et al. - 2016 - Cross-corpora unsupervised learning of trajectorie.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3WHVZUNG/Elibol et al. - 2016 - Cross-corpora unsupervised learning of trajectorie.pdf:application/pdf}
}

@book{wijeratne_feature_2017,
	title = {Feature {Engineering} for {Twitter}-based {Applications}},
	publisher = {Chapman and Hall. Data Mining and Knowledge Discovery Series},
	author = {Wijeratne, Sanjaya and Sheth, Amit and Bhatt, Shreyansh and Balasuriya, Lakshika and Al-Olimat, Hussein S. and Gaur, Manas and Hossein, Amir and Yazdavar, Krishnaprasad Thirunarayan},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/9WHL5JWN/Wijeratne et al. - 2017 - Feature Engineering for Twitter-based Applications.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/98TYCNII/Wijeratne et al. - 2017 - Feature Engineering for Twitter-based Applications.pdf:application/pdf}
}

@inproceedings{trotzek_linguistic_2017,
	title = {Linguistic {Metadata} {Augmented} {Classifiers} at the {CLEF} 2017 {Task} for {Early} {Detection} of {Depression}},
	booktitle = {8th {International} {Conference} of the {CLEF} {Association}, {CLEF}},
	author = {Trotzek, Marcel and Koitka, Sven and Friedrich, Christoph M.},
	year = {2017},
	pages = {11--14},
	file = {Fulltext:/Users/transfer/Zotero/storage/35VNKMVY/Trotzek et al. - 2017 - Linguistic Metadata Augmented Classifiers at the C.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/8WMBGDXE/Trotzek et al. - 2017 - Linguistic Metadata Augmented Classifiers at the C.pdf:application/pdf}
}

@inproceedings{wang_role_2016,
	title = {The {Role} of {Features} and {Context} on {Suicide} {Ideation} {Detection}},
	booktitle = {Proceedings of the {Australasian} {Language} {Technology} {Association} {Workshop} 2016},
	author = {Wang, Yufei and Wan, Stephen and Paris, Cécile},
	year = {2016},
	pages = {94--102},
	file = {Fulltext:/Users/transfer/Zotero/storage/95ZF48YF/Wang et al. - 2016 - The Role of Features and Context on Suicide Ideati.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PU24M5DF/Wang et al. - 2016 - The Role of Features and Context on Suicide Ideati.pdf:application/pdf}
}

@inproceedings{almeida_detecting_2017,
	title = {Detecting {Early} {Risk} of {Depression} from {Social} {Media} {User}-generated {Content}},
	booktitle = {8th {International} {Conference} of the {CLEF} {Association}, {CLEF}},
	author = {Almeida, Hayda and Briand, Antoine and Meurs, Marie-Jean},
	year = {2017},
	pages = {11--14},
	file = {Fulltext:/Users/transfer/Zotero/storage/RWUMNT7S/Almeida et al. - 2017 - Detecting Early Risk of Depression from Social Med.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/I6XCG8UB/Almeida et al. - 2017 - Detecting Early Risk of Depression from Social Med.pdf:application/pdf}
}

@phdthesis{yelland_what_2017,
	type = {{PhD} {Thesis}},
	title = {What text mining analysis of psychotherapy records can tell us about therapy process and outcome},
	school = {UCL (University College London)},
	author = {Yelland, Eleanor Rosa},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/5NF2NNIP/Yelland - 2017 - What text mining analysis of psychotherapy records.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MN37F9J5/1563447.html:text/html}
}

@article{cerutti_4_nodate,
	title = {4 {Working} groups 4.1 {A} {Pilot} {Study} in {Mining} {Argumentation} {Frameworks} from {Online} {Debates}},
	journal = {Natural Language Argumentation: Mining, Processing, and Reasoning over Textual Arguments},
	author = {Cerutti, Federico and Palmer, Alexis M.},
	pages = {103},
	file = {Fulltext:/Users/transfer/Zotero/storage/MQS4DBJ3/Cerutti and Palmer - 4 Working groups 4.1 A Pilot Study in Mining Argum.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/2JV3SXBX/Cerutti and Palmer - 4 Working groups 4.1 A Pilot Study in Mining Argum.pdf:application/pdf}
}

@article{armstrong_using_nodate,
	title = {Using {Topic} {Models} to {Investigate} {Depression} on {Social} {Media}},
	author = {Armstrong, William},
	file = {Fulltext:/Users/transfer/Zotero/storage/IR4IWD6C/Armstrong - Using Topic Models to Investigate Depression on So.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HEUTNUC6/Armstrong - Using Topic Models to Investigate Depression on So.pdf:application/pdf}
}

@inproceedings{fraser_detecting_2016,
	title = {Detecting late-life depression in {Alzheimer}'s disease through analysis of speech and language},
	booktitle = {Proceedings of the {Third} {Workshop} on {Computational} {Lingusitics} and {Clinical} {Psychology}},
	author = {Fraser, Kathleen C. and Rudzicz, Frank and Hirst, Graeme},
	year = {2016},
	pages = {1--11},
	file = {Fulltext:/Users/transfer/Zotero/storage/38HY82JE/Fraser et al. - 2016 - Detecting late-life depression in Alzheimer's dise.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XPX2HPWX/Fraser et al. - 2016 - Detecting late-life depression in Alzheimer's dise.pdf:application/pdf}
}

@inproceedings{zuorba_framework_2017,
	title = {A {Framework} for {Identifying} {Excessive} {Sadness} in {Students} through {Twitter} and {Facebook} in the {Philippines}},
	booktitle = {Proceedings of the {International} {Conference} on {Bioinformatics} {Research} and {Applications} 2017},
	publisher = {ACM},
	author = {Zuorba, Hussain D. and Olan, Celine Louise O. and Cantara, Anthonette D.},
	year = {2017},
	pages = {52--56},
	file = {Snapshot:/Users/transfer/Zotero/storage/EJKJFD5N/citation.html:text/html}
}

@article{paul_social_2017,
	title = {Social {Monitoring} for {Public} {Health}},
	volume = {9},
	number = {5},
	journal = {Synthesis Lectures on Information Concepts, Retrieval, and Services},
	author = {Paul, Michael J. and Dredze, Mark},
	year = {2017},
	pages = {1--183},
	file = {Snapshot:/Users/transfer/Zotero/storage/D5NLFDZ8/S00791ED1V01Y201707ICR060.html:text/html}
}

@inproceedings{yazdavar_semi-supervised_2017,
	title = {Semi-{Supervised} {Approach} to {Monitoring} {Clinical} {Depressive} {Symptoms} in {Social} {Media}},
	booktitle = {Proceedings of the 2017 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} 2017},
	publisher = {ACM},
	author = {Yazdavar, Amir Hossein and Al-Olimat, Hussein S. and Ebrahimi, Monireh and Bajaj, Goonmeet and Banerjee, Tanvi and Thirunarayan, Krishnaprasad and Pathak, Jyotishman and Sheth, Amit},
	year = {2017},
	pages = {1191--1198},
	file = {Fulltext:/Users/transfer/Zotero/storage/TQ523VLJ/Yazdavar et al. - 2017 - Semi-Supervised Approach to Monitoring Clinical De.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/9R2C8DN7/citation.html:text/html}
}

@article{guntuku_language_2017,
	title = {Language of {ADHD} in {Adults} on {Social} {Media}},
	journal = {Journal of attention disorders},
	author = {Guntuku, Sharath Chandra and Ramsay, J. Russell and Merchant, Raina M. and Ungar, Lyle H.},
	year = {2017},
	pages = {1087054717738083},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZH4H75XG/Guntuku et al. - 2017 - Language of ADHD in Adults on Social Media.pdf:application/pdf}
}

@phdthesis{jamil_monitoring_2017,
	type = {{PhD} {Thesis}},
	title = {Monitoring {Tweets} for {Depression} to {Detect} {At}-risk {Users}},
	school = {Université d'Ottawa/University of Ottawa},
	author = {Jamil, Zunaira},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/DY6XYL4H/Jamil - 2017 - Monitoring Tweets for Depression to Detect At-risk.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/FM5C7QNJ/36030.html:text/html}
}

@article{desmet_emotion_2013,
	title = {Emotion detection in suicide notes},
	volume = {40},
	number = {16},
	journal = {Expert Systems with Applications},
	author = {Desmet, Bart and Hoste, VéRonique},
	year = {2013},
	pages = {6351--6358},
	file = {Fulltext:/Users/transfer/Zotero/storage/FL82ZV5V/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/GJ9MM3B5/S0957417413003485.html:text/html}
}

@article{cherry_binary_2012,
	title = {Binary classifiers and latent sequence models for emotion detection in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Cherry, Colin and Mohammad, Saif M. and De Bruijn, Berry},
	year = {2012},
	pages = {BII--S8933}
}

@inproceedings{burnap_machine_2015,
	title = {Machine classification and analysis of suicide-related communication on twitter},
	booktitle = {Proceedings of the 26th {ACM} conference on hypertext \& social media},
	publisher = {ACM},
	author = {Burnap, Pete and Colombo, Walter and Scourfield, Jonathan},
	year = {2015},
	pages = {75--84}
}

@article{spasic_naive_2012,
	title = {A naïve bayes approach to classifying topics in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Spasić, Irena and Burnap, Pete and Greenwood, Mark and Arribas-Ayllon, Michael},
	year = {2012},
	pages = {BII--S8945}
}

@article{luyckx_fine-grained_2012,
	title = {Fine-grained emotion detection in suicide notes: {A} thresholding approach to multi-label classification},
	volume = {5},
	shorttitle = {Fine-grained emotion detection in suicide notes},
	journal = {Biomedical informatics insights},
	author = {Luyckx, Kim and Vaassen, Frederik and Peersman, Claudia and Daelemans, Walter},
	year = {2012},
	pages = {BII--S8966}
}

@inproceedings{lehrman_detecting_2012,
	title = {Detecting distressed and non-distressed affect states in short forum texts},
	booktitle = {Proceedings of the {Second} {Workshop} on {Language} in {Social} {Media}},
	publisher = {Association for Computational Linguistics},
	author = {Lehrman, Michael Thaul and Alm, Cecilia Ovesdotter and Proano, Rubén A.},
	year = {2012},
	pages = {9--18}
}

@article{althoff_large-scale_2016,
	title = {Large-scale analysis of counseling conversations: {An} application of natural language processing to mental health},
	volume = {4},
	shorttitle = {Large-scale analysis of counseling conversations},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Althoff, Tim and Clark, Kevin and Leskovec, Jure},
	year = {2016},
	pages = {463}
}

@inproceedings{pedersen_screening_2015-1,
	title = {Screening twitter users for depression and ptsd with lexical decision lists},
	booktitle = {Proceedings of the 2nd workshop on computational linguistics and clinical psychology: from linguistic signal to clinical reality},
	author = {Pedersen, Ted},
	year = {2015},
	pages = {46--53}
}

@inproceedings{desmet_recognising_2014,
	title = {Recognising suicidal messages in {Dutch} social media},
	booktitle = {9th international conference on language resources and evaluation ({LREC})},
	author = {Desmet, Bart and Hoste, Véronique},
	year = {2014},
	pages = {830--835}
}

@article{conway_social_2016,
	title = {Social media, big data, and mental health: current advances and ethical implications},
	volume = {9},
	shorttitle = {Social media, big data, and mental health},
	journal = {Current opinion in psychology},
	author = {Conway, Mike and O’Connor, Daniel},
	year = {2016},
	pages = {77--82}
}

@inproceedings{morris_extracting_2012,
	title = {Extracting and networking emotions in extremist propaganda},
	booktitle = {Intelligence and {Security} {Informatics} {Conference} ({EISIC}), 2012 {European}},
	publisher = {IEEE},
	author = {Morris, Travis},
	year = {2012},
	pages = {53--59},
	file = {Fulltext:/Users/transfer/Zotero/storage/XBZ3XDQB/Morris - 2012 - Extracting and networking emotions in extremist pr.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CE64FMST/6298813.html:text/html}
}

@article{wang_discovering_2012,
	title = {Discovering fine-grained sentiment in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Wang, Wenbo and Chen, Lu and Tan, Ming and Wang, Shaojun and Sheth, Amit P.},
	year = {2012},
	pages = {BII--S8963}
}

@article{wicentowski_emotion_2012,
	title = {emotion {Detection} in suicide notes using {Maximum} {Entropy} {Classification}},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Wicentowski, Richard and Sydes, Matthew R.},
	year = {2012},
	pages = {BII--S8972}
}

@article{nikfarjam_hybrid_2012,
	title = {A hybrid system for emotion extraction from suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Nikfarjam, Azadeh and Emadzadeh, Ehsan and Gonzalez, Graciela},
	year = {2012},
	keywords = {female first or senior, IE},
	pages = {BII--S8981}
}

@inproceedings{huang_detecting_2014,
	title = {Detecting suicidal ideation in {Chinese} microblogs with psychological lexicons},
	booktitle = {Ubiquitous {Intelligence} and {Computing}, 2014 {IEEE} 11th {Intl} {Conf} on and {IEEE} 11th {Intl} {Conf} on and {Autonomic} and {Trusted} {Computing}, and {IEEE} 14th {Intl} {Conf} on {Scalable} {Computing} and {Communications} and {Its} {Associated} {Workshops} ({UTC}-{ATC}-{ScalCom})},
	publisher = {IEEE},
	author = {Huang, Xiaolei and Zhang, Lei and Chiu, David and Liu, Tianli and Li, Xin and Zhu, Tingshao},
	year = {2014},
	pages = {844--849},
	file = {Fulltext:/Users/transfer/Zotero/storage/28242A57/Huang et al. - 2014 - Detecting suicidal ideation in Chinese microblogs .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6UHE5QAA/7307052.html:text/html}
}

@article{haefeli_communications-based_2015,
	title = {Communications-based early detection of gambling-related problems in online gambling},
	volume = {15},
	number = {1},
	journal = {International Gambling Studies},
	author = {Haefeli, Joerg and Lischer, Suzanne and Haeusler, Joachim},
	year = {2015},
	pages = {23--38}
}

@article{mccart_using_2012,
	title = {Using ensemble models to classify the sentiment expressed in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {McCart, James A. and Finch, Dezon K. and Jarman, Jay and Hickling, Edward and Lind, Jason D. and Richardson, Matthew R. and Berndt, Donald J. and Luther, Stephen L.},
	year = {2012},
	pages = {BII--S8931}
}

@article{ceballos-espinoza_suicidio_2013,
	title = {El suicidio en {Chile}: {Una} aproximación al perfil suicida a partir del análisis de notas suicidas},
	volume = {10},
	shorttitle = {El suicidio en {Chile}},
	number = {1},
	journal = {Estudios policiales},
	author = {Ceballos-Espinoza, F.},
	year = {2013},
	pages = {77--92}
}

@article{desmet_combining_2012,
	title = {Combining lexico-semantic features for emotion classification in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Desmet, Bart and Hoste, Véronique},
	year = {2012},
	pages = {BII--S8960}
}

@inproceedings{pappas_anger_2015,
	title = {Anger detection in call center dialogues},
	booktitle = {Cognitive {Infocommunications} ({CogInfoCom}), 2015 6th {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Pappas, Dimitris and Androutsopoulos, Ion and Papageorgiou, Haris},
	year = {2015},
	pages = {139--144},
	file = {Snapshot:/Users/transfer/Zotero/storage/ZU9VLT6Y/7390579.html:text/html}
}

@inproceedings{pestian_suicidal_2013,
	title = {Suicidal thought markers: a controlled trial examining the language of suicidal adolescents},
	shorttitle = {Suicidal thought markers},
	booktitle = {American association of {Suicidology} annual conference. {Austin}},
	author = {Pestian, J. and Matykiewicz, Pawel and Cohen, K. and Grupp-Phelan, Jacqueline and Richey, L. and Meyers, Gabriel and Canter, Christina M. and Sorter, Michael T.},
	year = {2013}
}

@book{denecke_health_2015,
	title = {Health {Web} {Science}: {Social} {Media} {Data} for {Healthcare}},
	shorttitle = {Health {Web} {Science}},
	publisher = {Springer},
	author = {Denecke, Kerstin},
	year = {2015}
}

@article{pak_combined_2012,
	title = {A combined {Approach} to emotion {Detection} in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Pak, Alexander and Bernhard, Delphine and Paroubek, Patrick and Grouin, Cyril},
	year = {2012},
	pages = {BII--S8969}
}

@phdthesis{desmet_finding_2014,
	type = {{PhD} {Thesis}},
	title = {Finding the online cry for help: automatic text classification for suicide prevention},
	shorttitle = {Finding the online cry for help},
	school = {Ghent University},
	author = {Desmet, Bart},
	year = {2014}
}

@article{lv_creating_2015,
	title = {Creating a {Chinese} suicide dictionary for identifying suicide risk on social media},
	volume = {3},
	journal = {PeerJ},
	author = {Lv, Meizhen and Li, Ang and Liu, Tianli and Zhu, Tingshao},
	year = {2015},
	pages = {e1455}
}

@article{pedersen_rule-based_2012,
	title = {Rule-based and lightly supervised methods to predict emotions in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Pedersen, Ted},
	year = {2012},
	pages = {BII--S8953}
}

@article{read_labeling_2012,
	title = {Labeling emotions in suicide notes: cost-sensitive {Learning} with {Heterogeneous} {Features}},
	volume = {5},
	shorttitle = {Labeling emotions in suicide notes},
	journal = {Biomedical informatics insights},
	author = {Read, Jonathon and Velldal, Erik and Øvrelid, Lilja},
	year = {2012},
	pages = {BII--S8930}
}

@article{kovacevic_topic_2012,
	title = {Topic categorisation of statements in suicide notes with integrated rules and machine learning},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Kovačević, Aleksandar and Dehghan, Azad and Keane, John A. and Nenadic, Goran},
	year = {2012},
	pages = {BII--S8978}
}

@article{yeh_leveraging_2012,
	title = {Leveraging psycholinguistic resources and emotional sequence models for suicide note emotion annotation},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Yeh, Eric and Jarrold, William and Jordan, Joshua},
	year = {2012},
	pages = {BII--S8979}
}

@inproceedings{wang_understanding_2017,
	title = {Understanding and discovering deliberate self-harm content in social media},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Wang, Yilin and Tang, Jiliang and Li, Jundong and Li, Baoxin and Wan, Yali and Mellina, Clayton and O'Hare, Neil and Chang, Yi},
	year = {2017},
	pages = {93--102}
}

@article{murphy_using_2014,
	title = {Using supervised learning to identify descriptions of personal experiences related to chronic disease on social media},
	author = {Murphy, William P.},
	year = {2014}
}

@article{roberts_statistical_2012,
	title = {statistical and similarity {Methods} for classifying emotion in suicide notes},
	volume = {5},
	journal = {Biomedical informatics insights},
	author = {Roberts, Kirk and Harabagiu, Sanda M.},
	year = {2012},
	pages = {BII--S8958}
}

@article{mokkenstorm_evaluation_2017,
	title = {Evaluation of the 113Online suicide prevention crisis chat service: outcomes, helper behaviors and comparison to telephone hotlines},
	volume = {47},
	shorttitle = {Evaluation of the 113Online suicide prevention crisis chat service},
	number = {3},
	journal = {Suicide and life-threatening behavior},
	author = {Mokkenstorm, Jan K. and Eikelenboom, Merijn and Huisman, Annemiek and Wiebenga, Jasper and Gilissen, Renske and Kerkhof, Ad JFM and Smit, Johannes H.},
	year = {2017},
	pages = {282--296}
}

@article{read_topic_2012,
	title = {Topic classification for suicidology},
	volume = {6},
	number = {2},
	journal = {Journal of computing science and engineering},
	author = {Read, Jonathon and Velldal, Erik and Øvrelid, Lilja},
	year = {2012},
	pages = {143--150}
}

@inproceedings{melzi_que_2014,
	title = {Que ressentent les patients?},
	booktitle = {{EGC}: {Extraction} et {Gestion} des {Connaissances}},
	author = {Melzi, Soumia and Abdaoui, Amine and Azé, Jérôme and Bringay, Sandra and Poncelet, Pascal and Galtier, Florence},
	year = {2014},
	keywords = {IE}
}

@inproceedings{liew_expanding_2014,
	title = {Expanding the {Range} of {Automatic} {Emotion} {Detection} in {Microblogging} {Text}},
	booktitle = {Proceedings of the {Student} {Research} {Workshop} at the 14th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	author = {Liew, Jasy Suet Yan},
	year = {2014},
	pages = {38--44}
}

@article{bringay_prevention_nodate,
	title = {Prévention des suicides via {Twitter}},
	author = {BRINGAY, Sandra and AZÉ, Jérôme and PONCELET, Pascal and ABBOUTE, Amayas and BOUDJERIOU, Yasser and ENTRINGER, Gilles}
}

@inproceedings{van_hee_analysing_2016,
	title = {Analysing emotions in social media coverage on {Paris} terror attacks: a pilot study},
	shorttitle = {Analysing emotions in social media coverage on {Paris} terror attacks},
	booktitle = {The {Second} {International} {Conference} on {Human} and {Social} {Analytics} ({HUSO} 2016)},
	publisher = {IARIA},
	author = {Van Hee, Cynthia and Verleye, Celine and Lefever, Els},
	year = {2016},
	pages = {33--37},
	file = {Snapshot:/Users/transfer/Zotero/storage/9ZDN7FJU/Van Hee et al. - 2016 - Analysing emotions in social media coverage on Par.pdf:application/pdf}
}

@article{patrick_textual_2015,
	title = {Textual prediction of attitudes towards mental health},
	volume = {3},
	number = {3-4},
	journal = {International Journal of Knowledge Engineering and Data Mining},
	author = {Patrick, Mensah Kwabena},
	year = {2015},
	pages = {274--285},
	file = {Snapshot:/Users/transfer/Zotero/storage/D2R934HR/IJKEDM.2015.html:text/html}
}

@article{litvinova_identification_2017,
	title = {Identification of {Suicidal} {Tendencies} of {Individuals} {Based} on the {Quantitative} {Analysis} of their {Internet} {Texts}},
	volume = {21},
	number = {2},
	journal = {Computación y Sistemas},
	author = {Litvinova, Tatiana and Seredin, Pavel V. and Litvinova, Olga A. and Romanchenko, Olga V.},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/VCVN6JC6/61551628006.html:text/html;Snapshot:/Users/transfer/Zotero/storage/WE6EDZFK/61551628006.html:text/html}
}

@article{pestian_whats_2013,
	title = {What’s {In} {A} {Note}: {Construction} of a {Suicide} {Note} {Corpora}},
	shorttitle = {What’s {In} {A} {Note}},
	author = {Pestian, John P. and Matykiewicz, Pawel and Linn-Gust, Michelle},
	year = {2013}
}

@article{alm_detecting_2012,
	title = {Detecting distressed and non-distressed affect states in short forum texts},
	journal = {NAACL-HLT 2012},
	author = {Alm, Michael Thaul Lehrman Cecilia Ovesdotter and Proaño, Rubén A.},
	year = {2012},
	pages = {9}
}

@article{clark_automatic_2017-1,
	title = {Automatic classification of {RDoC} positive valence severity with a neural network},
	volume = {75},
	journal = {Journal of biomedical informatics},
	author = {Clark, Cheryl and Wellner, Ben and Davis, Rachel and Aberdeen, John and Hirschman, Lynette},
	year = {2017},
	pages = {S120--S128},
	file = {Fulltext:/Users/transfer/Zotero/storage/DHJRYEQT/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/QQTYZ2RN/S1532046417301612.html:text/html}
}

@article{burnap_multi-class_2017,
	title = {Multi-class machine classification of suicide-related communication on {Twitter}},
	volume = {2},
	journal = {Online social networks and media},
	author = {Burnap, Pete and Colombo, Gualtiero and Amery, Rosie and Hodorog, Andrei and Scourfield, Jonathan},
	year = {2017},
	pages = {32--44},
	file = {Fulltext:/Users/transfer/Zotero/storage/53XZ594D/S2468696417300605.html:text/html;Snapshot:/Users/transfer/Zotero/storage/CPFBBJIB/S2468696417300605.html:text/html}
}

@inproceedings{shickel_automatic_2016,
	title = {Automatic {Triage} of {Mental} {Health} {Forum} {Posts}},
	booktitle = {Proceedings of the {Third} {Workshop} on {Computational} {Lingusitics} and {Clinical} {Psychology}},
	author = {Shickel, Benjamin and Rashidi, Parisa},
	year = {2016},
	pages = {188--192},
	file = {Fulltext:/Users/transfer/Zotero/storage/VLTN7I2P/Shickel and Rashidi - 2016 - Automatic Triage of Mental Health Forum Posts.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/A6BI32VN/Shickel and Rashidi - 2016 - Automatic Triage of Mental Health Forum Posts.pdf:application/pdf}
}

@article{yang_learning_nodate,
	title = {Learning {Depression} {Patterns} from {MyPersonality} and {Reddit}},
	author = {Yang, Weiwei and Sun, Xuetong and Du, Ruofei},
	file = {Fulltext:/Users/transfer/Zotero/storage/WLDWH8KE/Yang et al. - Learning Depression Patterns from MyPersonality an.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/T58MIMTK/Yang et al. - Learning Depression Patterns from MyPersonality an.pdf:application/pdf}
}

@inproceedings{oseguera_automatic_2017,
	title = {Automatic {Quantification} of the {Veracity} of {Suicidal} {Ideation} in {Counseling} {Transcripts}},
	booktitle = {International {Conference} on {Human}-{Computer} {Interaction}},
	publisher = {Springer},
	author = {Oseguera, Omar and Rinaldi, Alex and Tuazon, Joann and Cruz, Albert C.},
	year = {2017},
	pages = {473--479},
	file = {Snapshot:/Users/transfer/Zotero/storage/2XZQG9HQ/978-3-319-58750-9_66.html:text/html}
}

@article{jaiswal_hang_2017,
	title = {“{Hang} in {There}”: {Lexical} and {Visual} {Analysis} to {Identify} {Posts} {Warranting} {Empathetic} {Responses}},
	shorttitle = {“{Hang} in {There}”},
	author = {Jaiswal, Mimansa and Tabibu, Sairam and Cambria, Erik},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/A4C993T3/Jaiswal et al. - 2017 - “Hang in There” Lexical and Visual Analysis to Id.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/E84PLMHQ/Jaiswal et al. - 2017 - “Hang in There” Lexical and Visual Analysis to Id.pdf:application/pdf}
}

@article{zirkle_developing_2013,
	title = {Developing a manually annotated corpus of {VA} electronic medical record notes for post-traumatic stress disorder natural language processing tasks},
	author = {Zirkle, Maryan},
	year = {2013},
	file = {Fulltext:/Users/transfer/Zotero/storage/X8MDUK33/Zirkle - 2013 - Developing a manually annotated corpus of VA elect.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CLP6PUV5/Zirkle - 2013 - Developing a manually annotated corpus of VA elect.pdf:application/pdf}
}

@article{cero_assortativity_2017,
	title = {Assortativity of suicide-related posting on {Twitter}},
	author = {Cero, Ian},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/6PTVD6IG/Cero - 2017 - Assortativity of suicide-related posting on Twitte.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SR4V6QEU/5968.html:text/html}
}

@book{galasinski_discourses_2017,
	title = {Discourses of {Men}’s {Suicide} {Notes}: {A} {Qualitative} {Analysis}},
	shorttitle = {Discourses of {Men}’s {Suicide} {Notes}},
	publisher = {Bloomsbury Publishing},
	author = {Galasinski, Dariusz},
	year = {2017},
	file = {Snapshot:/Users/transfer/Zotero/storage/VVPQX74T/books.html:text/html}
}

@article{bennett_indicators_nodate,
	title = {Indicators of {Autism} in {Social} {Media}: {Predicting} {Autism} {Quotient} {Score} from {Personal} {Blogs}},
	shorttitle = {Indicators of {Autism} in {Social} {Media}},
	author = {Bennett, Sarah}
}

@article{liang_latest_2014,
	title = {Latest {Introduction} of {Suicide} {Notes} {Research} in the {West}},
	author = {Liang, Shuyu and Wang, Weihong},
	year = {2014},
	file = {Fulltext:/Users/transfer/Zotero/storage/IYJ63CYN/Liang and Wang - 2014 - Latest Introduction of Suicide Notes Research in t.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CE27IMVN/Liang and Wang - 2014 - Latest Introduction of Suicide Notes Research in t.pdf:application/pdf}
}

@article{desmet_online_2018,
	title = {Online suicide prevention through optimised text classification},
	journal = {Information Sciences},
	author = {Desmet, Bart and Hoste, Véronique},
	year = {2018},
	file = {Fulltext:/Users/transfer/Zotero/storage/KI5LNY9Z/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/4CJQPBI2/S002002551830094X.html:text/html}
}

@article{orooji_using_2017,
	title = {Using of {Natural} {Language} {Processing} {Techniques} in {Suicide} {Research}},
	volume = {1},
	number = {2},
	journal = {Emerging Science Journal},
	author = {Orooji, Azam and Langarizadeh, Mostafa},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/5UTDI5RL/Orooji and Langarizadeh - 2017 - Using of Natural Language Processing Techniques in.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/IQHK9GLZ/34.html:text/html}
}

@article{vaux_replicates_2012,
	title = {Replicates and repeats—what is the difference and is it significant?},
	volume = {13},
	issn = {1469-221X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3321166/},
	doi = {10.1038/embor.2012.36},
	abstract = {Replicate samples are important, but they cannot be used to properly test the
validity of a scientific hypothesis.},
	number = {4},
	urldate = {2018-03-03},
	journal = {EMBO Reports},
	author = {Vaux, David L and Fidler, Fiona and Cumming, Geoff},
	month = apr,
	year = {2012},
	pmid = {22421999},
	pmcid = {PMC3321166},
	pages = {291--296},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/UWRCARLA/Vaux et al. - 2012 - Replicates and repeats—what is the difference and .pdf:application/pdf}
}

@article{scherer_full_2007,
	title = {Full publication of results initially presented in abstracts},
	volume = {2},
	number = {2},
	journal = {Cochrane Database Syst Rev},
	author = {Scherer, Roberta W. and Langenberg, Patricia and Von Elm, Erik},
	year = {2007},
	pages = {MR000005},
	file = {Fulltext:/Users/transfer/Zotero/storage/PB8EG5CN/Scherer et al. - 2007 - Full publication of results initially presented in.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SNJIK4JH/Scherer et al. - 2007 - Full publication of results initially presented in:}
}

@article{scherer_full_1994,
	title = {Full publication of results initially presented in abstracts: a meta-analysis},
	volume = {272},
	shorttitle = {Full publication of results initially presented in abstracts},
	number = {2},
	journal = {Jama},
	author = {Scherer, Roberta W. and Dickersin, Kay and Langenberg, Patricia},
	year = {1994},
	pages = {158--162},
	file = {Snapshot:/Users/transfer/Zotero/storage/NPKE9EZW/376273.html:text/html}
}

@article{oliver_publication_2003,
	title = {Publication rates for abstracts presented at the {British} {Association} of {Plastic} {Surgeons} meetings: how do we compare with other specialties?},
	volume = {56},
	shorttitle = {Publication rates for abstracts presented at the {British} {Association} of {Plastic} {Surgeons} meetings},
	number = {2},
	journal = {British journal of plastic surgery},
	author = {Oliver, D. W. and Whitaker, I. S. and Chohan, D. P. K.},
	year = {2003},
	pages = {158--160},
	file = {Fulltext:/Users/transfer/Zotero/storage/W7M2QJBC/fulltext.html:text/html;Snapshot:/Users/transfer/Zotero/storage/H3T72QC6/Oliver et al. - 2003 - Publication rates for abstracts presented at the B:}
}

@article{harel_frequency_2011,
	title = {Frequency and factors influencing publication of abstracts presented at three major nephrology meetings},
	volume = {4},
	number = {1},
	journal = {International archives of medicine},
	author = {Harel, Ziv and Wald, Ron and Juda, Ari and Bell, Chaim M.},
	year = {2011},
	pages = {40},
	file = {Fulltext:/Users/transfer/Zotero/storage/IGNV85KK/1755-7682-4-40.html:text/html;Snapshot:/Users/transfer/Zotero/storage/FQ7I9A63/1755-7682-4-40.html:text/html}
}

@article{smollin_publication_2006,
	title = {Publication of abstracts presented at 2001 {NACCT}},
	volume = {2},
	number = {3},
	journal = {Journal of Medical Toxicology},
	author = {Smollin, Craig G. and Nelson, Lewis S.},
	year = {2006},
	pages = {97--100},
	file = {Fulltext:/Users/transfer/Zotero/storage/8XKJJZHF/Smollin and Nelson - 2006 - Publication of abstracts presented at 2001 NACCT.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/FQB8VM6J/BF03161017.html:text/html}
}

@article{autorino_fate_2006,
	title = {Fate of abstracts presented at the {World} {Congress} of {Endourology}: are they followed by publication in peer-reviewed journals?},
	volume = {20},
	shorttitle = {Fate of abstracts presented at the {World} {Congress} of {Endourology}},
	number = {12},
	journal = {Journal of endourology},
	author = {Autorino, Riccardo and Quarto, Giuseppe and Sio, Marco De and Lima, Estevao and Quarto, Ernesto and Damiano, Rocco and Oliviero, Rosario and Osorio, Luis and Marcelo, Filinto and D'Armiento, Massimo},
	year = {2006},
	pages = {996--1001},
	file = {Fulltext:/Users/transfer/Zotero/storage/JL2ZBFVV/Autorino et al. - 2006 - Fate of abstracts presented at the World Congress .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MFNMNL76/end.2006.20.html:text/html}
}

@article{sanders_research_2001,
	title = {Research outcomes in {British} gastroenterology: an audit of the subsequent full publication of abstracts presented at the {British} {Society} of {Gastroenterology}},
	volume = {49},
	shorttitle = {Research outcomes in {British} gastroenterology},
	number = {1},
	journal = {Gut},
	author = {Sanders, D. S. and Carter, M. J. and Hurlstone, D. P. and Lobo, A. J. and Hoggard, N.},
	year = {2001},
	pages = {154--155},
	file = {Fulltext:/Users/transfer/Zotero/storage/E23825RK/Sanders et al. - 2001 - Research outcomes in British gastroenterology an .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/UYXTLXGN/Sanders et al. - 2001 - Research outcomes in British gastroenterology an .short:}
}

@article{dahllof_subsequent_2008,
	title = {Subsequent publication of abstracts presented at the {International} {Association} of {Paediatric} {Dentistry} meetings},
	volume = {18},
	number = {2},
	journal = {International journal of paediatric dentistry},
	author = {DahllÖf, GÖran and Wondimu, Biniyam and MANIERE, MARIE-CÉCILE},
	year = {2008},
	pages = {91--97},
	file = {Fulltext:/Users/transfer/Zotero/storage/QP6GRSRV/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/HSUU3RGF/DahllÖf et al. - 2008 - Subsequent publication of abstracts presented at t:}
}

@article{varghese_publication_2011,
	title = {Publication of abstracts submitted to the annual meeting of the {Pediatric} {Orthopaedic} {Society} of {North} {America}: is there a difference between accepted versus rejected abstracts?},
	volume = {31},
	shorttitle = {Publication of abstracts submitted to the annual meeting of the {Pediatric} {Orthopaedic} {Society} of {North} {America}},
	number = {3},
	journal = {Journal of Pediatric Orthopaedics},
	author = {Varghese, Ranjit A. and Chang, Justin and Miyanji, Firoz and Reilly, Christopher W. and Mulpuri, Kishore},
	year = {2011},
	pages = {334--340},
	file = {Snapshot:/Users/transfer/Zotero/storage/CEZMN3X9/Publication_of_Abstracts_Submitted_to_the_Annual.20.html:text/html}
}

@article{herbison_full_2004,
	title = {Full publication of abstracts of randomised controlled trials published at {International} {Continence} {Society} meetings'},
	volume = {23},
	number = {2},
	journal = {Neurourology and urodynamics},
	author = {Herbison, Peter},
	year = {2004},
	pages = {101--103},
	file = {Snapshot:/Users/transfer/Zotero/storage/7555UUQF/Herbison - 2004 - Full publication of abstracts of randomised contro:}
}

@article{goodman_what_2016,
	title = {What does research reproducibility mean?},
	volume = {8},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {1946-6234, 1946-6242},
	url = {http://stm.sciencemag.org/content/8/341/341ps12},
	doi = {10.1126/scitranslmed.aaf5027},
	abstract = {The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for “truth.”
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.},
	language = {en},
	number = {341},
	urldate = {2018-03-04},
	journal = {Science Translational Medicine},
	author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
	month = jun,
	year = {2016},
	pmid = {27252173},
	pages = {341ps12--341ps12},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/NC5556WG/Goodman et al. - 2016 - What does research reproducibility mean.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/7Q8U8VLI/tab-pdf.html:text/html}
}

@article{atmanspacher_relevance_2014,
	title = {Relevance relations for the concept of reproducibility},
	volume = {11},
	issn = {1742-5689},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3973355/},
	doi = {10.1098/rsif.2013.1030},
	abstract = {The concept of reproducibility is widely considered a cornerstone of scientific methodology. However, recent problems with the reproducibility of empirical results in large-scale systems and in biomedical research have cast doubts on its universal and rigid applicability beyond the so-called basic sciences. Reproducibility is a particularly difficult issue in interdisciplinary work where the results to be reproduced typically refer to different levels of description of the system considered. In such cases, it is mandatory to distinguish between more and less relevant features, attributes or observables of the system, depending on the level at which they are described. For this reason, we propose a scheme for a general ‘relation of relevance’ between the level of complexity at which a system is considered and the granularity of its description. This relation implies relevance criteria for particular selected aspects of a system and its description, which can be operationally implemented by an interlevel relation called ‘contextual emergence’. It yields a formally sound and empirically applicable procedure to translate between descriptive levels and thus construct level-specific criteria for reproducibility in an overall consistent fashion. Relevance relations merged with contextual emergence challenge the old idea of one fundamental ontology from which everything else derives. At the same time, our proposal is specific enough to resist the backlash into a relativist patchwork of unconnected model fragments.},
	number = {94},
	urldate = {2018-03-04},
	journal = {Journal of the Royal Society Interface},
	author = {Atmanspacher, H. and Bezzola Lambert, L. and Folkers, G. and Schubiger, P. A.},
	month = may,
	year = {2014},
	pmid = {24554574},
	pmcid = {PMC3973355},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DB2QBB4T/Atmanspacher et al. - 2014 - Relevance relations for the concept of reproducibi.pdf:application/pdf}
}

@article{olorisade_reproducibility_2017,
	title = {Reproducibility of studies on text mining for citation screening in systematic reviews: {Evaluation} and checklist},
	volume = {73},
	issn = {1532-0464},
	shorttitle = {Reproducibility of studies on text mining for citation screening in systematic reviews},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046417301661},
	doi = {10.1016/j.jbi.2017.07.010},
	abstract = {Context
Independent validation of published scientific results through study replication is a pre-condition for accepting the validity of such results. In computation research, full replication is often unrealistic for independent results validation, therefore, study reproduction has been justified as the minimum acceptable standard to evaluate the validity of scientific claims. The application of text mining techniques to citation screening in the context of systematic literature reviews is a relatively young and growing computational field with high relevance for software engineering, medical research and other fields. However, there is little work so far on reproduction studies in the field.
Objective
In this paper, we investigate the reproducibility of studies in this area based on information contained in published articles and we propose reporting guidelines that could improve reproducibility.
Methods
The study was approached in two ways. Initially we attempted to reproduce results from six studies, which were based on the same raw dataset. Then, based on this experience, we identified steps considered essential to successful reproduction of text mining experiments and characterized them to measure how reproducible is a study given the information provided on these steps. 33 articles were systematically assessed for reproducibility using this approach.
Results
Our work revealed that it is currently difficult if not impossible to independently reproduce the results published in any of the studies investigated. The lack of information about the datasets used limits reproducibility of about 80\% of the studies assessed. Also, information about the machine learning algorithms is inadequate in about 27\% of the papers. On the plus side, the third party software tools used are mostly free and available.
Conclusions
The reproducibility potential of most of the studies can be significantly improved if more attention is paid to information provided on the datasets used, how they were partitioned and utilized, and how any randomization was controlled. We introduce a checklist of information that needs to be provided in order to ensure that a published study can be reproduced.},
	urldate = {2018-03-04},
	journal = {Journal of Biomedical Informatics},
	author = {Olorisade, Babatunde Kazeem and Brereton, Pearl and Andras, Peter},
	month = sep,
	year = {2017},
	pages = {1--13},
	file = {ScienceDirect Snapshot:/Users/transfer/Zotero/storage/38IFRVGM/S1532046417301661.html:text/html}
}

@article{amblard_pour_2016,
	title = {Pour un {TAL} responsable},
	volume = {57},
	url = {https://hal.inria.fr/hal-01414145/document},
	abstract = {L'intelligence artificielle (IA) a connu ces dernières années de grandes avancées qui ont résonné avec des préoccupations sociétales. Des instances ont été créées et ont commencé à structurer les problèmes posés par ces développements. Tant pour la société civile que pour de nombreux scientifiques, le champ de ces instances recouvre les problématiques du traitement automatique des langues (TAL). Dans cet article nous revenons sur certains aspects expliquant la relation entre IA et TAL, mais aussi sur les éléments qui les différencient. Nous revenons sur les problèmes d'éthique pour l'IA et également pour le TAL. Ces questions étant complexes, nous en donnons une lecture en contextualisant les problématiques. Enfin nous argumentons pour ne pas dresser l'éthique comme solution de facto à la réflexion, mais plutôt comme occasion de positionner les recherches dans des perspectives plus globales et nous revenons sur le problème de la relation entre utilisation de modèles numériques et faculté de les interpréter. ABSTRACT. Artificial intelligence (AI) has evolved in recent years along with societal concerns. Various committees were introduced in order to brainstorm on the consequences of these developments. These authorities are also concerned by Natural Language Processing (NLP), not only as a subfield of AI but also as a specific field with which it interacts. In this article we review the links between AI and NLP but also where they differ. We focus on ethical clues for both of them. Finally we argue for not using ethics as a unique solution, but rather as the way to abstract over our researches. In the end, we go back on how to interpret machine learning methods in the context of NLP. MOTS-CLÉS : éthique, intelligence artificielle, traitement automatique des langues, épistémolo-gie.},
	language = {fr},
	number = {2},
	urldate = {2018-03-04},
	journal = {Traitement Automatique des Langues},
	author = {Amblard, Maxime},
	year = {2016},
	pages = {21 -- 45},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/ZMMSLF7P/Amblard - 2016 - Pour un TAL responsable.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/KU27D3KR/hal-01414145.html:text/html}
}

@article{amblard_pour_2016-1,
	title = {Pour un {TAL} responsable},
	volume = {57},
	number = {2},
	journal = {Traitement Automatique des Langues},
	author = {Amblard, Maxime},
	year = {2016},
	pages = {21--45},
	file = {Fulltext:/Users/transfer/Zotero/storage/HGUF675S/Amblard - 2016 - Pour un TAL responsable.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/H9ZAQ4HZ/hal-01414145.html:text/html}
}

@misc{noauthor_rastier_nodate,
	title = {Rastier : {Enjeux} épistémologiques de la linguistique de corpus},
	url = {http://www.revue-texto.net/Inedits/Rastier/Rastier_Enjeux.html?iframe=true&width=100%&height=100%},
	urldate = {2018-03-04},
	file = {Rastier \: Enjeux épistémologiques de la linguistique de corpus:/Users/transfer/Zotero/storage/47QL59KP/Rastier_Enjeux.html:text/html}
}

@misc{noauthor_rastier_nodate-1,
	title = {Rastier : {Enjeux} épistémologiques de la linguistique de corpus},
	url = {http://www.revue-texto.net/Inedits/Rastier/Rastier_Enjeux.html?iframe=true&width=100%&height=100%},
	urldate = {2018-03-04},
	file = {Rastier \: Enjeux épistémologiques de la linguistique de corpus:/Users/transfer/Zotero/storage/MLBHIPWN/Rastier_Enjeux.html:text/html}
}

@inproceedings{daelemans_evaluation_2002,
	title = {Evaluation of machine learning methods for natural language processing tasks},
	copyright = {I have transferred the copyright for this publication to the publisher},
	url = {http://hdl.handle.net/1854/LU-598042},
	abstract = {We show that the methodology currently in use for comparing symbolic supervised learning methods applied to human language technology tasks is unreliable. We show that the interaction between algorithm parameter settings and feature selection within a single algorithm often accounts for a higher variation in results than differences between different algorithms or information sources. We illustrate this with experiments on a number of linguistic datasets. The consequences of this phenomenon are far-reaching, and we discuss possible solutions to this methodological problem.},
	language = {eng},
	urldate = {2018-03-04},
	booktitle = {{LREC} 2002 : third international conference on language resources and evaluation},
	publisher = {European Language Resources Association (ELRA)},
	author = {Daelemans, Walter and Hoste, Veronique},
	year = {2002},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/B5QFVA2E/Daelemans and Hoste - 2002 - Evaluation of machine learning methods for natural.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/L4II25AA/598042.html:text/html}
}

@article{baayen_word_1996,
	title = {Word frequency distributions and lexical semantics},
	volume = {30},
	issn = {0010-4817, 1572-8412},
	url = {https://link.springer.com/article/10.1007/BF00115137},
	doi = {10.1007/BF00115137},
	abstract = {This paper addresses the relation between meaning, lexical productivity, and frequency of use. Using density estimation as a visualization tool, we show that differences in semantic structure can be reflected in probability density functions estimated for word frequency distributions. We call attention to an example of a bimodal density, and suggest that bimodality arises when distributions of well-entrenched lexical items, which appear to be lognormal, are mixed with distributions of productively created nonce formations.},
	language = {en},
	number = {4},
	urldate = {2018-03-04},
	journal = {Computers and the Humanities},
	author = {Baayen, R. Harald and Lieber, Rochelle},
	month = jul,
	year = {1996},
	pages = {281--291},
	file = {Snapshot:/Users/transfer/Zotero/storage/AF9A7XGD/BF00115137.html:text/html}
}

@book{baayen_word_2001,
	title = {Word frequency distributions},
	volume = {18},
	publisher = {Springer Science \& Business Media},
	author = {Baayen, R. Harald},
	year = {2001},
	file = {Fulltext:/Users/transfer/Zotero/storage/8P88FMPN/VBaa.html:text/html;Snapshot:/Users/transfer/Zotero/storage/DJMLL54U/books.html:text/html}
}

@article{baayen_statistical_1992,
	title = {Statistical models for word frequency distributions: {A} linguistic evaluation},
	volume = {26},
	shorttitle = {Statistical models for word frequency distributions},
	number = {5-6},
	journal = {Computers and the Humanities},
	author = {Baayen, Harald},
	year = {1992},
	pages = {347--363},
	file = {Snapshot:/Users/transfer/Zotero/storage/VEMDG8FK/BF00136980.html:text/html}
}

@article{tweedie_how_1998,
	title = {How variable may a constant be? {Measures} of lexical richness in perspective},
	volume = {32},
	shorttitle = {How variable may a constant be?},
	number = {5},
	journal = {Computers and the Humanities},
	author = {Tweedie, Fiona J. and Baayen, R. Harald},
	year = {1998},
	pages = {323--352},
	file = {Snapshot:/Users/transfer/Zotero/storage/V834KZUR/A1001749303137.html:text/html}
}

@book{baayen_analyzing_2008,
	title = {Analyzing linguistic data: {A} practical introduction to statistics using {R}},
	shorttitle = {Analyzing linguistic data},
	publisher = {Cambridge University Press},
	author = {Baayen, R. Harald},
	year = {2008},
	file = {Fulltext:/Users/transfer/Zotero/storage/2YD8BKG7/Baayen - 2008 - Analyzing linguistic data A practical introductio.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/L9YN93LX/books.html:text/html}
}

@incollection{baayen_frequency_1993,
	title = {On frequency, transparency and productivity},
	booktitle = {Yearbook of {Morphology} 1992},
	publisher = {Springer},
	author = {Baayen, Harald},
	year = {1993},
	pages = {181--208},
	file = {Snapshot:/Users/transfer/Zotero/storage/EN6BZIDW/978-94-017-3710-4_7.html:text/html}
}

@inproceedings{baayen_stochastic_1991,
	title = {A stochastic process for word frequency distributions},
	booktitle = {Proceedings of the 29th annual meeting on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Baayen, Harald},
	year = {1991},
	pages = {271--278},
	file = {Fulltext:/Users/transfer/Zotero/storage/JVXW7FXU/Baayen - 1991 - A stochastic process for word frequency distributi.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GZLQMWDA/citation.html:text/html}
}

@article{baayen_word_1996-1,
	title = {Word frequency distributions and lexical semantics},
	volume = {30},
	number = {4},
	journal = {Computers and the Humanities},
	author = {Baayen, R. Harald and Lieber, Rochelle},
	year = {1996},
	pages = {281--291},
	file = {Snapshot:/Users/transfer/Zotero/storage/HVVC6XMF/BF00115137.html:text/html}
}

@article{frauenfelder_neighborhood_1993,
	title = {Neighborhood density and frequency across languages and modalities},
	volume = {32},
	number = {6},
	journal = {Journal of Memory and Language},
	author = {Frauenfelder, Ulrich H. and Baayen, R. Harald and Hellwig, Frauke M.},
	year = {1993},
	pages = {781--804},
	file = {Fulltext:/Users/transfer/Zotero/storage/9CYRNTZW/1297356293.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7PUTSPZW/chooseorg.html:text/html}
}

@article{baayen_lexical_2007,
	title = {Lexical dynamics for low-frequency complex words: {A} regression study across tasks and modalities},
	volume = {2},
	shorttitle = {Lexical dynamics for low-frequency complex words},
	number = {3},
	journal = {The mental lexicon},
	author = {Baayen, R. Harald and Wurm, Lee H. and Aycock, Joanna},
	year = {2007},
	pages = {419--463},
	file = {Fulltext:/Users/transfer/Zotero/storage/VVUA53VJ/Baayen et al. - 2007 - Lexical dynamics for low-frequency complex words .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/4FBPKGGE/ml.2.3.html:text/html}
}

@article{bloomfield_language_1936,
	title = {Language or {Ideas}?},
	volume = {12},
	issn = {0097-8507},
	url = {http://www.jstor.org/stable/408751},
	doi = {10.2307/408751},
	abstract = {The logicians of the Vienna Circle have independently reached the conclusion of physicalism: any scientifically meaningful statement reports a movement in space and time. This confirms the conclusion of A. P. Weiss and other American workers: the universe of science is a physical universe. This conclusion implies that statements about 'ideas' are to be translated into statements about speech-forms.},
	number = {2},
	urldate = {2018-03-04},
	journal = {Language},
	author = {Bloomfield, Leonard},
	year = {1936},
	pages = {89--95},
	file = {JSTOR Full Text PDF:/Users/transfer/Zotero/storage/5PLTCX7F/Bloomfield - 1936 - Language or Ideas.pdf:application/pdf}
}

@article{olorisade_reproducibility_2017-1,
	title = {Reproducibility in {Machine} {Learning}-{Based} {Studies}: {An} {Example} of {Text} {Mining}},
	shorttitle = {Reproducibility in {Machine} {Learning}-{Based} {Studies}},
	author = {Olorisade, Babatunde K. and Brereton, Pearl and Andras, Peter},
	year = {2017},
	file = {Fulltext:/Users/transfer/Zotero/storage/R2NUJECB/Olorisade et al. - 2017 - Reproducibility in Machine Learning-Based Studies.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/QPAKBAUL/forum.html:text/html}
}

@inproceedings{olorisade_reporting_2017,
	title = {Reporting {Statistical} {Validity} and {Model} {Complexity} in {Machine} {Learning} based {Computational} {Studies}},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {ACM},
	author = {Olorisade, Babatunde Kazeem and Brereton, Pearl and Andras, Peter},
	year = {2017},
	pages = {128--133},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZPMLU49Z/Olorisade et al. - 2017 - Reporting Statistical Validity and Model Complexit.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XRSW4V3H/citation.html:text/html}
}

@article{olorisade_reproducibility_2017-2,
	title = {Reproducibility of studies on text mining for citation screening in systematic reviews: {Evaluation} and checklist},
	volume = {73},
	shorttitle = {Reproducibility of studies on text mining for citation screening in systematic reviews},
	journal = {Journal of biomedical informatics},
	author = {Olorisade, Babatunde Kazeem and Brereton, Pearl and Andras, Peter},
	year = {2017},
	pages = {1--13},
	file = {Fulltext:/Users/transfer/Zotero/storage/25BCHZ3S/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/2TG7EYKS/chooseorg.html:text/html}
}

@inproceedings{olorisade_critical_2016,
	title = {A critical analysis of studies that address the use of text mining for citation screening in systematic reviews},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {ACM},
	author = {Olorisade, Babatunde K. and de Quincey, Ed and Brereton, Pearl and Andras, Peter},
	year = {2016},
	pages = {14},
	file = {Fulltext:/Users/transfer/Zotero/storage/EVQSAHT3/Olorisade et al. - 2016 - A critical analysis of studies that address the us.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/9IBIYBWP/citation.html:text/html}
}

@article{saha_large_2016,
	title = {A large scale study of {SVM} based methods for abstract screening in systematic reviews},
	journal = {arXiv preprint arXiv:1610.00192},
	author = {Saha, Tanay Kumar and Ouzzani, Mourad and Hammady, Hossam M. and Elmagarmid, Ahmed K.},
	year = {2016},
	file = {Fulltext:/Users/transfer/Zotero/storage/UN6LKKQE/Saha et al. - 2016 - A large scale study of SVM based methods for abstr.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/AUVGAJJ2/1610.html:text/html}
}

@article{morgan_iii_efficacy_2011,
	title = {Efficacy of forensic statement analysis in distinguishing truthful from deceptive eyewitness accounts of highly stressful events},
	volume = {56},
	number = {5},
	journal = {Journal of forensic sciences},
	author = {Morgan III, Charles A. and Colwell, Kevin and Hazlett, Gary A.},
	year = {2011},
	pages = {1227--1234},
	file = {Fulltext:/Users/transfer/Zotero/storage/YEBMB2YV/Morgan III et al. - 2011 - Efficacy of forensic statement analysis in disting.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/775DJRRI/Morgan III et al. - 2011 - Efficacy of forensic statement analysis in disting:}
}

@inproceedings{zweigenbaum_accenting_2002,
	title = {Accenting unknown words in a specialized language},
	booktitle = {Proceedings of the {ACL}-02 workshop on {Natural} language processing in the biomedical domain-{Volume} 3},
	publisher = {Association for Computational Linguistics},
	author = {Zweigenbaum, Pierre and Grabar, Natalia},
	year = {2002},
	pages = {21--28},
	file = {Fulltext:/Users/transfer/Zotero/storage/PFB5LGUF/Zweigenbaum and Grabar - 2002 - Accenting unknown words in a specialized language.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/JLSLC4P9/citation.html:text/html}
}

@article{zweigenbaum_restoring_2002,
	title = {Restoring accents in unknown biomedical words: application to the {French} {MeSH} thesaurus},
	volume = {67},
	shorttitle = {Restoring accents in unknown biomedical words},
	number = {1-3},
	journal = {International Journal of Medical Informatics},
	author = {Zweigenbaum, Pierre and Grabar, Natalia},
	year = {2002},
	pages = {113--126},
	file = {Fulltext:/Users/transfer/Zotero/storage/HURAMZ2Z/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/53IWTPBS/chooseorg.html:text/html}
}

@inproceedings{arens_preliminary_2004-1,
	title = {A preliminary look into the use of named entity information for bioscience text tokenization},
	booktitle = {Proceedings of the {Student} {Research} {Workshop} at {HLT}-{NAACL} 2004},
	publisher = {Association for Computational Linguistics},
	author = {Arens, Robert},
	year = {2004},
	pages = {37--42},
	file = {Fulltext:/Users/transfer/Zotero/storage/A2CQWEN4/Arens - 2004 - A preliminary look into the use of named entity in.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GKMG83EN/citation.html:text/html}
}

@inproceedings{habert_towards_1998-1,
	title = {Towards tokenization evaluation},
	volume = {98},
	booktitle = {Proceedings of {LREC}},
	author = {Habert, Benoit and Adda, Gilles and Adda-Decker, M. and de Marëuil, P. Boula and Ferrari, Silvana and Ferret, O. and Illouz, Gabriel and Paroubek, P.},
	year = {1998},
	pages = {427--431},
	file = {Fulltext:/Users/transfer/Zotero/storage/V8V8GAEB/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ZRZ34TZ4/Habert et al. - 1998 - Towards tokenization evaluation.pdf:application/pdf}
}

@misc{noauthor_17_nodate,
	title = {(17) {Reproducible} research in linguistics: {A} position statement on data citation and attribution in our field},
	shorttitle = {(17) {Reproducible} research in linguistics},
	url = {https://www.researchgate.net/publication/322465646_Reproducible_research_in_linguistics_A_position_statement_on_data_citation_and_attribution_in_our_field},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-03-06},
	journal = {ResearchGate},
	file = {Snapshot:/Users/transfer/Zotero/storage/DEUBBS3E/322465646_Reproducible_research_in_linguistics_A_position_statement_on_data_citation_and_attrib.html:text/html}
}

@article{demner-fushman_what_2009,
	title = {What can {Natural} {Language} {Processing} do for {Clinical} {Decision} {Support}?},
	volume = {42},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757540/},
	doi = {10.1016/j.jbi.2009.08.007},
	abstract = {Computerized Clinical Decision Support (CDS) aims to aid decision making of health care providers and the public by providing easily accessible health-related information at the point and time it is needed. Natural Language Processing (NLP) is instrumental in using free-text information to drive CDS, representing clinical knowledge and CDS interventions in standardized formats, and leveraging clinical narrative. The early innovative NLP research of clinical narrative was followed by a period of stable research conducted at the major clinical centers and a shift of mainstream interest to biomedical NLP. This review primarily focuses on the recently renewed interest in development of fundamental NLP methods and advances in the NLP systems for CDS. The current solutions to challenges posed by distinct sublanguages, intended user groups, and support goals are discussed.},
	number = {5},
	urldate = {2018-03-07},
	journal = {Journal of biomedical informatics},
	author = {Demner-Fushman, Dina and Chapman, Wendy W. and McDonald, Clement J.},
	month = oct,
	year = {2009},
	pmid = {19683066},
	pmcid = {PMC2757540},
	pages = {760--772},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DH24IVZQ/Demner-Fushman et al. - 2009 - What can Natural Language Processing do for Clinic.pdf:application/pdf}
}

@article{horng_creating_2017,
	title = {Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning},
	volume = {12},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0174708},
	abstract = {OBJECTIVE: To demonstrate the incremental benefit of using free text data in addition to vital sign and demographic data to identify patients with suspected infection in the emergency department.
METHODS: This was a retrospective, observational cohort study performed at a tertiary academic teaching hospital. All consecutive ED patient visits between 12/17/08 and 2/17/13 were included. No patients were excluded. The primary outcome measure was infection diagnosed in the emergency department defined as a patient having an infection related ED ICD-9-CM discharge diagnosis. Patients were randomly allocated to train (64\%), validate (20\%), and test (16\%) data sets. After preprocessing the free text using bigram and negation detection, we built four models to predict infection, incrementally adding vital signs, chief complaint, and free text nursing assessment. We used two different methods to represent free text: a bag of words model and a topic model. We then used a support vector machine to build the prediction model. We calculated the area under the receiver operating characteristic curve to compare the discriminatory power of each model.
RESULTS: A total of 230,936 patient visits were included in the study. Approximately 14\% of patients had the primary outcome of diagnosed infection. The area under the ROC curve (AUC) for the vitals model, which used only vital signs and demographic data, was 0.67 for the training data set, 0.67 for the validation data set, and 0.67 (95\% CI 0.65-0.69) for the test data set. The AUC for the chief complaint model which also included demographic and vital sign data was 0.84 for the training data set, 0.83 for the validation data set, and 0.83 (95\% CI 0.81-0.84) for the test data set. The best performing methods made use of all of the free text. In particular, the AUC for the bag-of-words model was 0.89 for training data set, 0.86 for the validation data set, and 0.86 (95\% CI 0.85-0.87) for the test data set. The AUC for the topic model was 0.86 for the training data set, 0.86 for the validation data set, and 0.85 (95\% CI 0.84-0.86) for the test data set.
CONCLUSION: Compared to previous work that only used structured data such as vital signs and demographic information, utilizing free text drastically improves the discriminatory ability (increase in AUC from 0.67 to 0.86) of identifying infection.},
	language = {eng},
	number = {4},
	journal = {PloS One},
	author = {Horng, Steven and Sontag, David A. and Halpern, Yoni and Jernite, Yacine and Shapiro, Nathan I. and Nathanson, Larry A.},
	year = {2017},
	pmid = {28384212},
	pmcid = {PMC5383046},
	pages = {e0174708}
}

@inproceedings{karim_clinical_2011,
	title = {Clinical decision support system based virtual telemedicine},
	volume = {1},
	booktitle = {Intelligent {Human}-{Machine} {Systems} and {Cybernetics} ({IHMSC}), 2011 {International} {Conference} on},
	publisher = {IEEE},
	author = {Karim, Shazia and Bajwa, Imran Sarwar},
	year = {2011},
	pages = {16--21},
	file = {Fulltext:/Users/transfer/Zotero/storage/97YYMEMT/Karim and Bajwa - 2011 - Clinical decision support system based virtual tel.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/VK8DV9UK/6038136.html:text/html}
}

@article{boguslav_improving_2018-3,
	title = {Improving precision in concept normalization},
	volume = {23},
	issn = {2335-6936},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5730334/},
	abstract = {Most natural language processing applications exhibit a trade-off between precision and recall. In some use cases for natural language processing, there are reasons to prefer to tilt that trade-off toward high precision. Relying on the Zipfian distribution of false positive results, we describe a strategy for increasing precision, using a variety of both pre-processing and post-processing methods. They draw on both knowledge-based and frequentist approaches to modeling language. Based on an existing high-performance biomedical concept recognition pipeline and a previously published manually annotated corpus, we apply this hybrid rationalist/empiricist strategy to concept normalization for eight different ontologies. Which approaches did and did not improve precision varied widely between the ontologies.},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Boguslav, Mayla and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2018},
	pmid = {29218915},
	pmcid = {PMC5730334},
	pages = {566--577},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VUU6XCA8/Boguslav et al. - 2018 - Improving precision in concept normalization.pdf:application/pdf}
}

@article{boguslav_improving_2018-4,
	title = {Improving precision in concept normalization},
	volume = {23},
	issn = {2335-6936},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5730334/},
	abstract = {Most natural language processing applications exhibit a trade-off between precision and recall. In some use cases for natural language processing, there are reasons to prefer to tilt that trade-off toward high precision. Relying on the Zipfian distribution of false positive results, we describe a strategy for increasing precision, using a variety of both pre-processing and post-processing methods. They draw on both knowledge-based and frequentist approaches to modeling language. Based on an existing high-performance biomedical concept recognition pipeline and a previously published manually annotated corpus, we apply this hybrid rationalist/empiricist strategy to concept normalization for eight different ontologies. Which approaches did and did not improve precision varied widely between the ontologies.},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Boguslav, Mayla and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2018},
	pmid = {29218915},
	pmcid = {PMC5730334},
	pages = {566--577},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PE2R3HRY/Boguslav et al. - 2018 - Improving precision in concept normalization.pdf:application/pdf}
}

@article{johnson_evaluation_2006,
	title = {{EVALUATION} {OF} {LEXICAL} {METHODS} {FOR} {DETECTING} {RELATIONSHIPS} {BETWEEN} {CONCEPTS} {FROM} {MULTIPLE} {ONTOLOGIES}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1810343/},
	abstract = {We used exact term matching, stemming, and inclusion of synonyms, implemented via the Lucene information retrieval library, to discover relationships between the Gene Ontology and three other OBO ontologies: ChEBI, Cell Type, and BRENDA Tissue. Proposed relationships were evaluated by domain experts. We discovered 91, 385 relationships between the ontologies. Various methods had a wide range of correctness. Based on these results, we recommend careful evaluation of all matching strategies before use, including exact string matching. The full set of relationships is available at compbio.uchsc.edu/dependencies.},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {JOHNSON, HELEN L. and COHEN, K. BRETONNEL and BAUMGARTNER, WILLIAM A. and LU, ZHIYONG and BADA, MICHAEL and KESTER, TODD and KIM, HYUNMIN and HUNTER, LAWRENCE},
	year = {2006},
	pmid = {17094225},
	pmcid = {PMC1810343},
	keywords = {female first or senior},
	pages = {28--39},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WDW66LU7/JOHNSON et al. - 2006 - EVALUATION OF LEXICAL METHODS FOR DETECTING RELATI.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DMQ4ASA4/JOHNSON et al. - 2006 - EVALUATION OF LEXICAL METHODS FOR DETECTING RELATI.pdf:application/pdf}
}

@article{johnson_fault_2007,
	title = {A {FAULT} {MODEL} {FOR} {ONTOLOGY} {MAPPING}, {ALIGNMENT}, {AND} {LINKING} {SYSTEMS}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516303/},
	abstract = {There has been much work devoted to the mapping, alignment, and linking of ontologies (MALO), but little has been published about how to evaluate systems that do this. A fault model for conducting fine-grained evaluations of MALO systems is proposed, and its application to the system described in Johnson et al. [] is illustrated. Two judges categorized errors according to the model, and inter-judge agreement was calculated by error category. Overall inter-judge agreement was 98\% after dispute resolution, suggesting that the model is consistently applicable. The results of applying the model to the system described in [] reveal the reason for a puzzling set of results in that paper, and also suggest a number of avenues and techniques for improving the state of the art in MALO, including the development of biomedical domain specific language processing tools, filtering of high frequency matching results, and word sense disambiguation.},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {JOHNSON, HELEN L. and COHEN, K. BRETONNEL and HUNTER, LAWRENCE},
	year = {2007},
	pmid = {17990495},
	pmcid = {PMC2516303},
	keywords = {reproducibility, female first or senior},
	pages = {233--244},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XSRDH3CZ/JOHNSON et al. - 2007 - A FAULT MODEL FOR ONTOLOGY MAPPING, ALIGNMENT, AND.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JS4IVIXK/JOHNSON et al. - 2007 - A FAULT MODEL FOR ONTOLOGY MAPPING, ALIGNMENT, AND.pdf:application/pdf}
}

@article{caporaso_intrinsic_2008-2,
	title = {{INTRINSIC} {EVALUATION} {OF} {TEXT} {MINING} {TOOLS} {MAY} {NOT} {PREDICT} {PERFORMANCE} {ON} {REALISTIC} {TASKS}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2517250/},
	abstract = {Biomedical text mining and other automated techniques are beginning to achieve performance which suggests that they could be applied to aid database curators. However, few studies have evaluated how these systems might work in practice. In this article we focus on the problem of annotating mutations in Protein Data Bank (PDB) entries, and evaluate the relationship between performance of two automated techniques, a text-mining-based approach (MutationFinder) and an alignment-based approach, in intrinsic versus extrinsic evaluations. We find that high performance on gold standard data (an intrinsic evaluation) does not necessarily translate to high performance for database annotation (an extrinsic evaluation). We show that this is in part a result of lack of access to the full text of journal articles, which appears to be critical for comprehensive database annotation by text mining. Additionally, we evaluate the accuracy and completeness of manually annotated mutation data in the PDB, and find that it is far from perfect. We conclude that currently the most cost-effective and reliable approach for database annotation might incorporate manual and automatic annotation methods.},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {CAPORASO, J. GREGORY and DESHPANDE, NITA and FINK, J. LYNN and BOURNE, PHILIP E. and COHEN, K. BRETONNEL and HUNTER, LAWRENCE},
	year = {2008},
	pmid = {18229722},
	pmcid = {PMC2517250},
	pages = {640--651},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JCJ49WCP/CAPORASO et al. - 2008 - INTRINSIC EVALUATION OF TEXT MINING TOOLS MAY NOT .pdf:application/pdf}
}

@article{cohen_translating_2008,
	title = {Translating biology: {Text} mining tools that work},
	volume = {13},
	shorttitle = {{TRANSLATING} {BIOLOGY}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2934913/},
	urldate = {2018-03-10},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {COHEN, K. BRETONNEL and YU, HONG and BOURNE, PHILIP E. and HIRSCHMAN, LYNETTE},
	month = jan,
	year = {2008},
	pmid = {20827444},
	pmcid = {PMC2934913},
	keywords = {reproducibility, female first or senior, review},
	pages = {551--555},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/Y25N6Z6V/COHEN et al. - 2008 - TRANSLATING BIOLOGY TEXT MINING TOOLS THAT WORK.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/THREJHXD/COHEN et al. - 2008 - TRANSLATING BIOLOGY TEXT MINING TOOLS THAT WORK.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/G8Q5BI8J/COHEN et al. - 2008 - TRANSLATING BIOLOGY TEXT MINING TOOLS THAT WORK.pdf:application/pdf}
}

@article{jonnalagadda_biosimplify:_2010,
	title = {{BioSimplify}: an open source sentence simplification engine to improve recall in automatic biomedical information extraction},
	volume = {2010},
	issn = {1942-597X},
	shorttitle = {{BioSimplify}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041388/},
	abstract = {BioSimplify is an open source tool written in Java that introduces and facilitates the use of a novel model for sentence simplification tuned for automatic discourse analysis and information extraction (as opposed to sentence simplification for improving human readability). The model is based on a “shot-gun” approach that produces many different (simpler) versions of the original sentence by combining variants of its constituent elements. This tool is optimized for processing biomedical scientific literature such as the abstracts indexed in PubMed. We tested our tool on its impact to the task of PPI extraction and it improved the f-score of the PPI tool by around 7\%, with an improvement in recall of around 20\%. The BioSimplify tool and test corpus can be downloaded from https://biosimplify.sourceforge.net},
	urldate = {2018-03-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Jonnalagadda, Siddhartha and Gonzalez, Graciela},
	year = {2010},
	pmid = {21346999},
	pmcid = {PMC3041388},
	keywords = {female first or senior},
	pages = {351--355},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VVBIMYH5/Jonnalagadda and Gonzalez - 2010 - BioSimplify an open source sentence simplificatio.pdf:application/pdf}
}

@article{hakenberg_gnat_2011,
	title = {The {GNAT} library for local and remote gene mention normalization},
	volume = {27},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3179658/},
	doi = {10.1093/bioinformatics/btr455},
	abstract = {Summary: Identifying mentions of named entities, such as genes or diseases, and normalizing them to database identifiers have become an important step in many text and data mining pipelines. Despite this need, very few entity normalization systems are publicly available as source code or web services for biomedical text mining. Here we present the Gnat Java library for text retrieval, named entity recognition, and normalization of gene and protein mentions in biomedical text. The library can be used as a component to be integrated with other text-mining systems, as a framework to add user-specific extensions, and as an efficient stand-alone application for the identification of gene and protein names for data analysis. On the BioCreative III test data, the current version of Gnat achieves a Tap-20 score of 0.1987., Availability: The library and web services are implemented in Java and the sources are available from http://gnat.sourceforge.net., Contact: jorg.hakenberg@roche.com},
	number = {19},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Hakenberg, Jörg and Gerner, Martin and Haeussler, Maximilian and Solt, Illés and Plake, Conrad and Schroeder, Michael and Gonzalez, Graciela and Nenadic, Goran and Bergman, Casey M.},
	month = oct,
	year = {2011},
	pmid = {21813477},
	pmcid = {PMC3179658},
	keywords = {female first or senior, normalization},
	pages = {2769--2771},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/T7DU9WEN/Hakenberg et al. - 2011 - The GNAT library for local and remote gene mention.pdf:application/pdf}
}

@article{scotch_enhancing_2011,
	title = {Enhancing {Phylogeography} by {Improving} {Geographical} {Information} from {GenBank}},
	volume = {44},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3199023/},
	doi = {10.1016/j.jbi.2011.06.005},
	abstract = {Phylogeography is a field that focuses on the geographical lineages of species such as vertebrates or viruses. Here, geographical data, such as location of a species or viral host is as important as the sequence information extracted from the species. Together, this information can help illustrate the migration of the species over time within a geographical area, the impact of geography over the evolutionary history, or the expected population of the species within the area. Molecular sequence data from NCBI, specifically GenBank, provide an abundance of available sequence data for phylogeography. However, geographical data is inconsistently represented and sparse across GenBank entries. This can impede analysis and in situations where the geographical information is inferred, and potentially lead to erroneous results. In this paper, we describe the current state of geographical data in GenBank, and illustrate how automated processing techniques such as named entity recognition, can enhance the geographical data available for phylogeographic studies.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {Journal of biomedical informatics},
	author = {Scotch, Matthew and Sarkar, Indra Neil and Mei, Changjiang and Leaman, Robert and Cheung, Kei-Hoi and Ortiz, Pierina and Singraur, Ashutosh and Gonzalez, Graciela},
	month = dec,
	year = {2011},
	pmid = {21723960},
	pmcid = {PMC3199023},
	keywords = {female first or senior},
	pages = {S44--S47},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KVURK94X/Scotch et al. - 2011 - Enhancing Phylogeography by Improving Geographical.pdf:application/pdf}
}

@article{nikfarjam_pattern_2011,
	title = {Pattern {Mining} for {Extraction} of mentions of {Adverse} {Drug} {Reactions} from {User} {Comments}},
	volume = {2011},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3243273/},
	abstract = {Rapid growth of online health social networks has enabled patients to communicate more easily with each other. This way of exchange of opinions and experiences has provided a rich source of information about drugs and their effectiveness and more importantly, their possible adverse reactions. We developed a system to automatically extract mentions of Adverse Drug Reactions (ADRs) from user reviews about drugs in social network websites by mining a set of language patterns. The system applied association rule mining on a set of annotated comments to extract the underlying patterns of colloquial expressions about adverse effects. The patterns were tested on a set of unseen comments to evaluate their performance. We reached to precision of 70.01\% and recall of 66.32\% and F-measure of 67.96\%.},
	urldate = {2018-03-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Nikfarjam, Azadeh and Gonzalez, Graciela H.},
	year = {2011},
	pmid = {22195162},
	pmcid = {PMC3243273},
	keywords = {female first or senior},
	pages = {1019--1026},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DTNR2FW5/Nikfarjam and Gonzalez - 2011 - Pattern Mining for Extraction of mentions of Adver.pdf:application/pdf}
}

@article{krallinger_protein-protein_2011,
	title = {The {Protein}-{Protein} {Interaction} tasks of {BioCreative} {III}: classification/ranking of articles and linking bio-ontology concepts to full text},
	volume = {12},
	issn = {1471-2105},
	shorttitle = {The {Protein}-{Protein} {Interaction} tasks of {BioCreative} {III}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3269938/},
	doi = {10.1186/1471-2105-12-S8-S3},
	abstract = {Background
Determining usefulness of biomedical text mining systems requires realistic task definition and data selection criteria without artificial constraints, measuring performance aspects that go beyond traditional metrics. The BioCreative III Protein-Protein Interaction (PPI) tasks were motivated by such considerations, trying to address aspects including how the end user would oversee the generated output, for instance by providing ranked results, textual evidence for human interpretation or measuring time savings by using automated systems. Detecting articles describing complex biological events like PPIs was addressed in the Article Classification Task (ACT), where participants were asked to implement tools for detecting PPI-describing abstracts. Therefore the BCIII-ACT corpus was provided, which includes a training, development and test set of over 12,000 PPI relevant and non-relevant PubMed abstracts labeled manually by domain experts and recording also the human classification times. The Interaction Method Task (IMT) went beyond abstracts and required mining for associations between more than 3,500 full text articles and interaction detection method ontology concepts that had been applied to detect the PPIs reported in them.

Results
A total of 11 teams participated in at least one of the two PPI tasks (10 in ACT and 8 in the IMT) and a total of 62 persons were involved either as participants or in preparing data sets/evaluating these tasks. Per task, each team was allowed to submit five runs offline and another five online via the BioCreative Meta-Server. From the 52 runs submitted for the ACT, the highest Matthew's Correlation Coefficient (MCC) score measured was 0.55 at an accuracy of 89\% and the best AUC iP/R was 68\%. Most ACT teams explored machine learning methods, some of them also used lexical resources like MeSH terms, PSI-MI concepts or particular lists of verbs and nouns, some integrated NER approaches. For the IMT, a total of 42 runs were evaluated by comparing systems against manually generated annotations done by curators from the BioGRID and MINT databases. The highest AUC iP/R achieved by any run was 53\%, the best MCC score 0.55. In case of competitive systems with an acceptable recall (above 35\%) the macro-averaged precision ranged between 50\% and 80\%, with a maximum F-Score of 55\%.

Conclusions
The results of the ACT task of BioCreative III indicate that classification of large unbalanced article collections reflecting the real class imbalance is still challenging. Nevertheless, text-mining tools that report ranked lists of relevant articles for manual selection can potentially reduce the time needed to identify half of the relevant articles to less than 1/4 of the time when compared to unranked results. Detecting associations between full text articles and interaction detection method PSI-MI terms (IMT) is more difficult than might be anticipated. This is due to the variability of method term mentions, errors resulting from pre-processing of articles provided as PDF files, and the heterogeneity and different granularity of method term concepts encountered in the ontology. However, combining the sophisticated techniques developed by the participants with supporting evidence strings derived from the articles for human interpretation could result in practical modules for biological annotation workflows.},
	number = {Suppl 8},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Krallinger, Martin and Vazquez, Miguel and Leitner, Florian and Salgado, David and Chatr-aryamontri, Andrew and Winter, Andrew and Perfetto, Livia and Briganti, Leonardo and Licata, Luana and Iannuccelli, Marta and Castagnoli, Luisa and Cesareni, Gianni and Tyers, Mike and Schneider, Gerold and Rinaldi, Fabio and Leaman, Robert and Gonzalez, Graciela and Matos, Sergio and Kim, Sun and Wilbur, W John and Rocha, Luis and Shatkay, Hagit and Tendulkar, Ashish V and Agarwal, Shashank and Liu, Feifan and Wang, Xinglong and Rak, Rafal and Noto, Keith and Elkan, Charles and Lu, Zhiyong and Dogan, Rezarta Islamaj and Fontaine, Jean-Fred and Andrade-Navarro, Miguel A and Valencia, Alfonso},
	month = oct,
	year = {2011},
	pmid = {22151929},
	pmcid = {PMC3269938},
	keywords = {female first or senior},
	pages = {S3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XWZVZGRS/Krallinger et al. - 2011 - The Protein-Protein Interaction tasks of BioCreati.pdf:application/pdf}
}

@article{jonnalagadda_enhancing_2012,
	title = {Enhancing clinical concept extraction with distributional semantics},
	volume = {45},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3272090/},
	doi = {10.1016/j.jbi.2011.10.007},
	abstract = {Extracting concepts (such as drugs, symptoms, and diagnoses) from clinical narratives constitutes a basic enabling technology to unlock the knowledge within and support more advanced reasoning applications such as diagnosis explanation, disease progression modeling, and intelligent analysis of the effectiveness of treatment. The recent release of annotated training sets of de-identified clinical narratives has contributed to the development and refinement of concept extraction methods. However, as the annotation process is labor-intensive, training data are necessarily limited in the concepts and concept patterns covered, which impacts the performance of supervised machine learning applications trained with these data. This paper proposes an approach to minimize this limitation by combining supervised machine learning with empirical learning of semantic relatedness from the distribution of the relevant words in additional unannotated text., The approach uses a sequential discriminative classifier (Conditional Random Fields) to extract the mentions of medical problems, treatments and tests from clinical narratives. It takes advantage of all Medline abstracts indexed as being of the publication type “clinical trials” to estimate the relatedness between words in the i2b2/VA training and testing corpora. In addition to the traditional features such as dictionary matching, pattern matching and part-of-speech tags, we also used as a feature words that appear in similar contexts to the word in question (that is, words that have a similar vector representation measured with the commonly used cosine metric, where vector representations are derived using methods of distributional semantics). To the best of our knowledge, this is the first effort exploring the use of distributional semantics, the semantics derived empirically from unannotated text often using vector space models, for a sequence classification task such as concept extraction. Therefore, we first experimented with different sliding window models and found the model with parameters that led to best performance in a preliminary sequence labeling task., The evaluation of this approach, performed against the i2b2/VA concept extraction corpus, showed that incorporating features based on the distribution of words across a large unannotated corpus significantly aids concept extraction. Compared to a supervised-only approach as a baseline, the micro-averaged f-measure for exact match increased from 80.3\% to 82.3\% and the micro-averaged f-measure based on inexact match increased from 89.7\% to 91.3\%. These improvements are highly significant according to the bootstrap resampling method and also considering the performance of other systems. Thus, distributional semantic features significantly improve the performance of concept extraction from clinical narratives by taking advantage of word distribution information obtained from unannotated data.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Jonnalagadda, Siddhartha and Cohen, Trevor and Wu, Stephen and Gonzalez, Graciela},
	month = feb,
	year = {2012},
	pmid = {22085698},
	pmcid = {PMC3272090},
	keywords = {female first or senior},
	pages = {129--140},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/R77NU4VT/Jonnalagadda et al. - 2012 - Enhancing clinical concept extraction with distrib.pdf:application/pdf}
}

@article{jonnalagadda_using_2013,
	title = {Using {Empirically} {Constructed} {Lexical} {Resources} for {Named} {Entity} {Recognition}},
	volume = {6},
	issn = {1178-2226},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3702195/},
	doi = {10.4137/BII.S11664},
	abstract = {Because of privacy concerns and the expense involved in creating an annotated corpus, the existing small-annotated corpora might not have sufficient examples for learning to statistically extract all the named-entities precisely. In this work, we evaluate what value may lie in automatically generated features based on distributional semantics when using machine-learning named entity recognition (NER). The features we generated and experimented with include n-nearest words, support vector machine (SVM)-regions, and term clustering, all of which are considered distributional semantic features. The addition of the n-nearest words feature resulted in a greater increase in F-score than by using a manually constructed lexicon to a baseline system. Although the need for relatively small-annotated corpora for retraining is not obviated, lexicons empirically derived from unannotated text can not only supplement manually created lexicons, but also replace them. This phenomenon is observed in extracting concepts from both biomedical literature and clinical notes.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {Biomedical Informatics Insights},
	author = {Jonnalagadda, Siddhartha and Cohen, Trevor and Wu, Stephen and Liu, Hongfang and Gonzalez, Graciela},
	month = jun,
	year = {2013},
	pmid = {23847424},
	pmcid = {PMC3702195},
	keywords = {female first or senior, NER},
	pages = {17--27},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/9A2HAHVD/Jonnalagadda et al. - 2013 - Using Empirically Constructed Lexical Resources fo.pdf:application/pdf}
}

@article{nikfarjam_towards_2013,
	title = {Towards generating a patient's timeline: {Extracting} temporal relationships from clinical notes},
	volume = {46},
	issn = {1532-0464},
	shorttitle = {Towards generating a patient's timeline},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3974721/},
	doi = {10.1016/j.jbi.2013.11.001},
	abstract = {Clinical records include both coded and free-text fields that interact to reflect complicated patient stories. The information often covers not only the present medical condition and events experienced by the patient, but also refers to relevant events in the past (such as signs, symptoms, tests or treatments). In order to automatically construct a timeline of these events, we first need to extract the temporal relations between pairs of events or time expressions presented in the clinical notes. We designed separate extraction components for different types of temporal relations, utilizing a novel hybrid system that combines machine learning with a graph-based inference mechanism to extract the temporal links. The temporal graph is a directed graph based on parse tree dependencies of the simplified sentences and frequent pattern clues. We generalized the sentences in order to discover patterns that, given the complexities of natural language, might not be directly discoverable in the original sentences. The proposed hybrid system performance reached an F-measure of 0.63, with precision at 0.76 and recall at 0.54 on the 2012 i2b2 Natural Language Processing corpus for the temporal relation (TLink) extraction task, achieving the highest precision and third highest f-measure among participating teams in the TLink track.},
	number = {0},
	urldate = {2018-03-10},
	journal = {Journal of biomedical informatics},
	author = {Nikfarjam, Azadeh and Emadzadeh, Ehsan and Gonzalez, Graciela},
	month = dec,
	year = {2013},
	pmid = {24212118},
	pmcid = {PMC3974721},
	keywords = {female first or senior},
	pages = {S40--S47},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZKUUCNV6/Nikfarjam et al. - 2013 - Towards generating a patient's timeline Extractin.pdf:application/pdf}
}

@article{mao_overview_2014,
	title = {Overview of the gene ontology task at {BioCreative} {IV}},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4142793/},
	doi = {10.1093/database/bau086},
	abstract = {Gene Ontology (GO) annotation is a common task among model organism databases (MODs) for capturing gene function data from journal articles. It is a time-consuming and labor-intensive task, and is thus often considered as one of the bottlenecks in literature curation. There is a growing need for semiautomated or fully automated GO curation techniques that will help database curators to rapidly and accurately identify gene function information in full-length articles. Despite multiple attempts in the past, few studies have proven to be useful with regard to assisting real-world GO curation. The shortage of sentence-level training data and opportunities for interaction between text-mining developers and GO curators has limited the advances in algorithm development and corresponding use in practical circumstances. To this end, we organized a text-mining challenge task for literature-based GO annotation in BioCreative IV. More specifically, we developed two subtasks: (i) to automatically locate text passages that contain GO-relevant information (a text retrieval task) and (ii) to automatically identify relevant GO terms for the genes in a given article (a concept-recognition task). With the support from five MODs, we provided teams with {\textgreater}4000 unique text passages that served as the basis for each GO annotation in our task data. Such evidence text information has long been recognized as critical for text-mining algorithm development but was never made available because of the high cost of curation. In total, seven teams participated in the challenge task. From the team results, we conclude that the state of the art in automatically mining GO terms from literature has improved over the past decade while much progress is still needed for computer-assisted GO curation. Future work should focus on addressing remaining technical challenges for improved performance of automatic GO concept recognition and incorporating practical benefits of text-mining tools into real-world GO annotation., Database URL:
http://www.biocreative.org/tasks/biocreative-iv/track-4-GO/.},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Mao, Yuqing and Van Auken, Kimberly and Li, Donghui and Arighi, Cecilia N. and McQuilton, Peter and Hayman, G. Thomas and Tweedie, Susan and Schaeffer, Mary L. and Laulederkind, Stanley J. F. and Wang, Shur-Jen and Gobeill, Julien and Ruch, Patrick and Luu, Anh Tuan and Kim, Jung-jae and Chiang, Jung-Hsien and Chen, Yu-De and Yang, Chia-Jung and Liu, Hongfang and Zhu, Dongqing and Li, Yanpeng and Yu, Hong and Emadzadeh, Ehsan and Gonzalez, Graciela and Chen, Jian-Ming and Dai, Hong-Jie and Lu, Zhiyong},
	month = aug,
	year = {2014},
	pmid = {25157073},
	pmcid = {PMC4142793},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SKFVA6DC/Mao et al. - 2014 - Overview of the gene ontology task at BioCreative .pdf:application/pdf}
}

@article{tahsin_natural_2014,
	title = {Natural {Language} {Processing} {Methods} for {Enhancing} {Geographic} {Metadata} for {Phylogeography} of {Zoonotic} {Viruses}},
	volume = {2014},
	issn = {2153-4063},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4333696/},
	abstract = {Zoonotic viruses represent emerging or re-emerging pathogens that pose significant public health threats throughout the world. It is therefore crucial to advance current surveillance mechanisms for these viruses through outlets such as phylogeography. Despite the abundance of zoonotic viral sequence data in publicly available databases such as GenBank, phylogeographic analysis of these viruses is often limited by the lack of adequate geographic metadata. However, many GenBank records include references to articles with more detailed information and automated systems may help extract this information efficiently and effectively. In this paper, we describe our efforts to determine the proportion of GenBank records with “insufficient” geographic metadata for seven well-studied viruses. We also evaluate the performance of four different Named Entity Recognition (NER) systems for automatically extracting related entities using a manually created gold-standard.},
	urldate = {2018-03-10},
	journal = {AMIA Summits on Translational Science Proceedings},
	author = {Tahsin, Tasnia and Beard, Rachel and Rivera, Robert and Lauder, Rob and Wallstrom, Garrick and Scotch, Matthew and Gonzalez, Graciela},
	month = apr,
	year = {2014},
	pmid = {25717409},
	pmcid = {PMC4333696},
	keywords = {female first or senior},
	pages = {102--111},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/HAUK98YA/Tahsin et al. - 2014 - Natural Language Processing Methods for Enhancing .pdf:application/pdf}
}

@article{sarker_portable_2015,
	title = {Portable {Automatic} {Text} {Classification} for {Adverse} {Drug} {Reaction} {Detection} via {Multi}-corpus {Training}},
	volume = {53},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4355323/},
	doi = {10.1016/j.jbi.2014.11.002},
	abstract = {Objective
Automatic detection of Adverse Drug Reaction (ADR) mentions from text has recently received significant interest in pharmacovigilance research. Current research focuses on various sources of text-based information, including social media — where enormous amounts of user posted data is available, which have the potential for use in pharmacovigilance if collected and filtered accurately. The aims of this study are: (i) to explore natural language processing approaches for generating useful features from text, and utilizing them in optimized machine learning algorithms for automatic classification of ADR assertive text segments; (ii) to present two data sets that we prepared for the task of ADR detection from user posted internet data; and (iii) to investigate if combining training data from distinct corpora can improve automatic classification accuracies.

Methods
One of our three data sets contains annotated sentences from clinical reports, and the two other data sets, built in-house, consist of annotated posts from social media. Our text classification approach relies on generating a large set of features, representing semantic properties (e.g., sentiment, polarity, and topic), from short text nuggets. Importantly, using our expanded feature sets, we combine training data from different corpora in attempts to boost classification accuracies.

Results
Our feature-rich classification approach performs significantly better than previously published approaches with ADR class F-scores of 0.812 (previously reported best: 0.770), 0.538 and 0.678 for the three data sets. Combining training data from multiple compatible corpora further improves the ADR F-scores for the in-house data sets to 0.597 (improvement of 5.9 units) and 0.704 (improvement of 2.6 units) respectively.

Conclusions
Our research results indicate that using advanced NLP techniques for generating information rich features from text can significantly improve classification accuracies over existing benchmarks. Our experiments illustrate the benefits of incorporating various semantic features such as topics, concepts, sentiments, and polarities. Finally, we show that integration of information from compatible corpora can significantly improve classification performance. This form of multi-corpus training may be particularly useful in cases where data sets are heavily imbalanced (e.g., social media data), and may reduce the time and costs associated with the annotation of data in the future.},
	urldate = {2018-03-10},
	journal = {Journal of biomedical informatics},
	author = {Sarker, Abeed and Gonzalez, Graciela},
	month = feb,
	year = {2015},
	pmid = {25451103},
	pmcid = {PMC4355323},
	keywords = {female first or senior},
	pages = {196--207},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TTPXS98D/Sarker and Gonzalez - 2015 - Portable Automatic Text Classification for Adverse.pdf:application/pdf}
}

@article{oconnor_pharmacovigilance_2014,
	title = {Pharmacovigilance on {Twitter}? {Mining} {Tweets} for {Adverse} {Drug} {Reactions}},
	volume = {2014},
	issn = {1942-597X},
	shorttitle = {Pharmacovigilance on {Twitter}?},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4419871/},
	abstract = {Recent research has shown that Twitter data analytics can have broad implications on public health research. However, its value for pharmacovigilance has been scantly studied – with health related forums and community support groups preferred for the task. We present a systematic study of tweets collected for 74 drugs to assess their value as sources of potential signals for adverse drug reactions (ADRs). We created an annotated corpus of 10,822 tweets. Each tweet was annotated for the presence or absence of ADR mentions, with the span and Unified Medical Language System (UMLS) concept ID noted for each ADR present. Using Cohen’s kappa, we calculated the inter-annotator agreement (IAA) for the binary annotations to be 0.69. To demonstrate the utility of the corpus, we attempted a lexicon-based approach for concept extraction, with promising success (54.1\% precision, 62.1\% recall, and 57.8\% F-measure). A subset of the corpus is freely available at: http://diego.asu.edu/downloads.},
	urldate = {2018-03-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {O’Connor, Karen and Pimpalkhute, Pranoti and Nikfarjam, Azadeh and Ginn, Rachel and Smith, Karen L and Gonzalez, Graciela},
	month = nov,
	year = {2014},
	pmid = {25954400},
	pmcid = {PMC4419871},
	keywords = {female first or senior},
	pages = {924--933},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/TQ9G8VEB/O’Connor et al. - 2014 - Pharmacovigilance on Twitter Mining Tweets for Ad.pdf:application/pdf}
}

@article{sullivan_text_2014,
	title = {Text {Classification} towards {Detecting} {Misdiagnosis} of an {Epilepsy} {Syndrome} in a {Pediatric} {Population}},
	volume = {2014},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4419916/},
	abstract = {When attempting to identify a specific epilepsy syndrome, physicians are often unable to make or agree upon a diagnosis. This is further complicated by the fact that the current classification and diagnosis of epilepsy requires specialized training and the use of resources not typically available to the average clinician, such as training to recognize specific seizure types and electroencephalography (EEG)–. Even when training and resources are available, expert epileptologists often find it challenging to identify seizure types and to distinguish between specific epilepsy syndromes. Information relevant to the diagnosis is present in narrative form in the medical record across several visits for an individual patient. Our ultimate goal is to create a system that will assist physicians in the diagnosis of epilepsy. This paper explores, as a baseline, text classification methods that attempt to correlate the narrative text features to the diagnosis of West syndrome (Infantile Spasms), using data from Phoenix Children’s Hospital (PCH). We tested these methods against a dataset containing known (coded) diagnosis of West Syndrome, and found the best performing method to have a precision / recall / f-measure of 76.8 / 66.7 / 71.4 when evaluated with 10-fold cross validation.},
	urldate = {2018-03-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Sullivan, Ryan and Yao, Robert and Jarrar, Randa and Buchhalter, Jeffrey and Gonzalez, Graciela},
	month = nov,
	year = {2014},
	pmid = {25954418},
	pmcid = {PMC4419916},
	keywords = {female first or senior},
	pages = {1082--1087},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WRH7E44Y/Sullivan et al. - 2014 - Text Classification towards Detecting Misdiagnosis.pdf:application/pdf}
}

@article{nikfarjam_pharmacovigilance_2015,
	title = {Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features},
	volume = {22},
	issn = {1067-5027},
	shorttitle = {Pharmacovigilance from social media},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4457113/},
	doi = {10.1093/jamia/ocu041},
	abstract = {Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utilized for public health monitoring tasks, particularly for pharmacovigilance, via the use of natural language processing (NLP) techniques. However, the language in social media is highly informal, and user-expressed medical concepts are often nontechnical, descriptive, and challenging to extract. There has been limited progress in addressing these challenges, and thus far, advanced machine learning-based NLP techniques have been underutilized. Our objective is to design a machine learning-based approach to extract mentions of adverse drug reactions (ADRs) from highly informal text in social media., Methods We introduce ADRMine, a machine learning-based concept extraction system that uses conditional random fields (CRFs). ADRMine utilizes a variety of features, including a novel feature for modeling words’ semantic similarities. The similarities are modeled by clustering words based on unsupervised, pretrained word representation vectors (embeddings) generated from unlabeled user posts in social media using a deep learning technique., Results ADRMine outperforms several strong baseline systems in the ADR extraction task by achieving an F-measure of 0.82. Feature analysis demonstrates that the proposed word cluster features significantly improve extraction performance., Conclusion It is possible to extract complex medical concepts, with relatively high performance, from informal, user-generated content. Our approach is particularly scalable, suitable for social media mining, as it relies on large volumes of unlabeled data, thus diminishing the need for large, annotated training data sets.},
	number = {3},
	urldate = {2018-03-10},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Nikfarjam, Azadeh and Sarker, Abeed and O’Connor, Karen and Ginn, Rachel and Gonzalez, Graciela},
	month = may,
	year = {2015},
	pmid = {25755127},
	pmcid = {PMC4457113},
	keywords = {female first or senior},
	pages = {671--681},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/LKREKIL8/Nikfarjam et al. - 2015 - Pharmacovigilance from social media mining advers.pdf:application/pdf}
}

@article{gonzalez_recent_2016,
	title = {Recent {Advances} and {Emerging} {Applications} in {Text} and {Data} {Mining} for {Biomedical} {Discovery}},
	volume = {17},
	issn = {1467-5463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4719073/},
	doi = {10.1093/bib/bbv087},
	abstract = {Precision medicine will revolutionize the way we treat and prevent disease. A major barrier to the implementation of precision medicine that clinicians and translational scientists face is understanding the underlying mechanisms of disease. We are starting to address this challenge through automatic approaches for information extraction, representation and analysis. Recent advances in text and data mining have been applied to a broad spectrum of key biomedical questions in genomics, pharmacogenomics and other fields. We present an overview of the fundamental methods for text and data mining, as well as recent advances and emerging applications toward precision medicine.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Briefings in Bioinformatics},
	author = {Gonzalez, Graciela H. and Tahsin, Tasnia and Goodale, Britton C. and Greene, Anna C. and Greene, Casey S.},
	month = jan,
	year = {2016},
	pmid = {26420781},
	pmcid = {PMC4719073},
	keywords = {female first or senior},
	pages = {33--42},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8YZHL499/Gonzalez et al. - 2016 - Recent Advances and Emerging Applications in Text .pdf:application/pdf}
}

@article{sarker_social_2016,
	title = {Social {Media} {Mining} for {Toxicovigilance}: {Automatic} {Monitoring} of {Prescription} {Medication} {Abuse} from {Twitter}},
	volume = {39},
	issn = {0114-5916},
	shorttitle = {Social {Media} {Mining} for {Toxicovigilance}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4749656/},
	doi = {10.1007/s40264-015-0379-4},
	abstract = {Introduction
Prescription medication overdose is the fastest growing drug-related problem in the USA. The growing nature of this problem necessitates the implementation of improved monitoring strategies for investigating the prevalence and patterns of abuse of specific medications.

Objectives
Our primary aims were to assess the possibility of utilizing social media as a resource for automatic monitoring of prescription medication abuse and to devise an automatic classification technique that can identify potentially abuse-indicating user posts.

Methods
We collected Twitter user posts (tweets) associated with three commonly abused medications (Adderall®, oxycodone, and quetiapine). We manually annotated 6400 tweets mentioning these three medications and a control medication (metformin) that is not the subject of abuse due to its mechanism of action. We performed quantitative and qualitative analyses of the annotated data to determine whether posts on Twitter contain signals of prescription medication abuse. Finally, we designed an automatic supervised classification technique to distinguish posts containing signals of medication abuse from those that do not and assessed the utility of Twitter in investigating patterns of abuse over time.

Results
Our analyses show that clear signals of medication abuse can be drawn from Twitter posts and the percentage of tweets containing abuse signals are significantly higher for the three case medications (Adderall®: 23 \%, quetiapine: 5.0 \%, oxycodone: 12 \%) than the proportion for the control medication (metformin: 0.3 \%). Our automatic classification approach achieves 82 \% accuracy overall (medication abuse class recall: 0.51, precision: 0.41, F measure: 0.46). To illustrate the utility of automatic classification, we show how the classification data can be used to analyze abuse patterns over time.

Conclusion
Our study indicates that social media can be a crucial resource for obtaining abuse-related information for medications, and that automatic approaches involving supervised classification and natural language processing hold promises for essential future monitoring and intervention tasks.},
	number = {3},
	urldate = {2018-03-10},
	journal = {Drug Safety},
	author = {Sarker, Abeed and O’Connor, Karen and Ginn, Rachel and Scotch, Matthew and Smith, Karen and Malone, Dan and Gonzalez, Graciela},
	year = {2016},
	pmid = {26748505},
	pmcid = {PMC4749656},
	keywords = {female first or senior},
	pages = {231--240},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U7QJ2WR8/Sarker et al. - 2016 - Social Media Mining for Toxicovigilance Automatic.pdf:application/pdf}
}

@article{korkontzelos_analysis_2016,
	title = {Analysis of the effect of sentiment analysis on extracting adverse drug reactions from tweets and forum posts},
	volume = {62},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4981644/},
	doi = {10.1016/j.jbi.2016.06.007},
	abstract = {•
              Sentiment analysis features are useful in spotting adverse drug reactions in text.
            
            
              •
              Sentiment analysis features help to distinguish adverse drug reactions and indications.
            
            
              •
              Posts about adverse drug reactions are associated with negative feelings.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Korkontzelos, Ioannis and Nikfarjam, Azadeh and Shardlow, Matthew and Sarker, Abeed and Ananiadou, Sophia and Gonzalez, Graciela H.},
	month = aug,
	year = {2016},
	pmid = {27363901},
	pmcid = {PMC4981644},
	keywords = {female first or senior},
	pages = {148--158}
}

@article{tahsin_high-precision_2016,
	title = {A high-precision rule-based extraction system for expanding geospatial metadata in {GenBank} records},
	volume = {23},
	issn = {1067-5027},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4997033/},
	doi = {10.1093/jamia/ocv172},
	abstract = {Objective The metadata reflecting the location of the infected host (LOIH) of virus sequences in GenBank often lacks specificity. This work seeks to enhance this metadata by extracting more specific geographic information from related full-text articles and mapping them to their latitude/longitudes using knowledge derived from external geographical databases., Materials and Methods We developed a rule-based information extraction framework for linking GenBank records to the latitude/longitudes of the LOIH. Our system first extracts existing geospatial metadata from GenBank records and attempts to improve it by seeking additional, relevant geographic information from text and tables in related full-text PubMed Central articles. The final extracted locations of the records, based on data assimilated from these sources, are then disambiguated and mapped to their respective geo-coordinates. We evaluated our approach on a manually annotated dataset comprising of 5728 GenBank records for the influenza A virus., Results We found the precision, recall, and f-measure of our system for linking GenBank records to the latitude/longitudes of their LOIH to be 0.832, 0.967, and 0.894, respectively., Discussion Our system had a high level of accuracy for linking GenBank records to the geo-coordinates of the LOIH. However, it can be further improved by expanding our database of geospatial data, incorporating spell correction, and enhancing the rules used for extraction., Conclusion Our system performs reasonably well for linking GenBank records for the influenza A virus to the geo-coordinates of their LOIH based on record metadata and information extracted from related full-text articles.},
	number = {5},
	urldate = {2018-03-10},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Tahsin, Tasnia and Weissenbacher, Davy and Rivera, Robert and Beard, Rachel and Firago, Mari and Wallstrom, Garrick and Scotch, Matthew and Gonzalez, Graciela},
	month = sep,
	year = {2016},
	pmid = {26911818},
	pmcid = {PMC4997033},
	keywords = {female first or senior, IE},
	pages = {934--941},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/9IT9RRWC/Tahsin et al. - 2016 - A high-precision rule-based extraction system for .pdf:application/pdf}
}

@article{sarker_corpus_2016,
	title = {A corpus for mining drug-related knowledge from {Twitter} chatter: {Language} models and their utilities},
	volume = {10},
	issn = {2352-3409},
	shorttitle = {A corpus for mining drug-related knowledge from {Twitter} chatter},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5144647/},
	doi = {10.1016/j.dib.2016.11.056},
	abstract = {In this data article, we present to the data science, natural language processing and public heath communities an unlabeled corpus and a set of language models. We collected the data from Twitter using drug names as keywords, including their common misspelled forms. Using this data, which is rich in drug-related chatter, we developed language models to aid the development of data mining tools and methods in this domain. We generated several models that capture (i) distributed word representations and (ii) probabilities of n-gram sequences. The data set we are releasing consists of 267,215 Twitter posts made during the four-month period—November, 2014 to February, 2015. The posts mention over 250 drug-related keywords. The language models encapsulate semantic and sequential properties of the texts.},
	urldate = {2018-03-10},
	journal = {Data in Brief},
	author = {Sarker, Abeed and Gonzalez, Graciela},
	month = nov,
	year = {2016},
	pmid = {27981203},
	pmcid = {PMC5144647},
	keywords = {female first or senior},
	pages = {122--131},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/QB4DLM39/Sarker and Gonzalez - 2016 - A corpus for mining drug-related knowledge from Tw.pdf:application/pdf}
}

@article{sarker_discovering_2017,
	title = {Discovering {Cohorts} of {Pregnant} {Women} {From} {Social} {Media} for {Safety} {Surveillance} and {Analysis}},
	volume = {19},
	issn = {1439-4456},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5684515/},
	doi = {10.2196/jmir.8164},
	abstract = {Background
Pregnancy exposure registries are the primary sources of information about the safety of maternal usage of medications during pregnancy. Such registries enroll pregnant women in a voluntary fashion early on in pregnancy and follow them until the end of pregnancy or longer to systematically collect information regarding specific pregnancy outcomes. Although the model of pregnancy registries has distinct advantages over other study designs, they are faced with numerous challenges and limitations such as low enrollment rate, high cost, and selection bias.

Objective
The primary objectives of this study were to systematically assess whether social media (Twitter) can be used to discover cohorts of pregnant women and to develop and deploy a natural language processing and machine learning pipeline for the automatic collection of cohort information. In addition, we also attempted to ascertain, in a preliminary fashion, what types of longitudinal information may potentially be mined from the collected cohort information.

Methods
Our discovery of pregnant women relies on detecting pregnancy-indicating tweets (PITs), which are statements posted by pregnant women regarding their pregnancies. We used a set of 14 patterns to first detect potential PITs. We manually annotated a sample of 14,156 of the retrieved user posts to distinguish real PITs from false positives and trained a supervised classification system to detect real PITs. We optimized the classification system via cross validation, with features and settings targeted toward optimizing precision for the positive class. For users identified to be posting real PITs via automatic classification, our pipeline collected all their available past and future posts from which other information (eg, medication usage and fetal outcomes) may be mined.

Results
Our rule-based PIT detection approach retrieved over 200,000 posts over a period of 18 months. Manual annotation agreement for three annotators was very high at kappa (κ)=.79. On a blind test set, the implemented classifier obtained an overall F1 score of 0.84 (0.88 for the pregnancy class and 0.68 for the nonpregnancy class). Precision for the pregnancy class was 0.93, and recall was 0.84. Feature analysis showed that the combination of dense and sparse vectors for classification achieved optimal performance. Employing the trained classifier resulted in the identification of 71,954 users from the collected posts. Over 250 million posts were retrieved for these users, which provided a multitude of longitudinal information about them.

Conclusions
Social media sources such as Twitter can be used to identify large cohorts of pregnant women and to gather longitudinal information via automated processing of their postings. Considering the many drawbacks and limitations of pregnancy registries, social media mining may provide beneficial complementary information. Although the cohort sizes identified over social media are large, future research will have to assess the completeness of the information available through them.},
	number = {10},
	urldate = {2018-03-10},
	journal = {Journal of Medical Internet Research},
	author = {Sarker, Abeed and Chandrashekar, Pramod and Magge, Arjun and Cai, Haitao and Klein, Ari and Gonzalez, Graciela},
	month = oct,
	year = {2017},
	pmid = {29084707},
	pmcid = {PMC5684515},
	keywords = {female first or senior}
}

@article{gonzalez_computerized_1993,
	title = {A {Computerized} {Speech} {Recognition} {Telephone} {Application} for {Screening} {Clinical} {Depression}},
	issn = {0195-4210},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2850753/},
	urldate = {2018-03-10},
	journal = {Proceedings of the Annual Symposium on Computer Application in Medical Care},
	author = {González, Gerardo M.},
	year = {1993},
	pmid = {null},
	pmcid = {PMC2850753},
	pages = {936},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KYHI4LUD/González - 1993 - A Computerized Speech Recognition Telephone Applic.pdf:application/pdf}
}

@article{gonzalez_generanker:_2008,
	title = {{GeneRanker}: {An} {Online} {System} for {Predicting} {Gene}-{Disease} {Associations} for {Translational} {Research}},
	volume = {2008},
	issn = {2153-6430},
	shorttitle = {{GeneRanker}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041521/},
	abstract = {With the overwhelming volume of genomic and molecular information available on many databases nowadays, researchers need from bioinformaticians more than encouragement to refine their searches. We present here GeneRanker, an online system that allows researchers to obtain a ranked list of genes potentially related to a specific disease or biological process by combining gene-disease (or genebiological process) associations with protein-protein interactions extracted from the literature, using computational analysis of the protein network topology to more accurately rank the predicted associations. GeneRanker was evaluated in the context of brain cancer research, and is freely available online at http://www.generanker.org.},
	urldate = {2018-03-10},
	journal = {Summit on Translational Bioinformatics},
	author = {Gonzalez, Graciela and Uribe, Juan C. and Armstrong, Brock and McDonough, Wendy and Berens, Michael E.},
	month = mar,
	year = {2008},
	pmid = {21347122},
	pmcid = {PMC3041521},
	keywords = {female first or senior, IE},
	pages = {26--30},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PIWPDXCJ/Gonzalez et al. - 2008 - GeneRanker An Online System for Predicting Gene-D.pdf:application/pdf}
}

@article{de_pablos_differential_2011,
	title = {Differential {Expression} and {Characterization} of a {Member} of the {Mucin}-{Associated} {Surface} {Protein} {Family} {Secreted} by {Trypanosoma} cruzi ▿},
	volume = {79},
	issn = {0019-9567},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3187265/},
	doi = {10.1128/IAI.05329-11},
	abstract = {We describe the characterization, purification, expression, and location of a 52-kDa protein secreted during interaction between the metacyclic form of Trypanosoma cruzi and its target host cell. The protein, which we have named MASP52, belongs to the family of mucin-associated surface proteins (MASPs). The highest levels of expression of both the protein and mRNA occur during the metacyclic and bloodstream trypomastigote stages, the forms that infect the vertebrate host cells. The protein is located in the plasma membrane and in the flagellar pockets of the epimastigote, metacyclic, and trypomastigote forms and is secreted into the medium at the point of contact between the parasite and the cell membrane, as well as into the host-cell cytosol during the amastigote stage. IgG antibodies specific against a synthetic peptide corresponding to the catalytic zone of MASP52 significantly reduce the parasite's capacity to infect the host cells. Furthermore, when the protein is adsorbed onto inert particles of bentonite and incubated with a nonphagocytic cell culture, the particles are able to induce endocytosis in the cells, which seems to demonstrate that MASP52 plays a role in a process whereby the trypomastigote forms of the parasite invade the host cell.},
	number = {10},
	urldate = {2018-03-10},
	journal = {Infection and Immunity},
	author = {De Pablos, Luis Miguel and González, Gloria González and Solano Parada, Jennifer and Seco Hidalgo, Víctor and Díaz Lozano, Isabel María and Gómez Samblás, María Mercedes and Cruz Bustos, Teresa and Osuna, Antonio},
	month = oct,
	year = {2011},
	pmid = {21788387},
	pmcid = {PMC3187265},
	pages = {3993--4001},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/59B4FMM6/De Pablos et al. - 2011 - Differential Expression and Characterization of a .pdf:application/pdf}
}

@article{chartron_structural_2011,
	title = {A {Structural} {Model} of the {Sgt}2 {Protein} and {Its} {Interactions} with {Chaperones} and the {Get}4/{Get}5 {Complex}},
	volume = {286},
	issn = {0021-9258},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3190793/},
	doi = {10.1074/jbc.M111.277798},
	abstract = {The insertion of tail-anchored transmembrane (TA) proteins into the appropriate membrane is a post-translational event that requires stabilization of the transmembrane domain and targeting to the proper destination. Sgt2 is a heat-shock protein cognate (HSC) co-chaperone that preferentially binds endoplasmic reticulum-destined TA proteins and directs them to the GET pathway via Get4 and Get5. Here, we present the crystal structure from a fungal Sgt2 homolog of the tetratrico-repeat (TPR) domain and part of the linker that connects to the C-terminal domain. The linker extends into the two-carboxylate clamp of the TPR domain from a symmetry-related molecule mimicking the binding to HSCs. Based on this structure, we provide biochemical evidence that the Sgt2 TPR domain has the ability to directly bind multiple HSC family members. The structure allows us to propose features involved in this lower specificity relative to other TPR containing co-chaperones. We further show that a dimer of Sgt2 binds a single Get5 and use small angle x-ray scattering to characterize the domain arrangement of Sgt2 in solution. These results allow us to present a structural model of the Sgt2-Get4/Get5-HSC complex.},
	number = {39},
	urldate = {2018-03-10},
	journal = {The Journal of Biological Chemistry},
	author = {Chartron, Justin W. and Gonzalez, Grecia M. and Clemons, William M.},
	month = sep,
	year = {2011},
	pmid = {21832041},
	pmcid = {PMC3190793},
	keywords = {female first or senior},
	pages = {34325--34334},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JC3BPSCA/Chartron et al. - 2011 - A Structural Model of the Sgt2 Protein and Its Int.pdf:application/pdf}
}

@article{nikfarjam_hybrid_2012-1,
	title = {A {Hybrid} {System} for {Emotion} {Extraction} from {Suicide} {Notes}},
	volume = {5},
	issn = {1178-2226},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3409484/},
	doi = {10.4137/BII.S8981},
	abstract = {The reasons that drive someone to commit suicide are complex and their study has attracted the attention of scientists in different domains. Analyzing this phenomenon could significantly improve the preventive efforts. In this paper we present a method for sentiment analysis of suicide notes submitted to the i2b2/VA/Cincinnati Shared Task 2011. In this task the sentences of 900 suicide notes were labeled with the possible emotions that they reflect. In order to label the sentence with emotions, we propose a hybrid approach which utilizes both rule based and machine learning techniques. To solve the multi class problem a rule-based engine and an SVM model is used for each category. A set of syntactic and semantic features are selected for each sentence to build the rules and train the classifier. The rules are generated manually based on a set of lexical and emotional clues. We propose a new approach to extract the sentence’s clauses and constitutive grammatical elements and to use them in syntactic and semantic feature generation. The method utilizes a novel method to measure the polarity of the sentence based on the extracted grammatical elements, reaching precision of 41.79 with recall of 55.03 for an f-measure of 47.50. The overall mean f-measure of all submissions was 48.75\% with a standard deviation of 7\%.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {Biomedical Informatics Insights},
	author = {Nikfarjam, Azadeh and Emadzadeh, Ehsan and Gonzalez, Graciela},
	month = jan,
	year = {2012},
	pmid = {22879773},
	pmcid = {PMC3409484},
	keywords = {female first or senior},
	pages = {165--174},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/2EXF4EIU/Nikfarjam et al. - 2012 - A Hybrid System for Emotion Extraction from Suicid.pdf:application/pdf}
}

@article{yamane_identification_2013,
	title = {Identification of {Contamination} in the {American} {Type} {Culture} {Collection} {Stock} of {Human} {Adenovirus} {Type} 8 by {Whole}-{Genome} {Sequencing}},
	volume = {87},
	issn = {0022-538X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3554079/},
	doi = {10.1128/JVI.02875-12},
	number = {2},
	urldate = {2018-03-10},
	journal = {Journal of Virology},
	author = {Yamane, Shotaro and Lee, Amanda Wei Ling and Hanaoka, Nozomu and Gonzalez, Gabriel and Kaneko, Hisatoshi and Ishida, Susumu and Kitaichi, Nobuyoshi and Ohno, Shigeaki and Koyanagi, Kanako O. and Aoki, Koki and Fujimoto, Tsuguto and Yawata, Nobuyo and Watanabe, Hidemi},
	month = jan,
	year = {2013},
	pmid = {23152510},
	pmcid = {PMC3554079},
	keywords = {female first or senior},
	pages = {1285--1286},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/9BEINCW3/Yamane et al. - 2013 - Identification of Contamination in the American Ty.pdf:application/pdf}
}

@article{gonzalez_real-time_2014,
	title = {A {Real}-{Time} {All}-{Atom} {Structural} {Search} {Engine} for {Proteins}},
	volume = {10},
	issn = {1553-734X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4117414/},
	doi = {10.1371/journal.pcbi.1003750},
	abstract = {Protein designers use a wide variety of software tools for de novo design, yet their repertoire still lacks a fast and interactive all-atom search engine. To solve this, we have built the Suns program: a real-time, atomic search engine integrated into the PyMOL molecular visualization system. Users build atomic-level structural search queries within PyMOL and receive a stream of search results aligned to their query within a few seconds. This instant feedback cycle enables a new “designability”-inspired approach to protein design where the designer searches for and interactively incorporates native-like fragments from proven protein structures. We demonstrate the use of Suns to interactively build protein motifs, tertiary interactions, and to identify scaffolds compatible with hot-spot residues. The official web site and installer are located at http://www.degradolab.org/suns/ and the source code is hosted at https://github.com/godotgildor/Suns (PyMOL plugin, BSD license), https://github.com/Gabriel439/suns-cmd (command line client, BSD license), and https://github.com/Gabriel439/suns-search (search engine server, GPLv2 license).},
	number = {7},
	urldate = {2018-03-10},
	journal = {PLoS Computational Biology},
	author = {Gonzalez, Gabriel and Hannigan, Brett and DeGrado, William F.},
	month = jul,
	year = {2014},
	pmid = {25079944},
	pmcid = {PMC4117414},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/27H9DRD8/Gonzalez et al. - 2014 - A Real-Time All-Atom Structural Search Engine for .pdf:application/pdf}
}

@article{poggio_genome_2014,
	title = {Genome downsizing and karyotype constancy in diploid and polyploid congeners: a model of genome size variation},
	volume = {6},
	issn = {2041-2851},
	shorttitle = {Genome downsizing and karyotype constancy in diploid and polyploid congeners},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4152747/},
	doi = {10.1093/aobpla/plu029},
	abstract = {In several genus evolutionary chromosome change involves variation in DNA amount in diploids and genome downsizing in polyploids. The constancy of bimodal karyotypes, even with changes in ploidy level and DNA content per basic genome indicate that the distribution of DNA within the complement is not at random and suggest the presence of mechanisms selecting for constancy, or against changes, in the karyotype morphology., Evolutionary chromosome change involves significant variation in DNA amount in diploids and genome downsizing in polyploids. Genome size and karyotype parameters of Hippeastrum species with different ploidy level were analysed. In Hippeastrum, polyploid species show less DNA content per basic genome than diploid species. The rate of variation is lower at higher ploidy levels. All the species have a basic number x = 11 and bimodal karyotypes. The basic karyotypes consist of four short metacentric chromosomes and seven large chromosomes (submetacentric and subtelocentric). The bimodal karyotype is preserved maintaining the relative proportions of members of the haploid chromosome set, even in the presence of genome downsizing. The constancy of the karyotype is maintained because changes in DNA amount are proportional to the length of the whole-chromosome complement and vary independently in the long and short sets of chromosomes. This karyotype constancy in taxa of Hippeastrum with different genome size and ploidy level indicates that the distribution of extra DNA within the complement is not at random and suggests the presence of mechanisms selecting for constancy, or against changes, in karyotype morphology.},
	urldate = {2018-03-10},
	journal = {AoB Plants},
	author = {Poggio, Lidia and Realini, María Florencia and Fourastié, María Florencia and García, Ana María and González, Graciela Esther},
	month = jun,
	year = {2014},
	pmid = {24969503},
	pmcid = {PMC4152747},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WQSRH9WL/Poggio et al. - 2014 - Genome downsizing and karyotype constancy in diplo.pdf:application/pdf}
}

@article{emadzadeh_unsupervised_2014,
	title = {Unsupervised gene function extraction using semantic vectors},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4160099/},
	doi = {10.1093/database/bau084},
	abstract = {Finding gene functions discussed in the literature is an important task of information extraction (IE) from biomedical documents. Automated computational methodologies can significantly reduce the need for manual curation and improve quality of other related IE systems. We propose an open-IE method for the BioCreative IV GO shared task (subtask b), focused on finding gene function terms [Gene Ontology (GO) terms] for different genes in an article. The proposed open-IE approach is based on distributional semantic similarity over the GO terms. The method does not require annotated data for training, which makes it highly generalizable. We achieve an F-measure of 0.26 on the test-set in the official submission for BioCreative-GO shared task, the third highest F-measure among the seven participants in the shared task., Database URL: https://code.google.com/p/rainbow-nlp/},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Emadzadeh, Ehsan and Nikfarjam, Azadeh and Ginn, Rachel E. and Gonzalez, Graciela},
	month = sep,
	year = {2014},
	pmid = {25209025},
	pmcid = {PMC4160099},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YKYBM5AL/Emadzadeh et al. - 2014 - Unsupervised gene function extraction using semant.pdf:application/pdf}
}

@article{drake_requirement_2014,
	title = {A {Requirement} for {ERK} dependent {Dicer} {Phosphorylation} in {Coordinating} {Oocyte}-to-{Embryo} {Transition} in {Caenorhabditis} elegans},
	volume = {31},
	issn = {1534-5807},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4261158/},
	doi = {10.1016/j.devcel.2014.11.004},
	abstract = {Signaling pathways and small RNAs direct diverse cellular events, but few examples are known of defined signaling pathways directly regulating small RNA biogenesis. We show that ERK phosphorylates Dicer on two conserved residues in its RNAse IIIb and dsRNA-binding domain, and phosphorylation of these residues is necessary and sufficient to trigger Dicer’s nuclear translocation in worms, mice, and human cells. Phosphorylation of Dicer on either site inhibits Dicer function in the female germ line and dampens small RNA repertoire. Our data demonstrate that ERK phosphorylates and inhibits Dicer during meiosis I for oogenesis to proceed normally in C. elegans and that this inhibition is released before fertilization for embryogenesis to proceed normally. The conserved Dicer residues, their phosphorylation by ERK, and the consequences of the resulting modifications implicate an ERK-Dicer nexus as a fundamental component of the oocyte-to-embryo transition and an underlying mechanism coupling extracellular cues to small RNA production.},
	number = {5},
	urldate = {2018-03-10},
	journal = {Developmental cell},
	author = {Drake, Melanie and Furuta, Tokiko and Man, Kin Suen and Gonzalez, Gabriel and Liu, Bin and Kalia, Awdhesh and Ladbury, John and Fire, Andrew Z. and Skeath, James B and Arur, Swathi},
	month = dec,
	year = {2014},
	pmid = {25490268},
	pmcid = {PMC4261158},
	keywords = {female first or senior},
	pages = {614--628},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/FAYHK3WB/Drake et al. - 2014 - A Requirement for ERK dependent Dicer Phosphorylat.pdf:application/pdf}
}

@article{espinel-ingroff_multicenter_2015,
	title = {Multicenter {Study} of {Isavuconazole} {MIC} {Distributions} and {Epidemiological} {Cutoff} {Values} for the {Cryptococcus} neoformans-{Cryptococcus} gattii {Species} {Complex} {Using} the {CLSI} {M}27-{A}3 {Broth} {Microdilution} {Method}},
	volume = {59},
	issn = {0066-4804},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4291414/},
	doi = {10.1128/AAC.04055-14},
	abstract = {Epidemiological cutoff values (ECVs) of isavuconazole are not available for Cryptococcus spp. The isavuconazole ECVs based on wild-type (WT) MIC distributions for 438 Cryptococcus neoformans nongenotyped isolates, 870 isolates of genotype VNI, and 406 Cryptococcus gattii isolates from six laboratories and different geographical areas were 0.06, 0.12, and 0.25 μg/ml, respectively. These ECVs may aid in detecting non-WT isolates with reduced susceptibilities to isavuconazole.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Antimicrobial Agents and Chemotherapy},
	author = {Espinel-Ingroff, A. and Chowdhary, A. and Gonzalez, G. M. and Guinea, J. and Hagen, F. and Meis, J. F. and Thompson, G. R. and Turnidge, J.},
	month = jan,
	year = {2015},
	pmid = {25313209},
	pmcid = {PMC4291414},
	keywords = {female first or senior},
	pages = {666--668},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/W8CZ4NX7/Espinel-Ingroff et al. - 2015 - Multicenter Study of Isavuconazole MIC Distributio.pdf:application/pdf}
}

@article{furniss_automatic_2014,
	title = {Automatic {Gene} {Prioritization} in {Support} of the {Inflammatory} {Contribution} to {Alzheimer}’s {Disease}},
	volume = {2014},
	issn = {2153-4063},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4333706/},
	abstract = {This research seeks to extend the process of novel therapeutic gene target discovery for the treatment of Alzheimer’s disease (AD). Gene-gene and gene-pathway annotation tools as well as human analysis are used to explore likely connections between potential gene targets and biochemical mechanisms of AD and associated genes. Rule-based annotation systems, such as GeneRanker, can be applied to the continuously growing volume of literature to extract relevant gene lists. The subsequent challenge is to abstract biological significance from associated genes to aid in discovery of novel therapeutic gene targets. Automatic annotation of genes deemed significant by data-driven assays and knowledge-driven analysis is limited. Therefore, human analysis is still crucial to exploring novel gene targets and new disease models. This research illustrates a method of analysis of an extracted gene list which lead to the discovery of KNG1 as a possible therapeutic target, suggests a connection between inflammation and AD pathogenesis.},
	urldate = {2018-03-10},
	journal = {AMIA Summits on Translational Science Proceedings},
	author = {Furniss, Stephanie K and Yao, Robert and Gonzalez, Graciela},
	month = apr,
	year = {2014},
	pmid = {25717399},
	pmcid = {PMC4333706},
	keywords = {female first or senior},
	pages = {42--47},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7PPFVGC4/Furniss et al. - 2014 - Automatic Gene Prioritization in Support of the In.pdf:application/pdf}
}

@article{sarker_utilizing_2015,
	title = {Utilizing {Social} {Media} {Data} for {Pharmacovigilance}: {A} {Review}},
	volume = {54},
	issn = {1532-0464},
	shorttitle = {Utilizing {Social} {Media} {Data} for {Pharmacovigilance}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4408239/},
	doi = {10.1016/j.jbi.2015.02.004},
	abstract = {Objective
Automatic monitoring of Adverse Drug Reactions (ADRs), defined as adverse patient outcomes caused by medications, is a challenging research problem that is currently receiving significant attention from the medical informatics community. In recent years, user-posted data on social media, primarily due to its sheer volume, has become a useful resource for ADR monitoring. Research using social media data has progressed using various data sources and techniques, making it difficult to compare distinct systems and their performances. In this paper, we perform a methodical review to characterize the different approaches to ADR detection/extraction from social media, and their applicability to pharmacovigilance. In addition, we present a potential systematic pathway to ADR monitoring from social media.

Methods
We identified studies, describing approaches for ADR detection from social media from the Medline, Embase, Scopus and Web of Science databases, and the Google Scholar search engine. Studies that met our inclusion criteria were those that attempted to utilize ADR information posted by users on any publicly available social media platform. We categorized the studies into various dimensions such as primary ADR detection approach, size of data, source(s), availability, evaluation criteria, and so on.

Results
Twenty-two studies met our inclusion criteria, with fifteen (68.2\%) published within the last two years. The survey revealed a clear trend towards the usage of annotated data with eleven of the fifteen (73.3\%) studies published in the last two years relying on expert annotations. However, publicly available annotated data is still scarce, and we found only six (27.3\%) studies that made the annotations used publicly available, making system performance comparisons difficult. In terms of algorithms, supervised classification techniques to detect posts containing ADR mentions, and lexicon-based approaches for extraction of ADR mentions from texts have been the most popular.

Conclusion
Our review suggests that interest in the utilization of the vast amounts of available social media data for ADR monitoring is increasing with time. In terms of sources, both health-related and general social media data have been used for ADR detection— while health-related sources tend to contain higher proportions of relevant data, the volume of data from general social media websites is significantly higher. There is still very limited publicly available annotated data available, and, as indicated by the promising results obtained by recent supervised learning approaches, there is a strong need to make such data available to the research community.},
	urldate = {2018-03-10},
	journal = {Journal of biomedical informatics},
	author = {Sarker, Abeed and Ginn, Rachel and Nikfarjam, Azadeh and O’Connor, Karen and Smith, Karen and Jayaraman, Swetha and Upadhaya, Tejaswi and Gonzalez, Graciela},
	month = apr,
	year = {2015},
	pmid = {25720841},
	pmcid = {PMC4408239},
	keywords = {female first or senior},
	pages = {202--212},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/HIW2EQSX/Sarker et al. - 2015 - Utilizing Social Media Data for Pharmacovigilance.pdf:application/pdf}
}

@article{weissenbacher_knowledge-driven_2015,
	title = {Knowledge-driven geospatial location resolution for phylogeographic models of virus migration},
	volume = {31},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4542781/},
	doi = {10.1093/bioinformatics/btv259},
	abstract = {Summary: Diseases caused by zoonotic viruses (viruses transmittable between humans and animals) are a major threat to public health throughout the world. By studying virus migration and mutation patterns, the field of phylogeography provides a valuable tool for improving their surveillance. A key component in phylogeographic analysis of zoonotic viruses involves identifying the specific locations of relevant viral sequences. This is usually accomplished by querying public databases such as GenBank and examining the geospatial metadata in the record. When sufficient detail is not available, a logical next step is for the researcher to conduct a manual survey of the corresponding published articles., Motivation: In this article, we present a system for detection and disambiguation of locations (toponym resolution) in full-text articles to automate the retrieval of sufficient metadata. Our system has been tested on a manually annotated corpus of journal articles related to phylogeography using integrated heuristics for location disambiguation including a distance heuristic, a population heuristic and a novel heuristic utilizing knowledge obtained from GenBank metadata (i.e. a ‘metadata heuristic’)., Results: For detecting and disambiguating locations, our system performed best using the metadata heuristic (0.54 Precision, 0.89 Recall and 0.68 F-score). Precision reaches 0.88 when examining only the disambiguation of location names. Our error analysis showed that a noticeable increase in the accuracy of toponym resolution is possible by improving the geospatial location detection. By improving these fundamental automated tasks, our system can be a useful resource to phylogeographers that rely on geospatial metadata of GenBank sequences. , Contact:
davy.weissenbacher@asu.edu},
	number = {12},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Weissenbacher, Davy and Tahsin, Tasnia and Beard, Rachel and Figaro, Mari and Rivera, Robert and Scotch, Matthew and Gonzalez, Graciela},
	month = jun,
	year = {2015},
	pmid = {26072502},
	pmcid = {PMC4542781},
	keywords = {female first or senior},
	pages = {i348--i356},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/L98JZRGS/Weissenbacher et al. - 2015 - Knowledge-driven geospatial location resolution fo.pdf:application/pdf}
}

@article{armangue_autoimmune_2015,
	title = {Autoimmune post–herpes simplex encephalitis of adults and teenagers},
	volume = {85},
	issn = {0028-3878},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4653102/},
	doi = {10.1212/WNL.0000000000002125},
	abstract = {Objective:
To report 14 patients with immune-mediated relapsing symptoms post–herpes simplex encephalitis (HSE) and to compare the clinical and immunologic features of the teenage and adult group with those of young children.

Methods:
Prospective observational study of patients diagnosed between June 2013 and February 2015. Immunologic techniques have been reported previously.

Results:
Among the teenage and adult group (8 patients, median age 40 years, range 13–69; 5 male), 3 had an acute symptom presentation suggesting a viral relapse, and 5 a presentation contiguous with HSE suggesting a recrudescence of previous deficits. Seven patients developed severe psychiatric/behavioral symptoms disrupting all social interactions, and one refractory status epilepticus. Blepharospasm occurred in one patient. Five patients had CSF antibodies against NMDA receptor (NMDAR) and 3 against unknown neuronal cell surface proteins. In 5/6 patients, the brain MRI showed new areas of contrast enhancement that decreased after immunotherapy and clinical improvement. Immunotherapy was useful in 7/7 patients, sometimes with impressive recoveries, returning to their baseline HSE residual deficits. Compared with the 6 younger children (median age 13 months, range 6–20, all with NMDAR antibodies), the teenagers and adults were less likely to develop choreoathetosis (0/8 vs 6/6, p {\textless} 0.01) and decreased level of consciousness (2/8 vs 6/6, p {\textless} 0.01) and had longer delays in diagnosis and treatment (interval relapse/antibody testing 85 days, range 17–296, vs 4 days, range 0–33, p = 0.037).

Conclusion:
In teenagers and adults, the immune-mediated relapsing syndrome post-HSE is different from that known in young children as choreoathetosis post-HSE and is underrecognized. Prompt diagnosis is important because immunotherapy can be highly effective.},
	number = {20},
	urldate = {2018-03-10},
	journal = {Neurology},
	author = {Armangue, Thaís and Moris, Germán and Cantarín-Extremera, Verónica and Conde, Carlos Enrique and Rostasy, Kevin and Erro, Maria Elena and Portilla-Cuenca, Juan Carlos and Turón-Viñas, Eulàlia and Málaga, Ignacio and Muñoz-Cabello, Beatriz and Torres-Torres, Carmen and Llufriu, Sara and González-Gutiérrez-Solana, Luis and González, Guillermo and Casado-Naranjo, Ignacio and Rosenfeld, Myrna and Graus, Francesc and Dalmau, Josep},
	month = nov,
	year = {2015},
	pmid = {26491084},
	pmcid = {PMC4653102},
	pages = {1736--1743},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZGQU5556/Armangue et al. - 2015 - Autoimmune post–herpes simplex encephalitis of adu.pdf:application/pdf}
}

@article{gonzalez_evaluation_2014,
	title = {An {Evaluation} of the {Implementation} and {Perceived} {Utility} of the {Airman} {Resilience} {Training} {Program}},
	volume = {4},
	issn = {2162-8254},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5052004/},
	abstract = {This study assesses Airman Resilience Training, a psychoeducational Air Force program designed to improve airmen's reactions to stress during and after deployment and to increase the use of mental health services when needed., Since 2001, the U.S. Military has been functioning at an operational tempo that is historically high for the all-volunteer force in which service members are deploying for extended periods on a repeated basis. Even with the drawdown of troops from Iraq in 2011, some service members are returning from deployment experiencing difficulties handling stress, mental health problems, or deficits caused by a traumatic brain injury (TBI). In response to these challenges, the U.S. Department of Defense (DoD) has implemented numerous programs to support service members and their families in these areas. In 2009, the Assistant Secretary of Defense for Health Affairs asked the RAND National Defense Research Institute to develop a comprehensive catalog of existing programs sponsored or funded by DoD to support psychological health and care for TBI, to create tools to support ongoing assessment and evaluation of the DoD portfolio of programs, and to conduct evaluations of a subset of these programs. This article describes RAND's assessment of an Air Force program, Airman Resilience Training (ART), which is a psychoeducational program designed to improve airmen's reactions to stress during and after deployment and to increase the use of mental health services when needed. ART was initiated in November 2010, replacing a previous program named Landing Gear, which had been in place since April 2008. The RAND study took place from August 2011 through November 2011. This study will be of particular interest to officials within the Air Force who are responsible for the psychological health and well-being of airmen, as well as to others within the military who are developing programs for service members to help them cope with stress while in combat situations and after returning from deployment.},
	number = {2},
	urldate = {2018-03-10},
	journal = {Rand Health Quarterly},
	author = {Gonzalez, Gabriella C. and Singh, Reema and Schell, Terry L. and Weinick, Robin M.},
	month = jun,
	year = {2014},
	pmid = {28083341},
	pmcid = {PMC5052004},
	keywords = {female first or senior}
}

@article{abbott_prospects_2016,
	title = {Prospects for {Observing} and {Localizing} {Gravitational}-{Wave} {Transients} with {Advanced} {LIGO} and {Advanced} {Virgo}},
	volume = {19},
	issn = {1433-8351},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5256041/},
	doi = {10.1007/lrr-2016-1},
	abstract = {We present a possible observing scenario for the Advanced LIGO and Advanced Virgo gravitational-wave detectors over the next decade, with the intention of providing information to the astronomy community to facilitate planning for multi-messenger astronomy with gravitational waves. We determine the expected sensitivity of the network to transient gravitational-wave signals, and study the capability of the network to determine the sky location of the source. We report our findings for gravitational-wave transients, with particular focus on gravitational-wave signals from the inspiral of binary neutron-star systems, which are considered the most promising for multi-messenger astronomy. The ability to localize the sources of the detected signals depends on the geographical distribution of the detectors and their relative sensitivity, and 90\% credible regions can be as large as thousands of square degrees when only two sensitive detectors are operational. Determining the sky position of a significant fraction of detected signals to areas of 5 deg2 to 20 deg2 will require at least three detectors of sensitivity within a factor of ∼ 2 of each other and with a broad frequency bandwidth. Should the third LIGO detector be relocated to India as expected, a significant fraction of gravitational-wave signals will be localized to a few square degrees by gravitational-wave observations alone.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Living Reviews in Relativity},
	author = {Abbott, B. P. and Abbott, R. and Abbott, T. D. and Abernathy, M. R. and Acernese, F. and Ackley, K. and Adams, C. and Adams, T. and Addesso, P. and Adhikari, R. X. and Adya, V. B. and Affeldt, C. and Agathos, M. and Agatsuma, K. and Aggarwal, N. and Aguiar, O. D. and Ain, A. and Ajith, P. and Allen, B. and Allocca, A. and Altin, P. A. and Amariutei, D. V. and Anderson, S. B. and Anderson, W. G. and Arai, K. and Araya, M. C. and Arceneaux, C. C. and Areeda, J. S. and Arnaud, N. and Arun, K. G. and Ashton, G. and Ast, M. and Aston, S. M. and Astone, P. and Aufmuth, P. and Aulbert, C. and Babak, S. and Baker, P. T. and Baldaccini, F. and Ballardin, G. and Ballmer, S. W. and Barayoga, J. C. and Barclay, S. E. and Barish, B. C. and Barker, D. and Barone, F. and Barr, B. and Barsotti, L. and Barsuglia, M. and Barta, D. and Bartlett, J. and Bartos, I. and Bassiri, R. and Basti, A. and Batch, J. C. and Baune, C. and Bavigadda, V. and Bazzan, M. and Behnke, B. and Bejger, M. and Belczynski, C. and Bell, A. S. and Bell, C. J. and Berger, B. K. and Bergman, J. and Bergmann, G. and Berry, C. P. L. and Bersanetti, D. and Bertolini, A. and Betzwieser, J. and Bhagwat, S. and Bhandare, R. and Bilenko, I. A. and Billingsley, G. and Birch, J. and Birney, R. and Biscans, S. and Bisht, A. and Bitossi, M. and Biwer, C. and Bizouard, M. A. and Blackburn, J. K. and Blair, C. D. and Blair, D. and Blair, R. M. and Bloemen, S. and Bock, O. and Bodiya, T. P. and Boer, M. and Bogaert, G. and Bogan, C. and Bohe, A. and Bojtos, P. and Bond, C. and Bondu, F. and Bonnand, R. and Bork, R. and Boschi, V. and Bose, S. and Bozzi, A. and Bradaschia, C. and Brady, P. R. and Braginsky, V. B. and Branchesi, M. and Brau, J. E. and Briant, T. and Brillet, A. and Brinkmann, M. and Brisson, V. and Brockill, P. and Brooks, A. F. and Brown, D. A. and Brown, D. D. and Brown, N. M. and Buchanan, C. C. and Buikema, A. and Bulik, T. and Bulten, H. J. and Buonanno, A. and Buskulic, D. and Buy, C. and Byer, R. L. and Cadonati, L. and Cagnoli, G. and Cahillane, C. and Calderón Bustillo, J. and Callister, T. and Calloni, E. and Camp, J. B. and Cannon, K. C. and Cao, J. and Capano, C. D. and Capocasa, E. and Carbognani, F. and Caride, S. and Casanueva Diaz, J. and Casentini, C. and Caudill, S. and Cavaglià, M. and Cavalier, F. and Cavalieri, R. and Cella, G. and Cepeda, C. and Cerboni Baiardi, L. and Cerretani, G. and Cesarini, E. and Chakraborty, R. and Chalermsongsak, T. and Chamberlin, S. J. and Chan, M. and Chao, S. and Charlton, P. and Chassande-Mottin, E. and Chen, H. Y. and Chen, Y. and Cheng, C. and Chincarini, A. and Chiummo, A. and Cho, H. S. and Cho, M. and Chow, J. H. and Christensen, N. and Chu, Q. and Chua, S. and Chung, S. and Ciani, G. and Clara, F. and Clark, J. A. and Cleva, F. and Coccia, E. and Cohadon, P.-F. and Colla, A. and Collette, C. G. and Constancio, M. and Conte, A. and Conti, L. and Cook, D. and Corbitt, T. R. and Cornish, N. and Corsi, A. and Cortese, S. and Costa, C. A. and Coughlin, M. W. and Coughlin, S. B. and Coulon, J.-P. and Countryman, S. T. and Couvares, P. and Coward, D. M. and Cowart, M. J. and Coyne, D. C. and Coyne, R. and Craig, K. and Creighton, J. D. E. and Cripe, J. and Crowder, S. G. and Cumming, A. and Cunningham, L. and Cuoco, E. and Dal Canton, T. and Danilishin, S. L. and D’Antonio, S. and Danzmann, K. and Darman, N. S. and Dattilo, V. and Dave, I. and Daveloza, H. P. and Davier, M. and Davies, G. S. and Daw, E. J. and Day, R. and DeBra, D. and Debreczeni, G. and Degallaix, J. and De Laurentis, M. and Deléglise, S. and Del Pozzo, W. and Denker, T. and Dent, T. and Dereli, H. and Dergachev, V. and DeRosa, R. and De Rosa, R. and DeSalvo, R. and Dhurandhar, S. and Díaz, M. C. and Di Fiore, L. and Di Giovanni, M. and Di Lieto, A. and Di Palma, I. and Di Virgilio, A. and Dojcinoski, G. and Dolique, V. and Donovan, F. and Dooley, K. L. and Doravari, S. and Douglas, R. and Downes, T. P. and Drago, M. and Drever, R. W. P. and Driggers, J. C. and Du, Z. and Ducrot, M. and Dwyer, S. E. and Edo, T. B. and Edwards, M. C. and Effler, A. and Eggenstein, H.-B. and Ehrens, P. and Eichholz, J. M. and Eikenberry, S. S. and Engels, W. and Essick, R. C. and Etzel, T. and Evans, M. and Evans, T. M. and Everett, R. and Factourovich, M. and Fafone, V. and Fair, H. and Fairhurst, S. and Fan, X. and Fang, Q. and Farinon, S. and Farr, B. and Farr, W. M. and Favata, M. and Fays, M. and Fehrmann, H. and Fejer, M. M. and Ferrante, I. and Ferreira, E. C. and Ferrini, F. and Fidecaro, F. and Fiori, I. and Fisher, R. P. and Flaminio, R. and Fletcher, M. and Fournier, J.-D. and Franco, S. and Frasca, S. and Frasconi, F. and Frei, Z. and Freise, A. and Frey, R. and Fricke, T. T. and Fritschel, P. and Frolov, V. V. and Fulda, P. and Fyffe, M. and Gabbard, H. A. G. and Gair, J. R. and Gammaitoni, L. and Gaonkar, S. G. and Garufi, F. and Gatto, A. and Gaur, G. and Gehrels, N. and Gemme, G. and Gendre, B. and Genin, E. and Gennai, A. and George, J. and Gergely, L. and Germain, V. and Ghosh, A. and Ghosh, S. and Giaime, J. A. and Giardina, K. D. and Giazotto, A. and Gill, K. and Glaefke, A. and Goetz, E. and Goetz, R. and Gondan, L. and González, G. and Castro, J. M. Gonzalez and Gopakumar, A. and Gordon, N. A. and Gorodetsky, M. L. and Gossan, S. E. and Gosselin, M. and Gouaty, R. and Graef, C. and Graff, P. B. and Granata, M. and Grant, A. and Gras, S. and Gray, C. and Greco, G. and Green, A. C. and Groot, P. and Grote, H. and Grunewald, S. and Guidi, G. M. and Guo, X. and Gupta, A. and Gupta, M. K. and Gushwa, K. E. and Gustafson, E. K. and Gustafson, R. and Hacker, J. J. and Hall, B. R. and Hall, E. D. and Hammond, G. and Haney, M. and Hanke, M. M. and Hanks, J. and Hanna, C. and Hannam, M. D. and Hanson, J. and Hardwick, T. and Harms, J. and Harry, G. M. and Harry, I. W. and Hart, M. J. and Hartman, M. T. and Haster, C.-J. and Haughian, K. and Heidmann, A. and Heintze, M. C. and Heitmann, H. and Hello, P. and Hemming, G. and Hendry, M. and Heng, I. S. and Hennig, J. and Heptonstall, A. W. and Heurs, M. and Hild, S. and Hoak, D. and Hodge, K. A. and Hofman, D. and Hollitt, S. E. and Holt, K. and Holz, D. E. and Hopkins, P. and Hosken, D. J. and Hough, J. and Houston, E. A. and Howell, E. J. and Hu, Y. M. and Huang, S. and Huerta, E. A. and Huet, D. and Hughey, B. and Husa, S. and Huttner, S. H. and Huynh-Dinh, T. and Idrisy, A. and Indik, N. and Ingram, D. R. and Inta, R. and Isa, H. N. and Isac, J.-M. and Isi, M. and Islas, G. and Isogai, T. and Iyer, B. R. and Izumi, K. and Jacqmin, T. and Jang, H. and Jani, K. and Jaranowski, P. and Jawahar, S. and Jiménez-Forteza, F. and Johnson, W. W. and Jones, D. I. and Jones, R. and Jonker, R. J. G. and Ju, L. and Haris, K. and Kalaghatgi, C. V. and Kalogera, V. and Kandhasamy, S. and Kang, G. and Kanner, J. B. and Karki, S. and Kasprzack, M. and Katsavounidis, E. and Katzman, W. and Kaufer, S. and Kaur, T. and Kawabe, K. and Kawazoe, F. and Kéfélian, F. and Kehl, M. S. and Keitel, D. and Kelley, D. B. and Kells, W. and Kennedy, R. and Key, J. S. and Khalaidovski, A. and Khalili, F. Y. and Khan, S. and Khan, Z. and Khazanov, E. A. and Kijbunchoo, N. and Kim, C. and Kim, J. and Kim, K. and Kim, N. and Kim, Y.-M. and King, E. J. and King, P. J. and Kinzel, D. L. and Kissel, J. S. and Kleybolte, L. and Klimenko, S. and Koehlenbeck, S. M. and Kokeyama, K. and Koley, S. and Kondrashov, V. and Kontos, A. and Korobko, M. and Korth, W. Z. and Kowalska, I. and Kozak, D. B. and Kringel, V. and Krishnan, B. and Królak, A. and Krueger, C. and Kuehn, G. and Kumar, P. and Kuo, L. and Kutynia, A. and Lackey, B. D. and Landry, M. and Lange, J. and Lantz, B. and Lasky, P. D. and Lazzarini, A. and Lazzaro, C. and Leaci, P. and Leavey, S. and Lebigot, E. and Lee, C. H. and Lee, H. K. and Lee, H. M. and Lee, K. and Lenon, A. and Leonardi, M. and Leong, J. R. and Leroy, N. and Letendre, N. and Levin, Y. and Levine, B. M. and Li, T. G. F. and Libson, A. and Littenberg, T. B. and Lockerbie, N. A. and Logue, J. and Lombardi, A. L. and Lord, J. E. and Lorenzini, M. and Loriette, V. and Lormand, M. and Losurdo, G. and Lough, J. D. and Lück, H. and Lundgren, A. P. and Luo, J. and Lynch, R. and Ma, Y. and MacDonald, T. and Machenschalk, B. and MacInnis, M. and Macleod, D. M. and Magaña-Sandoval, F. and Magee, R. M. and Mageswaran, M. and Majorana, E. and Maksimovic, I. and Malvezzi, V. and Man, N. and Mandel, I. and Mandic, V. and Mangano, V. and Mansell, G. L. and Manske, M. and Mantovani, M. and Marchesoni, F. and Marion, F. and Márka, S. and Márka, Z. and Markosyan, A. S. and Maros, E. and Martelli, F. and Martellini, L. and Martin, I. W. and Martin, R. M. and Martynov, D. V. and Marx, J. N. and Mason, K. and Masserot, A. and Massinger, T. J. and Masso-Reid, M. and Matichard, F. and Matone, L. and Mavalvala, N. and Mazumder, N. and Mazzolo, G. and McCarthy, R. and McClelland, D. E. and McCormick, S. and McGuire, S. C. and McIntyre, G. and McIver, J. and McManus, D. J. and McWilliams, S. T. and Meacher, D. and Meadors, G. D. and Meidam, J. and Melatos, A. and Mendell, G. and Mendoza-Gandara, D. and Mercer, R. A. and Merilh, E. and Merzougui, M. and Meshkov, S. and Messenger, C. and Messick, C. and Meyers, P. M. and Mezzani, F. and Miao, H. and Michel, C. and Middleton, H. and Mikhailov, E. E. and Milano, L. and Miller, J. and Millhouse, M. and Minenkov, Y. and Ming, J. and Mirshekari, S. and Mishra, C. and Mitra, S. and Mitrofanov, V. P. and Mitselmakher, G. and Mittleman, R. and Moggi, A. and Mohan, M. and Mohapatra, S. R. P. and Montani, M. and Moore, B. C. and Moore, C. J. and Moraru, D. and Moreno, G. and Morriss, S. R. and Mossavi, K. and Mours, B. and Mow-Lowry, C. M. and Mueller, C. L. and Mueller, G. and Muir, A. W. and Mukherjee, Arunava and Mukherjee, D. and Mukherjee, S. and Mullavey, A. and Munch, J. and Murphy, D. J. and Murray, P. G. and Mytidis, A. and Nardecchia, I. and Naticchioni, L. and Nayak, R. K. and Necula, V. and Nedkova, K. and Nelemans, G. and Neri, M. and Neunzert, A. and Newton, G. and Nguyen, T. T. and Nielsen, A. B. and Nissanke, S. and Nitz, A. and Nocera, F. and Nolting, D. and Normandin, M. E. N. and Nuttall, L. K. and Oberling, J. and Ochsner, E. and O’Dell, J. and Oelker, E. and Ogin, G. H. and Oh, J. J. and Oh, S. H. and Ohme, F. and Oliver, M. and Oppermann, P. and Oram, R. J. and O’Reilly, B. and O’Shaughnessy, R. and Ott, C. D. and Ottaway, D. J. and Ottens, R. S. and Overmier, H. and Owen, B. J. and Pai, A. and Pai, S. A. and Palamos, J. R. and Palashov, O. and Palomba, C. and Pal-Singh, A. and Pan, H. and Pankow, C. and Pannarale, F. and Pant, B. C. and Paoletti, F. and Paoli, A. and Papa, M. A. and Paris, H. R. and Parker, W. and Pascucci, D. and Pasqualetti, A. and Passaquieti, R. and Passuello, D. and Patrick, Z. and Pearlstone, B. L. and Pedraza, M. and Pedurand, R. and Pekowsky, L. and Pele, A. and Penn, S. and Pereira, R. and Perreca, A. and Phelps, M. and Piccinni, O. and Pichot, M. and Piergiovanni, F. and Pierro, V. and Pillant, G. and Pinard, L. and Pinto, I. M. and Pitkin, M. and Poggiani, R. and Post, A. and Powell, J. and Prasad, J. and Predoi, V. and Premachandra, S. S. and Prestegard, T. and Price, L. R. and Prijatelj, M. and Principe, M. and Privitera, S. and Prodi, G. A. and Prokhorov, L. and Punturo, M. and Puppo, P. and Pürrer, M. and Qi, H. and Qin, J. and Quetschke, V. and Quintero, E. A. and Quitzow-James, R. and Raab, F. J. and Rabeling, D. S. and Radkins, H. and Raffai, P. and Raja, S. and Rakhmanov, M. and Rapagnani, P. and Raymond, V. and Razzano, M. and Re, V. and Read, J. and Reed, C. M. and Regimbau, T. and Rei, L. and Reid, S. and Reitze, D. H. and Rew, H. and Ricci, F. and Riles, K. and Robertson, N. A. and Robie, R. and Robinet, F. and Rocchi, A. and Rolland, L. and Rollins, J. G. and Roma, V. J. and Romano, J. D. and Romano, R. and Romanov, G. and Romie, J. H. and Rosińska, D. and Rowan, S. and Rüdiger, A. and Ruggi, P. and Ryan, K. and Sachdev, S. and Sadecki, T. and Sadeghian, L. and Saleem, M. and Salemi, F. and Samajdar, A. and Sammut, L. and Sanchez, E. J. and Sandberg, V. and Sandeen, B. and Sanders, J. R. and Sassolas, B. and Sathyaprakash, B. S. and Saulson, P. R. and Sauter, O. and Savage, R. L. and Sawadsky, A. and Schale, P. and Schilling, R. and Schmidt, J. and Schmidt, P. and Schnabel, R. and Schofield, R. M. S. and Schönbeck, A. and Schreiber, E. and Schuette, D. and Schutz, B. F. and Scott, J. and Scott, S. M. and Sellers, D. and Sentenac, D. and Sequino, V. and Sergeev, A. and Serna, G. and Setyawati, Y. and Sevigny, A. and Shaddock, D. A. and Shah, S. and Shahriar, M. S. and Shaltev, M. and Shao, Z. and Shapiro, B. and Shawhan, P. and Sheperd, A. and Shoemaker, D. H. and Shoemaker, D. M. and Siellez, K. and Siemens, X. and Sigg, D. and Silva, A. D. and Simakov, D. and Singer, A. and Singer, L. P. and Singh, A. and Singh, R. and Sintes, A. M. and Slagmolen, B. J. J. and Smith, J. R. and Smith, N. D. and Smith, R. J. E. and Son, E. J. and Sorazu, B. and Sorrentino, F. and Souradeep, T. and Srivastava, A. K. and Staley, A. and Steinke, M. and Steinlechner, J. and Steinlechner, S. and Steinmeyer, D. and Stephens, B. C. and Stone, R. and Strain, K. A. and Straniero, N. and Stratta, G. and Strauss, N. A. and Strigin, S. and Sturani, R. and Stuver, A. L. and Summerscales, T. Z. and Sun, L. and Sutton, P. J. and Swinkels, B. L. and Szczepanczyk, M. J. and Tacca, M. and Talukder, D. and Tanner, D. B. and Tápai, M. and Tarabrin, S. P. and Taracchini, A. and Taylor, R. and Theeg, T. and Thirugnanasambandam, M. P. and Thomas, E. G. and Thomas, M. and Thomas, P. and Thorne, K. A. and Thorne, K. S. and Thrane, E. and Tiwari, S. and Tiwari, V. and Tokmakov, K. V. and Tomlinson, C. and Tonelli, M. and Torres, C. V. and Torrie, C. I. and Töyrä, D. and Travasso, F. and Traylor, G. and Trifirò, D. and Tringali, M. C. and Trozzo, L. and Tse, M. and Turconi, M. and Tuyenbayev, D. and Ugolini, D. and Unnikrishnan, C. S. and Urban, A. L. and Usman, S. A. and Vahlbruch, H. and Vajente, G. and Valdes, G. and van Bakel, N. and van Beuzekom, M. and van den Brand, J. F. J. and van den Broeck, C. and Vander-Hyde, D. C. and van der Schaaf, L. and van der Sluys, M. V. and van Heijningen, J. V. and van Veggel, A. A. and Vardaro, M. and Vass, S. and Vasúth, M. and Vaulin, R. and Vecchio, A. and Vedovato, G. and Veitch, J. and Veitch, P. J. and Venkateswara, K. and Verkindt, D. and Vetrano, F. and Viceré, A. and Vinciguerra, S. and Vine, D. J. and Vinet, J.-Y. and Vitale, S. and Vo, T. and Vocca, H. and Vorvick, C. and Vousden, W. D. and Vyatchanin, S. P. and Wade, A. R. and Wade, L. E. and Wade, M. and Walker, M. and Wallace, L. and Walsh, S. and Wang, G. and Wang, H. and Wang, M. and Wang, X. and Wang, Y. and Ward, R. L. and Warner, J. and Was, M. and Weaver, B. and Wei, L.-W. and Weinert, M. and Weinstein, A. J. and Weiss, R. and Welborn, T. and Wen, L. and Weßels, P. and Westphal, T. and Wette, K. and Whelan, J. T. and White, D. J. and Whiting, B. F. and Williams, R. D. and Williamson, A. R. and Willis, J. L. and Willke, B. and Wimmer, M. H. and Winkler, W. and Wipf, C. C. and Wittel, H. and Woan, G. and Worden, J. and Wright, J. L. and Wu, G. and Yablon, J. and Yam, W. and Yamamoto, H. and Yancey, C. C. and Yap, M. J. and Yu, H. and Yvert, M. and Zadrożny, A. and Zangrando, L. and Zanolin, M. and Zendri, J.-P. and Zevin, M. and Zhang, F. and Zhang, L. and Zhang, M. and Zhang, Y. and Zhao, C. and Zhou, M. and Zhou, Z. and Zhu, X. J. and Zucker, M. E. and Zuraw, S. E. and Zweizig, J.},
	year = {2016},
	pmid = {28179853},
	pmcid = {PMC5256041},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DY8M9MPA/Abbott et al. - 2016 - Prospects for Observing and Localizing Gravitation.pdf:application/pdf}
}

@article{martinez-aleman_understanding_2017,
	title = {Understanding the {Entanglement}: {Neutrophil} {Extracellular} {Traps} ({NETs}) in {Cystic} {Fibrosis}},
	volume = {7},
	issn = {2235-2988},
	shorttitle = {Understanding the {Entanglement}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5382324/},
	doi = {10.3389/fcimb.2017.00104},
	abstract = {Cystic fibrosis (CF) is an autosomal recessive disorder caused by mutations in the gene that codes for the CF trans-membrane conductance regulator. These mutations result in abnormal secretions viscous airways of the lungs, favoring pulmonary infection and inflammation in the middle of neutrophil recruitment. Recently it was described that neutrophils can contribute with disease pathology by extruding large amounts of nuclear material through a mechanism of cell death known as Neutrophil Extracellular Traps (NETs) into the airways of patients with CF. Additionally, NETs production can contribute to airway colonization with bacteria, since they are the microorganisms most frequently found in these patients. In this review, we will discuss the implication of individual or mixed bacterial infections that most often colonize the lung of patients with CF, and the NETs role on the disease.},
	urldate = {2018-03-10},
	journal = {Frontiers in Cellular and Infection Microbiology},
	author = {Martínez-Alemán, Saira R. and Campos-García, Lizbeth and Palma-Nicolas, José P. and Hernández-Bello, Romel and González, Gloria M. and Sánchez-González, Alejandro},
	month = apr,
	year = {2017},
	pmid = {28428948},
	pmcid = {PMC5382324},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/H5WM82JL/Martínez-Alemán et al. - 2017 - Understanding the Entanglement Neutrophil Extrace.pdf:application/pdf}
}

@article{murphy_reassessing_2017,
	title = {Reassessing rainfall in the {Luquillo} {Mountains}, {Puerto} {Rico}: {Local} and global ecohydrological implications},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Reassessing rainfall in the {Luquillo} {Mountains}, {Puerto} {Rico}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5501619/},
	doi = {10.1371/journal.pone.0180987},
	abstract = {Mountains receive a greater proportion of precipitation than other environments, and thus make a disproportionate contribution to the world’s water supply. The Luquillo Mountains receive the highest rainfall on the island of Puerto Rico and serve as a critical source of water to surrounding communities. The area’s role as a long-term research site has generated numerous hydrological, ecological, and geological investigations that have been included in regional and global overviews that compare tropical forests to other ecosystems. Most of the forest- and watershed-wide estimates of precipitation (and evapotranspiration, as inferred by a water balance) have assumed that precipitation increases consistently with elevation. However, in this new analysis of all known current and historical rain gages in the region, we find that similar to other mountainous islands in the trade wind latitudes, leeward (western) watersheds in the Luquillo Mountains receive lower mean annual precipitation than windward (eastern) watersheds. Previous studies in the Luquillo Mountains have therefore overestimated precipitation in leeward watersheds by up to 40\%. The Icacos watershed, however, despite being located at elevations 200–400 m below the tallest peaks and to the lee of the first major orographic barrier, receives some of the highest precipitation. Such lee-side enhancement has been observed in other island mountains of similar height and width, and may be caused by several mechanisms. Thus, the long-reported discrepancy of unrealistically low rates of evapotranspiration in the Icacos watershed is likely caused by previous underestimation of precipitation, perhaps by as much as 20\%. Rainfall/runoff ratios in several previous studies suggested either runoff excess or runoff deficiency in Luquillo watersheds, but this analysis suggests that in fact they are similar to other tropical watersheds. Because the Luquillo Mountains often serve as a wet tropical archetype in global assessments of basic ecohydrological processes, these revised estimates are relevant to regional and global assessments of runoff efficiency, hydrologic effects of reforestation, geomorphic processes, and climate change.},
	number = {7},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Murphy, Sheila F. and Stallard, Robert F. and Scholl, Martha A. and González, Grizelle and Torres-Sánchez, Angel J.},
	month = jul,
	year = {2017},
	pmid = {28686734},
	pmcid = {PMC5501619},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U7MK3594/Murphy et al. - 2017 - Reassessing rainfall in the Luquillo Mountains, Pu.pdf:application/pdf}
}

@article{weissenbacher_extracting_2017,
	title = {Extracting geographic locations from the literature for virus phylogeography using supervised and distant supervision methods},
	volume = {2017},
	issn = {2153-4063},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543364/},
	abstract = {The field of phylogeography allows researchers to model the spread and evolution of viral genetic sequences. Phylogeography plays a major role in infectious disease surveillance, viral epidemiology and vaccine design. When conducting viral phylogeographic studies, researchers require the location of the infected host of the virus, which is often present in public databases such as GenBank. However, the geographic metadata in most GenBank records is not precise enough for many phylogeographic studies; therefore, researchers often need to search the articles linked to the records for more information, which can be a tedious process. Here, we describe two approaches for automatically detecting geographic location mentions in articles pertaining to virus-related GenBank records: a supervised sequence labeling approach with innovative features and a distant-supervision approach with novel noise- reduction methods. Evaluated on a manually annotated gold standard, our supervised sequence labeling and distant supervision approaches attained F-scores of 0.81 and 0.66, respectively.},
	urldate = {2018-03-10},
	journal = {AMIA Summits on Translational Science Proceedings},
	author = {Weissenbacher, Davy and Sarker, Abeed and Tahsin, Tasnia and Scotch, Matthew and Gonzalez, Graciela},
	month = jul,
	year = {2017},
	pmid = {28815119},
	pmcid = {PMC5543364},
	keywords = {female first or senior},
	pages = {114--122},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/9IEHKMI3/Weissenbacher et al. - 2017 - Extracting geographic locations from the literatur.pdf:application/pdf}
}

@article{rak_argo:_2012,
	title = {Argo: an integrative, interactive, text mining-based workbench supporting curation},
	volume = {2012},
	issn = {1758-0463},
	shorttitle = {Argo},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3308166/},
	doi = {10.1093/database/bas010},
	abstract = {Curation of biomedical literature is often supported by the automatic analysis of textual content that generally involves a sequence of individual processing components. Text mining (TM) has been used to enhance the process of manual biocuration, but has been focused on specific databases and tasks rather than an environment integrating TM tools into the curation pipeline, catering for a variety of tasks, types of information and applications. Processing components usually come from different sources and often lack interoperability. The well established Unstructured Information Management Architecture is a framework that addresses interoperability by defining common data structures and interfaces. However, most of the efforts are targeted towards software developers and are not suitable for curators, or are otherwise inconvenient to use on a higher level of abstraction. To overcome these issues we introduce Argo, an interoperable, integrative, interactive and collaborative system for text analysis with a convenient graphic user interface to ease the development of processing workflows and boost productivity in labour-intensive manual curation. Robust, scalable text analytics follow a modular approach, adopting component modules for distinct levels of text analysis. The user interface is available entirely through a web browser that saves the user from going through often complicated and platform-dependent installation procedures. Argo comes with a predefined set of processing components commonly used in text analysis, while giving the users the ability to deposit their own components. The system accommodates various areas and levels of user expertise, from TM and computational linguistics to ontology-based curation. One of the key functionalities of Argo is its ability to seamlessly incorporate user-interactive components, such as manual annotation editors, into otherwise completely automatic pipelines. As a use case, we demonstrate the functionality of an in-built manual annotation editor that is well suited for in-text corpus annotation tasks., Database URL:
http://www.nactem.ac.uk/Argo},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Rak, Rafal and Rowley, Andrew and Black, William and Ananiadou, Sophia},
	month = feb,
	year = {2012},
	pmid = {22434844},
	pmcid = {PMC3308166},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DPXRCZTZ/Rak et al. - 2012 - Argo an integrative, interactive, text mining-bas.pdf:application/pdf}
}

@article{pyysalo_event_2012,
	title = {Event extraction across multiple levels of biological organization},
	volume = {28},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3436834/},
	doi = {10.1093/bioinformatics/bts407},
	abstract = {Motivation: Event extraction using expressive structured representations has been a significant focus of recent efforts in biomedical information extraction. However, event extraction resources and methods have so far focused almost exclusively on molecular-level entities and processes, limiting their applicability., Results: We extend the event extraction approach to biomedical information extraction to encompass all levels of biological organization from the molecular to the whole organism. We present the ontological foundations, target types and guidelines for entity and event annotation and introduce the new multi-level event extraction (MLEE) corpus, manually annotated using a structured representation for event extraction. We further adapt and evaluate named entity and event extraction methods for the new task, demonstrating that both can be achieved with performance broadly comparable with that for established molecular entity and event extraction tasks., Availability: The resources and methods introduced in this study are available from http://nactem.ac.uk/MLEE/., Contact:
pyysalos@cs.man.ac.uk, Supplementary information:
Supplementary data are available at Bioinformatics online.},
	number = {18},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Pyysalo, Sampo and Ohta, Tomoko and Miwa, Makoto and Cho, Han-Cheol and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = sep,
	year = {2012},
	pmid = {22962484},
	pmcid = {PMC3436834},
	pages = {i575--i581},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/H392RYRT/Pyysalo et al. - 2012 - Event extraction across multiple levels of biologi.pdf:application/pdf}
}

@article{nawaz_negated_2013,
	title = {Negated bio-events: analysis and identification},
	volume = {14},
	issn = {1471-2105},
	shorttitle = {Negated bio-events},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3561152/},
	doi = {10.1186/1471-2105-14-14},
	abstract = {Background
Negation occurs frequently in scientific literature, especially in biomedical literature. It has previously been reported that around 13\% of sentences found in biomedical research articles contain negation. Historically, the main motivation for identifying negated events has been to ensure their exclusion from lists of extracted interactions. However, recently, there has been a growing interest in negative results, which has resulted in negation detection being identified as a key challenge in biomedical relation extraction. In this article, we focus on the problem of identifying negated bio-events, given gold standard event annotations.

Results
We have conducted a detailed analysis of three open access bio-event corpora containing negation information (i.e., GENIA Event, BioInfer and BioNLP’09 ST), and have identified the main types of negated bio-events. We have analysed the key aspects of a machine learning solution to the problem of detecting negated events, including selection of negation cues, feature engineering and the choice of learning algorithm. Combining the best solutions for each aspect of the problem, we propose a novel framework for the identification of negated bio-events. We have evaluated our system on each of the three open access corpora mentioned above. The performance of the system significantly surpasses the best results previously reported on the BioNLP’09 ST corpus, and achieves even better results on the GENIA Event and BioInfer corpora, both of which contain more varied and complex events.

Conclusions
Recently, in the field of biomedical text mining, the development and enhancement of event-based systems has received significant interest. The ability to identify negated events is a key performance element for these systems. We have conducted the first detailed study on the analysis and identification of negated bio-events. Our proposed framework can be integrated with state-of-the-art event extraction systems. The resulting systems will be able to extract bio-events with attached polarities from textual documents, which can serve as the foundation for more elaborate systems that are able to detect mutually contradicting bio-events.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Nawaz, Raheel and Thompson, Paul and Ananiadou, Sophia},
	month = jan,
	year = {2013},
	pmid = {23323936},
	pmcid = {PMC3561152},
	pages = {14},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PVE86UYG/Nawaz et al. - 2013 - Negated bio-events analysis and identification.pdf:application/pdf}
}

@article{restificar_method_2013,
	title = {A method for discovering and inferring appropriate eligibility criteria in clinical trial protocols without labeled data},
	volume = {13},
	issn = {1472-6947},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3618207/},
	doi = {10.1186/1472-6947-13-S1-S6},
	abstract = {Background
We consider the user task of designing clinical trial protocols and propose a method that discovers and outputs the most appropriate eligibility criteria from a potentially huge set of candidates. Each document d in our collection D is a clinical trial protocol which itself contains a set of eligibility criteria. Given a small set of sample documentsD′,{\textbar}D′{\textbar}≪{\textbar}D{\textbar}, a user has initially identified as relevant e.g., via a user query interface, our scoring method automatically suggests eligibility criteria from D, D ⊃ D', by ranking them according to how appropriate they are to the clinical trial protocol currently being designed. The appropriateness is measured by the degree to which they are consistent with the user-supplied sample documents D'.

Method
We propose a novel three-step method called LDALR which views documents as a mixture of latent topics. First, we infer the latent topics in the sample documents using Latent Dirichlet Allocation (LDA). Next, we use logistic regression models to compute the probability that a given candidate criterion belongs to a particular topic. Lastly, we score each criterion by computing its expected value, the probability-weighted sum of the topic proportions inferred from the set of sample documents. Intuitively, the greater the probability that a candidate criterion belongs to the topics that are dominant in the samples, the higher its expected value or score.

Results
Our experiments have shown that LDALR is 8 and 9 times better (resp., for inclusion and exclusion criteria) than randomly choosing from a set of candidates obtained from relevant documents. In user simulation experiments using LDALR, we were able to automatically construct eligibility criteria that are on the average 75\% and 70\% (resp., for inclusion and exclusion criteria) similar to the correct eligibility criteria.

Conclusions
We have proposed LDALR, a practical method for discovering and inferring appropriate eligibility criteria in clinical trial protocols without labeled data. Results from our experiments suggest that LDALR models can be used to effectively find appropriate eligibility criteria from a large repository of clinical trial protocols.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Restificar, Angelo and Korkontzelos, Ioannis and Ananiadou, Sophia},
	month = apr,
	year = {2013},
	pmid = {23566239},
	pmcid = {PMC3618207},
	pages = {S6},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/UA39MYFU/Restificar et al. - 2013 - A method for discovering and inferring appropriate.pdf:application/pdf}
}

@article{van_landeghem_large-scale_2013,
	title = {Large-{Scale} {Event} {Extraction} from {Literature} with {Multi}-{Level} {Gene} {Normalization}},
	volume = {8},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3629104/},
	doi = {10.1371/journal.pone.0055814},
	abstract = {Text mining for the life sciences aims to aid database curation, knowledge summarization and information retrieval through the automated processing of biomedical texts. To provide comprehensive coverage and enable full integration with existing biomolecular database records, it is crucial that text mining tools scale up to millions of articles and that their analyses can be unambiguously linked to information recorded in resources such as UniProt, KEGG, BioGRID and NCBI databases. In this study, we investigate how fully automated text mining of complex biomolecular events can be augmented with a normalization strategy that identifies biological concepts in text, mapping them to identifiers at varying levels of granularity, ranging from canonicalized symbols to unique gene and proteins and broad gene families. To this end, we have combined two state-of-the-art text mining components, previously evaluated on two community-wide challenges, and have extended and improved upon these methods by exploiting their complementary nature. Using these systems, we perform normalization and event extraction to create a large-scale resource that is publicly available, unique in semantic scope, and covers all 21.9 million PubMed abstracts and 460 thousand PubMed Central open access full-text articles. This dataset contains 40 million biomolecular events involving 76 million gene/protein mentions, linked to 122 thousand distinct genes from 5032 species across the full taxonomic tree. Detailed evaluations and analyses reveal promising results for application of this data in database and pathway curation efforts. The main software components used in this study are released under an open-source license. Further, the resulting dataset is freely accessible through a novel API, providing programmatic and customized access (http://www.evexdb.org/api/v001/). Finally, to allow for large-scale bioinformatic analyses, the entire resource is available for bulk download from http://evexdb.org/download/, under the Creative Commons – Attribution – Share Alike (CC BY-SA) license.},
	number = {4},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Van Landeghem, Sofie and Björne, Jari and Wei, Chih-Hsuan and Hakala, Kai and Pyysalo, Sampo and Ananiadou, Sophia and Kao, Hung-Yu and Lu, Zhiyong and Salakoski, Tapio and Van de Peer, Yves and Ginter, Filip},
	month = apr,
	year = {2013},
	pmid = {23613707},
	pmcid = {PMC3629104},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/B6BUUVGN/Van Landeghem et al. - 2013 - Large-Scale Event Extraction from Literature with .pdf:application/pdf}
}

@article{kontonatsios_deploying_2013,
	title = {Deploying and sharing {U}-{Compare} workflows as web services},
	volume = {4},
	issn = {2041-1480},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3658995/},
	doi = {10.1186/2041-1480-4-7},
	abstract = {Background
U-Compare is a text mining platform that allows the construction, evaluation and comparison of text mining workflows. U-Compare contains a large library of components that are tuned to the biomedical domain. Users can rapidly develop biomedical text mining workflows by mixing and matching U-Compare’s components. Workflows developed using U-Compare can be exported and sent to other users who, in turn, can import and re-use them. However, the resulting workflows are standalone applications, i.e., software tools that run and are accessible only via a local machine, and that can only be run with the U-Compare platform.

Results
We address the above issues by extending U-Compare to convert standalone workflows into web services automatically, via a two-click process. The resulting web services can be registered on a central server and made publicly available. Alternatively, users can make web services available on their own servers, after installing the web application framework, which is part of the extension to U-Compare. We have performed a user-oriented evaluation of the proposed extension, by asking users who have tested the enhanced functionality of U-Compare to complete questionnaires that assess its functionality, reliability, usability, efficiency and maintainability. The results obtained reveal that the new functionality is well received by users.

Conclusions
The web services produced by U-Compare are built on top of open standards, i.e., REST and SOAP protocols, and therefore, they are decoupled from the underlying platform. Exported workflows can be integrated with any application that supports these open standards. We demonstrate how the newly extended U-Compare enhances the cross-platform interoperability of workflows, by seamlessly importing a number of text mining workflow web services exported from U-Compare into Taverna, i.e., a generic scientific workflow construction platform.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Semantics},
	author = {Kontonatsios, Georgios and Korkontzelos, Ioannis and Kolluru, BalaKrishna and Thompson, Paul and Ananiadou, Sophia},
	month = feb,
	year = {2013},
	pmid = {23419017},
	pmcid = {PMC3658995},
	pages = {7},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/4RFZ78LA/Kontonatsios et al. - 2013 - Deploying and sharing U-Compare workflows as web s.pdf:application/pdf}
}

@article{miwa_wide_2013,
	title = {Wide coverage biomedical event extraction using multiple partially overlapping corpora},
	volume = {14},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680179/},
	doi = {10.1186/1471-2105-14-175},
	abstract = {Background
Biomedical events are key to understanding physiological processes and disease, and wide coverage extraction is required for comprehensive automatic analysis of statements describing biomedical systems in the literature. In turn, the training and evaluation of extraction methods requires manually annotated corpora. However, as manual annotation is time-consuming and expensive, any single event-annotated corpus can only cover a limited number of semantic types. Although combined use of several such corpora could potentially allow an extraction system to achieve broad semantic coverage, there has been little research into learning from multiple corpora with partially overlapping semantic annotation scopes.

Results
We propose a method for learning from multiple corpora with partial semantic annotation overlap, and implement this method to improve our existing event extraction system, EventMine. An evaluation using seven event annotated corpora, including 65 event types in total, shows that learning from overlapping corpora can produce a single, corpus-independent, wide coverage extraction system that outperforms systems trained on single corpora and exceeds previously reported results on two established event extraction tasks from the BioNLP Shared Task 2011.

Conclusions
The proposed method allows the training of a wide-coverage, state-of-the-art event extraction system from multiple corpora with partial semantic annotation overlap. The resulting single model makes broad-coverage extraction straightforward in practice by removing the need to either select a subset of compatible corpora or semantic types, or to merge results from several models trained on different individual corpora. Multi-corpus learning also allows annotation efforts to focus on covering additional semantic types, rather than aiming for exhaustive coverage in any single annotation effort, or extending the coverage of semantic types annotated in existing corpora.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Miwa, Makoto and Pyysalo, Sampo and Ohta, Tomoko and Ananiadou, Sophia},
	month = jun,
	year = {2013},
	pmid = {23731785},
	pmcid = {PMC3680179},
	pages = {175},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BRJBT69G/Miwa et al. - 2013 - Wide coverage biomedical event extraction using mu.pdf:application/pdf}
}

@article{miwa_method_2013,
	title = {A method for integrating and ranking the evidence for biochemical pathways by mining reactions from text},
	volume = {29},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3694679/},
	doi = {10.1093/bioinformatics/btt227},
	abstract = {Motivation: To create, verify and maintain pathway models, curators must discover and assess knowledge distributed over the vast body of biological literature. Methods supporting these tasks must understand both the pathway model representations and the natural language in the literature. These methods should identify and order documents by relevance to any given pathway reaction. No existing system has addressed all aspects of this challenge., Method: We present novel methods for associating pathway model reactions with relevant publications. Our approach extracts the reactions directly from the models and then turns them into queries for three text mining-based MEDLINE literature search systems. These queries are executed, and the resulting documents are combined and ranked according to their relevance to the reactions of interest. We manually annotate document-reaction pairs with the relevance of the document to the reaction and use this annotation to study several ranking methods, using various heuristic and machine-learning approaches., Results: Our evaluation shows that the annotated document-reaction pairs can be used to create a rule-based document ranking system, and that machine learning can be used to rank documents by their relevance to pathway reactions. We find that a Support Vector Machine-based system outperforms several baselines and matches the performance of the rule-based system. The success of the query extraction and ranking methods are used to update our existing pathway search system, PathText., Availability: An online demonstration of PathText 2 and the annotated corpus are available for research purposes at http://www.nactem.ac.uk/pathtext2/., Contact:
makoto.miwa@manchester.ac.uk, Supplementary information:
Supplementary data are available at Bioinformatics online.},
	number = {13},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Miwa, Makoto and Ohta, Tomoko and Rak, Rafal and Rowley, Andrew and Kell, Douglas B. and Pyysalo, Sampo and Ananiadou, Sophia},
	month = jul,
	year = {2013},
	pmid = {23813008},
	pmcid = {PMC3694679},
	pages = {i44--i52},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JCWGT7LE/Miwa et al. - 2013 - A method for integrating and ranking the evidence .pdf:application/pdf}
}

@article{pyysalo_anatomical_2014,
	title = {Anatomical entity mention recognition at literature scale},
	volume = {30},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3957068/},
	doi = {10.1093/bioinformatics/btt580},
	abstract = {Motivation: Anatomical entities ranging from subcellular structures to organ systems are central to biomedical science, and mentions of these entities are essential to understanding the scientific literature. Despite extensive efforts to automatically analyze various aspects of biomedical text, there have been only few studies focusing on anatomical entities, and no dedicated methods for learning to automatically recognize anatomical entity mentions in free-form text have been introduced., Results: We present AnatomyTagger, a machine learning-based system for anatomical entity mention recognition. The system incorporates a broad array of approaches proposed to benefit tagging, including the use of Unified Medical Language System (UMLS)- and Open Biomedical Ontologies (OBO)-based lexical resources, word representations induced from unlabeled text, statistical truecasing and non-local features. We train and evaluate the system on a newly introduced corpus that substantially extends on previously available resources, and apply the resulting tagger to automatically annotate the entire open access scientific domain literature. The resulting analyses have been applied to extend services provided by the Europe PubMed Central literature database., Availability and implementation: All tools and resources introduced in this work are available from http://nactem.ac.uk/anatomytagger., Contact:
sophia.ananiadou@manchester.ac.uk, Supplementary Information:
Supplementary data are available at Bioinformatics online.},
	number = {6},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Pyysalo, Sampo and Ananiadou, Sophia},
	month = mar,
	year = {2014},
	pmid = {24162468},
	pmcid = {PMC3957068},
	keywords = {female first or senior, NER},
	pages = {868--875},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/NWQNXKHN/Pyysalo and Ananiadou - 2014 - Anatomical entity mention recognition at literatur.pdf:application/pdf}
}

@article{omara-eves_using_2015,
	title = {Using text mining for study identification in systematic reviews: a systematic review of current approaches},
	volume = {4},
	issn = {2046-4053},
	shorttitle = {Using text mining for study identification in systematic reviews},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4320539/},
	doi = {10.1186/2046-4053-4-5},
	abstract = {Background
The large and growing number of published studies, and their increasing rate of publication, makes the task of identifying relevant studies in an unbiased way for inclusion in systematic reviews both complex and time consuming. Text mining has been offered as a potential solution: through automating some of the screening process, reviewer time can be saved. The evidence base around the use of text mining for screening has not yet been pulled together systematically; this systematic review fills that research gap. Focusing mainly on non-technical issues, the review aims to increase awareness of the potential of these technologies and promote further collaborative research between the computer science and systematic review communities.

Methods
Five research questions led our review: what is the state of the evidence base; how has workload reduction been evaluated; what are the purposes of semi-automation and how effective are they; how have key contextual problems of applying text mining to the systematic review field been addressed; and what challenges to implementation have emerged?, We answered these questions using standard systematic review methods: systematic and exhaustive searching, quality-assured data extraction and a narrative synthesis to synthesise findings.

Results
The evidence base is active and diverse; there is almost no replication between studies or collaboration between research teams and, whilst it is difficult to establish any overall conclusions about best approaches, it is clear that efficiencies and reductions in workload are potentially achievable., On the whole, most suggested that a saving in workload of between 30\% and 70\% might be possible, though sometimes the saving in workload is accompanied by the loss of 5\% of relevant studies (i.e. a 95\% recall).

Conclusions
Using text mining to prioritise the order in which items are screened should be considered safe and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines.

Electronic supplementary material
The online version of this article (doi:10.1186/2046-4053-4-5) contains supplementary material, which is available to authorized users.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Systematic Reviews},
	author = {O’Mara-Eves, Alison and Thomas, James and McNaught, John and Miwa, Makoto and Ananiadou, Sophia},
	month = jan,
	year = {2015},
	pmid = {25588314},
	pmcid = {PMC4320539},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/862I2DEC/O’Mara-Eves et al. - 2015 - Using text mining for study identification in syst.pdf:application/pdf}
}

@article{fu_supporting_2015,
	title = {Supporting the annotation of chronic obstructive pulmonary disease ({COPD}) phenotypes with text mining workflows},
	volume = {6},
	issn = {2041-1480},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4364458/},
	doi = {10.1186/s13326-015-0004-6},
	abstract = {Background
Chronic obstructive pulmonary disease (COPD) is a life-threatening lung disorder whose recent prevalence has led to an increasing burden on public healthcare. Phenotypic information in electronic clinical records is essential in providing suitable personalised treatment to patients with COPD. However, as phenotypes are often “hidden” within free text in clinical records, clinicians could benefit from text mining systems that facilitate their prompt recognition. This paper reports on a semi-automatic methodology for producing a corpus that can ultimately support the development of text mining tools that, in turn, will expedite the process of identifying groups of COPD patients.

Methods
A corpus of 30 full-text papers was formed based on selection criteria informed by the expertise of COPD specialists. We developed an annotation scheme that is aimed at producing fine-grained, expressive and computable COPD annotations without burdening our curators with a highly complicated task. This was implemented in the Argo platform by means of a semi-automatic annotation workflow that integrates several text mining tools, including a graphical user interface for marking up documents.

Results
When evaluated using gold standard (i.e., manually validated) annotations, the semi-automatic workflow was shown to obtain a micro-averaged F-score of 45.70\% (with relaxed matching). Utilising the gold standard data to train new concept recognisers, we demonstrated that our corpus, although still a work in progress, can foster the development of significantly better performing COPD phenotype extractors.

Conclusions
We describe in this work the means by which we aim to eventually support the process of COPD phenotype curation, i.e., by the application of various text mining tools integrated into an annotation workflow. Although the corpus being described is still under development, our results thus far are encouraging and show great potential in stimulating the development of further automatic COPD phenotype extractors.

Electronic supplementary material
The online version of this article (doi:10.1186/s13326-015-0004-6) contains supplementary material, which is available to authorized users.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Semantics},
	author = {Fu, Xiao and Batista-Navarro, Riza and Rak, Rafal and Ananiadou, Sophia},
	month = mar,
	year = {2015},
	pmid = {25789153},
	pmcid = {PMC4364458},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SFK964NJ/Fu et al. - 2015 - Supporting the annotation of chronic obstructive p.pdf:application/pdf}
}

@article{bollegala_cross-lingual_2015,
	title = {A {Cross}-{Lingual} {Similarity} {Measure} for {Detecting} {Biomedical} {Term} {Translations}},
	volume = {10},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4452086/},
	doi = {10.1371/journal.pone.0126196},
	abstract = {Bilingual dictionaries for technical terms such as biomedical terms are an important resource for machine translation systems as well as for humans who would like to understand a concept described in a foreign language. Often a biomedical term is first proposed in English and later it is manually translated to other languages. Despite the fact that there are large monolingual lexicons of biomedical terms, only a fraction of those term lexicons are translated to other languages. Manually compiling large-scale bilingual dictionaries for technical domains is a challenging task because it is difficult to find a sufficiently large number of bilingual experts. We propose a cross-lingual similarity measure for detecting most similar translation candidates for a biomedical term specified in one language (source) from another language (target). Specifically, a biomedical term in a language is represented using two types of features: (a) intrinsic features that consist of character n-grams extracted from the term under consideration, and (b) extrinsic features that consist of unigrams and bigrams extracted from the contextual windows surrounding the term under consideration. We propose a cross-lingual similarity measure using each of those feature types. First, to reduce the dimensionality of the feature space in each language, we propose prototype vector projection (PVP)—a non-negative lower-dimensional vector projection method. Second, we propose a method to learn a mapping between the feature spaces in the source and target language using partial least squares regression (PLSR). The proposed method requires only a small number of training instances to learn a cross-lingual similarity measure. The proposed PVP method outperforms popular dimensionality reduction methods such as the singular value decomposition (SVD) and non-negative matrix factorization (NMF) in a nearest neighbor prediction task. Moreover, our experimental results covering several language pairs such as English–French, English–Spanish, English–Greek, and English–Japanese show that the proposed method outperforms several other feature projection methods in biomedical term translation prediction tasks.},
	number = {6},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Bollegala, Danushka and Kontonatsios, Georgios and Ananiadou, Sophia},
	month = jun,
	year = {2015},
	pmid = {26030738},
	pmcid = {PMC4452086},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RI9EMUCV/Bollegala et al. - 2015 - A Cross-Lingual Similarity Measure for Detecting B.pdf:application/pdf}
}

@article{alnazzawi_using_2015,
	title = {Using text mining techniques to extract phenotypic information from the {PhenoCHF} corpus},
	volume = {15},
	issn = {1472-6947},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4474585/},
	doi = {10.1186/1472-6947-15-S2-S3},
	abstract = {Background
Phenotypic information locked away in unstructured narrative text presents significant barriers to information accessibility, both for clinical practitioners and for computerised applications used for clinical research purposes. Text mining (TM) techniques have previously been applied successfully to extract different types of information from text in the biomedical domain. They have the potential to be extended to allow the extraction of information relating to phenotypes from free text.

Methods
To stimulate the development of TM systems that are able to extract phenotypic information from text, we have created a new corpus (PhenoCHF) that is annotated by domain experts with several types of phenotypic information relating to congestive heart failure. To ensure that systems developed using the corpus are robust to multiple text types, it integrates text from heterogeneous sources, i.e., electronic health records (EHRs) and scientific articles from the literature. We have developed several different phenotype extraction methods to demonstrate the utility of the corpus, and tested these methods on a further corpus, i.e., ShARe/CLEF 2013.

Results
Evaluation of our automated methods showed that PhenoCHF can facilitate the training of reliable phenotype extraction systems, which are robust to variations in text type. These results have been reinforced by evaluating our trained systems on the ShARe/CLEF corpus, which contains clinical records of various types. Like other studies within the biomedical domain, we found that solutions based on conditional random fields produced the best results, when coupled with a rich feature set.

Conclusions
PhenoCHF is the first annotated corpus aimed at encoding detailed phenotypic information. The unique heterogeneous composition of the corpus has been shown to be advantageous in the training of systems that can accurately extract phenotypic information from a range of different text types. Although the scope of our annotation is currently limited to a single disease, the promising results achieved can stimulate further work into the extraction of phenotypic information for other diseases. The PhenoCHF annotation guidelines and annotations are publicly available at https://code.google.com/p/phenochf-corpus.},
	number = {Suppl 2},
	urldate = {2018-03-10},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Alnazzawi, Noha and Thompson, Paul and Batista-Navarro, Riza and Ananiadou, Sophia},
	month = jun,
	year = {2015},
	pmid = {26099853},
	pmcid = {PMC4474585},
	pages = {S3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/Y5LFHHJP/Alnazzawi et al. - 2015 - Using text mining techniques to extract phenotypic.pdf:application/pdf}
}

@article{thompson_text_2016,
	title = {Text {Mining} the {History} of {Medicine}},
	volume = {11},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4703377/},
	doi = {10.1371/journal.pone.0144717},
	abstract = {Historical text archives constitute a rich and diverse source of information, which is becoming increasingly readily accessible, due to large-scale digitisation efforts. However, it can be difficult for researchers to explore and search such large volumes of data in an efficient manner. Text mining (TM) methods can help, through their ability to recognise various types of semantic information automatically, e.g., instances of concepts (places, medical conditions, drugs, etc.), synonyms/variant forms of concepts, and relationships holding between concepts (which drugs are used to treat which medical conditions, etc.). TM analysis allows search systems to incorporate functionality such as automatic suggestions of synonyms of user-entered query terms, exploration of different concepts mentioned within search results or isolation of documents in which concepts are related in specific ways. However, applying TM methods to historical text can be challenging, according to differences and evolutions in vocabulary, terminology, language structure and style, compared to more modern text. In this article, we present our efforts to overcome the various challenges faced in the semantic analysis of published historical medical text dating back to the mid 19th century. Firstly, we used evidence from diverse historical medical documents from different periods to develop new resources that provide accounts of the multiple, evolving ways in which concepts, their variants and relationships amongst them may be expressed. These resources were employed to support the development of a modular processing pipeline of TM tools for the robust detection of semantic information in historical medical documents with varying characteristics. We applied the pipeline to two large-scale medical document archives covering wide temporal ranges as the basis for the development of a publicly accessible semantically-oriented search system. The novel resources are available for research purposes, while the processing pipeline and its modules may be used and configured within the Argo TM platform.},
	number = {1},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Thompson, Paul and Batista-Navarro, Riza Theresa and Kontonatsios, Georgios and Carter, Jacob and Toon, Elizabeth and McNaught, John and Timmermann, Carsten and Worboys, Michael and Ananiadou, Sophia},
	month = jan,
	year = {2016},
	pmid = {26734936},
	pmcid = {PMC4703377},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/IRSKQ8VY/Thompson et al. - 2016 - Text Mining the History of Medicine.pdf:application/pdf}
}

@article{korkontzelos_analysis_2016-1,
	title = {Analysis of the effect of sentiment analysis on extracting adverse drug reactions from tweets and forum posts},
	volume = {62},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4981644/},
	doi = {10.1016/j.jbi.2016.06.007},
	abstract = {•
              Sentiment analysis features are useful in spotting adverse drug reactions in text.
            
            
              •
              Sentiment analysis features help to distinguish adverse drug reactions and indications.
            
            
              •
              Posts about adverse drug reactions are associated with negative feelings.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Korkontzelos, Ioannis and Nikfarjam, Azadeh and Shardlow, Matthew and Sarker, Abeed and Ananiadou, Sophia and Gonzalez, Graciela H.},
	month = aug,
	year = {2016},
	pmid = {27363901},
	pmcid = {PMC4981644},
	keywords = {female first or senior},
	pages = {148--158}
}

@article{wang_overview_2016-1,
	title = {Overview of the interactive task in {BioCreative} {V}},
	volume = {2016},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5009325/},
	doi = {10.1093/database/baw119},
	abstract = {Fully automated text mining (TM) systems promote efficient literature searching, retrieval, and review but are not sufficient to produce ready-to-consume curated documents. These systems are not meant to replace biocurators, but instead to assist them in one or more literature curation steps. To do so, the user interface is an important aspect that needs to be considered for tool adoption. The BioCreative Interactive task (IAT) is a track designed for exploring user-system interactions, promoting development of useful TM tools, and providing a communication channel between the biocuration and the TM communities. In BioCreative V, the IAT track followed a format similar to previous interactive tracks, where the utility and usability of TM tools, as well as the generation of use cases, have been the focal points. The proposed curation tasks are user-centric and formally evaluated by biocurators. In BioCreative V IAT, seven TM systems and 43 biocurators participated. Two levels of user participation were offered to broaden curator involvement and obtain more feedback on usability aspects. The full level participation involved training on the system, curation of a set of documents with and without TM assistance, tracking of time-on-task, and completion of a user survey. The partial level participation was designed to focus on usability aspects of the interface and not the performance per se. In this case, biocurators navigated the system by performing pre-designed tasks and then were asked whether they were able to achieve the task and the level of difficulty in completing the task. In this manuscript, we describe the development of the interactive task, from planning to execution and discuss major findings for the systems tested., Database URL:
http://www.biocreative.org},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Wang, Qinghua and S. Abdul, Shabbir and Almeida, Lara and Ananiadou, Sophia and Balderas-Martínez, Yalbi I. and Batista-Navarro, Riza and Campos, David and Chilton, Lucy and Chou, Hui-Jou and Contreras, Gabriela and Cooper, Laurel and Dai, Hong-Jie and Ferrell, Barbra and Fluck, Juliane and Gama-Castro, Socorro and George, Nancy and Gkoutos, Georgios and Irin, Afroza K. and Jensen, Lars J. and Jimenez, Silvia and Jue, Toni R. and Keseler, Ingrid and Madan, Sumit and Matos, Sérgio and McQuilton, Peter and Milacic, Marija and Mort, Matthew and Natarajan, Jeyakumar and Pafilis, Evangelos and Pereira, Emiliano and Rao, Shruti and Rinaldi, Fabio and Rothfels, Karen and Salgado, David and Silva, Raquel M. and Singh, Onkar and Stefancsik, Raymund and Su, Chu-Hsien and Subramani, Suresh and Tadepally, Hamsa D. and Tsaprouni, Loukia and Vasilevsky, Nicole and Wang, Xiaodong and Chatr-Aryamontri, Andrew and Laulederkind, Stanley J. F. and Matis-Mitchell, Sherri and McEntyre, Johanna and Orchard, Sandra and Pundir, Sangya and Rodriguez-Esteban, Raul and Van Auken, Kimberly and Lu, Zhiyong and Schaeffer, Mary and Wu, Cathy H. and Hirschman, Lynette and Arighi, Cecilia N.},
	month = sep,
	year = {2016},
	pmid = {27589961},
	pmcid = {PMC5009325},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/XYD7STUW/Wang et al. - 2016 - Overview of the interactive task in BioCreative V.pdf:application/pdf}
}

@article{alnazzawi_mapping_2016,
	title = {Mapping {Phenotypic} {Information} in {Heterogeneous} {Textual} {Sources} to a {Domain}-{Specific} {Terminological} {Resource}},
	volume = {11},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5028053/},
	doi = {10.1371/journal.pone.0162287},
	abstract = {Biomedical literature articles and narrative content from Electronic Health Records (EHRs) both constitute rich sources of disease-phenotype information. Phenotype concepts may be mentioned in text in multiple ways, using phrases with a variety of structures. This variability stems partly from the different backgrounds of the authors, but also from the different writing styles typically used in each text type. Since EHR narrative reports and literature articles contain different but complementary types of valuable information, combining details from each text type can help to uncover new disease-phenotype associations. However, the alternative ways in which the same concept may be mentioned in each source constitutes a barrier to the automatic integration of information. Accordingly, identification of the unique concepts represented by phrases in text can help to bridge the gap between text types. We describe our development of a novel method, PhenoNorm, which integrates a number of different similarity measures to allow automatic linking of phenotype concept mentions to known concepts in the UMLS Metathesaurus, a biomedical terminological resource. PhenoNorm was developed using the PhenoCHF corpus—a collection of literature articles and narratives in EHRs, annotated for phenotypic information relating to congestive heart failure (CHF). We evaluate the performance of PhenoNorm in linking CHF-related phenotype mentions to Metathesaurus concepts, using a newly enriched version of PhenoCHF, in which each phenotype mention has an expert-verified link to a concept in the UMLS Metathesaurus. We show that PhenoNorm outperforms a number of alternative methods applied to the same task. Furthermore, we demonstrate PhenoNorm’s wider utility, by evaluating its ability to link mentions of various other types of medically-related information, occurring in texts covering wider subject areas, to concepts in different terminological resources. We show that PhenoNorm can maintain performance levels, and that its accuracy compares favourably to other methods applied to these tasks.},
	number = {9},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Alnazzawi, Noha and Thompson, Paul and Ananiadou, Sophia},
	month = sep,
	year = {2016},
	pmid = {27643689},
	pmcid = {PMC5028053},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BN8BTU37/Alnazzawi et al. - 2016 - Mapping Phenotypic Information in Heterogeneous Te.pdf:application/pdf}
}

@article{przybyla_text_2016,
	title = {Text mining resources for the life sciences},
	volume = {2016},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5199186/},
	doi = {10.1093/database/baw145},
	abstract = {Text mining is a powerful technology for quickly distilling key information from vast quantities of biomedical literature. However, to harness this power the researcher must be well versed in the availability, suitability, adaptability, interoperability and comparative accuracy of current text mining resources. In this survey, we give an overview of the text mining resources that exist in the life sciences to help researchers, especially those employed in biocuration, to engage with text mining in their own work. We categorize the various resources under three sections: Content Discovery looks at where and how to find biomedical publications for text mining; Knowledge Encoding describes the formats used to represent the different levels of information associated with content that enable text mining, including those formats used to carry such information between processes; Tools and Services gives an overview of workflow management systems that can be used to rapidly configure and compare domain- and task-specific processes, via access to a wide range of pre-built tools. We also provide links to relevant repositories in each section to enable the reader to find resources relevant to their own area of interest. Throughout this work we give a special focus to resources that are interoperable—those that have the crucial ability to share information, enabling smooth integration and reusability.},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Przybyła, Piotr and Shardlow, Matthew and Aubin, Sophie and Bossy, Robert and Eckart de Castilho, Richard and Piperidis, Stelios and McNaught, John and Ananiadou, Sophia},
	month = oct,
	year = {2016},
	pmid = {27888231},
	pmcid = {PMC5199186},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZVB7N8AC/Przybyła et al. - 2016 - Text mining resources for the life sciences.pdf:application/pdf}
}

@article{nguyen_constructing_2017,
	title = {Constructing a biodiversity terminological inventory},
	volume = {12},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5393592/},
	doi = {10.1371/journal.pone.0175277},
	abstract = {The increasing growth of literature in biodiversity presents challenges to users who need to discover pertinent information in an efficient and timely manner. In response, text mining techniques offer solutions by facilitating the automated discovery of knowledge from large textual data. An important step in text mining is the recognition of concepts via their linguistic realisation, i.e., terms. However, a given concept may be referred to in text using various synonyms or term variants, making search systems likely to overlook documents mentioning less known variants, which are albeit relevant to a query term. Domain-specific terminological resources, which include term variants, synonyms and related terms, are thus important in supporting semantic search over large textual archives. This article describes the use of text mining methods for the automatic construction of a large-scale biodiversity term inventory. The inventory consists of names of species, amongst which naming variations are prevalent. We apply a number of distributional semantic techniques on all of the titles in the Biodiversity Heritage Library, to compute semantic similarity between species names and support the automated construction of the resource. With the construction of our biodiversity term inventory, we demonstrate that distributional semantic models are able to identify semantically similar names that are not yet recorded in existing taxonomies. Such methods can thus be used to update existing taxonomies semi-automatically by deriving semantically related taxonomic names from a text corpus and allowing expert curators to validate them. We also evaluate our inventory as a means to improve search by facilitating automatic query expansion. Specifically, we developed a visual search interface that suggests semantically related species names, which are available in our inventory but not always in other repositories, to incorporate into the search query. An assessment of the interface by domain experts reveals that our query expansion based on related names is useful for increasing the number of relevant documents retrieved. Its exploitation can benefit both users and developers of search engines and text mining applications.},
	number = {4},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Nguyen, Nhung T. H. and Soto, Axel J. and Kontonatsios, Georgios and Batista-Navarro, Riza and Ananiadou, Sophia},
	month = apr,
	year = {2017},
	pmid = {28414821},
	pmcid = {PMC5393592},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KW6SMN2B/Nguyen et al. - 2017 - Constructing a biodiversity terminological invento.pdf:application/pdf}
}

@article{kontonatsios_semi-supervised_2017,
	title = {A semi-supervised approach using label propagation to support citation screening},
	volume = {72},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5726085/},
	doi = {10.1016/j.jbi.2017.06.018},
	abstract = {•
              Systematic reviews can benefit from automatically screening relevant citations.
            
            
              •
              We propose a new method that improves the performance by using similar citations.
            
            
              •
              We utilise unlabelled documents by propagating labels in close neighbourhood.
            
            
              •
              A space of spectral embeddings is used for better distance representation.
            
            
              •
              Results on clinical and biomedical domains show consistent improvements.
            
          
        , Citation screening, an integral process within systematic reviews that identifies citations relevant to the underlying research question, is a time-consuming and resource-intensive task. During the screening task, analysts manually assign a label to each citation, to designate whether a citation is eligible for inclusion in the review. Recently, several studies have explored the use of active learning in text classification to reduce the human workload involved in the screening task. However, existing approaches require a significant amount of manually labelled citations for the text classification to achieve a robust performance. In this paper, we propose a semi-supervised method that identifies relevant citations as early as possible in the screening process by exploiting the pairwise similarities between labelled and unlabelled citations to improve the classification performance without additional manual labelling effort. Our approach is based on the hypothesis that similar citations share the same label (e.g., if one citation should be included, then other similar citations should be included also). To calculate the similarity between labelled and unlabelled citations we investigate two different feature spaces, namely a bag-of-words and a spectral embedding based on the bag-of-words. The semi-supervised method propagates the classification codes of manually labelled citations to neighbouring unlabelled citations in the feature space. The automatically labelled citations are combined with the manually labelled citations to form an augmented training set. For evaluation purposes, we apply our method to reviews from clinical and public health. The results show that our semi-supervised method with label propagation achieves statistically significant improvements over two state-of-the-art active learning approaches across both clinical and public health reviews.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Kontonatsios, Georgios and Brockmeier, Austin J. and Przybyła, Piotr and McNaught, John and Mu, Tingting and Goulermas, John Y. and Ananiadou, Sophia},
	month = aug,
	year = {2017},
	pmid = {28648605},
	pmcid = {PMC5726085},
	pages = {67--76}
}

@article{ananiadou_proceedings_2006,
	title = {Proceedings of the {Second} {International} {Symposium} for {Semantic} {Mining} in {Biomedicine}},
	volume = {7},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1764445/},
	doi = {10.1186/1471-2105-7-S3-S1},
	number = {Suppl 3},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Ananiadou, Sophia and Fluck, Juliane},
	month = nov,
	year = {2006},
	pmid = {null},
	pmcid = {PMC1764445},
	keywords = {female first or senior},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U663ZT8B/Ananiadou and Fluck - 2006 - Proceedings of the Second International Symposium .pdf:application/pdf}
}

@article{tsuruoka_normalizing_2008,
	title = {Normalizing biomedical terms by minimizing ambiguity and variability},
	volume = {9},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2352870/},
	doi = {10.1186/1471-2105-9-S3-S2},
	abstract = {Background
One of the difficulties in mapping biomedical named entities, e.g. genes, proteins, chemicals and diseases, to their concept identifiers stems from the potential variability of the terms. Soft string matching is a possible solution to the problem, but its inherent heavy computational cost discourages its use when the dictionaries are large or when real time processing is required. A less computationally demanding approach is to normalize the terms by using heuristic rules, which enables us to look up a dictionary in a constant time regardless of its size. The development of good heuristic rules, however, requires extensive knowledge of the terminology in question and thus is the bottleneck of the normalization approach.

Results
We present a novel framework for discovering a list of normalization rules from a dictionary in a fully automated manner. The rules are discovered in such a way that they minimize the ambiguity and variability of the terms in the dictionary. We evaluated our algorithm using two large dictionaries: a human gene/protein name dictionary built from BioThesaurus and a disease name dictionary built from UMLS.

Conclusions
The experimental results showed that automatically discovered rules can perform comparably to carefully crafted heuristic rules in term mapping tasks, and the computational overhead of rule application is small enough that a very fast implementation is possible. This work will help improve the performance of term-concept mapping tasks in biomedical information extraction especially when good normalization heuristics for the target terminology are not fully known.},
	number = {Suppl 3},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Tsuruoka, Yoshimasa and McNaught, John and Ananiadou, Sophia},
	month = apr,
	year = {2008},
	pmid = {18426547},
	pmcid = {PMC2352870},
	pages = {S2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/KEKC9YGU/Tsuruoka et al. - 2008 - Normalizing biomedical terms by minimizing ambigui.pdf:application/pdf}
}

@article{sasaki_how_2008,
	title = {How to make the most of {NE} dictionaries in statistical {NER}},
	volume = {9},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2586754/},
	doi = {10.1186/1471-2105-9-S11-S5},
	abstract = {Background
When term ambiguity and variability are very high, dictionary-based Named Entity Recognition (NER) is not an ideal solution even though large-scale terminological resources are available. Many researches on statistical NER have tried to cope with these problems. However, it is not straightforward how to exploit existing and additional Named Entity (NE) dictionaries in statistical NER. Presumably, addition of NEs to an NE dictionary leads to better performance. However, in reality, the retraining of NER models is required to achieve this. We chose protein name recognition as a case study because it most suffers the problems related to heavy term variation and ambiguity.

Methods
We have established a novel way to improve the NER performance by adding NEs to an NE dictionary without retraining. In our approach, first, known NEs are identified in parallel with Part-of-Speech (POS) tagging based on a general word dictionary and an NE dictionary. Then, statistical NER is trained on the POS/PROTEIN tagger outputs with correct NE labels attached.

Results
We evaluated performance of our NER on the standard JNLPBA-2004 data set. The F-score on the test set has been improved from 73.14 to 73.78 after adding protein names appearing in the training data to the POS tagger dictionary without any model retraining. The performance further increased to 78.72 after enriching the tagging dictionary with test set protein names.

Conclusion
Our approach has demonstrated high performance in protein name recognition, which indicates how to make the most of known NEs in statistical NER.},
	number = {Suppl 11},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Sasaki, Yutaka and Tsuruoka, Yoshimasa and McNaught, John and Ananiadou, Sophia},
	month = nov,
	year = {2008},
	pmid = {19025691},
	pmcid = {PMC2586754},
	pages = {S5},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8WEBUWN4/Sasaki et al. - 2008 - How to make the most of NE dictionaries in statist.pdf:application/pdf}
}

@article{thompson_construction_2009,
	title = {Construction of an annotated corpus to support biomedical information extraction},
	volume = {10},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2774701/},
	doi = {10.1186/1471-2105-10-349},
	abstract = {Background
Information Extraction (IE) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. As events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. Corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of IE components and resources.

Results
We have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. For each event instance, all participants (arguments) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the Gene Regulation Ontology. To our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. Using the scheme, we have created the Gene Regulation Event Corpus (GREC), consisting of 240 MEDLINE abstracts, in which events relating to gene regulation and expression have been annotated by biologists. A novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66\% - 90\%.

Conclusion
The GREC is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. As such, it is specifically designed to support bio-specific tool and resource development. It has already been used to acquire semantic frames for inclusion within the BioLexicon (a lexical, terminological resource to aid biomedical text mining). Initial experiments have also shown that the corpus may viably be used to train IE components, such as semantic role labellers. The corpus and annotation guidelines are freely available for academic purposes.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Thompson, Paul and Iqbal, Syed A and McNaught, John and Ananiadou, Sophia},
	month = oct,
	year = {2009},
	pmid = {19852798},
	pmcid = {PMC2774701},
	pages = {349},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/GCRMTZDD/Thompson et al. - 2009 - Construction of an annotated corpus to support bio.pdf:application/pdf}
}

@article{okazaki_building_2010,
	title = {Building a high-quality sense inventory for improved abbreviation disambiguation},
	volume = {26},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859134/},
	doi = {10.1093/bioinformatics/btq129},
	abstract = {Motivation: The ultimate goal of abbreviation management is to disambiguate every occurrence of an abbreviation into its expanded form (concept or sense). To collect expanded forms for abbreviations, previous studies have recognized abbreviations and their expanded forms in parenthetical expressions of bio-medical texts. However, expanded forms extracted by abbreviation recognition are mixtures of concepts/senses and their term variations. Consequently, a list of expanded forms should be structured into a sense inventory, which provides possible concepts or senses for abbreviation disambiguation., Results: A sense inventory is a key to robust management of abbreviations. Therefore, we present a supervised approach for clustering expanded forms. The experimental result reports 0.915 F1 score in clustering expanded forms. We then investigate the possibility of conflicts of protein and gene names with abbreviations. Finally, an experiment of abbreviation disambiguation on the sense inventory yielded 0.984 accuracy and 0.986 F1 score using the dataset obtained from MEDLINE abstracts., Availability: The sense inventory and disambiguator of abbreviations are accessible at http://www.nactem.ac.uk/software/acromine/ and http://www.nactem.ac.uk/software/acromine\_disambiguation/, Contact: okazaki@chokkan.org},
	number = {9},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Okazaki, Naoaki and Ananiadou, Sophia and Tsujii, Jun'ichi},
	month = may,
	year = {2010},
	pmid = {20360059},
	pmcid = {PMC2859134},
	pages = {1246--1253},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RHKS27RG/Okazaki et al. - 2010 - Building a high-quality sense inventory for improv.pdf:application/pdf}
}

@article{kemper_pathtext:_2010,
	title = {{PathText}: a text mining integrator for biological pathway visualizations},
	volume = {26},
	issn = {1367-4803},
	shorttitle = {{PathText}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881405/},
	doi = {10.1093/bioinformatics/btq221},
	abstract = {Motivation: Metabolic and signaling pathways are an increasingly important part of organizing knowledge in systems biology. They serve to integrate collective interpretations of facts scattered throughout literature. Biologists construct a pathway by reading a large number of articles and interpreting them as a consistent network, but most of the models constructed currently lack direct links to those articles. Biologists who want to check the original articles have to spend substantial amounts of time to collect relevant articles and identify the sections relevant to the pathway. Furthermore, with the scientific literature expanding by several thousand papers per week, keeping a model relevant requires a continuous curation effort. In this article, we present a system designed to integrate a pathway visualizer, text mining systems and annotation tools into a seamless environment. This will enable biologists to freely move between parts of a pathway and relevant sections of articles, as well as identify relevant papers from large text bases. The system, PathText, is developed by Systems Biology Institute, Okinawa Institute of Science and Technology, National Centre for Text Mining (University of Manchester) and the University of Tokyo, and is being used by groups of biologists from these locations., Contact: brian@monrovian.com.},
	number = {12},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Kemper, Brian and Matsuzaki, Takuya and Matsuoka, Yukiko and Tsuruoka, Yoshimasa and Kitano, Hiroaki and Ananiadou, Sophia and Tsujii, Jun'ichi},
	month = jun,
	year = {2010},
	pmid = {20529930},
	pmcid = {PMC2881405},
	pages = {i374--i381},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZCJQRPSP/Kemper et al. - 2010 - PathText a text mining integrator for biological .pdf:application/pdf}
}

@article{kano_text_2010,
	title = {Text mining meets workflow: linking {U}-{Compare} with {Taverna}},
	volume = {26},
	issn = {1367-4803},
	shorttitle = {Text mining meets workflow},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944208/},
	doi = {10.1093/bioinformatics/btq464},
	abstract = {Summary: Text mining from the biomedical literature is of increasing importance, yet it is not easy for the bioinformatics community to create and run text mining workflows due to the lack of accessibility and interoperability of the text mining resources. The U-Compare system provides a wide range of bio text mining resources in a highly interoperable workflow environment where workflows can very easily be created, executed, evaluated and visualized without coding. We have linked U-Compare to Taverna, a generic workflow system, to expose text mining functionality to the bioinformatics community., Availability: http://u-compare.org/taverna.html, http://u-compare.org, Contact: kano@is.s.u-tokyo.ac.jp, Supplementary information: Supplementary data are available at Bioinformatics online.},
	number = {19},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Kano, Yoshinobu and Dobson, Paul and Nakanishi, Mio and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = oct,
	year = {2010},
	pmid = {20709690},
	pmcid = {PMC2944208},
	pages = {2486--2487},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VKMDVZQ7/Kano et al. - 2010 - Text mining meets workflow linking U-Compare with.pdf:application/pdf}
}

@article{kolluru_using_2011,
	title = {Using {Workflows} to {Explore} and {Optimise} {Named} {Entity} {Recognition} for                     {Chemistry}},
	volume = {6},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102085/},
	doi = {10.1371/journal.pone.0020181},
	abstract = {Chemistry text mining tools should be interoperable and adaptable regardless of
                    system-level implementation, installation or even programming issues. We aim to
                    abstract the functionality of these tools from the underlying implementation via
                    reconfigurable workflows for automatically identifying chemical names. To
                    achieve this, we refactored an established named entity recogniser (in the
                    chemistry domain), OSCAR and studied the impact of each component on the net
                    performance. We developed two reconfigurable workflows from OSCAR using an
                    interoperable text mining framework, U-Compare. These workflows can be altered
                    using the drag-\&-drop mechanism of the graphical user
                    interface of U-Compare. These workflows also provide a platform to study the
                    relationship between text mining components such as tokenisation and named
                    entity recognition (using maximum entropy Markov model (MEMM) and pattern
                    recognition based classifiers). Results indicate that, for chemistry in
                    particular, eliminating noise generated by tokenisation techniques lead to a
                    slightly better performance than others, in terms of named entity recognition
                    (NER) accuracy. Poor tokenisation translates into poorer input to the classifier
                    components which in turn leads to an increase in Type I or Type II errors, thus,
                    lowering the overall performance. On the Sciborg corpus, the workflow based
                    system, which uses a new tokeniser whilst retaining the same MEMM component,
                    increases the F-score from 82.35\% to 84.44\%. On the PubMed corpus,
                    it recorded an F-score of 84.84\% as against 84.23\% by OSCAR.},
	number = {5},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Kolluru, BalaKrishna and Hawizy, Lezan and Murray-Rust, Peter and Tsujii, Junichi and Ananiadou, Sophia},
	month = may,
	year = {2011},
	pmid = {21633495},
	pmcid = {PMC3102085},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CG6E55QT/Kolluru et al. - 2011 - Using Workflows to Explore and Optimise Named Enti.pdf:application/pdf}
}

@article{tsuruoka_discovering_2011,
	title = {Discovering and visualizing indirect associations between biomedical concepts},
	volume = {27},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3117364/},
	doi = {10.1093/bioinformatics/btr214},
	abstract = {Motivation: Discovering useful associations between biomedical concepts has been one of the main goals in biomedical text-mining, and understanding their biomedical contexts is crucial in the discovery process. Hence, we need a text-mining system that helps users explore various types of (possibly hidden) associations in an easy and comprehensible manner., Results: This article describes FACTA+, a real-time text-mining system for finding and visualizing indirect associations between biomedical concepts from MEDLINE abstracts. The system can be used as a text search engine like PubMed with additional features to help users discover and visualize indirect associations between important biomedical concepts such as genes, diseases and chemical compounds. FACTA+ inherits all functionality from its predecessor, FACTA, and extends it by incorporating three new features: (i) detecting biomolecular events in text using a machine learning model, (ii) discovering hidden associations using co-occurrence statistics between concepts, and (iii) visualizing associations to improve the interpretability of the output. To the best of our knowledge, FACTA+ is the first real-time web application that offers the functionality of finding concepts involving biomolecular events and visualizing indirect associations of concepts with both their categories and importance., Availability: FACTA+ is available as a web application at http://refine1-nactem.mc.man.ac.uk/facta/, and its visualizer is available at http://refine1-nactem.mc.man.ac.uk/facta-visualizer/., Contact: tsuruoka@jaist.ac.jp},
	number = {13},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Tsuruoka, Yoshimasa and Miwa, Makoto and Hamamoto, Kaisei and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = jul,
	year = {2011},
	pmid = {21685059},
	pmcid = {PMC3117364},
	pages = {i111--i119}
}

@article{wang_automatic_2011,
	title = {Automatic extraction of angiogenesis bioprocess from text},
	volume = {27},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3179660/},
	doi = {10.1093/bioinformatics/btr460},
	abstract = {Motivation: Understanding key biological processes (bioprocesses) and their relationships with constituent biological entities and pharmaceutical agents is crucial for drug design and discovery. One way to harvest such information is searching the literature. However, bioprocesses are difficult to capture because they may occur in text in a variety of textual expressions. Moreover, a bioprocess is often composed of a series of bioevents, where a bioevent denotes changes to one or a group of cells involved in the bioprocess. Such bioevents are often used to refer to bioprocesses in text, which current techniques, relying solely on specialized lexicons, struggle to find., Results: This article presents a range of methods for finding bioprocess terms and events. To facilitate the study, we built a gold standard corpus in which terms and events related to angiogenesis, a key biological process of the growth of new blood vessels, were annotated. Statistics of the annotated corpus revealed that over 36\% of the text expressions that referred to angiogenesis appeared as events. The proposed methods respectively employed domain-specific vocabularies, a manually annotated corpus and unstructured domain-specific documents. Evaluation results showed that, while a supervised machine-learning model yielded the best precision, recall and F1 scores, the other methods achieved reasonable performance and less cost to develop., Availability: The angiogenesis vocabularies, gold standard corpus, annotation guidelines and software described in this article are available at http://text0.mib.man.ac.uk/{\textasciitilde}mbassxw2/angiogenesis/, Contact: xinglong.wang@gmail.com},
	number = {19},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Wang, Xinglong and McKendrick, Iain and Barrett, Ian and Dix, Ian and French, Tim and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = oct,
	year = {2011},
	pmid = {21821664},
	pmcid = {PMC3179660},
	pages = {2730--2737},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/M6N2BQVJ/Wang et al. - 2011 - Automatic extraction of angiogenesis bioprocess fr.pdf:application/pdf}
}

@article{thompson_enriching_2011,
	title = {Enriching a biomedical event corpus with meta-knowledge annotation},
	volume = {12},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3222636/},
	doi = {10.1186/1471-2105-12-393},
	abstract = {Background
Biomedical papers contain rich information about entities, facts and events of biological relevance. To discover these automatically, we use text mining techniques, which rely on annotated corpora for training. In order to extract protein-protein interactions, genotype-phenotype/gene-disease associations, etc., we rely on event corpora that are annotated with classified, structured representations of important facts and findings contained within text. These provide an important resource for the training of domain-specific information extraction (IE) systems, to facilitate semantic-based searching of documents. Correct interpretation of these events is not possible without additional information, e.g., does an event describe a fact, a hypothesis, an experimental result or an analysis of results? How confident is the author about the validity of her analyses? These and other types of information, which we collectively term meta-knowledge, can be derived from the context of the event.

Results
We have designed an annotation scheme for meta-knowledge enrichment of biomedical event corpora. The scheme is multi-dimensional, in that each event is annotated for 5 different aspects of meta-knowledge that can be derived from the textual context of the event. Textual clues used to determine the values are also annotated. The scheme is intended to be general enough to allow integration with different types of bio-event annotation, whilst being detailed enough to capture important subtleties in the nature of the meta-knowledge expressed in the text. We report here on both the main features of the annotation scheme, as well as its application to the GENIA event corpus (1000 abstracts with 36,858 events). High levels of inter-annotator agreement have been achieved, falling in the range of 0.84-0.93 Kappa.

Conclusion
By augmenting event annotations with meta-knowledge, more sophisticated IE systems can be trained, which allow interpretative information to be specified as part of the search criteria. This can assist in a number of important tasks, e.g., finding new experimental knowledge to facilitate database curation, enabling textual inference to detect entailments and contradictions, etc. To our knowledge, our scheme is unique within the field with regards to the diversity of meta-knowledge aspects annotated for each event.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Thompson, Paul and Nawaz, Raheel and McNaught, John and Ananiadou, Sophia},
	month = oct,
	year = {2011},
	pmid = {21985429},
	pmcid = {PMC3222636},
	pages = {393},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VWBGR4V7/Thompson et al. - 2011 - Enriching a biomedical event corpus with meta-know.pdf:application/pdf}
}

@article{thompson_biolexicon:_2011,
	title = {The {BioLexicon}: a large-scale terminological resource for biomedical text mining},
	volume = {12},
	issn = {1471-2105},
	shorttitle = {The {BioLexicon}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3228855/},
	doi = {10.1186/1471-2105-12-397},
	abstract = {Background
Due to the rapidly expanding body of biomedical literature, biologists require increasingly sophisticated and efficient systems to help them to search for relevant information. Such systems should account for the multiple written variants used to represent biomedical concepts, and allow the user to search for specific pieces of knowledge (or events) involving these concepts, e.g., protein-protein interactions. Such functionality requires access to detailed information about words used in the biomedical literature. Existing databases and ontologies often have a specific focus and are oriented towards human use. Consequently, biological knowledge is dispersed amongst many resources, which often do not attempt to account for the large and frequently changing set of variants that appear in the literature. Additionally, such resources typically do not provide information about how terms relate to each other in texts to describe events.

Results
This article provides an overview of the design, construction and evaluation of a large-scale lexical and conceptual resource for the biomedical domain, the BioLexicon. The resource can be exploited by text mining tools at several levels, e.g., part-of-speech tagging, recognition of biomedical entities, and the extraction of events in which they are involved. As such, the BioLexicon must account for real usage of words in biomedical texts. In particular, the BioLexicon gathers together different types of terms from several existing data resources into a single, unified repository, and augments them with new term variants automatically extracted from biomedical literature. Extraction of events is facilitated through the inclusion of biologically pertinent verbs (around which events are typically organized) together with information about typical patterns of grammatical and semantic behaviour, which are acquired from domain-specific texts. In order to foster interoperability, the BioLexicon is modelled using the Lexical Markup Framework, an ISO standard.

Conclusions
The BioLexicon contains over 2.2 M lexical entries and over 1.8 M terminological variants, as well as over 3.3 M semantic relations, including over 2 M synonymy relations. Its exploitation can benefit both application developers and users. We demonstrate some such benefits by describing integration of the resource into a number of different tools, and evaluating improvements in performance that this can bring.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Thompson, Paul and McNaught, John and Montemagni, Simonetta and Calzolari, Nicoletta and del Gratta, Riccardo and Lee, Vivian and Marchi, Simone and Monachini, Monica and Pezik, Piotr and Quochi, Valeria and Rupp, CJ and Sasaki, Yutaka and Venturi, Giulia and Rebholz-Schuhmann, Dietrich and Ananiadou, Sophia},
	month = oct,
	year = {2011},
	pmid = {21992002},
	pmcid = {PMC3228855},
	pages = {397},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/NRUCDVVF/Thompson et al. - 2011 - The BioLexicon a large-scale terminological resou.pdf:application/pdf}
}

@article{miwa_adaptable_2015,
	title = {Adaptable, high recall, event extraction system with minimal configuration},
	volume = {16},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4511382/},
	doi = {10.1186/1471-2105-16-S10-S7},
	abstract = {Background
Biomedical event extraction has been a major focus of biomedical natural language processing (BioNLP) research since the first BioNLP shared task was held in 2009. Accordingly, a large number of event extraction systems have been developed. Most such systems, however, have been developed for specific tasks and/or incorporated task specific settings, making their application to new corpora and tasks problematic without modification of the systems themselves. There is thus a need for event extraction systems that can achieve high levels of accuracy when applied to corpora in new domains, without the need for exhaustive tuning or modification, whilst retaining competitive levels of performance.

Results
We have enhanced our state-of-the-art event extraction system, EventMine, to alleviate the need for task-specific tuning. Task-specific details are specified in a configuration file, while extensive task-specific parameter tuning is avoided through the integration of a weighting method, a covariate shift method, and their combination. The task-specific configuration and weighting method have been employed within the context of two different sub-tasks of BioNLP shared task 2013, i.e. Cancer Genetics (CG) and Pathway Curation (PC), removing the need to modify the system specifically for each task. With minimal task specific configuration and tuning, EventMine achieved the 1st place in the PC task, and 2nd in the CG, achieving the highest recall for both tasks. The system has been further enhanced following the shared task by incorporating the covariate shift method and entity generalisations based on the task definitions, leading to further performance improvements.

Conclusions
We have shown that it is possible to apply a state-of-the-art event extraction system to new tasks with high levels of performance, without having to modify the system internally. Both covariate shift and weighting methods are useful in facilitating the production of high recall systems. These methods and their combination can adapt a model to the target data with no deep tuning and little manual configuration.},
	number = {Suppl 10},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Miwa, Makoto and Ananiadou, Sophia},
	month = jul,
	year = {2015},
	pmid = {26201408},
	pmcid = {PMC4511382},
	keywords = {female first or senior},
	pages = {S7},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/P4V9CUAK/Miwa and Ananiadou - 2015 - Adaptable, high recall, event extraction system wi.pdf:application/pdf}
}

@article{pyysalo_overview_2015,
	title = {Overview of the {Cancer} {Genetics} and {Pathway} {Curation} tasks of {BioNLP} {Shared} {Task} 2013},
	volume = {16},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4511510/},
	doi = {10.1186/1471-2105-16-S10-S2},
	abstract = {Background
Since their introduction in 2009, the BioNLP Shared Task events have been instrumental in advancing the development of methods and resources for the automatic extraction of information from the biomedical literature. In this paper, we present the Cancer Genetics (CG) and Pathway Curation (PC) tasks, two event extraction tasks introduced in the BioNLP Shared Task 2013. The CG task focuses on cancer, emphasizing the extraction of physiological and pathological processes at various levels of biological organization, and the PC task targets reactions relevant to the development of biomolecular pathway models, defining its extraction targets on the basis of established pathway representations and ontologies.

Results
Six groups participated in the CG task and two groups in the PC task, together applying a wide range of extraction approaches including both established state-of-the-art systems and newly introduced extraction methods. The best-performing systems achieved F-scores of 55\% on the CG task and 53\% on the PC task, demonstrating a level of performance comparable to the best results achieved in similar previously proposed tasks.

Conclusions
The results indicate that existing event extraction technology can generalize to meet the novel challenges represented by the CG and PC task settings, suggesting that extraction methods are capable of supporting the construction of knowledge bases on the molecular mechanisms of cancer and the curation of biomolecular pathway models. The CG and PC tasks continue as open challenges for all interested parties, with data, tools and resources available from the shared task homepage.},
	number = {Suppl 10},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Pyysalo, Sampo and Ohta, Tomoko and Rak, Rafal and Rowley, Andrew and Chun, Hong-Woo and Jung, Sung-Jae and Choi, Sung-Pil and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = jul,
	year = {2015},
	pmid = {26202570},
	pmcid = {PMC4511510},
	pages = {S2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/UCA8KUM4/Pyysalo et al. - 2015 - Overview of the Cancer Genetics and Pathway Curati.pdf:application/pdf}
}

@article{mo_supporting_2015,
	title = {Supporting systematic reviews using {LDA}-based document representations},
	volume = {4},
	issn = {2046-4053},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4662004/},
	doi = {10.1186/s13643-015-0117-0},
	abstract = {Background
Identifying relevant studies for inclusion in a systematic review (i.e. screening) is a complex, laborious and expensive task. Recently, a number of studies has shown that the use of machine learning and text mining methods to automatically identify relevant studies has the potential to drastically decrease the workload involved in the screening phase. The vast majority of these machine learning methods exploit the same underlying principle, i.e. a study is modelled as a bag-of-words (BOW).

Methods
We explore the use of topic modelling methods to derive a more informative representation of studies. We apply Latent Dirichlet allocation (LDA), an unsupervised topic modelling approach, to automatically identify topics in a collection of studies. We then represent each study as a distribution of LDA topics. Additionally, we enrich topics derived using LDA with multi-word terms identified by using an automatic term recognition (ATR) tool. For evaluation purposes, we carry out automatic identification of relevant studies using support vector machine (SVM)-based classifiers that employ both our novel topic-based representation and the BOW representation.

Results
Our results show that the SVM classifier is able to identify a greater number of relevant studies when using the LDA representation than the BOW representation. These observations hold for two systematic reviews of the clinical domain and three reviews of the social science domain.

Conclusions
A topic-based feature representation of documents outperforms the BOW representation when applied to the task of automatic citation screening. The proposed term-enriched topics are more informative and less ambiguous to systematic reviewers.

Electronic supplementary material
The online version of this article (doi:10.1186/s13643-015-0117-0) contains supplementary material, which is available to authorized users.},
	urldate = {2018-03-10},
	journal = {Systematic Reviews},
	author = {Mo, Yuanhan and Kontonatsios, Georgios and Ananiadou, Sophia},
	month = nov,
	year = {2015},
	pmid = {26612232},
	pmcid = {PMC4662004},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/26IFA9W5/Mo et al. - 2015 - Supporting systematic reviews using LDA-based docu.pdf:application/pdf}
}

@article{batista-navarro_argo:_2016,
	title = {Argo: enabling the development of bespoke workflows and services for disease annotation},
	volume = {2016},
	issn = {1758-0463},
	shorttitle = {Argo},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4869796/},
	doi = {10.1093/database/baw066},
	abstract = {Argo (http://argo.nactem.ac.uk) is a generic text mining workbench that can cater to a variety of use cases, including the semi-automatic annotation of literature. It enables its technical users to build their own customised text mining solutions by providing a wide array of interoperable and configurable elementary components that can be seamlessly integrated into processing workflows. With Argo's graphical annotation interface, domain experts can then make use of the workflows' automatically generated output to curate information of interest., With the continuously rising need to understand the aetiology of diseases as well as the demand for their informed diagnosis and personalised treatment, the curation of disease-relevant information from medical and clinical documents has become an indispensable scientific activity. In the Fifth BioCreative Challenge Evaluation Workshop (BioCreative V), there was substantial interest in the mining of literature for disease-relevant information. Apart from a panel discussion focussed on disease annotations, the chemical-disease relations (CDR) track was also organised to foster the sharing and advancement of disease annotation tools and resources., This article presents the application of Argo’s capabilities to the literature-based annotation of diseases. As part of our participation in BioCreative V’s User Interactive Track (IAT), we demonstrated and evaluated Argo’s suitability to the semi-automatic curation of chronic obstructive pulmonary disease (COPD) phenotypes. Furthermore, the workbench facilitated the development of some of the CDR track’s top-performing web services for normalising disease mentions against the Medical Subject Headings (MeSH) database. In this work, we highlight Argo’s support for developing various types of bespoke workflows ranging from ones which enabled us to easily incorporate information from various databases, to those which train and apply machine learning-based concept recognition models, through to user-interactive ones which allow human curators to manually provide their corrections to automatically generated annotations. Our participation in the BioCreative V challenges shows Argo’s potential as an enabling technology for curating disease and phenotypic information from literature., Database URL: http://argo.nactem.ac.uk},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Batista-Navarro, Riza and Carter, Jacob and Ananiadou, Sophia},
	month = may,
	year = {2016},
	pmid = {27189607},
	pmcid = {PMC4869796},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3WZ7QK55/Batista-Navarro et al. - 2016 - Argo enabling the development of bespoke workflow.pdf:application/pdf}
}

@article{hashimoto_topic_2016,
	title = {Topic detection using paragraph vectors to support active learning in systematic reviews},
	volume = {62},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4981645/},
	doi = {10.1016/j.jbi.2016.06.001},
	abstract = {•
              We propose a topic detection method based on paragraph vectors.
            
            
              •
              The method is integrated with an active learner to accelerate citation screening.
            
            
              •
              The method outperforms LDA when applied to clinical and public health reviews.
            
          
        , Systematic reviews require expert reviewers to manually screen thousands of citations in order to identify all relevant articles to the review. Active learning text classification is a supervised machine learning approach that has been shown to significantly reduce the manual annotation workload by semi-automating the citation screening process of systematic reviews. In this paper, we present a new topic detection method that induces an informative representation of studies, to improve the performance of the underlying active learner. Our proposed topic detection method uses a neural network-based vector space model to capture semantic similarities between documents. We firstly represent documents within the vector space, and cluster the documents into a predefined number of clusters. The centroids of the clusters are treated as latent topics. We then represent each document as a mixture of latent topics. For evaluation purposes, we employ the active learning strategy using both our novel topic detection method and a baseline topic model (i.e., Latent Dirichlet Allocation). Results obtained demonstrate that our method is able to achieve a high sensitivity of eligible studies and a significantly reduced manual annotation cost when compared to the baseline method. This observation is consistent across two clinical and three public health reviews. The tool introduced in this work is available from https://nactem.ac.uk/pvtopic/.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Hashimoto, Kazuma and Kontonatsios, Georgios and Miwa, Makoto and Ananiadou, Sophia},
	month = aug,
	year = {2016},
	pmid = {27293211},
	pmcid = {PMC4981645},
	pages = {59--65}
}

@article{kim_biocreative_2016,
	title = {{BioCreative} {V} {BioC} track overview: collaborative biocurator assistant task for {BioGRID}},
	volume = {2016},
	issn = {1758-0463},
	shorttitle = {{BioCreative} {V} {BioC} track overview},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5009341/},
	doi = {10.1093/database/baw121},
	abstract = {BioC is a simple XML format for text, annotations and relations, and was developed to achieve interoperability for biomedical text processing. Following the success of BioC in BioCreative IV, the BioCreative V BioC track addressed a collaborative task to build an assistant system for BioGRID curation. In this paper, we describe the framework of the collaborative BioC task and discuss our findings based on the user survey. This track consisted of eight subtasks including gene/protein/organism named entity recognition, protein–protein/genetic interaction passage identification and annotation visualization. Using BioC as their data-sharing and communication medium, nine teams, world-wide, participated and contributed either new methods or improvements of existing tools to address different subtasks of the BioC track. Results from different teams were shared in BioC and made available to other teams as they addressed different subtasks of the track. In the end, all submitted runs were merged using a machine learning classifier to produce an optimized output. The biocurator assistant system was evaluated by four BioGRID curators in terms of practical usability. The curators’ feedback was overall positive and highlighted the user-friendly design and the convenient gene/protein curation tool based on text mining., Database URL: http://www.biocreative.org/tasks/biocreative-v/track-1-bioc/},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Kim, Sun and Islamaj Doğan, Rezarta and Chatr-Aryamontri, Andrew and Chang, Christie S. and Oughtred, Rose and Rust, Jennifer and Batista-Navarro, Riza and Carter, Jacob and Ananiadou, Sophia and Matos, Sérgio and Santos, André and Campos, David and Oliveira, José Luís and Singh, Onkar and Jonnagaddala, Jitendra and Dai, Hong-Jie and Su, Emily Chia-Yu and Chang, Yung-Chun and Su, Yu-Chen and Chu, Chun-Han and Chen, Chien Chin and Hsu, Wen-Lian and Peng, Yifan and Arighi, Cecilia and Wu, Cathy H. and Vijay-Shanker, K. and Aydın, Ferhat and Hüsünbeyi, Zehra Melce and Özgür, Arzucan and Shin, Soo-Yong and Kwon, Dongseop and Dolinski, Kara and Tyers, Mike and Wilbur, W. John and Comeau, Donald C.},
	month = sep,
	year = {2016},
	pmid = {27589962},
	pmcid = {PMC5009341},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MJ9NF758/Kim et al. - 2016 - BioCreative V BioC track overview collaborative b.pdf:application/pdf}
}

@article{swainston_biochem4j:_2017,
	title = {biochem4j: {Integrated} and extensible biochemical knowledge through graph databases},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {biochem4j},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5510799/},
	doi = {10.1371/journal.pone.0179130},
	abstract = {Biologists and biochemists have at their disposal a number of excellent, publicly available data resources such as UniProt, KEGG, and NCBI Taxonomy, which catalogue biological entities. Despite the usefulness of these resources, they remain fundamentally unconnected. While links may appear between entries across these databases, users are typically only able to follow such links by manual browsing or through specialised workflows. Although many of the resources provide web-service interfaces for computational access, performing federated queries across databases remains a non-trivial but essential activity in interdisciplinary systems and synthetic biology programmes. What is needed are integrated repositories to catalogue both biological entities and–crucially–the relationships between them. Such a resource should be extensible, such that newly discovered relationships–for example, those between novel, synthetic enzymes and non-natural products–can be added over time. With the introduction of graph databases, the barrier to the rapid generation, extension and querying of such a resource has been lowered considerably. With a particular focus on metabolic engineering as an illustrative application domain, biochem4j, freely available at http://biochem4j.org, is introduced to provide an integrated, queryable database that warehouses chemical, reaction, enzyme and taxonomic data from a range of reliable resources. The biochem4j framework establishes a starting point for the flexible integration and exploitation of an ever-wider range of biological data sources, from public databases to laboratory-specific experimental datasets, for the benefit of systems biologists, biosystems engineers and the wider community of molecular biologists and biological chemists.},
	number = {7},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Swainston, Neil and Batista-Navarro, Riza and Carbonell, Pablo and Dobson, Paul D. and Dunstan, Mark and Jervis, Adrian J. and Vinaixa, Maria and Williams, Alan R. and Ananiadou, Sophia and Faulon, Jean-Loup and Mendes, Pedro and Kell, Douglas B. and Scrutton, Nigel S. and Breitling, Rainer},
	month = jul,
	year = {2017},
	pmid = {28708831},
	pmcid = {PMC5510799},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/K49Z2NCJ/Swainston et al. - 2017 - biochem4j Integrated and extensible biochemical k.pdf:application/pdf}
}

@article{venkatesan_scilite:_2017,
	title = {{SciLite}: a platform for displaying text-mined annotations as a means to link research articles with biological data},
	volume = {1},
	issn = {2398-502X},
	shorttitle = {{SciLite}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5527546/},
	doi = {10.12688/wellcomeopenres.10210.2},
	abstract = {The tremendous growth in biological data has resulted in an increase in the number of research papers being published. This presents a great challenge for scientists in searching and assimilating facts described in those papers. Particularly, biological databases depend on curators to add highly precise and useful information that are usually extracted by reading research articles. Therefore, there is an urgent need to find ways to improve linking literature to the underlying data, thereby minimising the effort in browsing content and identifying key biological concepts.  ,  As part of the development of Europe PMC, we have developed a new platform, SciLite, which integrates text-mined annotations from different sources and overlays those outputs on research articles. The aim is to aid researchers and curators using Europe PMC in finding key concepts more easily and provide links to related resources or tools, bridging the gap between literature and biological data.},
	urldate = {2018-03-10},
	journal = {Wellcome Open Research},
	author = {Venkatesan, Aravind and Kim, Jee-Hyub and Talo, Francesco and Ide-Smith, Michele and Gobeill, Julien and Carter, Jacob and Batista-Navarro, Riza and Ananiadou, Sophia and Ruch, Patrick and McEntyre, Johanna},
	month = jul,
	year = {2017},
	pmid = {28948232},
	pmcid = {PMC5527546},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/3JXZYCYP/Venkatesan et al. - 2017 - SciLite a platform for displaying text-mined anno.pdf:application/pdf}
}

@article{mcentyre_ukpmc:_2011,
	title = {{UKPMC}: a full text article resource for the life sciences},
	volume = {39},
	issn = {0305-1048},
	shorttitle = {{UKPMC}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013671/},
	doi = {10.1093/nar/gkq1063},
	abstract = {UK PubMed Central (UKPMC) is a full-text article database that extends the functionality of the original PubMed Central (PMC) repository. The UKPMC project was launched as the first ‘mirror’ site to PMC, which in analogy to the International Nucleotide Sequence Database Collaboration, aims to provide international preservation of the open and free-access biomedical literature. UKPMC (http://ukpmc.ac.uk) has undergone considerable development since its inception in 2007 and now includes both a UKPMC and PubMed search, as well as access to other records such as Agricola, Patents and recent biomedical theses. UKPMC also differs from PubMed/PMC in that the full text and abstract information can be searched in an integrated manner from one input box. Furthermore, UKPMC contains ‘Cited By’ information as an alternative way to navigate the literature and has incorporated text-mining approaches to semantically enrich content and integrate it with related database resources. Finally, UKPMC also offers added-value services (UKPMC+) that enable grantees to deposit manuscripts, link papers to grants, publish online portfolios and view citation information on their papers. Here we describe UKPMC and clarify the relationship between PMC and UKPMC, providing historical context and future directions, 10 years on from when PMC was first launched.},
	number = {Database issue},
	urldate = {2018-03-10},
	journal = {Nucleic Acids Research},
	author = {McEntyre, Johanna R. and Ananiadou, Sophia and Andrews, Stephen and Black, William J. and Boulderstone, Richard and Buttery, Paula and Chaplin, David and Chevuru, Sandeepreddy and Cobley, Norman and Coleman, Lee-Ann and Davey, Paul and Gupta, Bharti and Haji-Gholam, Lesley and Hawkins, Craig and Horne, Alan and Hubbard, Simon J. and Kim, Jee-Hyub and Lewin, Ian and Lyte, Vic and MacIntyre, Ross and Mansoor, Sami and Mason, Linda and McNaught, John and Newbold, Elizabeth and Nobata, Chikashi and Ong, Ernest and Pillai, Sharmila and Rebholz-Schuhmann, Dietrich and Rosie, Heather and Rowbotham, Rob and Rupp, C. J. and Stoehr, Peter and Vaughan, Philip},
	month = jan,
	year = {2011},
	pmid = {21062818},
	pmcid = {PMC3013671},
	keywords = {female first or senior},
	pages = {D58--D65},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/THHJFJYC/McEntyre et al. - 2011 - UKPMC a full text article resource for the life s.pdf:application/pdf}
}

@article{ananiadou_named_2011,
	title = {Named {Entity} {Recognition} for {Bacterial} {Type} {IV} {Secretion} {Systems}},
	volume = {6},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3066171/},
	doi = {10.1371/journal.pone.0014780},
	abstract = {Research on specialized biological systems is often hampered by a lack of consistent terminology, especially across species. In bacterial Type IV secretion systems genes within one set of orthologs may have over a dozen different names. Classifying research publications based on biological processes, cellular components, molecular functions, and microorganism species should improve the precision and recall of literature searches allowing researchers to keep up with the exponentially growing literature, through resources such as the Pathosystems Resource Integration Center (PATRIC, patricbrc.org). We developed named entity recognition (NER) tools for four entities related to Type IV secretion systems: 1) bacteria names, 2) biological processes, 3) molecular functions, and 4) cellular components. These four entities are important to pathogenesis and virulence research but have received less attention than other entities, e.g., genes and proteins. Based on an annotated corpus, large domain terminological resources, and machine learning techniques, we developed recognizers for these entities. High accuracy rates ({\textgreater}80\%) are achieved for bacteria, biological processes, and molecular function. Contrastive experiments highlighted the effectiveness of alternate recognition strategies; results of term extraction on contrasting document sets demonstrated the utility of these classes for identifying T4SS-related documents.},
	number = {3},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Ananiadou, Sophia and Sullivan, Dan and Black, William and Levow, Gina-Anne and Gillespie, Joseph J. and Mao, Chunhong and Pyysalo, Sampo and Kolluru, BalaKrishna and Tsujii, Junichi and Sobral, Bruno},
	month = mar,
	year = {2011},
	pmid = {21468321},
	pmcid = {PMC3066171},
	keywords = {female first or senior, NER},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JGQFS9AF/Ananiadou et al. - 2011 - Named Entity Recognition for Bacterial Type IV Sec.pdf:application/pdf}
}

@article{kocbek_agra:_2011,
	title = {{AGRA}: analysis of gene ranking algorithms},
	volume = {27},
	issn = {1367-4803},
	shorttitle = {{AGRA}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3072556/},
	doi = {10.1093/bioinformatics/btr097},
	abstract = {Summary: Often, the most informative genes have to be selected from different gene sets and several computer gene ranking algorithms have been developed to cope with the problem. To help researchers decide which algorithm to use, we developed the analysis of gene ranking algorithms (AGRA) system that offers a novel technique for comparing ranked lists of genes. The most important feature of AGRA is that no previous knowledge of gene ranking algorithms is needed for their comparison. Using the text mining system finding-associated concepts with text analysis. AGRA defines what we call biomedical concept space (BCS) for each gene list and offers a comparison of the gene lists in six different BCS categories. The uploaded gene lists can be compared using two different methods. In the first method, the overlap between each pair of two gene lists of BCSs is calculated. The second method offers a text field where a specific biomedical concept can be entered. AGRA searches for this concept in each gene lists' BCS, highlights the rank of the concept and offers a visual representation of concepts ranked above and below it., Availability and Implementation: Available at http://agra.fzv.uni-mb.si/, implemented in Java and running on the Glassfish server., Contact: simon.kocbek@uni-mb.si},
	number = {8},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Kocbek, Simon and Sætre, Rune and Stiglic, Gregor and Kim, Jin-Dong and Pernek, Igor and Tsuruoka, Yoshimasa and Kokol, Peter and Ananiadou, Sophia and Tsujii, Jun'ichi},
	month = apr,
	year = {2011},
	pmid = {21349873},
	pmcid = {PMC3072556},
	pages = {1185--1186},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WJMZAB2T/Kocbek et al. - 2011 - AGRA analysis of gene ranking algorithms.pdf:application/pdf}
}

@article{wang_detecting_2011,
	title = {Detecting experimental techniques and selecting relevant documents for protein-protein interactions from biomedical literature},
	volume = {12},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3269934/},
	doi = {10.1186/1471-2105-12-S8-S11},
	abstract = {Background
The selection of relevant articles for curation, and linking those articles to experimental techniques confirming the findings became one of the primary subjects of the recent BioCreative III contest. The contest’s Protein-Protein Interaction (PPI) task consisted of two sub-tasks: Article Classification Task (ACT) and Interaction Method Task (IMT). ACT aimed to automatically select relevant documents for PPI curation, whereas the goal of IMT was to recognise the methods used in experiments for identifying the interactions in full-text articles.

Results
We proposed and compared several classification-based methods for both tasks, employing rich contextual features as well as features extracted from external knowledge sources. For IMT, a new method that classifies pair-wise relations between every text phrase and candidate interaction method obtained promising results with an F1 score of 64.49\%, as tested on the task’s development dataset. We also explored ways to combine this new approach and more conventional, multi-label document classification methods. For ACT, our classifiers exploited automatically detected named entities and other linguistic information. The evaluation results on the BioCreative III PPI test datasets showed that our systems were very competitive: one of our IMT methods yielded the best performance among all participants, as measured by F1 score, Matthew’s Correlation Coefficient and AUC iP/R; whereas for ACT, our best classifier was ranked second as measured by AUC iP/R, and also competitive according to other metrics.

Conclusions
Our novel approach that converts the multi-class, multi-label classification problem to a binary classification problem showed much promise in IMT. Nevertheless, on the test dataset the best performance was achieved by taking the union of the output of this method and that of a multi-class, multi-label document classifier, which indicates that the two types of systems complement each other in terms of recall. For ACT, our system exploited a rich set of features and also obtained encouraging results. We examined the features with respect to their contributions to the classification results, and concluded that contextual words surrounding named entities, as well as the MeSH headings associated with the documents were among the main contributors to the performance.},
	number = {Suppl 8},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Wang, Xinglong and Rak, Rafal and Restificar, Angelo and Nobata, Chikashi and Rupp, CJ and Batista-Navarro, Riza Theresa B and Nawaz, Raheel and Ananiadou, Sophia},
	month = oct,
	year = {2011},
	pmid = {22151769},
	pmcid = {PMC3269934},
	pages = {S11},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/FZCGINJH/Wang et al. - 2011 - Detecting experimental techniques and selecting re.pdf:application/pdf}
}

@article{korkontzelos_ascot:_2012,
	title = {{ASCOT}: a text mining-based web-service for efficient search and assisted creation of clinical trials},
	volume = {12},
	issn = {1472-6947},
	shorttitle = {{ASCOT}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3339391/},
	doi = {10.1186/1472-6947-12-S1-S3},
	abstract = {Clinical trials are mandatory protocols describing medical research on humans and among the most valuable sources of medical practice evidence. Searching for trials relevant to some query is laborious due to the immense number of existing protocols. Apart from search, writing new trials includes composing detailed eligibility criteria, which might be time-consuming, especially for new researchers. In this paper we present ASCOT, an efficient search application customised for clinical trials. ASCOT uses text mining and data mining methods to enrich clinical trials with metadata, that in turn serve as effective tools to narrow down search. In addition, ASCOT integrates a component for recommending eligibility criteria based on a set of selected protocols.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Korkontzelos, Ioannis and Mu, Tingting and Ananiadou, Sophia},
	month = apr,
	year = {2012},
	pmid = {22595088},
	pmcid = {PMC3339391},
	pages = {S3},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/Z3I2H5WK/Korkontzelos et al. - 2012 - ASCOT a text mining-based web-service for efficie.pdf:application/pdf}
}

@article{miwa_boosting_2012,
	title = {Boosting automatic event extraction from the literature using domain adaptation and coreference resolution},
	volume = {28},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3381963/},
	doi = {10.1093/bioinformatics/bts237},
	abstract = {Motivation: In recent years, several biomedical event extraction (EE) systems have been developed. However, the nature of the annotated training corpora, as well as the training process itself, can limit the performance levels of the trained EE systems. In particular, most event-annotated corpora do not deal adequately with coreference. This impacts on the trained systems' ability to recognize biomedical entities, thus affecting their performance in extracting events accurately. Additionally, the fact that most EE systems are trained on a single annotated corpus further restricts their coverage., Results: We have enhanced our existing EE system, EventMine, in two ways. First, we developed a new coreference resolution (CR) system and integrated it with EventMine. The standalone performance of our CR system in resolving anaphoric references to proteins is considerably higher than the best ranked system in the COREF subtask of the BioNLP'11 Shared Task. Secondly, the improved EventMine incorporates domain adaptation (DA) methods, which extend EE coverage by allowing several different annotated corpora to be used during training. Combined with a novel set of methods to increase the generality and efficiency of EventMine, the integration of both CR and DA have resulted in significant improvements in EE, ranging between 0.5\% and 3.4\% F-Score. The enhanced EventMine outperforms the highest ranked systems from the BioNLP'09 shared task, and from the GENIA and Infectious Diseases subtasks of the BioNLP'11 shared task., Availability: The improved version of EventMine, incorporating the CR system and DA methods, is available at: http://www.nactem.ac.uk/EventMine/., Contact:
makoto.miwa@manchester.ac.uk},
	number = {13},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Miwa, Makoto and Thompson, Paul and Ananiadou, Sophia},
	month = jul,
	year = {2012},
	pmid = {22539668},
	pmcid = {PMC3381963},
	pages = {1759--1765},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/WDHLY9MC/Miwa et al. - 2012 - Boosting automatic event extraction from the liter.pdf:application/pdf}
}

@article{pyysalo_overview_2012,
	title = {Overview of the {ID}, {EPI} and {REL} tasks of {BioNLP} {Shared} {Task} 2011},
	volume = {13},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384257/},
	doi = {10.1186/1471-2105-13-S11-S2},
	abstract = {We present the preparation, resources, results and analysis of three tasks of the BioNLP Shared Task 2011: the main tasks on Infectious Diseases (ID) and Epigenetics and Post-translational Modifications (EPI), and the supporting task on Entity Relations (REL). The two main tasks represent extensions of the event extraction model introduced in the BioNLP Shared Task 2009 (ST'09) to two new areas of biomedical scientific literature, each motivated by the needs of specific biocuration tasks. The ID task concerns the molecular mechanisms of infection, virulence and resistance, focusing in particular on the functions of a class of signaling systems that are ubiquitous in bacteria. The EPI task is dedicated to the extraction of statements regarding chemical modifications of DNA and proteins, with particular emphasis on changes relating to the epigenetic control of gene expression. By contrast to these two application-oriented main tasks, the REL task seeks to support extraction in general by separating challenges relating to part-of relations into a subproblem that can be addressed by independent systems. Seven groups participated in each of the two main tasks and four groups in the supporting task. The participating systems indicated advances in the capability of event extraction methods and demonstrated generalization in many aspects: from abstracts to full texts, from previously considered subdomains to new ones, and from the ST'09 extraction targets to other entities and events. The highest performance achieved in the supporting task REL, 58\% F-score, is broadly comparable with levels reported for other relation extraction tasks. For the ID task, the highest-performing system achieved 56\% F-score, comparable to the state-of-the-art performance at the established ST'09 task. In the EPI task, the best result was 53\% F-score for the full set of extraction targets and 69\% F-score for a reduced set of core extraction targets, approaching a level of performance sufficient for user-facing applications. In this study, we extend on previously reported results and perform further analyses of the outputs of the participating systems. We place specific emphasis on aspects of system performance relating to real-world applicability, considering alternate evaluation metrics and performing additional manual analysis of system outputs. We further demonstrate that the strengths of extraction systems can be combined to improve on the performance achieved by any system in isolation. The manually annotated corpora, supporting resources, and evaluation tools for all tasks are available from http://www.bionlp-st.org and the tasks continue as open challenges for all interested parties.},
	number = {Suppl 11},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Pyysalo, Sampo and Ohta, Tomoko and Rak, Rafal and Sullivan, Dan and Mao, Chunhong and Wang, Chunxia and Sobral, Bruno and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = jun,
	year = {2012},
	pmid = {22759456},
	pmcid = {PMC3384257},
	pages = {S2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/FKEVAFIM/Pyysalo et al. - 2012 - Overview of the ID, EPI and REL tasks of BioNLP Sh.pdf:application/pdf}
}

@article{miwa_extracting_2012,
	title = {Extracting semantically enriched events from biomedical literature},
	volume = {13},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3464657/},
	doi = {10.1186/1471-2105-13-108},
	abstract = {Background
Research into event-based text mining from the biomedical literature has been growing in popularity to facilitate the development of advanced biomedical text mining systems. Such technology permits advanced search, which goes beyond document or sentence-based retrieval. However, existing event-based systems typically ignore additional information within the textual context of events that can determine, amongst other things, whether an event represents a fact, hypothesis, experimental result or analysis of results, whether it describes new or previously reported knowledge, and whether it is speculated or negated. We refer to such contextual information as meta-knowledge. The automatic recognition of such information can permit the training of systems allowing finer-grained searching of events according to the meta-knowledge that is associated with them.

Results
Based on a corpus of 1,000 MEDLINE abstracts, fully manually annotated with both events and associated meta-knowledge, we have constructed a machine learning-based system that automatically assigns meta-knowledge information to events. This system has been integrated into EventMine, a state-of-the-art event extraction system, in order to create a more advanced system (EventMine-MK) that not only extracts events from text automatically, but also assigns five different types of meta-knowledge to these events. The meta-knowledge assignment module of EventMine-MK performs with macro-averaged F-scores in the range of 57-87\% on the BioNLP’09 Shared Task corpus. EventMine-MK has been evaluated on the BioNLP’09 Shared Task subtask of detecting negated and speculated events. Our results show that EventMine-MK can outperform other state-of-the-art systems that participated in this task.

Conclusions
We have constructed the first practical system that extracts both events and associated, detailed meta-knowledge information from biomedical literature. The automatically assigned meta-knowledge information can be used to refine search systems, in order to provide an extra search layer beyond entities and assertions, dealing with phenomena such as rhetorical intent, speculations, contradictions and negations. This finer grained search functionality can assist in several important tasks, e.g., database curation (by locating new experimental knowledge) and pathway enrichment (by providing information for inference). To allow easy integration into text mining systems, EventMine-MK is provided as a UIMA component that can be used in the interoperable text mining infrastructure, U-Compare.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Miwa, Makoto and Thompson, Paul and McNaught, John and Kell, Douglas B and Ananiadou, Sophia},
	month = may,
	year = {2012},
	pmid = {22621266},
	pmcid = {PMC3464657},
	pages = {108},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/6F8NDIA2/Miwa et al. - 2012 - Extracting semantically enriched events from biome.pdf:application/pdf}
}

@article{mihaila_biocause:_2013,
	title = {{BioCause}: {Annotating} and analysing causality in the biomedical domain},
	volume = {14},
	issn = {1471-2105},
	shorttitle = {{BioCause}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3621543/},
	doi = {10.1186/1471-2105-14-2},
	abstract = {Background
Biomedical corpora annotated with event-level information represent an important resource for domain-specific information extraction (IE) systems. However, bio-event annotation alone cannot cater for all the needs of biologists. Unlike work on relation and event extraction, most of which focusses on specific events and named entities, we aim to build a comprehensive resource, covering all statements of causal association present in discourse. Causality lies at the heart of biomedical knowledge, such as diagnosis, pathology or systems biology, and, thus, automatic causality recognition can greatly reduce the human workload by suggesting possible causal connections and aiding in the curation of pathway models. A biomedical text corpus annotated with such relations is, hence, crucial for developing and evaluating biomedical text mining.

Results
We have defined an annotation scheme for enriching biomedical domain corpora with causality relations. This schema has subsequently been used to annotate 851 causal relations to form BioCause, a collection of 19 open-access full-text biomedical journal articles belonging to the subdomain of infectious diseases. These documents have been pre-annotated with named entity and event information in the context of previous shared tasks. We report an inter-annotator agreement rate of over 60\% for triggers and of over 80\% for arguments using an exact match constraint. These increase significantly using a relaxed match setting. Moreover, we analyse and describe the causality relations in BioCause from various points of view. This information can then be leveraged for the training of automatic causality detection systems.

Conclusion
Augmenting named entity and event annotations with information about causal discourse relations could benefit the development of more sophisticated IE systems. These will further influence the development of multiple tasks, such as enabling textual inference to detect entailments, discovering new facts and providing new hypotheses for experimental work.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Mihăilă, Claudiu and Ohta, Tomoko and Pyysalo, Sampo and Ananiadou, Sophia},
	month = jan,
	year = {2013},
	pmid = {23323613},
	pmcid = {PMC3621543},
	pages = {2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/V8HXLBQS/Mihăilă et al. - 2013 - BioCause Annotating and analysing causality in th.pdf:application/pdf}
}

@article{rak_processing_2014,
	title = {Processing biological literature with customizable {Web} services supporting interoperable formats},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4086403/},
	doi = {10.1093/database/bau064},
	abstract = {Web services have become a popular means of interconnecting solutions for processing a body of scientific literature. This has fuelled research on high-level data exchange formats suitable for a given domain and ensuring the interoperability of Web services. In this article, we focus on the biological domain and consider four interoperability formats, BioC, BioNLP, XMI and RDF, that represent domain-specific and generic representations and include well-established as well as emerging specifications. We use the formats in the context of customizable Web services created in our Web-based, text-mining workbench Argo that features an ever-growing library of elementary analytics and capabilities to build and deploy Web services straight from a convenient graphical user interface. We demonstrate a 2-fold customization of Web services: by building task-specific processing pipelines from a repository of available analytics, and by configuring services to accept and produce a combination of input and output data interchange formats. We provide qualitative evaluation of the formats as well as quantitative evaluation of automatic analytics. The latter was carried out as part of our participation in the fourth edition of the BioCreative challenge. Our analytics built into Web services for recognizing biochemical concepts in BioC collections achieved the highest combined scores out of 10 participating teams., Database URL:
http://argo.nactem.ac.uk.},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Rak, Rafal and Batista-Navarro, Riza Theresa and Carter, Jacob and Rowley, Andrew and Ananiadou, Sophia},
	month = jul,
	year = {2014},
	pmid = {25006225},
	pmcid = {PMC4086403},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DN9W96GZ/Rak et al. - 2014 - Processing biological literature with customizable.pdf:application/pdf}
}

@article{rak_text-mining-assisted_2014,
	title = {Text-mining-assisted biocuration workflows in {Argo}},
	volume = {2014},
	issn = {1758-0463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4103424/},
	doi = {10.1093/database/bau070},
	abstract = {Biocuration activities have been broadly categorized into the selection of relevant documents, the annotation of biological concepts of interest and identification of interactions between the concepts. Text mining has been shown to have a potential to significantly reduce the effort of biocurators in all the three activities, and various semi-automatic methodologies have been integrated into curation pipelines to support them. We investigate the suitability of Argo, a workbench for building text-mining solutions with the use of a rich graphical user interface, for the process of biocuration. Central to Argo are customizable workflows that users compose by arranging available elementary analytics to form task-specific processing units. A built-in manual annotation editor is the single most used biocuration tool of the workbench, as it allows users to create annotations directly in text, as well as modify or delete annotations created by automatic processing components. Apart from syntactic and semantic analytics, the ever-growing library of components includes several data readers and consumers that support well-established as well as emerging data interchange formats such as XMI, RDF and BioC, which facilitate the interoperability of Argo with other platforms or resources. To validate the suitability of Argo for curation activities, we participated in the BioCreative IV challenge whose purpose was to evaluate Web-based systems addressing user-defined biocuration tasks. Argo proved to have the edge over other systems in terms of flexibility of defining biocuration tasks. As expected, the versatility of the workbench inevitably lengthened the time the curators spent on learning the system before taking on the task, which may have affected the usability of Argo. The participation in the challenge gave us an opportunity to gather valuable feedback and identify areas of improvement, some of which have already been introduced., Database URL:
http://argo.nactem.ac.uk},
	urldate = {2018-03-10},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Rak, Rafal and Batista-Navarro, Riza Theresa and Rowley, Andrew and Carter, Jacob and Ananiadou, Sophia},
	month = jul,
	year = {2014},
	pmid = {25037308},
	pmcid = {PMC4103424},
	keywords = {female first or senior},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/EBGQEGMD/Rak et al. - 2014 - Text-mining-assisted biocuration workflows in Argo.pdf:application/pdf}
}

@article{stenetorp_generalising_2014,
	title = {Generalising semantic category disambiguation with large lexical resources for fun and profit},
	volume = {5},
	issn = {2041-1480},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4107982/},
	doi = {10.1186/2041-1480-5-26},
	abstract = {Background
Semantic Category Disambiguation (SCD) is the task of assigning the appropriate semantic category to given spans of text from a fixed set of candidate categories, for example Protein to “Fibrin”. SCD is relevant to Natural Language Processing tasks such as Named Entity Recognition, coreference resolution and coordination resolution. In this work, we study machine learning-based SCD methods using large lexical resources and approximate string matching, aiming to generalise these methods with regard to domains, lexical resources and the composition of data sets. We specifically consider the applicability of SCD for the purposes of supporting human annotators and acting as a pipeline component for other Natural Language Processing systems.

Results
While previous research has mostly cast SCD purely as a classification task, we consider a task setting that allows for multiple semantic categories to be suggested, aiming to minimise the number of suggestions while maintaining high recall. We argue that this setting reflects aspects which are essential for both a pipeline component and when supporting human annotators. We introduce an SCD method based on a recently introduced machine learning-based system and evaluate it on 15 corpora covering biomedical, clinical and newswire texts and ranging in the number of semantic categories from 2 to 91., With appropriate settings, our system maintains an average recall of 99\% while reducing the number of candidate semantic categories on average by 65\% over all data sets.

Conclusions
Machine learning-based SCD using large lexical resources and approximate string matching is sensitive to the selection and granularity of lexical resources, but generalises well to a wide range of text domains and data sets given appropriate resources and parameter settings. By substantially reducing the number of candidate categories while only very rarely excluding the correct one, our method is shown to be applicable to manual annotation support tasks and use as a high-recall component in text processing pipelines. The introduced system and all related resources are freely available for research purposes at: https://github.com/ninjin/simsem.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Semantics},
	author = {Stenetorp, Pontus and Pyysalo, Sampo and Ananiadou, Sophia and Tsujii, Jun’ichi},
	month = jun,
	year = {2014},
	pmid = {25093067},
	pmcid = {PMC4107982},
	pages = {26},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/4JQCXIUW/Stenetorp et al. - 2014 - Generalising semantic category disambiguation with.pdf:application/pdf}
}

@article{miwa_reducing_2014,
	title = {Reducing systematic review workload through certainty-based screening},
	volume = {51},
	issn = {1532-0464},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4199186/},
	doi = {10.1016/j.jbi.2014.06.005},
	abstract = {•
              Active learning is promising in the areas with complex topics in systematic reviews.
            
            
              •
              Certainty criteria is promising to accelerate screening regardless of the topic.
            
            
              •
              Certainty criteria performs as well as uncertainty criteria in classification.
            
            
              •
              Weighting positive instances is promising to overcome the data imbalance.
            
            
              •
              Unsupervised methods enhance the classification performance.
            
          
        , In systematic reviews, the growing number of published studies imposes a significant screening workload on reviewers. Active learning is a promising approach to reduce the workload by automating some of the screening decisions, but it has been evaluated for a limited number of disciplines. The suitability of applying active learning to complex topics in disciplines such as social science has not been studied, and the selection of useful criteria and enhancements to address the data imbalance problem in systematic reviews remains an open problem. We applied active learning with two criteria (certainty and uncertainty) and several enhancements in both clinical medicine and social science (specifically, public health) areas, and compared the results in both. The results show that the certainty criterion is useful for finding relevant documents, and weighting positive instances is promising to overcome the data imbalance problem in both data sets. Latent dirichlet allocation (LDA) is also shown to be promising when little manually-assigned information is available. Active learning is effective in complex topics, although its efficiency is limited due to the difficulties in text classification. The most promising criterion and weighting method are the same regardless of the review topic, and unsupervised techniques like LDA have a possibility to boost the performance of active learning without manual annotation.},
	urldate = {2018-03-10},
	journal = {Journal of Biomedical Informatics},
	author = {Miwa, Makoto and Thomas, James and O’Mara-Eves, Alison and Ananiadou, Sophia},
	month = oct,
	year = {2014},
	pmid = {24954015},
	pmcid = {PMC4199186},
	pages = {242--253}
}

@article{xu_anatomical_2014,
	title = {Anatomical {Entity} {Recognition} with a {Hierarchical} {Framework} {Augmented} by {External} {Resources}},
	volume = {9},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4208750/},
	doi = {10.1371/journal.pone.0108396},
	abstract = {References to anatomical entities in medical records consist not only of explicit references to anatomical locations, but also other diverse types of expressions, such as specific diseases, clinical tests, clinical treatments, which constitute implicit references to anatomical entities. In order to identify these implicit anatomical entities, we propose a hierarchical framework, in which two layers of named entity recognizers (NERs) work in a cooperative manner. Each of the NERs is implemented using the Conditional Random Fields (CRF) model, which use a range of external resources to generate features. We constructed a dictionary of anatomical entity expressions by exploiting four existing resources, i.e., UMLS, MeSH, RadLex and BodyPart3D, and supplemented information from two external knowledge bases, i.e., Wikipedia and WordNet, to improve inference of anatomical entities from implicit expressions.  conducted on 300 discharge summaries showed a micro-averaged performance of 0.8509 Precision, 0.7796 Recall and 0.8137 F1 for explicit anatomical entity recognition, and 0.8695 Precision, 0.6893 Recall and 0.7690 F1 for implicit anatomical entity recognition. The use of the hierarchical framework, which combines the recognition of named entities of various types (diseases, clinical tests, treatments) with information embedded in external knowledge bases, resulted in a 5.08\% increment in F1. The resources constructed for this research will be made publicly available.},
	number = {10},
	urldate = {2018-03-10},
	journal = {PLoS ONE},
	author = {Xu, Yan and Hua, Ji and Ni, Zhaoheng and Chen, Qinlang and Fan, Yubo and Ananiadou, Sophia and Chang, Eric I-Chao and Tsujii, Junichi},
	month = oct,
	year = {2014},
	pmid = {25343498},
	pmcid = {PMC4208750},
	keywords = {NER},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/BGV2YVCS/Xu et al. - 2014 - Anatomical Entity Recognition with a Hierarchical .pdf:application/pdf}
}

@article{mihaila_semi-supervised_2014,
	title = {Semi-supervised learning of causal relations in biomedical scientific discourse},
	volume = {13},
	issn = {1475-925X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4304242/},
	doi = {10.1186/1475-925X-13-S2-S1},
	abstract = {Background
The increasing number of daily published articles in the biomedical domain has become too large for humans to handle on their own. As a result, bio-text mining technologies have been developed to improve their workload by automatically analysing the text and extracting important knowledge. Specific bio-entities, bio-events between these and facts can now be recognised with sufficient accuracy and are widely used by biomedical researchers. However, understanding how the extracted facts are connected in text is an extremely difficult task, which cannot be easily tackled by machinery.

Results
In this article, we describe our method to recognise causal triggers and their arguments in biomedical scientific discourse. We introduce new features and show that a self-learning approach improves the performance obtained by supervised machine learners to 83.47\% for causal triggers. Furthermore, the spans of causal arguments can be recognised to a slightly higher level that by using supervised or rule-based methods that have been employed before.

Conclusion
Exploiting the large amount of unlabelled data that is already available can help improve the performance of recognising causal discourse relations in the biomedical domain. This improvement will further benefit the development of multiple tasks, such as hypothesis generation for experimental laboratories, contradiction detection, and the creation of causal networks.},
	number = {Suppl 2},
	urldate = {2018-03-10},
	journal = {BioMedical Engineering OnLine},
	author = {Mihăilă, Claudiu and Ananiadou, Sophia},
	month = dec,
	year = {2014},
	pmid = {25559746},
	pmcid = {PMC4304242},
	keywords = {female first or senior},
	pages = {S1},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7N46XFLL/Mihăilă and Ananiadou - 2014 - Semi-supervised learning of causal relations in bi.pdf:application/pdf}
}

@article{batista-navarro_optimising_2015,
	title = {Optimising chemical named entity recognition with pre-processing analytics, knowledge-rich features and heuristics},
	volume = {7},
	issn = {1758-2946},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331696/},
	doi = {10.1186/1758-2946-7-S1-S6},
	abstract = {Background
The development of robust methods for chemical named entity recognition, a challenging natural language processing task, was previously hindered by the lack of publicly available, large-scale, gold standard corpora. The recent public release of a large chemical entity-annotated corpus as a resource for the CHEMDNER track of the Fourth BioCreative Challenge Evaluation (BioCreative IV) workshop greatly alleviated this problem and allowed us to develop a conditional random fields-based chemical entity recogniser. In order to optimise its performance, we introduced customisations in various aspects of our solution. These include the selection of specialised pre-processing analytics, the incorporation of chemistry knowledge-rich features in the training and application of the statistical model, and the addition of post-processing rules.

Results
Our evaluation shows that optimal performance is obtained when our customisations are integrated into the chemical entity recogniser. When its performance is compared with that of state-of-the-art methods, under comparable experimental settings, our solution achieves competitive advantage. We also show that our recogniser that uses a model trained on the CHEMDNER corpus is suitable for recognising names in a wide range of corpora, consistently outperforming two popular chemical NER tools.

Conclusion
The contributions resulting from this work are two-fold. Firstly, we present the details of a chemical entity recognition methodology that has demonstrated performance at a competitive, if not superior, level as that of state-of-the-art methods. Secondly, the developed suite of solutions has been made publicly available as a configurable workflow in the interoperable text mining workbench Argo. This allows interested users to conveniently apply and evaluate our solutions in the context of other chemical text mining tasks.},
	number = {Suppl 1},
	urldate = {2018-03-10},
	journal = {Journal of Cheminformatics},
	author = {Batista-Navarro, Riza and Rak, Rafal and Ananiadou, Sophia},
	month = jan,
	year = {2015},
	pmid = {25810777},
	pmcid = {PMC4331696},
	keywords = {female first or senior, NER},
	pages = {S6},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/J5XYM6W5/Batista-Navarro et al. - 2015 - Optimising chemical named entity recognition with .pdf:application/pdf}
}

@article{omara-eves_erratum_2015,
	title = {Erratum to: {Using} text mining for study identification in systematic reviews: a systematic review of current approaches},
	volume = {4},
	issn = {2046-4053},
	shorttitle = {Erratum to},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4411935/},
	doi = {10.1186/s13643-015-0031-5},
	urldate = {2018-03-10},
	journal = {Systematic Reviews},
	author = {O’Mara-Eves, Alison and Thomas, James and McNaught, John and Miwa, Makoto and Ananiadou, Sophia},
	month = apr,
	year = {2015},
	pmid = {25927201},
	pmcid = {PMC4411935},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/8LCQKUU3/O’Mara-Eves et al. - 2015 - Erratum to Using text mining for study identifica.pdf:application/pdf}
}

@article{xu_bilingual_2015,
	title = {Bilingual term alignment from comparable corpora in {English} discharge summary and {Chinese} discharge summary},
	volume = {16},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4424557/},
	doi = {10.1186/s12859-015-0606-0},
	abstract = {Background
Electronic medical record (EMR) systems have become widely used throughout the world to improve the quality of healthcare and the efficiency of hospital services. A bilingual medical lexicon of Chinese and English is needed to meet the demand for the multi-lingual and multi-national treatment. We make efforts to extract a bilingual lexicon from English and Chinese discharge summaries with a small seed lexicon. The lexical terms can be classified into two categories: single-word terms (SWTs) and multi-word terms (MWTs). For SWTs, we use a label propagation (LP; context-based) method to extract candidates of translation pairs. For MWTs, which are pervasive in the medical domain, we propose a term alignment method, which firstly obtains translation candidates for each component word of a Chinese MWT, and then generates their combinations, from which the system selects a set of plausible translation candidates.

Results
We compare our LP method with a baseline method based on simple context-similarity. The LP based method outperforms the baseline with the accuracies: 4.44\% Acc1, 24.44\% Acc10, and 62.22\% Acc100, where AccN means the top N accuracy. The accuracy of the LP method drops to 5.41\% Acc10 and 8.11\% Acc20 for MWTs. Our experiments show that the method based on term alignment improves the performance for MWTs to 16.22\% Acc10 and 27.03\% Acc20.

Conclusions
We constructed a framework for building an English-Chinese term dictionary from discharge summaries in the two languages. Our experiments have shown that the LP-based method augmented with the term alignment method will contribute to reduction of manual work required to compile a bilingual sydictionary of clinical terms.},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Xu, Yan and Chen, Luoxin and Wei, Junsheng and Ananiadou, Sophia and Fan, Yubo and Qian, Yi and Chang, Eric I-Chao and Tsujii, Junichi},
	month = may,
	year = {2015},
	pmid = {25956056},
	pmcid = {PMC4424557},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7KNNYEHD/Xu et al. - 2015 - Bilingual term alignment from comparable corpora i.pdf:application/pdf}
}

@article{ananiadou_event-based_2015,
	title = {Event-based text mining for biology and functional genomics},
	volume = {14},
	issn = {2041-2649},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4499874/},
	doi = {10.1093/bfgp/elu015},
	abstract = {The assessment of genome function requires a mapping between genome-derived entities and biochemical reactions, and the biomedical literature represents a rich source of information about reactions between biological components. However, the increasingly rapid growth in the volume of literature provides both a challenge and an opportunity for researchers to isolate information about reactions of interest in a timely and efficient manner. In response, recent text mining research in the biology domain has been largely focused on the identification and extraction of ‘events’, i.e. categorised, structured representations of relationships between biochemical entities, from the literature. Functional genomics analyses necessarily encompass events as so defined. Automatic event extraction systems facilitate the development of sophisticated semantic search applications, allowing researchers to formulate structured queries over extracted events, so as to specify the exact types of reactions to be retrieved. This article provides an overview of recent research into event extraction. We cover annotated corpora on which systems are trained, systems that achieve state-of-the-art performance and details of the community shared tasks that have been instrumental in increasing the quality, coverage and scalability of recent systems. Finally, several concrete applications of event extraction are covered, together with emerging directions of research.},
	number = {3},
	urldate = {2018-03-10},
	journal = {Briefings in Functional Genomics},
	author = {Ananiadou, Sophia and Thompson, Paul and Nawaz, Raheel and McNaught, John and Kell, Douglas B.},
	month = may,
	year = {2015},
	pmid = {24907365},
	pmcid = {PMC4499874},
	keywords = {female first or senior},
	pages = {213--230},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/VUS5G926/Ananiadou et al. - 2015 - Event-based text mining for biology and functional.pdf:application/pdf}
}

@article{tsuruoka_facta:_2008,
	title = {{FACTA}: a text search engine for finding associated biomedical concepts},
	volume = {24},
	issn = {1367-4803},
	shorttitle = {{FACTA}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2572701/},
	doi = {10.1093/bioinformatics/btn469},
	abstract = {Summary: FACTA is a text search engine for MEDLINE abstracts, which is designed particularly to help users browse biomedical concepts (e.g. genes/proteins, diseases, enzymes and chemical compounds) appearing in the documents retrieved by the query. The concepts are presented to the user in a tabular format and ranked based on the co-occurrence statistics. Unlike existing systems that provide similar functionality, FACTA pre-indexes not only the words but also the concepts mentioned in the documents, which enables the user to issue a flexible query (e.g. free keywords or Boolean combinations of keywords/concepts) and receive the results immediately even when the number of the documents that match the query is very large. The user can also view snippets from MEDLINE to get textual evidence of associations between the query terms and the concepts. The concept IDs and their names/synonyms for building the indexes were collected from several biomedical databases and thesauri, such as UniProt, BioThesaurus, UMLS, KEGG and DrugBank., Availability: The system is available at http://www.nactem.ac.uk/software/facta/, Contact: yoshimasa.tsuruoka@manchester.ac.uk},
	number = {21},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Tsuruoka, Yoshimasa and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = nov,
	year = {2008},
	pmid = {18772154},
	pmcid = {PMC2572701},
	pages = {2559--2560}
}

@article{tsuruoka_accelerating_2008,
	title = {Accelerating the annotation of sparse named entities by dynamic sentence selection},
	volume = {9},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2586757/},
	doi = {10.1186/1471-2105-9-S11-S8},
	abstract = {Background
Previous studies of named entity recognition have shown that a reasonable level of recognition accuracy can be achieved by using machine learning models such as conditional random fields or support vector machines. However, the lack of training data (i.e. annotated corpora) makes it difficult for machine learning-based named entity recognizers to be used in building practical information extraction systems.

Results
This paper presents an active learning-like framework for reducing the human effort required to create named entity annotations in a corpus. In this framework, the annotation work is performed as an iterative and interactive process between the human annotator and a probabilistic named entity tagger. Unlike active learning, our framework aims to annotate all occurrences of the target named entities in the given corpus, so that the resulting annotations are free from the sampling bias which is inevitable in active learning approaches.

Conclusion
We evaluate our framework by simulating the annotation process using two named entity corpora and show that our approach can reduce the number of sentences which need to be examined by the human annotator. The cost reduction achieved by the framework could be drastic when the target named entities are sparse.},
	number = {Suppl 11},
	urldate = {2018-03-10},
	journal = {BMC Bioinformatics},
	author = {Tsuruoka, Yoshimasa and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = nov,
	year = {2008},
	pmid = {19025694},
	pmcid = {PMC2586757},
	keywords = {female first or senior, NER},
	pages = {S8},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/7FHSVCQY/Tsuruoka et al. - 2008 - Accelerating the annotation of sparse named entiti.pdf:application/pdf}
}

@article{wang_disambiguating_2010,
	title = {Disambiguating the species of biomedical named entities using natural language parsers},
	volume = {26},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2828111/},
	doi = {10.1093/bioinformatics/btq002},
	abstract = {Motivation: Text mining technologies have been shown to reduce the laborious work involved in organizing the vast amount of information hidden in the literature. One challenge in text mining is linking ambiguous word forms to unambiguous biological concepts. This article reports on a comprehensive study on resolving the ambiguity in mentions of biomedical named entities with respect to model organisms and presents an array of approaches, with focus on methods utilizing natural language parsers., Results: We build a corpus for organism disambiguation where every occurrence of protein/gene entity is manually tagged with a species ID, and evaluate a number of methods on it. Promising results are obtained by training a machine learning model on syntactic parse trees, which is then used to decide whether an entity belongs to the model organism denoted by a neighbouring species-indicating word (e.g. yeast). The parser-based approaches are also compared with a supervised classification method and results indicate that the former are a more favorable choice when domain portability is of concern. The best overall performance is obtained by combining the strengths of syntactic features and supervised classification., Availability: The corpus and demo are available at http://www.nactem.ac.uk/deca\_details/start.cgi, and the software is freely available as U-Compare components (Kano et al., ): NaCTeM Species Word Detector and NaCTeM Species Disambiguator. U-Compare is available at http://-compare.org/, Contact: xinglong.wang@manchester.ac.uk},
	number = {5},
	urldate = {2018-03-10},
	journal = {Bioinformatics},
	author = {Wang, Xinglong and Tsujii, Jun'ichi and Ananiadou, Sophia},
	month = mar,
	year = {2010},
	pmid = {20053840},
	pmcid = {PMC2828111},
	pages = {661--667},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/YPULJU82/Wang et al. - 2010 - Disambiguating the species of biomedical named ent.pdf:application/pdf}
}

@article{ananiadou_supporting_2010,
	title = {Supporting the education evidence portal via text mining},
	volume = {368},
	issn = {1364-503X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2981997/},
	doi = {10.1098/rsta.2010.0152},
	abstract = {The UK Education Evidence Portal (eep) provides a single, searchable, point of access to the contents of the websites of 33 organizations relating to education, with the aim of revolutionizing work practices for the education community. Use of the portal alleviates the need to spend time searching multiple resources to find relevant information. However, the combined content of the websites of interest is still very large (over 500 000 documents and growing). This means that searches using the portal can produce very large numbers of hits. As users often have limited time, they would benefit from enhanced methods of performing searches and viewing results, allowing them to drill down to information of interest more efficiently, without having to sift through potentially long lists of irrelevant documents. The Joint Information Systems Committee (JISC)-funded ASSIST project has produced a prototype web interface to demonstrate the applicability of integrating a number of text-mining tools and methods into the eep, to facilitate an enhanced searching, browsing and document-viewing experience. New features include automatic classification of documents according to a taxonomy, automatic clustering of search results according to similar document content, and automatic identification and highlighting of key terms within documents.},
	number = {1925},
	urldate = {2018-03-10},
	journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
	author = {Ananiadou, Sophia and Thompson, Paul and Thomas, James and Mu, Tingting and Oliver, Sandy and Rickinson, Mark and Sasaki, Yutaka and Weissenbacher, Davy and McNaught, John},
	month = aug,
	year = {2010},
	pmid = {20643679},
	pmcid = {PMC2981997},
	keywords = {female first or senior},
	pages = {3829--3844},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ZIWLF7MG/Ananiadou et al. - 2010 - Supporting the education evidence portal via text .pdf:application/pdf}
}

@article{nobata_mining_2011,
	title = {Mining metabolites: extracting the yeast metabolome from the literature},
	volume = {7},
	issn = {1573-3882},
	shorttitle = {Mining metabolites},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3111869/},
	doi = {10.1007/s11306-010-0251-6},
	abstract = {Text mining methods have added considerably to our capacity to extract biological knowledge from the literature. Recently the field of systems biology has begun to model and simulate metabolic networks, requiring knowledge of the set of molecules involved. While genomics and proteomics technologies are able to supply the macromolecular parts list, the metabolites are less easily assembled. Most metabolites are known and reported through the scientific literature, rather than through large-scale experimental surveys. Thus it is important to recover them from the literature. Here we present a novel tool to automatically identify metabolite names in the literature, and associate structures where possible, to define the reported yeast metabolome. With ten-fold cross validation on a manually annotated corpus, our recognition tool generates an f-score of 78.49 (precision of 83.02) and demonstrates greater suitability in identifying metabolite names than other existing recognition tools for general chemical molecules. The metabolite recognition tool has been applied to the literature covering an important model organism, the yeast Saccharomyces cerevisiae, to define its reported metabolome. By coupling to ChemSpider, a major chemical database, we have identified structures for much of the reported metabolome and, where structure identification fails, been able to suggest extensions to ChemSpider. Our manually annotated gold-standard data on 296 abstracts are available as supplementary materials. Metabolite names and, where appropriate, structures are also available as supplementary materials.},
	number = {1},
	urldate = {2018-03-10},
	journal = {Metabolomics},
	author = {Nobata, Chikashi and Dobson, Paul D. and Iqbal, Syed A. and Mendes, Pedro and Tsujii, Jun’ichi and Kell, Douglas B. and Ananiadou, Sophia},
	month = mar,
	year = {2011},
	pmid = {21687783},
	pmcid = {PMC3111869},
	pages = {94--101},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/MDWJCMX3/Nobata et al. - 2011 - Mining metabolites extracting the yeast metabolom.pdf:application/pdf}
}

@article{haerian_methods_2012-1,
	title = {Methods for identifying suicide or suicidal ideation in {EHRs}},
	volume = {2012},
	issn = {1942-597X},
	abstract = {Electronic health records contain important data elements for detection of novel adverse drug reactions, genotype/phenotype identification and psychosocial factor analysis, and the role of each of these as risk factors for suicidality warrants further investigation. Suicide and suicidal ideation are documented in clinical narratives. The specific purpose of this study was to define an algorithm for automated detection of this serious event. We found that ICD-9 E-Codes had the lowest positive predictive value: 0.55 (90\% CI: 0.42-0.67), while combining ICD-9 and NLP had the best PPV: 0.97 (90\% CI: 0.92-0.99). A qualitative analysis and classification of the types of errors by ICD-9 and NLP automated coding compared to manual review are also discussed.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Haerian, K. and Salmasian, H. and Friedman, C.},
	year = {2012},
	pmid = {23304402},
	pmcid = {PMC3540459},
	pages = {1244--1253}
}

@article{haerian_methods_2012-2,
	title = {Methods for {Identifying} {Suicide} or {Suicidal} {Ideation} in {EHRs}},
	volume = {2012},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540459/},
	abstract = {Electronic health records contain important data elements for detection of novel adverse drug reactions, genotype/phenotype identification and psychosocial factor analysis, and the role of each of these as risk factors for suicidality warrants further investigation. Suicide and suicidal ideation are documented in clinical narratives. The specific purpose of this study was to define an algorithm for automated detection of this serious event. We found that ICD-9 E-Codes had the lowest positive predictive value: 0.55 (90\% CI: 0.42–0.67), while combining ICD-9 and NLP had the best PPV: 0.97 (90\% CI: 0.92–0.99). A qualitative analysis and classification of the types of errors by ICD-9 and NLP automated coding compared to manual review are also discussed.},
	urldate = {2018-03-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Haerian, K and Salmasian, H and Friedman, C},
	month = nov,
	year = {2012},
	pmid = {23304402},
	pmcid = {PMC3540459},
	pages = {1244--1253},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/QFBEXU48/Haerian et al. - 2012 - Methods for Identifying Suicide or Suicidal Ideati.pdf:application/pdf}
}

@misc{noauthor_natural_nodate,
	title = {Natural language processing: {State} of the art and prospects for significant progress, a workshop sponsored by the {National} {Library} of {Medicine} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046413000798?via%3Dihub},
	urldate = {2018-03-10},
	file = {Natural language processing\: State of the art and prospects for significant progress, a workshop sponsored by the National Library of Medicine - ScienceDirect:/Users/transfer/Zotero/storage/X7KVU7S5/S1532046413000798.html:text/html}
}

@article{vilar_detection_2017,
	title = {Detection of drug-drug interactions through data mining studies using clinical sources, scientific literature and social media},
	issn = {1477-4054},
	doi = {10.1093/bib/bbx010},
	abstract = {Drug-drug interactions (DDIs) constitute an important concern in drug development and postmarketing pharmacovigilance. They are considered the cause of many adverse drug effects exposing patients to higher risks and increasing public health system costs. Methods to follow-up and discover possible DDIs causing harm to the population are a primary aim of drug safety researchers. Here, we review different methodologies and recent advances using data mining to detect DDIs with impact on patients. We focus on data mining of different pharmacovigilance sources, such as the US Food and Drug Administration Adverse Event Reporting System and electronic health records from medical institutions, as well as on the diverse data mining studies that use narrative text available in the scientific biomedical literature and social media. We pay attention to the strengths but also further explain challenges related to these methods. Data mining has important applications in the analysis of DDIs showing the impact of the interactions as a cause of adverse effects, extracting interactions to create knowledge data sets and gold standards and in the discovery of novel and dangerous DDIs.},
	language = {eng},
	journal = {Briefings in Bioinformatics},
	author = {Vilar, Santiago and Friedman, Carol and Hripcsak, George},
	month = feb,
	year = {2017},
	pmid = {28334070}
}

@misc{noauthor_deriving_nodate,
	title = {Deriving a probabilistic syntacto-semantic grammar for biomedicine based on domain-specific terminologies},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3172402/},
	urldate = {2018-03-10},
	file = {Deriving a probabilistic syntacto-semantic grammar for biomedicine based on domain-specific terminologies:/Users/transfer/Zotero/storage/85PLSXDF/PMC3172402.html:text/html}
}

@article{friedman_umls_1992,
	title = {The {UMLS} coverage of clinical radiology.},
	issn = {0195-4210},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2248002/},
	abstract = {The informational content of clinical radiology reports was examined to determine the coverage of the Unified Medical Language System (UMLS) in relation to the terminology used by physicians in the Radiology Department of Columbia Presbyterian Medical Center (CPMC). The UMLS semantic network contained 17 semantic types which were compatible with the types of clinical information in the reports. The type of semantic categories missing from the UMLS consisted mainly of modifier information relating to certainty, degree, and change type of information. This type of information formed a substantial part of the domain. Although most of the informational categories were found in the UMLS semantic network, most of the domain terms were not. Our results strongly suggest that the UMLS could be a significant tool for developing clinical text processing applications if it were extended to cover clinical domains.},
	urldate = {2018-03-10},
	journal = {Proceedings of the Annual Symposium on Computer Application in Medical Care},
	author = {Friedman, C.},
	year = {1992},
	pmid = {1482888},
	pmcid = {PMC2248002},
	pages = {309--313},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/SK93XTXR/Friedman - 1992 - The UMLS coverage of clinical radiology..pdf:application/pdf}
}

@article{friedman_evaluating_1998,
	title = {Evaluating natural language processors in the clinical domain},
	volume = {37},
	issn = {0026-1270},
	abstract = {Evaluating natural language processing (NLP) systems in the clinical domain is a difficult task which is important for advancement of the field. A number of NLP systems have been reported that extract information from free-text clinical reports, but not many of the systems have been evaluated. Those that were evaluated noted good performance measures but the results were often weakened by ineffective evaluation methods. In this paper we describe a set of criteria aimed at improving the quality of NLP evaluation studies. We present an overview of NLP evaluations in the clinical domain and also discuss the Message Understanding Conferences (MUC) [1-4]. Although these conferences constitute a series of NLP evaluation studies performed outside of the clinical domain, some of the results are relevant within medicine. In addition, we discuss a number of factors which contribute to the complexity that is inherent in the task of evaluating natural language systems.},
	language = {eng},
	number = {4-5},
	journal = {Methods of Information in Medicine},
	author = {Friedman, C. and Hripcsak, G.},
	month = nov,
	year = {1998},
	pmid = {9865031},
	pages = {334--344}
}

@article{bieliaieva_paronymy_2017,
	title = {{PARONYMY} {IN} {THE} {SUBLANGUAGE} {OF} {MEDICINE} ({LINGUISTIC} {AND} {LINGUO}-{DIDACTIC} {ASPECTS})},
	issn = {1512-0112},
	abstract = {The present paper examines the phenomenon of paronymy in the sublanguage of medicine. The study of paronyms plays an important role in the development of terminological competence of future specialists in the field of medicine and healthcare. The authors emphasize the need to pay due attention to terminological paronyms when compiling teaching manuals and developing didactic materials in Latin for students of medical universities. The urgency of organizing the work with these lexical units is determined, on the one hand, by the propaedeutic objective - minimization of difficulties that students may encounter in dealing with special terminology in the process of educational and professional communication; on the other hand, the study of paronyms is aimed at expanding the active and passive vocabulary of medical students. The objective of the research is to systematize paronyms in the international medical terminology, to develop the cycle of training assignments and methodological recommendations for organizing the work with this group of lexical units, and minimizing errors in oral and written speech of medical students. The authors have justified the methodological algorithm for the proposed cycle of tasks: presentation of the basic paronymic pairs, learning the vocabulary, control of mastering the material, creation of didactic conditions for correction and propaedeutics of speech errors; revision of the material. The proposed cycle of educational tasks is aimed at improving the lexical, grammatical, word-building, spelling knowledge, skills and abilities, as well as expanding and enriching the vocabulary of future medical professionals. The study may be of interest to specialists in the field of translation and terminology studies, professional linguo-didactics. The prospects for study consist in further in-depth research of the phenomenon of paronymy in the sublanguage of medicine and comprehensive analysis of other lexico-semantic relationships, the practical result of which will be the compilation of Latin medical dictionary of synonyms, homonyms and paronyms.},
	language = {eng},
	number = {271},
	journal = {Georgian Medical News},
	author = {Bieliaieva, O. and Lysanets, Yu and Havrylieva, K. and Znamenska, I. and Rozhenko, I. and Nikolaieva, N.},
	month = oct,
	year = {2017},
	pmid = {29099718},
	pages = {144--149}
}

@article{liu_facilitating_2014,
	title = {Facilitating post-surgical complication detection through sublanguage analysis},
	volume = {2014},
	issn = {2153-4063},
	abstract = {Identification of postsurgical complications is the first step towards improving patient safety and health care quality as well as reducing heath care cost. Existing NLP-based approaches for retrieving postsurgical complications are based on search strategies. Here, we conduct a sublanguage analysis study using free text reports available for a cohort of patients with postsurgical complications identified manually to compare the keywords identified by subject matter experts with words/phrases automatically identified by sublanguage analysis. The results suggest that search-based approaches may miss some cases and the sublanguage analysis results can be used as a base to develop an information extraction system or support search-based NLP approaches by augmenting search queries.},
	language = {eng},
	journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
	author = {Liu, Hongfang and Sohn, Sunghwan and Murphy, Sean and Lovely, Jenna and Burton, Matthew and Naessens, James and Larson, David W.},
	year = {2014},
	pmid = {25717405},
	pmcid = {PMC4333707},
	pages = {77--82}
}

@article{denecke_sublanguage_2014,
	title = {Sublanguage analysis of medical weblogs},
	volume = {205},
	issn = {0926-9630},
	abstract = {Analysing medical social media data gains in importance given an increased availability of such data. In this paper, we analyse the language of medical blogs by means of a sublanguage analysis. More specifically, verb usage, semantic categories of used words as well as co-occurrence patterns are determined by means of natural language processing tools. The results show that in this text type, many concepts refer to the semantic categories Living Beings and Chemicals and Drugs. In contrast to clinical documents, the spectrum of verbs in blogs is very broad creating semantic relations of different types. From these language characteristics, we conclude for automatic processing tools for medical blogs that methods for reference resolution and for relation extraction where the relation type does not need to be specified in advance are required.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Denecke, Kerstin},
	year = {2014},
	pmid = {25160249},
	pages = {565--569}
}

@article{spasic_text_2014,
	title = {Text mining of cancer-related information: review of current status and future directions},
	volume = {83},
	issn = {1872-8243},
	shorttitle = {Text mining of cancer-related information},
	doi = {10.1016/j.ijmedinf.2014.06.009},
	abstract = {PURPOSE: This paper reviews the research literature on text mining (TM) with the aim to find out (1) which cancer domains have been the subject of TM efforts, (2) which knowledge resources can support TM of cancer-related information and (3) to what extent systems that rely on knowledge and computational methods can convert text data into useful clinical information. These questions were used to determine the current state of the art in this particular strand of TM and suggest future directions in TM development to support cancer research.
METHODS: A review of the research on TM of cancer-related information was carried out. A literature search was conducted on the Medline database as well as IEEE Xplore and ACM digital libraries to address the interdisciplinary nature of such research. The search results were supplemented with the literature identified through Google Scholar.
RESULTS: A range of studies have proven the feasibility of TM for extracting structured information from clinical narratives such as those found in pathology or radiology reports. In this article, we provide a critical overview of the current state of the art for TM related to cancer. The review highlighted a strong bias towards symbolic methods, e.g. named entity recognition (NER) based on dictionary lookup and information extraction (IE) relying on pattern matching. The F-measure of NER ranges between 80\% and 90\%, while that of IE for simple tasks is in the high 90s. To further improve the performance, TM approaches need to deal effectively with idiosyncrasies of the clinical sublanguage such as non-standard abbreviations as well as a high degree of spelling and grammatical errors. This requires a shift from rule-based methods to machine learning following the success of similar trends in biological applications of TM. Machine learning approaches require large training datasets, but clinical narratives are not readily available for TM research due to privacy and confidentiality concerns. This issue remains the main bottleneck for progress in this area. In addition, there is a need for a comprehensive cancer ontology that would enable semantic representation of textual information found in narrative reports.},
	language = {eng},
	number = {9},
	journal = {International Journal of Medical Informatics},
	author = {Spasić, Irena and Livsey, Jacqueline and Keane, John A. and Nenadić, Goran},
	month = sep,
	year = {2014},
	pmid = {25008281},
	pages = {605--623}
}

@article{elhadad_characterizing_2014,
	title = {Characterizing the sublanguage of online breast cancer forums for medications, symptoms, and emotions},
	volume = {2014},
	issn = {1942-597X},
	abstract = {Online health communities play an increasingly prevalent role for patients and are the source of a growing body of research. A lexicon that represents the sublanguage of an online community is an important resource to enable analysis and tool development over this data source. This paper investigates a method to generate a lexicon representative of the language of members in a given community with respect to specific semantic types. We experiment with a breast cancer community and detect terms that belong to three semantic types: medications, symptoms and side effects, and emotions. We assess the ability of our automatically generated lexicons to detect new terms, and show that a data-driven approach captures the sublanguage of members in these communities, all the while increasing coverage of general-purpose terminologies. The code and the generated lexicons are made available to the research community.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Elhadad, Noémie and Zhang, Shaodian and Driscoll, Patricia and Brody, Samuel},
	year = {2014},
	pmid = {25954356},
	pmcid = {PMC4419934},
	pages = {516--525}
}

@article{doing-harris_document_2013,
	title = {Document {Sublanguage} {Clustering} to {Detect} {Medical} {Specialty} in {Cross}-institutional {Clinical} {Texts}},
	volume = {2013},
	doi = {10.1145/2512089.2512101},
	abstract = {This paper reports on a set of studies designed to identify sublanguages in documents for domain-specific processing across institutions. Psychological evidence indicates that humans use context-specific linguistic information when they read. Natural Language Processing (NLP) pipelines are successful within specific domains (i.e., contexts). To limit the number of domain-specific NLP systems, a natural focus would be on sublanguages. Sublanguages are identified by shared lexical and semantic features.[1] Patterson and Hurdle[2] developed a sublanguage identification system that functioned well for 12 clinical specialties at the University of Utah. The current work compares sublanguages across institutions. Using a clinical NLP pipeline augmented by a new document corpus from the University of Pittsburg (UPitt), new documents were assigned to clusters based on the minimum cosine-distance to a Utah cluster centroid. The UPitt documents were divided into a nine-group specialty corpus. Across institutions, five of the specialty groups fell within the expected clusters. We find that clustering encounters difficulty due to documents with mixed sublanguages; naming convention differences across institutions; and document types used across specialties. The findings indicate that clinical specialty sublanguages can be identified across institutions.},
	language = {eng},
	journal = {Proceedings of the ACM ... International Workshop on Data and Text Mining in Biomedical Informatics. ACM International Workshop on Data and Text Mining in Biomedical Informatics},
	author = {Doing-Harris, Kristina and Patterson, Olga and Igo, Sean and Hurdle, John},
	month = nov,
	year = {2013},
	pmid = {27077137},
	pmcid = {PMC4827341},
	pages = {9--12}
}

@article{wang_study_2012,
	title = {A study of actions in operative notes},
	volume = {2012},
	issn = {1942-597X},
	abstract = {Operative notes contain rich information about techniques, instruments, and materials used in procedures. To assist development of effective information extraction (IE) techniques for operative notes, we investigated the sublanguage used to describe actions within the operative report 'procedure description' section. Deep parsing results of 362,310 operative notes with an expanded Stanford parser using the SPECIALIST Lexicon resulted in 200 verbs (92\% coverage) including 147 action verbs. Nominal action predicates for each action verb were gathered from WordNet, SPECIALIST Lexicon, New Oxford American Dictionary and Stedman's Medical Dictionary. Coverage gaps were seen in existing lexical, domain, and semantic resources (Unified Medical Language System (UMLS) Metathesaurus, SPECIALIST Lexicon, WordNet and FrameNet). Our findings demonstrate the need to construct surgical domain-specific semantic resources for IE from operative notes.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Wang, Yan and Pakhomov, Serguei and Burkart, Nora E. and Ryan, James O. and Melton, Genevieve B.},
	year = {2012},
	pmid = {23304423},
	pmcid = {PMC3540433},
	pages = {1431--1440}
}

@article{kate_unsupervised_2012,
	title = {Unsupervised grammar induction of clinical report sublanguage},
	volume = {3 Suppl 3},
	issn = {2041-1480},
	doi = {10.1186/2041-1480-3-S3-S4},
	abstract = {BACKGROUND: Clinical reports are written using a subset of natural language while employing many domain-specific terms; such a language is also known as a sublanguage for a scientific or a technical domain. Different genres of clinical reports use different sublaguages, and in addition, different medical facilities use different medical language conventions. This makes supervised training of a parser for clinical sentences very difficult as it would require expensive annotation effort to adapt to every type of clinical text.
METHODS: In this paper, we present an unsupervised method which automatically induces a grammar and a parser for the sublanguage of a given genre of clinical reports from a corpus with no annotations. In order to capture sentence structures specific to clinical domains, the grammar is induced in terms of semantic classes of clinical terms in addition to part-of-speech tags. Our method induces grammar by minimizing the combined encoding cost of the grammar and the corresponding sentence derivations. The probabilities for the productions of the induced grammar are then learned from the unannotated corpus using an instance of the expectation-maximization algorithm.
RESULTS: Our experiments show that the induced grammar is able to parse novel sentences. Using a dataset of discharge summary sentences with no annotations, our method obtains 60.5\% F-measure for parse-bracketing on sentences of maximum length 10. By varying a parameter, the method can induce a range of grammars, from very specific to very general, and obtains the best performance in between the two extremes.},
	language = {eng},
	journal = {Journal of Biomedical Semantics},
	author = {Kate, Rohit J.},
	month = oct,
	year = {2012},
	pmid = {23046834},
	pmcid = {PMC3465207},
	pages = {S4}
}

@article{danielsson-ojala_describing_2012,
	title = {Describing the sublanguage of wound care in an adult {ICU}},
	volume = {180},
	issn = {0926-9630},
	abstract = {Comprehensive wound documentation is an important tool in evaluating and planning patient care. The sublanguage used in ICUs may affect negatively to the wound care and thus to the healing process. We made a quantitative content analysis of nursing documentation of cardiac surgery adult patients (n=60) who had stayed over four days in the ICU. The sublanguage used in nursing documentation of wounds and ulcers in the ICU was unstructured with many words of colloquial language, misspellings and abbreviations. The documentation did not cover all aspects of proper wound care. The information technology could be helpful for nurses to document right things with plain language.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Danielsson-Ojala, Riitta and Lundgren-Laine, Heljä and Salanterä, Sanna},
	year = {2012},
	pmid = {22874364},
	pages = {1093--1095}
}

@article{patterson_document_2011,
	title = {Document clustering of clinical narratives: a systematic study of clinical sublanguages},
	volume = {2011},
	issn = {1942-597X},
	shorttitle = {Document clustering of clinical narratives},
	abstract = {It is widely believed that different clinical domains use their own sublanguage in clinical notes, complicating natural language processing, but this has never been demonstrated on a broad selection of note types. Starting from formal sublanguage theory, we constructed a feature space based on vocabulary and semantic types used in 17 different clinical domains by three author types (physicians, nurses, and social workers) in both the in- and outpatient settings. We supplied the resulting vectors to CLUTO, a robust clustering tool suitable for this high-dimensional space. Our results confirm that note types with a broad clinical scope, e.g, History \& Physicals and Discharge Summaries, cluster together, while note types with a narrow clinical scope form surprisingly pure, disjoint sublanguages. A reasonable conclusion from this study is that any tool relying on term statistics or semantics trained on one clinical note type may not work well on any other.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Patterson, Olga and Hurdle, John F.},
	year = {2011},
	pmid = {22195171},
	pmcid = {PMC3243234},
	pages = {1099--1107}
}

@article{laros_formalized_2011,
	title = {A formalized description of the standard human variant nomenclature in {Extended} {Backus}-{Naur} {Form}},
	volume = {12 Suppl 4},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-12-S4-S5},
	abstract = {BACKGROUND: The use of a standard human sequence variant nomenclature is advocated by the Human Genome Variation Society in order to unambiguously describe genetic variants in databases and literature. There is a clear need for tools that allow the mining of data about human sequence variants and their functional consequences from databases and literature. Existing text mining focuses on the recognition of protein variants and their effects. The recognition of variants at the DNA and RNA levels is essential for dissemination of variant data for diagnostic purposes. Development of new tools is hampered by the complexity of the current nomenclature, which requires processing at the character level to recognize the specific syntactic constructs used in variant descriptions.
RESULTS: We approached the gene variant nomenclature as a scientific sublanguage and created two formal descriptions of the syntax in Extended Backus-Naur Form: one at the DNA-RNA level and one at the protein level. To ensure compatibility to older versions of the human sequence variant nomenclature, previously recommended variant description formats have been included. The first grammar versions were designed to help build variant description handling in the Alamut mutation interpretation software. The DNA and RNA level descriptions were then updated and used to construct the context-free parser of the Mutalyzer 2 sequence variant nomenclature checker, which has already been used to check more than one million variant descriptions.
CONCLUSIONS: The Extended Backus-Naur Form provided an overview of the full complexity of the syntax of the sequence variant nomenclature, which remained hidden in the textual format and the division of the recommendations across the DNA, RNA and protein sections of the Human Genome Variation Society nomenclature website (http://www.hgvs.org/mutnomen/). This insight into the syntax of the nomenclature could be used to design detailed and clear rules for software development. The Mutalyzer 2 parser demonstrated that it facilitated decomposition of complex variant descriptions into their individual parts. The Extended Backus-Naur Form or parts of it can be used or modified by adding rules, allowing the development of specific sequence variant text mining tools and other programs, which can generate or handle sequence variant descriptions.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Laros, Jeroen F. J. and Blavier, André and den Dunnen, Johan T. and Taschner, Peter E. M.},
	year = {2011},
	pmid = {21992071},
	pmcid = {PMC3194197},
	pages = {S5}
}

@article{xu_applying_2011,
	title = {Applying semantic-based probabilistic context-free grammar to medical language processing--a preliminary study on parsing medication sentences},
	volume = {44},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2011.08.009},
	abstract = {Semantic-based sublanguage grammars have been shown to be an efficient method for medical language processing. However, given the complexity of the medical domain, parsers using such grammars inevitably encounter ambiguous sentences, which could be interpreted by different groups of production rules and consequently result in two or more parse trees. One possible solution, which has not been extensively explored previously, is to augment productions in medical sublanguage grammars with probabilities to resolve the ambiguity. In this study, we associated probabilities with production rules in a semantic-based grammar for medication findings and evaluated its performance on reducing parsing ambiguity. Using the existing data set from 2009 i2b2 NLP (Natural Language Processing) challenge for medication extraction, we developed a semantic-based CFG (Context Free Grammar) for parsing medication sentences and manually created a Treebank of 4564 medication sentences from discharge summaries. Using the Treebank, we derived a semantic-based PCFG (Probabilistic Context Free Grammar) for parsing medication sentences. Our evaluation using a 10-fold cross validation showed that the PCFG parser dramatically improved parsing performance when compared to the CFG parser.},
	language = {eng},
	number = {6},
	journal = {Journal of Biomedical Informatics},
	author = {Xu, Hua and AbdelRahman, Samir and Lu, Yanxin and Denny, Joshua C. and Doan, Son},
	month = dec,
	year = {2011},
	pmid = {21856440},
	pmcid = {PMC3226929},
	pages = {1068--1075}
}

@article{prasad_biomedical_2011,
	title = {The biomedical discourse relation bank},
	volume = {12},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-12-188},
	abstract = {BACKGROUND: Identification of discourse relations, such as causal and contrastive relations, between situations mentioned in text is an important task for biomedical text-mining. A biomedical text corpus annotated with discourse relations would be very useful for developing and evaluating methods for biomedical discourse processing. However, little effort has been made to develop such an annotated resource.
RESULTS: We have developed the Biomedical Discourse Relation Bank (BioDRB), in which we have annotated explicit and implicit discourse relations in 24 open-access full-text biomedical articles from the GENIA corpus. Guidelines for the annotation were adapted from the Penn Discourse TreeBank (PDTB), which has discourse relations annotated over open-domain news articles. We introduced new conventions and modifications to the sense classification. We report reliable inter-annotator agreement of over 80\% for all sub-tasks. Experiments for identifying the sense of explicit discourse connectives show the connective itself as a highly reliable indicator for coarse sense classification (accuracy 90.9\% and F1 score 0.89). These results are comparable to results obtained with the same classifier on the PDTB data. With more refined sense classification, there is degradation in performance (accuracy 69.2\% and F1 score 0.28), mainly due to sparsity in the data. The size of the corpus was found to be sufficient for identifying the sense of explicit connectives, with classifier performance stabilizing at about 1900 training instances. Finally, the classifier performs poorly when trained on PDTB and tested on BioDRB (accuracy 54.5\% and F1 score 0.57).
CONCLUSION: Our work shows that discourse relations can be reliably annotated in biomedical text. Coarse sense disambiguation of explicit connectives can be done with high reliability by using just the connective as a feature, but more refined sense classification requires either richer features or more annotated data. The poor performance of a classifier trained in the open domain and tested in the biomedical domain suggests significant differences in the semantic usage of connectives across these domains, and provides robust evidence for a biomedical sublanguage for discourse and the need to develop a specialized biomedical discourse annotated corpus. The results of our cross-domain experiments are consistent with related work on identifying connectives in BioDRB.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Prasad, Rashmi and McRoy, Susan and Frid, Nadya and Joshi, Aravind and Yu, Hong},
	month = may,
	year = {2011},
	pmid = {21605399},
	pmcid = {PMC3130691},
	pages = {188}
}

@article{patterson_automatic_2010,
	title = {Automatic acquisition of sublanguage semantic schema: towards the word sense disambiguation of clinical narratives},
	volume = {2010},
	issn = {1942-597X},
	shorttitle = {Automatic acquisition of sublanguage semantic schema},
	abstract = {Natural language processing of clinical notes is challenging due to a high degree of semantic ambiguity. Previous research has uncovered ways to improve disambiguation accuracy using manually created rules of semantic sentence structure. However, applying a natural language processing system in a new clinical domain using this method is very labor intensive. This paper presents an automatic method of developing such disambiguation rules for a wide range of clinical domains. Our rules are based on the co-occurrence patterns of semantic types of terms unambiguously mapped to UMLS concepts by MetaMap. These patterns are combined into a sublanguage semantic schema that can be used by an existing natural language processing system such as MetaMap. The differences of co-occurrence patterns across clinical notes of different domains are presented here as evidence of clinical sublanguages.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Patterson, Olga and Igo, Sean and Hurdle, John F.},
	month = nov,
	year = {2010},
	pmid = {21347051},
	pmcid = {PMC3041300},
	pages = {612--616}
}

@article{stewart_using_2010,
	title = {Using {ProMED}-{Mail} and {MedWorm} blogs for cross-domain pattern analysis in epidemic intelligence},
	volume = {160},
	issn = {0926-9630},
	abstract = {In this work we motivate the use of medical blog user generated content for gathering facts about disease reporting events to support biosurveillance investigation. Given the characteristics of blogs, the extraction of such events is made more difficult due to noise and data abundance. We address the problem of automatically inferring disease reporting event extraction patterns in this more noisy setting. The sublanguage used in outbreak reports is exploited to align with the sequences of disease reporting sentences in blogs. Based our Cross Domain Pattern Analysis Framework, experimental results show that Phase-Level sequences tend to produce more overlap across the domains than Word-Level sequences. The cross domain alignment process is effective at filtering noisy sequences from blogs and extracting good candidate sequence patterns from an abundance of text.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Stewart, Avaré and Denecke, Kerstin},
	year = {2010},
	pmid = {20841724},
	pages = {437--441}
}

@article{laippala_towards_2009,
	title = {Towards automated processing of clinical {Finnish}: sublanguage analysis and a rule-based parser},
	volume = {78},
	issn = {1872-8243},
	shorttitle = {Towards automated processing of clinical {Finnish}},
	doi = {10.1016/j.ijmedinf.2009.02.005},
	abstract = {INTRODUCTION: In this paper, we present steps taken towards more efficient automated processing of clinical Finnish, focusing on daily nursing notes in a Finnish Intensive Care Unit (ICU). First, we analyze ICU Finnish as a sublanguage, identifying its specific features facilitating, for example, the development of a specialized syntactic analyser. The identified features include frequent omission of finite verbs, limitations in allowed syntactic structures, and domain-specific vocabulary. Second, we develop a formal grammar and a parser for ICU Finnish, thus providing better tools for the development of further applications in the clinical domain.
METHODS: The grammar is implemented in the LKB system in a typed feature structure formalism. The lexicon is automatically generated based on the output of the FinTWOL morphological analyzer adapted to the clinical domain. As an additional experiment, we study the effect of using Finnish constraint grammar to reduce the size of the lexicon. The parser construction thus makes efficient use of existing resources for Finnish.
RESULTS: The grammar currently covers 76.6\% of ICU Finnish sentences, producing highly accurate best-parse analyzes with F-score of 91.1\%. We find that building a parser for the highly specialized domain sublanguage is not only feasible, but also surprisingly efficient, given an existing morphological analyzer with broad vocabulary coverage. The resulting parser enables a deeper analysis of the text than was previously possible.},
	language = {eng},
	number = {12},
	journal = {International Journal of Medical Informatics},
	author = {Laippala, Veronika and Ginter, Filip and Pyysalo, Sampo and Salakoski, Tapio},
	month = dec,
	year = {2009},
	pmid = {19299195},
	pages = {e7--12}
}

@article{wermter_high-performance_2009,
	title = {High-performance gene name normalization with {GeNo}},
	volume = {25},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btp071},
	abstract = {MOTIVATION: The recognition and normalization of textual mentions of gene and protein names is both particularly important and challenging. Its importance lies in the fact that they constitute the crucial conceptual entities in biomedicine. Their recognition and normalization remains a challenging task because of widespread gene name ambiguities within species, across species, with common English words and with medical sublanguage terms.
RESULTS: We present GeNo, a highly competitive system for gene name normalization, which obtains an F-measure performance of 86.4\% (precision: 87.8\%, recall: 85.0\%) on the BioCreAtIvE-II test set, thus being on a par with the best system on that task. Our system tackles the complex gene normalization problem by employing a carefully crafted suite of symbolic and statistical methods, and by fully relying on publicly available software and data resources, including extensive background knowledge based on semantic profiling. A major goal of our work is to present GeNo's architecture in a lucid and perspicuous way to pave the way to full reproducibility of our results.
AVAILABILITY: GeNo, including its underlying resources, will be available from www.julielab.de. It is also currently deployed in the Semedico search engine at www.semedico.org.},
	language = {eng},
	number = {6},
	journal = {Bioinformatics (Oxford, England)},
	author = {Wermter, Joachim and Tomanek, Katrin and Hahn, Udo},
	month = mar,
	year = {2009},
	pmid = {19188193},
	pages = {815--821}
}

@article{pyysalo_lexical_2006,
	title = {Lexical adaptation of link grammar to the biomedical sublanguage: a comparative evaluation of three approaches},
	volume = {7 Suppl 3},
	issn = {1471-2105},
	shorttitle = {Lexical adaptation of link grammar to the biomedical sublanguage},
	doi = {10.1186/1471-2105-7-S3-S2},
	abstract = {BACKGROUND: We study the adaptation of Link Grammar Parser to the biomedical sublanguage with a focus on domain terms not found in a general parser lexicon. Using two biomedical corpora, we implement and evaluate three approaches to addressing unknown words: automatic lexicon expansion, the use of morphological clues, and disambiguation using a part-of-speech tagger. We evaluate each approach separately for its effect on parsing performance and consider combinations of these approaches.
RESULTS: In addition to a 45\% increase in parsing efficiency, we find that the best approach, incorporating information from a domain part-of-speech tagger, offers a statistically significant 10\% relative decrease in error.
CONCLUSION: When available, a high-quality domain part-of-speech tagger is the best solution to unknown word issues in the domain adaptation of a general parser. In the absence of such a resource, surface clues can provide remarkably good coverage and performance when tuned to the domain. The adapted parser is available under an open-source license.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Pyysalo, Sampo and Salakoski, Tapio and Aubin, Sophie and Nazarenko, Adeline},
	month = nov,
	year = {2006},
	pmid = {17134475},
	pmcid = {PMC1764446},
	pages = {S2}
}

@article{wermter_really_2004,
	title = {Really, is medical sublanguage that different? {Experimental} counter-evidence from tagging medical and newspaper corpora},
	volume = {107},
	issn = {0926-9630},
	shorttitle = {Really, is medical sublanguage that different?},
	abstract = {We compare the performance of two part-of-speech taggers trained on a German newspaper corpus for mixed types of medical documents. TnT, a tagger based on a statistical language model, outperforms Brill's rule-based tagger, and supplied with additional lexicon resources matches state-of-the-art performance figures (close to 97\% accuracy) on the medical corpus. We explain this unexpected result by focusing on the statistically significant part-of-speech type overlap between the newspaper training set and the medical test set. At least at that level, sublanguage differences seem to vanish. Thus, statistical off-the-shelf part-of-speech taggers can immediately be reused for medical language processing},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Wermter, Joachim and Hahn, Udo},
	year = {2004},
	pmid = {15360875},
	pages = {560--564}
}

@article{noauthor_special_2002,
	title = {Special {Issue}: {Sublanguage}. {Dedicated} to the memory of {Zellig} {Harris}},
	volume = {35},
	issn = {1532-0464},
	shorttitle = {Special {Issue}},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	month = aug,
	year = {2002},
	pmid = {14712827},
	pages = {213--277}
}

@article{friedman_two_2002-1,
	title = {Two biomedical sublanguages: a description based on the theories of {Zellig} {Harris}},
	volume = {35},
	issn = {1532-0464},
	shorttitle = {Two biomedical sublanguages},
	abstract = {Natural language processing (NLP) systems have been developed to provide access to the tremendous body of data and knowledge that is available in the biomedical domain in the form of natural language text. These NLP systems are valuable because they can encode and amass the information in the text so that it can be used by other automated processes to improve patient care and our understanding of disease processes and treatments. Zellig Harris proposed a theory of sublanguage that laid the foundation for natural language processing in specialized domains. He hypothesized that the informational content and structure form a specialized language that can be delineated in the form of a sublanguage grammar. The grammar can then be used by a language processor to capture and encode the salient information and relations in text. In this paper, we briefly summarize his language and sublanguage theories. In addition, we summarize our prior research, which is associated with the sublanguage grammars we developed for two different biomedical domains. These grammars illustrate how Harris' theories provide a basis for the development of language processing systems in the biomedical domain. The two domains and their associated sublanguages discussed are: the clinical domain, where the text consists of patient reports, and the biomolecular domain, where the text consists of complete journal articles.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	author = {Friedman, Carol and Kra, Pauline and Rzhetsky, Andrey},
	month = aug,
	year = {2002},
	pmid = {12755517},
	pages = {222--235}
}

@article{stetson_sublanguage_2002,
	title = {The sublanguage of cross-coverage},
	issn = {1531-605X},
	abstract = {At Columbia-Presbyterian Medical Center, free-text "Signout" notes are typed into the electronic record by clinicians for the purpose of cross-coverage. We plan to "unlock" information about adverse events contained in these notes in a subsequent project using Natural Language Processing (NLP). To better understand the requirements for parsing, Signout notes were compared to other common medical notes (ambulatory clinic notes and discharge summaries) on a series of quantitative metrics. They are shorter (mean length 59.25 words vs. 144.11 and 340.85 for ambulatory and discharge notes respectively) and use more abbreviations (26.88\% vs. 20.07\% and 3.57\%). Despite being terser, Signout notes use less ambiguous abbreviations (8.34\% vs. 9.09\% and 18.02\%). Differences were found using Relative Entropy and Squared Chi-square Distance in a novel fashion to compare these medical corpora. Signout notes appear to constitute a unique sublanguage of medicine. The implications for parsing free-text cross-coverage notes into coded medical data are discussed.},
	language = {eng},
	journal = {Proceedings. AMIA Symposium},
	author = {Stetson, Peter D. and Johnson, Stephen B. and Scotch, Matthew and Hripcsak, George},
	year = {2002},
	pmid = {12463923},
	pmcid = {PMC2244148},
	pages = {742--746}
}

@article{johnson_conceptual_1998,
	title = {Conceptual graph grammar--a simple formalism for sublanguage},
	volume = {37},
	issn = {0026-1270},
	abstract = {There are a wide variety of computer applications that deal with various aspects of medical language: concept representation, controlled vocabulary, natural language processing, and information retrieval. While technical and theoretical methods appear to differ, all approaches investigate different aspects of the same phenomenon: medical sublanguage. This paper surveys the properties of medical sublanguage from a formal perspective, based on detailed analyses cited in the literature. A review of several computer systems based on sublanguage approaches shows some of the difficulties in addressing the interaction between the syntactic and semantic aspects of sublanguage. A formalism called Conceptual Graph Grammar is presented that attempts to combine both syntax and semantics into a single notation by extending standard Conceptual Graph notation. Examples from the domain of pathology diagnoses are provided to illustrate the use of this formalism in medical language analysis. The strengths and weaknesses of the approach are then considered. Conceptual Graph Grammar is an attempt to synthesize the common properties of different approaches to sublanguage into a single formalism, and to begin to define a common foundation for language-related research in medical informatics.},
	language = {eng},
	number = {4-5},
	journal = {Methods of Information in Medicine},
	author = {Johnson, S. B.},
	month = nov,
	year = {1998},
	pmid = {9865032},
	pages = {345--352}
}

@article{do_amaral_marcio_associating_1995,
	title = {Associating semantic grammars with the {SNOMED}: processing medical language and representing clinical facts into a language-independent frame},
	volume = {8 Pt 1},
	issn = {1569-6332},
	shorttitle = {Associating semantic grammars with the {SNOMED}},
	abstract = {We describe one approach for natural language processing of medical texts that associates a semantic grammar with the SNOMED (Systematized Nomenclature of Medicine). Our research hypothesis is that the combination of the nomenclature's declarative knowledge with a formal grammar would create a scientific sublanguage embedded with medical knowledge that could be used for analyzing and formatting medical texts. This combination permitted the abstraction of templates we call "semantic patterns." These patterns represent both linguistic and medical knowledge, packed into a hybrid information format. We analyzed manually case reports described in the New England Journal of Medicine (NEJM) from 1985 to 1988 and extracted empirically a semantic grammar. Over 2,000 sentences were analyzed. About 160 structural semantic patterns were abstracted and included in the database of one parser. We tested the parser using reports from 1989 to 1990. Results show that this approach is efficient for processing, indexing, and structuring diverse parts of case reports narrative. The analyzed medical sentences are structured into a language-independent semantic frame format. We conclude that the association of semantic grammars with the SNOMED enabled the construction of a formal system for analysis and representation of clinical facts. The transformation of the structured information from its frame format into other representational schemes, like conceptual graphs, is straightforward. Another application includes the use of the formatted language-independent frame for telegraphic English-Japanese translations of medical sentences.},
	language = {eng},
	journal = {Medinfo. MEDINFO},
	author = {Do Amaral Marcio, B. and Satomura, Y.},
	year = {1995},
	pmid = {8591149},
	pages = {18--22}
}

@article{sager_natural_1994,
	title = {Natural language processing and the representation of clinical data},
	volume = {1},
	issn = {1067-5027},
	abstract = {OBJECTIVE: Develop a representation of clinical observations and actions and a method of processing free-text patient documents to facilitate applications such as quality assurance.
DESIGN: The Linguistic String Project (LSP) system of New York University utilizes syntactic analysis, augmented by a sublanguage grammar and an information structure that are specific to the clinical narrative, to map free-text documents into a database for querying.
MEASUREMENTS: Information precision (I-P) and information recall (I-R) were measured for queries for the presence of 13 asthma-health-care quality assurance criteria in a database generated from 59 discharge letters.
RESULTS: I-P, using counts of major errors only, was 95.7\% for the 28-letter training set and 98.6\% for the 31-letter test set. I-R, using counts of major omissions only, was 93.9\% for the training set and 92.5\% for the test set.},
	language = {eng},
	number = {2},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Sager, N. and Lyman, M. and Bucknall, C. and Nhan, N. and Tick, L. J.},
	month = apr,
	year = {1994},
	pmid = {7719796},
	pmcid = {PMC116193},
	keywords = {female first or senior},
	pages = {142--160}
}

@article{rossi_mori_semantic_1991,
	title = {Semantic standards for the representation of medical records},
	volume = {11},
	issn = {0272-989X},
	abstract = {Physicians developed their sublanguage (a system to represent medical concepts and their relations) to store and transmit general medical knowledge and patient-related information. Adequate formalisms are needed to obtain a standard representation of semantics of medical expressions for computer use. Comparison of the semantic contents of two expressions is possible only if a unique canonical form is defined; the transmission of medical facts or patient-related information is really meaningful only by defining a set of primitives (semantic categories and links) and the domains of values (concepts). These primitives must be harmonized to yield a "common core subset" of semantic categories and links. This subset provides a common basis; a procedure to register extension sets of primitives must also be defined, to comply with specific representation needs of specialties and classes of application software.},
	language = {eng},
	number = {4 Suppl},
	journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
	author = {Rossi Mori, A. and Galeazzi, E. and Gangemi, A. and Pisanelli, D. M. and Thornton, A. M.},
	month = dec,
	year = {1991},
	pmid = {1770855},
	pages = {S76--80}
}

@article{viani_information_2018,
	title = {Information extraction from {Italian} medical reports: {An} ontology-driven approach},
	volume = {111},
	issn = {1872-8243},
	shorttitle = {Information extraction from {Italian} medical reports},
	doi = {10.1016/j.ijmedinf.2017.12.013},
	abstract = {OBJECTIVE: In this work, we propose an ontology-driven approach to identify events and their attributes from episodes of care included in medical reports written in Italian. For this language, shared resources for clinical information extraction are not easily accessible.
MATERIALS AND METHODS: The corpus considered in this work includes 5432 non-annotated medical reports belonging to patients with rare arrhythmias. To guide the information extraction process, we built a domain-specific ontology that includes the events and the attributes to be extracted, with related regular expressions. The ontology and the annotation system were constructed on a development set, while the performance was evaluated on an independent test set. As a gold standard, we considered a manually curated hospital database named TRIAD, which stores most of the information written in reports.
RESULTS: The proposed approach performs well on the considered Italian medical corpus, with a percentage of correct annotations above 90\% for most considered clinical events. We also assessed the possibility to adapt the system to the analysis of another language (i.e., English), with promising results.
DISCUSSION AND CONCLUSION: Our annotation system relies on a domain ontology to extract and link information in clinical text. We developed an ontology that can be easily enriched and translated, and the system performs well on the considered task. In the future, it could be successfully used to automatically populate the TRIAD database.},
	language = {eng},
	journal = {International Journal of Medical Informatics},
	author = {Viani, Natalia and Larizza, Cristiana and Tibollo, Valentina and Napolitano, Carlo and Priori, Silvia G. and Bellazzi, Riccardo and Sacchi, Lucia},
	month = mar,
	year = {2018},
	pmid = {29425625},
	pages = {140--148}
}

@article{matthies_scholarly_2017,
	title = {Scholarly {Information} {Extraction} {Is} {Going} to {Make} a {Quantum} {Leap} with {PubMed} {Central} ({PMC})},
	volume = {245},
	issn = {0926-9630},
	abstract = {With the increasing availability of complete full texts (journal articles), rather than their surrogates (titles, abstracts), as resources for text analytics, entirely new opportunities arise for information extraction and text mining from scholarly publications. Yet, we gathered evidence that a range of problems are encountered for full-text processing when biomedical text analytics simply reuse existing NLP pipelines which were developed on the basis of abstracts (rather than full texts). We conducted experiments with four different relation extraction engines all of which were top performers in previous BioNLP Event Extraction Challenges. We found that abstract-trained engines loose up to 6.6\% F-score points when run on full-text data. Hence, the reuse of existing abstract-based NLP software in a full-text scenario is considered harmful because of heavy performance losses. Given the current lack of annotated full-text resources to train on, our study quantifies the price paid for this short cut.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Matthies, Franz and Hahn, Udo},
	year = {2017},
	pmid = {29295149},
	pages = {521--525}
}

@article{wang_clinical_2018,
	title = {Clinical information extraction applications: {A} literature review},
	volume = {77},
	issn = {1532-0480},
	shorttitle = {Clinical information extraction applications},
	doi = {10.1016/j.jbi.2017.11.011},
	abstract = {BACKGROUND: With the rapid adoption of electronic health records (EHRs), it is desirable to harvest information and knowledge from EHRs to support automated systems at the point of care and to enable secondary use of EHRs for clinical and translational research. One critical component used to facilitate the secondary use of EHR data is the information extraction (IE) task, which automatically extracts and encodes clinical information from text.
OBJECTIVES: In this literature review, we present a review of recent published research on clinical information extraction (IE) applications.
METHODS: A literature search was conducted for articles published from January 2009 to September 2016 based on Ovid MEDLINE In-Process \& Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and ACM Digital Library.
RESULTS: A total of 1917 publications were identified for title and abstract screening. Of these publications, 263 articles were selected and discussed in this review in terms of publication venues and data sources, clinical IE tools, methods, and applications in the areas of disease- and drug-related studies, and clinical workflow optimizations.
CONCLUSIONS: Clinical IE has been used for a wide range of applications, however, there is a considerable gap between clinical studies using EHR data and studies using clinical IE. This study enabled us to gain a more concrete understanding of the gap and to provide potential solutions to bridge this gap.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Wang, Yanshan and Wang, Liwei and Rastegar-Mojarad, Majid and Moon, Sungrim and Shen, Feichen and Afzal, Naveed and Liu, Sijia and Zeng, Yuqun and Mehrabi, Saeed and Sohn, Sunghwan and Liu, Hongfang},
	month = jan,
	year = {2018},
	pmid = {29162496},
	pmcid = {PMC5771858},
	pages = {34--49}
}

@article{madan_bel_2016,
	title = {The {BEL} information extraction workflow ({BELIEF}): evaluation in the {BioCreative} {V} {BEL} and {IAT} track},
	volume = {2016},
	issn = {1758-0463},
	shorttitle = {The {BEL} information extraction workflow ({BELIEF})},
	doi = {10.1093/database/baw136},
	abstract = {Network-based approaches have become extremely important in systems biology to achieve a better understanding of biological mechanisms. For network representation, the Biological Expression Language (BEL) is well designed to collate findings from the scientific literature into biological network models. To facilitate encoding and biocuration of such findings in BEL, a BEL Information Extraction Workflow (BELIEF) was developed. BELIEF provides a web-based curation interface, the BELIEF Dashboard, that incorporates text mining techniques to support the biocurator in the generation of BEL networks. The underlying UIMA-based text mining pipeline (BELIEF Pipeline) uses several named entity recognition processes and relationship extraction methods to detect concepts and BEL relationships in literature. The BELIEF Dashboard allows easy curation of the automatically generated BEL statements and their context annotations. Resulting BEL statements and their context annotations can be syntactically and semantically verified to ensure consistency in the BEL network. In summary, the workflow supports experts in different stages of systems biology network building. Based on the BioCreative V BEL track evaluation, we show that the BELIEF Pipeline automatically extracts relationships with an F-score of 36.4\% and fully correct statements can be obtained with an F-score of 30.8\%. Participation in the BioCreative V Interactive task (IAT) track with BELIEF revealed a systems usability scale (SUS) of 67. Considering the complexity of the task for new users-learning BEL, working with a completely new interface, and performing complex curation-a score so close to the overall SUS average highlights the usability of BELIEF.Database URL: BELIEF is available at http://www.scaiview.com/belief/.},
	language = {eng},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Madan, Sumit and Hodapp, Sven and Senger, Philipp and Ansari, Sam and Szostak, Justyna and Hoeng, Julia and Peitsch, Manuel and Fluck, Juliane},
	year = {2016},
	pmid = {27694210},
	pmcid = {PMC5045868}
}

@article{yim_tumor_2016,
	title = {Tumor information extraction in radiology reports for hepatocellular carcinoma patients},
	volume = {2016},
	issn = {2153-4063},
	abstract = {Hepatocellular carcinoma (HCC) is a deadly disease affecting the liver for which there are many available therapies. Targeting treatments towards specific patient groups necessitates defining patients by stage of disease. Criteria for such stagings include information on tumor number, size, and anatomic location, typically only found in narrative clinical text in the electronic medical record (EMR). Natural language processing (NLP) offers an automatic and scale-able means to extract this information, which can further evidence-based research. In this paper, we created a corpus of 101 radiology reports annotated for tumor information. Afterwards we applied machine learning algorithms to extract tumor information. Our inter-annotator partial match agreement scored at 0.93 and 0.90 F1 for entities and relations, respectively. Based on the annotated corpus, our sequential labeling entity extraction achieved 0.87 F1 partial match, and our maximum entropy classification relation extraction achieved scores 0.89 and 0. 74 F1 with gold and system entities, respectively.},
	language = {eng},
	journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
	author = {Yim, Wen-Wai and Denman, Tyler and Kwan, Sharon W. and Yetisgen, Meliha},
	year = {2016},
	pmid = {27570686},
	pmcid = {PMC5001784},
	pages = {455--464}
}

@article{meystre_congestive_2017,
	title = {Congestive heart failure information extraction framework for automated treatment performance measures assessment},
	volume = {24},
	issn = {1527-974X},
	doi = {10.1093/jamia/ocw097},
	abstract = {Objective: This paper describes a new congestive heart failure (CHF) treatment performance measure information extraction system - CHIEF - developed as part of the Automated Data Acquisition for Heart Failure project, a Veterans Health Administration project aiming at improving the detection of patients not receiving recommended care for CHF.
Design: CHIEF is based on the Apache Unstructured Information Management Architecture framework, and uses a combination of rules, dictionaries, and machine learning methods to extract left ventricular function mentions and values, CHF medications, and documented reasons for a patient not receiving these medications.
Measurements: The training and evaluation of CHIEF were based on subsets of a reference standard of various clinical notes from 1083 Veterans Health Administration patients. Domain experts manually annotated these notes to create our reference standard. Metrics used included recall, precision, and the F 1 -measure.
Results: In general, CHIEF extracted CHF medications with high recall ({\textgreater}0.990) and good precision (0.960-0.978). Mentions of Left Ventricular Ejection Fraction were also extracted with high recall (0.978-0.986) and precision (0.986-0.994), and quantitative values of Left Ventricular Ejection Fraction were found with 0.910-0.945 recall and with high precision (0.939-0.976). Reasons for not prescribing CHF medications were more difficult to extract, only reaching fair accuracy with about 0.310-0.400 recall and 0.250-0.320 precision.
Conclusion: This study demonstrated that applying natural language processing to unlock the rich and detailed clinical information found in clinical narrative text notes makes fast and scalable quality improvement approaches possible, eventually improving management and outpatient treatment of patients suffering from CHF.},
	language = {eng},
	number = {e1},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Meystre, Stéphane M. and Kim, Youngjun and Gobbel, Glenn T. and Matheny, Michael E. and Redd, Andrew and Bray, Bruce E. and Garvin, Jennifer H.},
	month = apr,
	year = {2017},
	pmid = {27413122},
	pages = {e40--e46}
}

@article{scuba_knowledge_2016,
	title = {Knowledge {Author}: facilitating user-driven, domain content development to support clinical information extraction},
	volume = {7},
	issn = {2041-1480},
	shorttitle = {Knowledge {Author}},
	doi = {10.1186/s13326-016-0086-9},
	abstract = {BACKGROUND: Clinical Natural Language Processing (NLP) systems require a semantic schema comprised of domain-specific concepts, their lexical variants, and associated modifiers to accurately extract information from clinical texts. An NLP system leverages this schema to structure concepts and extract meaning from the free texts. In the clinical domain, creating a semantic schema typically requires input from both a domain expert, such as a clinician, and an NLP expert who will represent clinical concepts created from the clinician's domain expertise into a computable format usable by an NLP system. The goal of this work is to develop a web-based tool, Knowledge Author, that bridges the gap between the clinical domain expert and the NLP system development by facilitating the development of domain content represented in a semantic schema for extracting information from clinical free-text.
RESULTS: Knowledge Author is a web-based, recommendation system that supports users in developing domain content necessary for clinical NLP applications. Knowledge Author's schematic model leverages a set of semantic types derived from the Secondary Use Clinical Element Models and the Common Type System to allow the user to quickly create and modify domain-related concepts. Features such as collaborative development and providing domain content suggestions through the mapping of concepts to the Unified Medical Language System Metathesaurus database further supports the domain content creation process. Two proof of concept studies were performed to evaluate the system's performance. The first study evaluated Knowledge Author's flexibility to create a broad range of concepts. A dataset of 115 concepts was created of which 87 (76 \%) were able to be created using Knowledge Author. The second study evaluated the effectiveness of Knowledge Author's output in an NLP system by extracting concepts and associated modifiers representing a clinical element, carotid stenosis, from 34 clinical free-text radiology reports using Knowledge Author and an NLP system, pyConText. Knowledge Author's domain content produced high recall for concepts (targeted findings: 86 \%) and varied recall for modifiers (certainty: 91 \% sidedness: 80 \%, neurovascular anatomy: 46 \%).
CONCLUSION: Knowledge Author can support clinical domain content development for information extraction by supporting semantic schema creation by domain experts.},
	language = {eng},
	number = {1},
	journal = {Journal of Biomedical Semantics},
	author = {Scuba, William and Tharp, Melissa and Mowery, Danielle and Tseytlin, Eugene and Liu, Yang and Drews, Frank A. and Chapman, Wendy W.},
	month = jun,
	year = {2016},
	pmid = {27338146},
	pmcid = {PMC4919842},
	pages = {42}
}

@article{liu_information_2013,
	title = {An information extraction framework for cohort identification using electronic health records},
	volume = {2013},
	issn = {2153-4063},
	abstract = {Information extraction (IE), a natural language processing (NLP) task that automatically extracts structured or semi-structured information from free text, has become popular in the clinical domain for supporting automated systems at point-of-care and enabling secondary use of electronic health records (EHRs) for clinical and translational research. However, a high performance IE system can be very challenging to construct due to the complexity and dynamic nature of human language. In this paper, we report an IE framework for cohort identification using EHRs that is a knowledge-driven framework developed under the Unstructured Information Management Architecture (UIMA). A system to extract specific information can be developed by subject matter experts through expert knowledge engineering of the externalized knowledge resources used in the framework.},
	language = {eng},
	journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
	author = {Liu, Hongfang and Bielinski, Suzette J. and Sohn, Sunghwan and Murphy, Sean and Wagholikar, Kavishwar B. and Jonnalagadda, Siddhartha R. and Ravikumar, K. E. and Wu, Stephen T. and Kullo, Iftikhar J. and Chute, Christopher G.},
	year = {2013},
	pmid = {24303255},
	pmcid = {PMC3845757},
	pages = {149--153}
}

@article{kim_improving_2013,
	title = {Improving heart failure information extraction by domain adaptation},
	volume = {192},
	issn = {0926-9630},
	abstract = {Adapting an information extraction application to a new domain (e.g., new categories of narrative text) typically requires re-training the application with the new narratives. But could previous training from the original domain alleviate this adaptation? After having developed an NLP-based application to extract congestive heart failure treatment performance measures from echocardiogram reports (i.e., the source domain), we adapted it to a large variety of clinical documents (i.e., the target domain). We wanted to reuse the machine learning trained models from the source domain, and experimented with several popular domain adaptation approaches such as reusing the predictions from the source model, or applying a linear interpolation. As a result, we measured higher recall and precision (92.4\% and 95.3\% respectively) than when training with the target domain only.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Kim, Youngjun and Garvin, Jennifer and Heavirland, Julia and Meystre, Stéphane M.},
	year = {2013},
	pmid = {23920541},
	pages = {185--189}
}

@article{tang_hybrid_2013,
	title = {A hybrid system for temporal information extraction from clinical text},
	volume = {20},
	issn = {1527-974X},
	doi = {10.1136/amiajnl-2013-001635},
	abstract = {OBJECTIVE: To develop a comprehensive temporal information extraction system that can identify events, temporal expressions, and their temporal relations in clinical text. This project was part of the 2012 i2b2 clinical natural language processing (NLP) challenge on temporal information extraction.
MATERIALS AND METHODS: The 2012 i2b2 NLP challenge organizers manually annotated 310 clinic notes according to a defined annotation guideline: a training set of 190 notes and a test set of 120 notes. All participating systems were developed on the training set and evaluated on the test set. Our system consists of three modules: event extraction, temporal expression extraction, and temporal relation (also called Temporal Link, or 'TLink') extraction. The TLink extraction module contains three individual classifiers for TLinks: (1) between events and section times, (2) within a sentence, and (3) across different sentences. The performance of our system was evaluated using scripts provided by the i2b2 organizers. Primary measures were micro-averaged Precision, Recall, and F-measure.
RESULTS: Our system was among the top ranked. It achieved F-measures of 0.8659 for temporal expression extraction (ranked fourth), 0.6278 for end-to-end TLink track (ranked first), and 0.6932 for TLink-only track (ranked first) in the challenge. We subsequently investigated different strategies for TLink extraction, and were able to marginally improve performance with an F-measure of 0.6943 for TLink-only track.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Tang, Buzhou and Wu, Yonghui and Jiang, Min and Chen, Yukun and Denny, Joshua C. and Xu, Hua},
	month = oct,
	year = {2013},
	pmid = {23571849},
	pmcid = {PMC3756274},
	pages = {828--835}
}

@article{deleger_large-scale_2013,
	title = {Large-scale evaluation of automated clinical note de-identification and its impact on information extraction},
	volume = {20},
	issn = {1527-974X},
	doi = {10.1136/amiajnl-2012-001012},
	abstract = {OBJECTIVE: (1) To evaluate a state-of-the-art natural language processing (NLP)-based approach to automatically de-identify a large set of diverse clinical notes. (2) To measure the impact of de-identification on the performance of information extraction algorithms on the de-identified documents.
MATERIAL AND METHODS: A cross-sectional study that included 3503 stratified, randomly selected clinical notes (over 22 note types) from five million documents produced at one of the largest US pediatric hospitals. Sensitivity, precision, F value of two automated de-identification systems for removing all 18 HIPAA-defined protected health information elements were computed. Performance was assessed against a manually generated 'gold standard'. Statistical significance was tested. The automated de-identification performance was also compared with that of two humans on a 10\% subsample of the gold standard. The effect of de-identification on the performance of subsequent medication extraction was measured.
RESULTS: The gold standard included 30 815 protected health information elements and more than one million tokens. The most accurate NLP method had 91.92\% sensitivity (R) and 95.08\% precision (P) overall. The performance of the system was indistinguishable from that of human annotators (annotators' performance was 92.15\%(R)/93.95\%(P) and 94.55\%(R)/88.45\%(P) overall while the best system obtained 92.91\%(R)/95.73\%(P) on same text). The impact of automated de-identification was minimal on the utility of the narrative notes for subsequent information extraction as measured by the sensitivity and precision of medication name extraction.
DISCUSSION AND CONCLUSION: NLP-based de-identification shows excellent performance that rivals the performance of human annotators. Furthermore, unlike manual de-identification, the automated approach scales up to millions of documents quickly and inexpensively.},
	language = {eng},
	number = {1},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Deleger, Louise and Molnar, Katalin and Savova, Guergana and Xia, Fei and Lingren, Todd and Li, Qi and Marsolo, Keith and Jegga, Anil and Kaiser, Megan and Stoutenborough, Laura and Solti, Imre},
	month = jan,
	year = {2013},
	pmid = {22859645},
	pmcid = {PMC3555323},
	pages = {84--94}
}

@article{grouin_automatic_2011,
	title = {Automatic computation of {CHA}2DS2-{VASc} score: information extraction from clinical texts for thromboembolism risk assessment},
	volume = {2011},
	issn = {1942-597X},
	shorttitle = {Automatic computation of {CHA}2DS2-{VASc} score},
	abstract = {The CHA2DS2-VASc score is a 10-point scale which allows cardiologists to easily identify potential stroke risk for patients with non-valvular fibrillation. In this article, we present a system based on natural language processing (lexicon and linguistic modules), including negation and speculation handling, which extracts medical concepts from French clinical records and uses them as criteria to compute the CHA2DS2-VASc score. We evaluate this system by comparing its computed criteria with those obtained by human reading of the same clinical texts, and by assessing the impact of the observed differences on the resulting CHA2DS2-VASc scores. Given 21 patient records, 168 instances of criteria were computed, with an accuracy of 97.6\%, and the accuracy of the 21 CHA2DS2-VASc scores was 85.7\%. All differences in scores trigger the same alert, which means that system performance on this test set yields similar results to human reading of the texts.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Grouin, Cyril and Deléger, Louise and Rosier, Arnaud and Temal, Lynda and Dameron, Olivier and Van Hille, Pascal and Burgun, Anita and Zweigenbaum, Pierre},
	year = {2011},
	pmid = {22195104},
	pmcid = {PMC3243195},
	pages = {501--510}
}

@article{jonnalagadda_biosimplify:_2010-1,
	title = {{BioSimplify}: an open source sentence simplification engine to improve recall in automatic biomedical information extraction},
	volume = {2010},
	issn = {1942-597X},
	shorttitle = {{BioSimplify}},
	abstract = {BioSimplify is an open source tool written in Java that introduces and facilitates the use of a novel model for sentence simplification tuned for automatic discourse analysis and information extraction (as opposed to sentence simplification for improving human readability). The model is based on a "shot-gun" approach that produces many different (simpler) versions of the original sentence by combining variants of its constituent elements. This tool is optimized for processing biomedical scientific literature such as the abstracts indexed in PubMed. We tested our tool on its impact to the task of PPI extraction and it improved the f-score of the PPI tool by around 7\%, with an improvement in recall of around 20\%. The BioSimplify tool and test corpus can be downloaded from https://biosimplify.sourceforge.net.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Jonnalagadda, Siddhartha and Gonzalez, Graciela},
	month = nov,
	year = {2010},
	pmid = {21346999},
	pmcid = {PMC3041388},
	pages = {351--355}
}

@article{thompson_construction_2009-1,
	title = {Construction of an annotated corpus to support biomedical information extraction},
	volume = {10},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-10-349},
	abstract = {BACKGROUND: Information Extraction (IE) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. As events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. Corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of IE components and resources.
RESULTS: We have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. For each event instance, all participants (arguments) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the Gene Regulation Ontology. To our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. Using the scheme, we have created the Gene Regulation Event Corpus (GREC), consisting of 240 MEDLINE abstracts, in which events relating to gene regulation and expression have been annotated by biologists. A novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66\% - 90\%.
CONCLUSION: The GREC is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. As such, it is specifically designed to support bio-specific tool and resource development. It has already been used to acquire semantic frames for inclusion within the BioLexicon (a lexical, terminological resource to aid biomedical text mining). Initial experiments have also shown that the corpus may viably be used to train IE components, such as semantic role labellers. The corpus and annotation guidelines are freely available for academic purposes.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Thompson, Paul and Iqbal, Syed A. and McNaught, John and Ananiadou, Sophia},
	month = oct,
	year = {2009},
	pmid = {19852798},
	pmcid = {PMC2774701},
	pages = {349}
}

@article{krallinger_linking_2008-1,
	title = {Linking genes to literature: text mining, information extraction, and retrieval applications for biology},
	volume = {9 Suppl 2},
	issn = {1474-760X},
	shorttitle = {Linking genes to literature},
	doi = {10.1186/gb-2008-9-s2-s8},
	abstract = {Efficient access to information contained in online scientific literature collections is essential for life science research, playing a crucial role from the initial stage of experiment planning to the final interpretation and communication of the results. The biological literature also constitutes the main information source for manual literature curation used by expert-curated databases. Following the increasing popularity of web-based applications for analyzing biological data, new text-mining and information extraction strategies are being implemented. These systems exploit existing regularities in natural language to extract biologically relevant information from electronic texts automatically. The aim of the BioCreative challenge is to promote the development of such tools and to provide insight into their performance. This review presents a general introduction to the main characteristics and applications of currently available text-mining systems for life sciences in terms of the following: the type of biological information demands being addressed; the level of information granularity of both user queries and results; and the features and methods commonly exploited by these applications. The current trend in biomedical text mining points toward an increasing diversification in terms of application types and techniques, together with integration of domain-specific resources such as ontologies. Additional descriptions of some of the systems discussed here are available on the internet http://zope.bioinfo.cnio.es/bionlp\_tools/.},
	language = {eng},
	journal = {Genome Biology},
	author = {Krallinger, Martin and Valencia, Alfonso and Hirschman, Lynette},
	year = {2008},
	pmid = {18834499},
	pmcid = {PMC2559992},
	pages = {S8}
}

@article{manschreck_type--token_1984,
	title = {The type--token ratio in schizophrenic disorders: clinical and research value},
	volume = {14},
	issn = {0033-2917},
	shorttitle = {The type--token ratio in schizophrenic disorders},
	abstract = {Prior research has indicated that the type-token ratio (TTR), a measure of repetition in language, correlates with clinical judgements of thought disorder when spoken language was examined, and differentiates statistically thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. We replicated this finding and examined the clinical sensitivity and specificity of the TTR measure in the diagnosis and in the assessment of thought disorder. The current clinical value of the TTR is limited, but further investigations of the nature of repetition in schizophrenic language are warranted.},
	language = {eng},
	number = {1},
	journal = {Psychological Medicine},
	author = {Manschreck, T. C. and Maher, B. A. and Hoover, T. M. and Ames, D.},
	month = feb,
	year = {1984},
	pmid = {6709781},
	keywords = {tokenization},
	pages = {151--157}
}

@article{manschreck_formal_1981-1,
	title = {Formal thought disorder, the type-token ratio and disturbed voluntary motor movement in schizophrenia},
	volume = {139},
	issn = {0007-1250},
	abstract = {Little work has been done to determine objective, reliable differences in formal characteristics of the actual utterances of thought-disordered and non-thought-disordered subjects. The type-token ratio (TTR), a quantitative measure of repetition in language, correlated highly with clinical judgments of thought disorder when spoken language was examined, and statistically differentiated thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. Elicited and spontaneous motor abnormalities were associated with reduced TTRs both in schizophrenics and in affective subjects with motor disturbance. The TTR is a reliable, objective indicator of language deviance and thought disorder, and strongly associated with motor disturbances.},
	language = {eng},
	journal = {The British Journal of Psychiatry: The Journal of Mental Science},
	author = {Manschreck, T. C. and Maher, B. A. and Ader, D. N.},
	month = jul,
	year = {1981},
	pmid = {6117348},
	keywords = {tokenization},
	pages = {7--15}
}

@article{baracchini_[language_1970-1,
	title = {[{Language} in mental retardates: the {Type}-{Token} ratio]},
	volume = {16},
	issn = {0035-6336},
	shorttitle = {[{Language} in mental retardates},
	language = {ita},
	number = {2},
	journal = {Rivista Di Neurobiologia: Organo Ufficiale Della Societa Dei Neurologi, Neuroradiologi E Neurochirurghi Ospedalieri},
	author = {Baracchini, G. and Bickel, J. and Bertocchini, M.},
	month = jun,
	year = {1970},
	pmid = {5505861},
	keywords = {tokenization},
	pages = {235--240}
}

@article{chen_type-token_1946,
	title = {The type-token ratio applied to infant speech sounds},
	volume = {11},
	language = {eng},
	journal = {The Journal of Speech Disorders},
	author = {Chen, H. P. and Irwin, O. C.},
	month = jun,
	year = {1946},
	pmid = {20986559},
	keywords = {tokenization},
	pages = {126--130}
}

@article{fromm_discourse_2017,
	title = {Discourse {Characteristics} in {Aphasia} {Beyond} the {Western} {Aphasia} {Battery} {Cutoff}},
	volume = {26},
	issn = {1558-9110},
	doi = {10.1044/2016_AJSLP-16-0071},
	abstract = {Purpose: This study examined discourse characteristics of individuals with aphasia who scored at or above the 93.8 cutoff on the Aphasia Quotient subtests of the Western Aphasia Battery-Revised (WAB-R; Kertesz, 2007). They were compared with participants without aphasia and those with anomic aphasia.
Method: Participants were from the AphasiaBank database and included 28 participants who were not aphasic by WAB-R score (NABW), 92 participants with anomic aphasia, and 177 controls. Cinderella narratives were analyzed using the Computerized Language Analysis programs (MacWhinney, 2000). Outcome measures were words per minute, percent word errors, lexical diversity using the moving average type-token ratio (Covington, 2007b), main concept production, number of utterances, mean length of utterance, and proposition density.
Results: Results showed that the NABW group was significantly different from the controls on all measures except MLU and proposition density. These individuals were compared to participants without aphasia and those with anomic aphasia.
Conclusion: Individuals with aphasia who score above the WAB-R Aphasia Quotient cutoff demonstrate discourse impairments that warrant both treatment and special attention in the research literature.},
	language = {eng},
	number = {3},
	journal = {American Journal of Speech-Language Pathology},
	author = {Fromm, Davida and Forbes, Margaret and Holland, Audrey and Dalton, Sarah Grace and Richardson, Jessica and MacWhinney, Brian},
	month = aug,
	year = {2017},
	pmid = {28505222},
	keywords = {tokenization},
	pages = {762--768}
}

@article{fergadiotis_measuring_2013,
	title = {Measuring lexical diversity in narrative discourse of people with aphasia},
	volume = {22},
	issn = {1558-9110},
	doi = {10.1044/1058-0360(2013/12-0083)},
	abstract = {PURPOSE: A microlinguistic content analysis for assessing lexical semantics in people with aphasia (PWA) is lexical diversity (LD). Sophisticated techniques have been developed to measure LD. However, validity evidence for these methodologies when applied to the discourse of PWA is lacking. The purpose of this study was to evaluate four measures of LD to determine how effective they were at measuring LD in PWA.
METHOD: Four measures of LD were applied to short discourse samples produced by 101 PWA: (a) the Measure of Textual Lexical Diversity (MTLD; McCarthy, 2005), (b) the Moving-Average Type-Token Ratio (MATTR; Covington, 2007), (c) D (McKee, Malvern, \& Richards, 2000), and (d) the Hypergeometric Distribution (HD-D; McCarthy \& Jarvis, 2007). LD was estimated using each method, and the scores were subjected to a series of analyses (e.g., curve-fitting, analysis of variance, confirmatory factor analysis).
RESULTS: Results from the confirmatory factor analysis suggested that MTLD and MATTR reflect LD and little of anything else. Further, two indices (HD-D and D) were found to be equivalent, suggesting that either one can be used when samples are {\textgreater}50 tokens.
CONCLUSION: MTLD and MATTR yielded the strongest evidence for producing unbiased LD scores, suggesting that they may be the best measures for capturing LD in PWA.},
	language = {eng},
	number = {2},
	journal = {American Journal of Speech-Language Pathology},
	author = {Fergadiotis, Gerasimos and Wright, Heather H. and West, Thomas M.},
	month = may,
	year = {2013},
	pmid = {23695912},
	pmcid = {PMC3813439},
	keywords = {tokenization},
	pages = {S397--408}
}

@article{adewuya_flexibility_2008,
	title = {Flexibility and variability in lexicon usage among {Yoruba}-speaking {Nigerian} outpatients with schizophrenia: a controlled study},
	volume = {41},
	issn = {1423-033X},
	shorttitle = {Flexibility and variability in lexicon usage among {Yoruba}-speaking {Nigerian} outpatients with schizophrenia},
	doi = {10.1159/000141924},
	abstract = {BACKGROUND: The studies on language dysfunction in schizophrenia are few, inconclusive and have all been done in the western culture. There may be cross-cultural and cross-lingual differences in problems with speeches of patients with schizophrenia. This study aims to examine the flexibility or variability in the use of words among a group of Nigerian patients with schizophrenia compared with healthy controls.
SAMPLING AND METHODS: The spoken samples of 48 outpatients with schizophrenia and 48 matched controls were assessed using the mean segmental type-token ratio (MSTTR). The sociodemographic and clinical variables of the patients with schizophrenia were also compared with their MSTTR scores.
RESULTS: The MSTTR score for the patients with schizophrenia was significantly lower compared with that of healthy controls (p {\textless} 0.001). The factors independently associated with a lower MSTTR in patients with schizophrenia include younger age at onset of illness, presence of negative formal thought disorder and simple or hebephrenic subtype of schizophrenia.
CONCLUSIONS: The problem with flexibility and variability in lexicon usage among patients with schizophrenia is a cross-cultural phenomenon. The MSTTR may have value in predicting clinical judgements of thought disorder or in identifying deviant language. These may have broad potentials for application in longitudinal and pathogenetic studies of schizophrenia.},
	language = {eng},
	number = {5},
	journal = {Psychopathology},
	author = {Adewuya, Abiola O. and Adewuya, Abiodun O.},
	year = {2008},
	pmid = {18594164},
	keywords = {tokenization},
	pages = {294--299}
}

@article{gordon_measuring_2008,
	title = {Measuring the lexical semantics of picture description in aphasia},
	volume = {22},
	issn = {0268-7038},
	doi = {10.1080/02687030701820063},
	abstract = {BACKGROUND: Individuals with non-fluent aphasia have difficulty producing syntactically laden words, such as function words, whereas individuals with fluent aphasia often have difficulty producing semantically specific words. It is hypothesised that such dissociations arise, at least in part, from a trade-off between syntactic and semantic sources of input to lexical retrieval. AIMS: The aims of this study were (a) to identify quantitative measures of the semantic content of narrative for people with aphasia that are reliable indicators of semantic competence, independent of overall aphasia severity; (b) to determine whether these measures distinguish between fluent and non-fluent aphasia; and (c) to assess whether individuals with fluent and non-fluent aphasia show a trade-off between measures of syntactic and semantic production. METHODS \#ENTITYSTARTX00026; PROCEDURES: Connected speech samples were elicited from 16 participants with aphasia, 8 fluent and 8 non-fluent. The semantic sufficiency of the samples was analysed by measuring the proportion of correct information units (CIUs), the type-token ratios (TTRs) of content words, and the proportion of semantically specific ("heavy") to semantically general ("light") verbs produced. These measures were then correlated with syntactic measures from the QPA (Berndt, Wayland, Rochon, Saffran, \& Schwartz, 2000) across and within participant groups. OUTCOMES \#ENTITYSTARTX00026; RESULTS: CIUs were found to reflect primarily aphasia severity, and not to differentiate between fluent and non-fluent groups. TTRs were also strongly influenced by severity among fluent, but not non-fluent, participants. The ratio of heavy to light verbs reliably distinguished the groups, and showed different patterns of correlation with the syntactic measures. CONCLUSIONS: Results show some evidence for a trade-off between syntactic and semantic inputs to word retrieval, at least among non-fluent participants. The heavy-light verb ratio provides information about semantic specificity, beyond what is provided by the CIU or TTR measures.},
	language = {eng},
	number = {7-8},
	journal = {Aphasiology},
	author = {Gordon, Jean K.},
	month = jan,
	year = {2008},
	pmid = {22399832},
	pmcid = {PMC3293396},
	keywords = {tokenization},
	pages = {839--852}
}

@article{linscott_thought_2005,
	title = {Thought disorder, pragmatic language impairment, and generalized cognitive decline in schizophrenia},
	volume = {75},
	issn = {0920-9964},
	doi = {10.1016/j.schres.2004.10.007},
	abstract = {BACKGROUND: Schizophrenia is associated with pragmatic language impairment (PLI), a reduced ability to communicate intention in a rule-governed fashion. Two explanations for PLI include that PLI is equivalent to thought disorder and that PLI is secondary to generalized cognitive decline.
OBJECTIVES: The aims of this study were to demonstrate PLI in schizophrenia and to test which of these explanations best accounts for the relationships among thought disorder, PLI, and generalized cognitive decline.
METHOD: Schizophrenia (n=20) and control (n=26) participants provided speech samples that were scored for thought disorder (type-token ratio and Cloze procedure) and PLI [Profile of Pragmatic Impairment in Communication (PPIC)]. Generalized cognitive decline was determined from discrepancies between current and premorbid verbal IQ.
RESULTS: Patients with schizophrenia exhibited significant PLI and generalized cognitive decline. There was no evidence of an association between thought disorder and PLI. Moreover, generalized cognitive decline predicted PLI (r(2)=0.33 to 0.59) but not thought disorder (r(2)=0.02 to 0.06).
CONCLUSIONS: The results conformed to a predicted pattern of associations based on the notion that PLI in schizophrenia is secondary to generalized cognitive decline.},
	language = {eng},
	number = {2-3},
	journal = {Schizophrenia Research},
	author = {Linscott, Richard J.},
	month = jun,
	year = {2005},
	pmid = {15885514},
	keywords = {tokenization},
	pages = {225--232}
}

@article{damba_[biological_1990,
	title = {[{Biological} and behavioral rhythms of patients with schizophrenia. {Preliminary} study]},
	volume = {16},
	issn = {0013-7006},
	abstract = {Relying on the ethological model for the collection of data (ethogram), psycholinguistic methods (Cloze procedure, type token ratio) and chronobiological techniques, the present study tests the hypothesis of behavioural, speech and biological ultradian or circadian rhythms in certain types of schizophrenic patients after a 2 week study. Six daily, direct and meticulous 25 minutes observations of the behaviour and speech of four schizophrenics show that stereotyped motor or verbal behaviour does not always fluctuate at random; certain behavioural patterns recur regularly at fixed intervals, according to a set time structure. Most of the behavioural, verbal and biological variables have their acrophase at 10 a.m. and/or at 4 p.m. Instability in the rhythm of the sleep/wake cycle and the oral temperature observed in schizophrenics could be the result of desynchronization of the central pacemakers or of the resynchronization, or even of hypersynchronization with a delay of one phase. It is difficult to ascribe this desynchronization to the illness or the treatment.},
	language = {fre},
	number = {1},
	journal = {L'Encephale},
	author = {Damba, D. B.},
	month = feb,
	year = {1990},
	pmid = {2328681},
	keywords = {tokenization},
	pages = {3--12}
}

@article{manschreck_formal_1981-2,
	title = {Formal thought disorder, the type-token ratio and disturbed voluntary motor movement in schizophrenia},
	volume = {139},
	issn = {0007-1250},
	abstract = {Little work has been done to determine objective, reliable differences in formal characteristics of the actual utterances of thought-disordered and non-thought-disordered subjects. The type-token ratio (TTR), a quantitative measure of repetition in language, correlated highly with clinical judgments of thought disorder when spoken language was examined, and statistically differentiated thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. Elicited and spontaneous motor abnormalities were associated with reduced TTRs both in schizophrenics and in affective subjects with motor disturbance. The TTR is a reliable, objective indicator of language deviance and thought disorder, and strongly associated with motor disturbances.},
	language = {eng},
	journal = {The British Journal of Psychiatry: The Journal of Mental Science},
	author = {Manschreck, T. C. and Maher, B. A. and Ader, D. N.},
	month = jul,
	year = {1981},
	pmid = {6117348},
	keywords = {tokenization},
	pages = {7--15}
}

@book{kukla_mass_2005,
	title = {Mass hysteria: {Medicine}, culture, and mothers' bodies},
	shorttitle = {Mass hysteria},
	publisher = {Rowman \& Littlefield Publishers},
	author = {Kukla, Rebecca},
	year = {2005},
	keywords = {ethics},
	file = {Kukla - 2005 - Mass hysteria Medicine, culture, and mothers' bod.pdf:/Users/transfer/Zotero/storage/5BCCSG8L/Kukla - 2005 - Mass hysteria Medicine, culture, and mothers' bod.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/XFASFSJW/books.html:text/html}
}

@book{lakoff_language_2000,
	title = {The language war},
	publisher = {Univ of California Press},
	author = {Lakoff, Robin Tolmach},
	year = {2000},
	file = {Fulltext:/Users/transfer/Zotero/storage/BW9EKWUQ/Lakoff - 2000 - The language war.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/4ZWXM3GU/books.html:text/html}
}

@article{noauthor_platform_nodate,
	title = {A {Platform} for {Biomedical} {Discovery} and {Data}-{Powered} {Health} {Strategic} {Plan} 2017-2027},
	pages = {39},
	file = {A Platform for Biomedical Discovery and Data-Power.pdf:/Users/transfer/Zotero/storage/YJ78NRB3/A Platform for Biomedical Discovery and Data-Power.pdf:application/pdf;A Platform for Biomedical Discovery and Data-Power.pdf:/Users/transfer/Zotero/storage/IFE2HERB/A Platform for Biomedical Discovery and Data-Power.pdf:application/pdf;A Platform for Biomedical Discovery and Data-Power.pdf:/Users/transfer/Zotero/storage/BV8PLHLI/A Platform for Biomedical Discovery and Data-Power.pdf:application/pdf}
}

@inproceedings{suzuki_convolution_2004,
	title = {Convolution kernels with feature selection for natural language processing tasks},
	booktitle = {Proceedings of the 42nd {Annual} {Meeting} on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Suzuki, Jun and Isozaki, Hideki and Maeda, Eisaku},
	year = {2004},
	pages = {119},
	file = {Fulltext:/Users/transfer/Zotero/storage/BRPC48BG/Suzuki et al. - 2004 - Convolution kernels with feature selection for nat.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/AXMUD4D6/citation.html:text/html}
}

@inproceedings{daelemans_combined_2003,
	title = {Combined optimization of feature selection and algorithm parameters in machine learning of language},
	booktitle = {European {Conference} on {Machine} {Learning}},
	publisher = {Springer},
	author = {Daelemans, Walter and Hoste, Véronique and De Meulder, Fien and Naudts, Bart},
	year = {2003},
	pages = {84--95},
	file = {Fulltext:/Users/transfer/Zotero/storage/GM664KWA/Daelemans et al. - 2003 - Combined optimization of feature selection and alg.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ZB46GUBN/978-3-540-39857-8_10.html:text/html}
}

@inproceedings{lewis_feature_1992,
	title = {Feature selection and feature extraction for text categorization},
	booktitle = {Proceedings of the workshop on {Speech} and {Natural} {Language}},
	publisher = {Association for Computational Linguistics},
	author = {Lewis, David D.},
	year = {1992},
	pages = {212--217},
	file = {Fulltext:/Users/transfer/Zotero/storage/HQJ3LXFC/Lewis - 1992 - Feature selection and feature extraction for text .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SMUP5YAB/citation.html:text/html}
}

@article{bieliaieva_paronymy_2017-1,
	title = {{PARONYMY} {IN} {THE} {SUBLANGUAGE} {OF} {MEDICINE} ({LINGUISTIC} {AND} {LINGUO}-{DIDACTIC} {ASPECTS})},
	issn = {1512-0112},
	abstract = {The present paper examines the phenomenon of paronymy in the sublanguage of medicine. The study of paronyms plays an important role in the development of terminological competence of future specialists in the field of medicine and healthcare. The authors emphasize the need to pay due attention to terminological paronyms when compiling teaching manuals and developing didactic materials in Latin for students of medical universities. The urgency of organizing the work with these lexical units is determined, on the one hand, by the propaedeutic objective - minimization of difficulties that students may encounter in dealing with special terminology in the process of educational and professional communication; on the other hand, the study of paronyms is aimed at expanding the active and passive vocabulary of medical students. The objective of the research is to systematize paronyms in the international medical terminology, to develop the cycle of training assignments and methodological recommendations for organizing the work with this group of lexical units, and minimizing errors in oral and written speech of medical students. The authors have justified the methodological algorithm for the proposed cycle of tasks: presentation of the basic paronymic pairs, learning the vocabulary, control of mastering the material, creation of didactic conditions for correction and propaedeutics of speech errors; revision of the material. The proposed cycle of educational tasks is aimed at improving the lexical, grammatical, word-building, spelling knowledge, skills and abilities, as well as expanding and enriching the vocabulary of future medical professionals. The study may be of interest to specialists in the field of translation and terminology studies, professional linguo-didactics. The prospects for study consist in further in-depth research of the phenomenon of paronymy in the sublanguage of medicine and comprehensive analysis of other lexico-semantic relationships, the practical result of which will be the compilation of Latin medical dictionary of synonyms, homonyms and paronyms.},
	language = {eng},
	number = {271},
	journal = {Georgian Medical News},
	author = {Bieliaieva, O. and Lysanets, Yu and Havrylieva, K. and Znamenska, I. and Rozhenko, I. and Nikolaieva, N.},
	month = oct,
	year = {2017},
	pmid = {29099718},
	pages = {144--149}
}

@article{liu_facilitating_2014-1,
	title = {Facilitating post-surgical complication detection through sublanguage analysis},
	volume = {2014},
	issn = {2153-4063},
	abstract = {Identification of postsurgical complications is the first step towards improving patient safety and health care quality as well as reducing heath care cost. Existing NLP-based approaches for retrieving postsurgical complications are based on search strategies. Here, we conduct a sublanguage analysis study using free text reports available for a cohort of patients with postsurgical complications identified manually to compare the keywords identified by subject matter experts with words/phrases automatically identified by sublanguage analysis. The results suggest that search-based approaches may miss some cases and the sublanguage analysis results can be used as a base to develop an information extraction system or support search-based NLP approaches by augmenting search queries.},
	language = {eng},
	journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
	author = {Liu, Hongfang and Sohn, Sunghwan and Murphy, Sean and Lovely, Jenna and Burton, Matthew and Naessens, James and Larson, David W.},
	year = {2014},
	pmid = {25717405},
	pmcid = {PMC4333707},
	pages = {77--82}
}

@article{denecke_sublanguage_2014-1,
	title = {Sublanguage analysis of medical weblogs},
	volume = {205},
	issn = {0926-9630},
	abstract = {Analysing medical social media data gains in importance given an increased availability of such data. In this paper, we analyse the language of medical blogs by means of a sublanguage analysis. More specifically, verb usage, semantic categories of used words as well as co-occurrence patterns are determined by means of natural language processing tools. The results show that in this text type, many concepts refer to the semantic categories Living Beings and Chemicals and Drugs. In contrast to clinical documents, the spectrum of verbs in blogs is very broad creating semantic relations of different types. From these language characteristics, we conclude for automatic processing tools for medical blogs that methods for reference resolution and for relation extraction where the relation type does not need to be specified in advance are required.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Denecke, Kerstin},
	year = {2014},
	pmid = {25160249},
	pages = {565--569}
}

@article{elhadad_characterizing_2014-1,
	title = {Characterizing the sublanguage of online breast cancer forums for medications, symptoms, and emotions},
	volume = {2014},
	issn = {1942-597X},
	abstract = {Online health communities play an increasingly prevalent role for patients and are the source of a growing body of research. A lexicon that represents the sublanguage of an online community is an important resource to enable analysis and tool development over this data source. This paper investigates a method to generate a lexicon representative of the language of members in a given community with respect to specific semantic types. We experiment with a breast cancer community and detect terms that belong to three semantic types: medications, symptoms and side effects, and emotions. We assess the ability of our automatically generated lexicons to detect new terms, and show that a data-driven approach captures the sublanguage of members in these communities, all the while increasing coverage of general-purpose terminologies. The code and the generated lexicons are made available to the research community.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Elhadad, Noémie and Zhang, Shaodian and Driscoll, Patricia and Brody, Samuel},
	year = {2014},
	pmid = {25954356},
	pmcid = {PMC4419934},
	pages = {516--525}
}

@article{doing-harris_document_2013-1,
	title = {Document {Sublanguage} {Clustering} to {Detect} {Medical} {Specialty} in {Cross}-institutional {Clinical} {Texts}},
	volume = {2013},
	doi = {10.1145/2512089.2512101},
	abstract = {This paper reports on a set of studies designed to identify sublanguages in documents for domain-specific processing across institutions. Psychological evidence indicates that humans use context-specific linguistic information when they read. Natural Language Processing (NLP) pipelines are successful within specific domains (i.e., contexts). To limit the number of domain-specific NLP systems, a natural focus would be on sublanguages. Sublanguages are identified by shared lexical and semantic features.[1] Patterson and Hurdle[2] developed a sublanguage identification system that functioned well for 12 clinical specialties at the University of Utah. The current work compares sublanguages across institutions. Using a clinical NLP pipeline augmented by a new document corpus from the University of Pittsburg (UPitt), new documents were assigned to clusters based on the minimum cosine-distance to a Utah cluster centroid. The UPitt documents were divided into a nine-group specialty corpus. Across institutions, five of the specialty groups fell within the expected clusters. We find that clustering encounters difficulty due to documents with mixed sublanguages; naming convention differences across institutions; and document types used across specialties. The findings indicate that clinical specialty sublanguages can be identified across institutions.},
	language = {eng},
	journal = {Proceedings of the ACM ... International Workshop on Data and Text Mining in Biomedical Informatics. ACM International Workshop on Data and Text Mining in Biomedical Informatics},
	author = {Doing-Harris, Kristina and Patterson, Olga and Igo, Sean and Hurdle, John},
	month = nov,
	year = {2013},
	pmid = {27077137},
	pmcid = {PMC4827341},
	pages = {9--12}
}

@article{kate_unsupervised_2012-1,
	title = {Unsupervised grammar induction of clinical report sublanguage},
	volume = {3 Suppl 3},
	issn = {2041-1480},
	doi = {10.1186/2041-1480-3-S3-S4},
	abstract = {BACKGROUND: Clinical reports are written using a subset of natural language while employing many domain-specific terms; such a language is also known as a sublanguage for a scientific or a technical domain. Different genres of clinical reports use different sublaguages, and in addition, different medical facilities use different medical language conventions. This makes supervised training of a parser for clinical sentences very difficult as it would require expensive annotation effort to adapt to every type of clinical text.
METHODS: In this paper, we present an unsupervised method which automatically induces a grammar and a parser for the sublanguage of a given genre of clinical reports from a corpus with no annotations. In order to capture sentence structures specific to clinical domains, the grammar is induced in terms of semantic classes of clinical terms in addition to part-of-speech tags. Our method induces grammar by minimizing the combined encoding cost of the grammar and the corresponding sentence derivations. The probabilities for the productions of the induced grammar are then learned from the unannotated corpus using an instance of the expectation-maximization algorithm.
RESULTS: Our experiments show that the induced grammar is able to parse novel sentences. Using a dataset of discharge summary sentences with no annotations, our method obtains 60.5\% F-measure for parse-bracketing on sentences of maximum length 10. By varying a parameter, the method can induce a range of grammars, from very specific to very general, and obtains the best performance in between the two extremes.},
	language = {eng},
	journal = {Journal of Biomedical Semantics},
	author = {Kate, Rohit J.},
	month = oct,
	year = {2012},
	pmid = {23046834},
	pmcid = {PMC3465207},
	pages = {S4}
}

@article{danielsson-ojala_describing_2012-1,
	title = {Describing the sublanguage of wound care in an adult {ICU}},
	volume = {180},
	issn = {0926-9630},
	abstract = {Comprehensive wound documentation is an important tool in evaluating and planning patient care. The sublanguage used in ICUs may affect negatively to the wound care and thus to the healing process. We made a quantitative content analysis of nursing documentation of cardiac surgery adult patients (n=60) who had stayed over four days in the ICU. The sublanguage used in nursing documentation of wounds and ulcers in the ICU was unstructured with many words of colloquial language, misspellings and abbreviations. The documentation did not cover all aspects of proper wound care. The information technology could be helpful for nurses to document right things with plain language.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Danielsson-Ojala, Riitta and Lundgren-Laine, Heljä and Salanterä, Sanna},
	year = {2012},
	pmid = {22874364},
	pages = {1093--1095}
}

@article{patterson_automatic_2010-1,
	title = {Automatic acquisition of sublanguage semantic schema: towards the word sense disambiguation of clinical narratives},
	volume = {2010},
	issn = {1942-597X},
	shorttitle = {Automatic acquisition of sublanguage semantic schema},
	abstract = {Natural language processing of clinical notes is challenging due to a high degree of semantic ambiguity. Previous research has uncovered ways to improve disambiguation accuracy using manually created rules of semantic sentence structure. However, applying a natural language processing system in a new clinical domain using this method is very labor intensive. This paper presents an automatic method of developing such disambiguation rules for a wide range of clinical domains. Our rules are based on the co-occurrence patterns of semantic types of terms unambiguously mapped to UMLS concepts by MetaMap. These patterns are combined into a sublanguage semantic schema that can be used by an existing natural language processing system such as MetaMap. The differences of co-occurrence patterns across clinical notes of different domains are presented here as evidence of clinical sublanguages.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Patterson, Olga and Igo, Sean and Hurdle, John F.},
	month = nov,
	year = {2010},
	pmid = {21347051},
	pmcid = {PMC3041300},
	pages = {612--616}
}

@article{laippala_towards_2009-1,
	title = {Towards automated processing of clinical {Finnish}: sublanguage analysis and a rule-based parser},
	volume = {78},
	issn = {1872-8243},
	shorttitle = {Towards automated processing of clinical {Finnish}},
	doi = {10.1016/j.ijmedinf.2009.02.005},
	abstract = {INTRODUCTION: In this paper, we present steps taken towards more efficient automated processing of clinical Finnish, focusing on daily nursing notes in a Finnish Intensive Care Unit (ICU). First, we analyze ICU Finnish as a sublanguage, identifying its specific features facilitating, for example, the development of a specialized syntactic analyser. The identified features include frequent omission of finite verbs, limitations in allowed syntactic structures, and domain-specific vocabulary. Second, we develop a formal grammar and a parser for ICU Finnish, thus providing better tools for the development of further applications in the clinical domain.
METHODS: The grammar is implemented in the LKB system in a typed feature structure formalism. The lexicon is automatically generated based on the output of the FinTWOL morphological analyzer adapted to the clinical domain. As an additional experiment, we study the effect of using Finnish constraint grammar to reduce the size of the lexicon. The parser construction thus makes efficient use of existing resources for Finnish.
RESULTS: The grammar currently covers 76.6\% of ICU Finnish sentences, producing highly accurate best-parse analyzes with F-score of 91.1\%. We find that building a parser for the highly specialized domain sublanguage is not only feasible, but also surprisingly efficient, given an existing morphological analyzer with broad vocabulary coverage. The resulting parser enables a deeper analysis of the text than was previously possible.},
	language = {eng},
	number = {12},
	journal = {International Journal of Medical Informatics},
	author = {Laippala, Veronika and Ginter, Filip and Pyysalo, Sampo and Salakoski, Tapio},
	month = dec,
	year = {2009},
	pmid = {19299195},
	pages = {e7--12}
}

@article{pyysalo_lexical_2006-1,
	title = {Lexical adaptation of link grammar to the biomedical sublanguage: a comparative evaluation of three approaches},
	volume = {7 Suppl 3},
	issn = {1471-2105},
	shorttitle = {Lexical adaptation of link grammar to the biomedical sublanguage},
	doi = {10.1186/1471-2105-7-S3-S2},
	abstract = {BACKGROUND: We study the adaptation of Link Grammar Parser to the biomedical sublanguage with a focus on domain terms not found in a general parser lexicon. Using two biomedical corpora, we implement and evaluate three approaches to addressing unknown words: automatic lexicon expansion, the use of morphological clues, and disambiguation using a part-of-speech tagger. We evaluate each approach separately for its effect on parsing performance and consider combinations of these approaches.
RESULTS: In addition to a 45\% increase in parsing efficiency, we find that the best approach, incorporating information from a domain part-of-speech tagger, offers a statistically significant 10\% relative decrease in error.
CONCLUSION: When available, a high-quality domain part-of-speech tagger is the best solution to unknown word issues in the domain adaptation of a general parser. In the absence of such a resource, surface clues can provide remarkably good coverage and performance when tuned to the domain. The adapted parser is available under an open-source license.},
	language = {eng},
	journal = {BMC bioinformatics},
	author = {Pyysalo, Sampo and Salakoski, Tapio and Aubin, Sophie and Nazarenko, Adeline},
	month = nov,
	year = {2006},
	pmid = {17134475},
	pmcid = {PMC1764446},
	pages = {S2}
}

@article{wermter_really_2004-1,
	title = {Really, is medical sublanguage that different? {Experimental} counter-evidence from tagging medical and newspaper corpora},
	volume = {107},
	issn = {0926-9630},
	shorttitle = {Really, is medical sublanguage that different?},
	abstract = {We compare the performance of two part-of-speech taggers trained on a German newspaper corpus for mixed types of medical documents. TnT, a tagger based on a statistical language model, outperforms Brill's rule-based tagger, and supplied with additional lexicon resources matches state-of-the-art performance figures (close to 97\% accuracy) on the medical corpus. We explain this unexpected result by focusing on the statistically significant part-of-speech type overlap between the newspaper training set and the medical test set. At least at that level, sublanguage differences seem to vanish. Thus, statistical off-the-shelf part-of-speech taggers can immediately be reused for medical language processing},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Wermter, Joachim and Hahn, Udo},
	year = {2004},
	pmid = {15360875},
	pages = {560--564}
}

@article{noauthor_special_2002-1,
	title = {Special {Issue}: {Sublanguage}. {Dedicated} to the memory of {Zellig} {Harris}},
	volume = {35},
	issn = {1532-0464},
	shorttitle = {Special {Issue}},
	language = {eng},
	number = {4},
	journal = {Journal of Biomedical Informatics},
	month = aug,
	year = {2002},
	pmid = {14712827},
	pages = {213--277}
}

@article{stetson_sublanguage_2002-1,
	title = {The sublanguage of cross-coverage},
	issn = {1531-605X},
	abstract = {At Columbia-Presbyterian Medical Center, free-text "Signout" notes are typed into the electronic record by clinicians for the purpose of cross-coverage. We plan to "unlock" information about adverse events contained in these notes in a subsequent project using Natural Language Processing (NLP). To better understand the requirements for parsing, Signout notes were compared to other common medical notes (ambulatory clinic notes and discharge summaries) on a series of quantitative metrics. They are shorter (mean length 59.25 words vs. 144.11 and 340.85 for ambulatory and discharge notes respectively) and use more abbreviations (26.88\% vs. 20.07\% and 3.57\%). Despite being terser, Signout notes use less ambiguous abbreviations (8.34\% vs. 9.09\% and 18.02\%). Differences were found using Relative Entropy and Squared Chi-square Distance in a novel fashion to compare these medical corpora. Signout notes appear to constitute a unique sublanguage of medicine. The implications for parsing free-text cross-coverage notes into coded medical data are discussed.},
	language = {eng},
	journal = {Proceedings. AMIA Symposium},
	author = {Stetson, Peter D. and Johnson, Stephen B. and Scotch, Matthew and Hripcsak, George},
	year = {2002},
	pmid = {12463923},
	pmcid = {PMC2244148},
	pages = {742--746}
}

@article{johnson_conceptual_1998-1,
	title = {Conceptual graph grammar--a simple formalism for sublanguage},
	volume = {37},
	issn = {0026-1270},
	abstract = {There are a wide variety of computer applications that deal with various aspects of medical language: concept representation, controlled vocabulary, natural language processing, and information retrieval. While technical and theoretical methods appear to differ, all approaches investigate different aspects of the same phenomenon: medical sublanguage. This paper surveys the properties of medical sublanguage from a formal perspective, based on detailed analyses cited in the literature. A review of several computer systems based on sublanguage approaches shows some of the difficulties in addressing the interaction between the syntactic and semantic aspects of sublanguage. A formalism called Conceptual Graph Grammar is presented that attempts to combine both syntax and semantics into a single notation by extending standard Conceptual Graph notation. Examples from the domain of pathology diagnoses are provided to illustrate the use of this formalism in medical language analysis. The strengths and weaknesses of the approach are then considered. Conceptual Graph Grammar is an attempt to synthesize the common properties of different approaches to sublanguage into a single formalism, and to begin to define a common foundation for language-related research in medical informatics.},
	language = {eng},
	number = {4-5},
	journal = {Methods of Information in Medicine},
	author = {Johnson, S. B.},
	month = nov,
	year = {1998},
	pmid = {9865032},
	pages = {345--352}
}

@article{pyysalo_lexical_2006-2,
	title = {Lexical adaptation of link grammar to the biomedical sublanguage: a comparative evaluation of three approaches},
	volume = {7},
	issn = {1471-2105},
	shorttitle = {Lexical adaptation of link grammar to the biomedical sublanguage},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1764446/},
	doi = {10.1186/1471-2105-7-S3-S2},
	abstract = {Background
We study the adaptation of Link Grammar Parser to the biomedical sublanguage with a focus on domain terms not found in a general parser lexicon. Using two biomedical corpora, we implement and evaluate three approaches to addressing unknown words: automatic lexicon expansion, the use of morphological clues, and disambiguation using a part-of-speech tagger. We evaluate each approach separately for its effect on parsing performance and consider combinations of these approaches.

Results
In addition to a 45\% increase in parsing efficiency, we find that the best approach, incorporating information from a domain part-of-speech tagger, offers a statistically significant 10\% relative decrease in error.

Conclusion
When available, a high-quality domain part-of-speech tagger is the best solution to unknown word issues in the domain adaptation of a general parser. In the absence of such a resource, surface clues can provide remarkably good coverage and performance when tuned to the domain. The adapted parser is available under an open-source license.},
	number = {Suppl 3},
	urldate = {2018-03-24},
	journal = {BMC Bioinformatics},
	author = {Pyysalo, Sampo and Salakoski, Tapio and Aubin, Sophie and Nazarenko, Adeline},
	month = nov,
	year = {2006},
	pmid = {17134475},
	pmcid = {PMC1764446},
	pages = {S2},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/X723ZQXQ/Pyysalo et al. - 2006 - Lexical adaptation of link grammar to the biomedic.pdf:application/pdf}
}

@article{stetson_sublanguage_2002-2,
	title = {The sublanguage of cross-coverage.},
	issn = {1531-605X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2244148/},
	abstract = {At Columbia-Presbyterian Medical Center, free-text "Signout" notes are typed into the electronic record by clinicians for the purpose of cross-coverage. We plan to "unlock" information about adverse events contained in these notes in a subsequent project using Natural Language Processing (NLP). To better understand the requirements for parsing, Signout notes were compared to other common medical notes (ambulatory clinic notes and discharge summaries) on a series of quantitative metrics. They are shorter (mean length 59.25 words vs. 144.11 and 340.85 for ambulatory and discharge notes respectively) and use more abbreviations (26.88\% vs. 20.07\% and 3.57\%). Despite being terser, Signout notes use less ambiguous abbreviations (8.34\% vs. 9.09\% and 18.02\%). Differences were found using Relative Entropy and Squared Chi-square Distance in a novel fashion to compare these medical corpora. Signout notes appear to constitute a unique sublanguage of medicine. The implications for parsing free-text cross-coverage notes into coded medical data are discussed.},
	urldate = {2018-03-24},
	journal = {Proceedings of the AMIA Symposium},
	author = {Stetson, Peter D. and Johnson, Stephen B. and Scotch, Matthew and Hripcsak, George},
	year = {2002},
	pmid = {12463923},
	pmcid = {PMC2244148},
	pages = {742--746},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/DSTR4H8H/Stetson et al. - 2002 - The sublanguage of cross-coverage..pdf:application/pdf}
}

@article{johnson_sublanguage_1989,
	title = {Sublanguage {Analysis} as a {Basis} for a {Controlled} {Medical} {Vocabulary}},
	issn = {0195-4210},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245667/},
	abstract = {A method for establishing controlled vocabularies is proposed, based on the analysis of natural language as used in particular areas of expertise (sublanguage). The proposed vocabulary includes terms for relations as well as terms for objects, organized into class hierarchies. The method provides a controlled technique for eliciting distinctions about terms from experts, and aids in minimizing redundancy in the vocabulary. The vocabulary can be represented and managed using frames, semantic nets, or object-oriented techniques. The approach suggests a way of integrating free text and controlled terms in medical information systems through the intermediate structures of sublanguage.},
	urldate = {2018-03-24},
	journal = {Proceedings of the Annual Symposium on Computer Application in Medical Care},
	author = {Johnson, Stephen B. and Gottfried, Michael},
	month = nov,
	year = {1989},
	pmid = {null},
	pmcid = {PMC2245667},
	pages = {519--523},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/I5LL2Q5Y/Johnson and Gottfried - 1989 - Sublanguage Analysis as a Basis for a Controlled M.pdf:application/pdf}
}

@article{patterson_automatic_2010-2,
	title = {Automatic {Acquisition} of {Sublanguage} {Semantic} {Schema}: {Towards} the {Word} {Sense} {Disambiguation} of {Clinical} {Narratives}},
	volume = {2010},
	issn = {1942-597X},
	shorttitle = {Automatic {Acquisition} of {Sublanguage} {Semantic} {Schema}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041300/},
	abstract = {Natural language processing of clinical notes is challenging due to a high degree of semantic ambiguity. Previous research has uncovered ways to improve disambiguation accuracy using manually created rules of semantic sentence structure. However, applying a natural language processing system in a new clinical domain using this method is very labor intensive. This paper presents an automatic method of developing such disambiguation rules for a wide range of clinical domains. Our rules are based on the co-occurrence patterns of semantic types of terms unambiguously mapped to UMLS concepts by MetaMap. These patterns are combined into a sublanguage semantic schema that can be used by an existing natural language processing system such as MetaMap. The differences of co-occurrence patterns across clinical notes of different domains are presented here as evidence of clinical sublanguages.},
	urldate = {2018-03-24},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Patterson, Olga and Igo, Sean and Hurdle, John F.},
	year = {2010},
	pmid = {21347051},
	pmcid = {PMC3041300},
	pages = {612--616},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/44XNKSRA/Patterson et al. - 2010 - Automatic Acquisition of Sublanguage Semantic Sche.pdf:application/pdf}
}

@article{kate_unsupervised_2012-2,
	title = {Unsupervised grammar induction of clinical report sublanguage},
	volume = {3},
	issn = {2041-1480},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3465207/},
	doi = {10.1186/2041-1480-3-S3-S4},
	abstract = {Background
Clinical reports are written using a subset of natural language while employing many domain-specific terms; such a language is also known as a sublanguage for a scientific or a technical domain. Different genres of clinical reports use different sublaguages, and in addition, different medical facilities use different medical language conventions. This makes supervised training of a parser for clinical sentences very difficult as it would require expensive annotation effort to adapt to every type of clinical text.

Methods
In this paper, we present an unsupervised method which automatically induces a grammar and a parser for the sublanguage of a given genre of clinical reports from a corpus with no annotations. In order to capture sentence structures specific to clinical domains, the grammar is induced in terms of semantic classes of clinical terms in addition to part-of-speech tags. Our method induces grammar by minimizing the combined encoding cost of the grammar and the corresponding sentence derivations. The probabilities for the productions of the induced grammar are then learned from the unannotated corpus using an instance of the expectation-maximization algorithm.

Results
Our experiments show that the induced grammar is able to parse novel sentences. Using a dataset of discharge summary sentences with no annotations, our method obtains 60.5\% F-measure for parse-bracketing on sentences of maximum length 10. By varying a parameter, the method can induce a range of grammars, from very specific to very general, and obtains the best performance in between the two extremes.},
	number = {Suppl 3},
	urldate = {2018-03-24},
	journal = {Journal of Biomedical Semantics},
	author = {Kate, Rohit J},
	month = oct,
	year = {2012},
	pmid = {23046834},
	pmcid = {PMC3465207},
	pages = {S4},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/88D9YNVB/Kate - 2012 - Unsupervised grammar induction of clinical report .pdf:application/pdf}
}

@article{liu_facilitating_2014-2,
	title = {Facilitating post-surgical complication detection through sublanguage analysis},
	volume = {2014},
	issn = {2153-4063},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4333707/},
	abstract = {Identification of postsurgical complications is the first step towards improving patient safety and health care quality as well as reducing heath care cost. Existing NLP-based approaches for retrieving postsurgical complications are based on search strategies. Here, we conduct a sublanguage analysis study using free text reports available for a cohort of patients with postsurgical complications identified manually to compare the keywords identified by subject matter experts with words/phrases automatically identified by sublanguage analysis. The results suggest that search-based approaches may miss some cases and the sublanguage analysis results can be used as a base to develop an information extraction system or support search-based NLP approaches by augmenting search queries.},
	urldate = {2018-03-24},
	journal = {AMIA Summits on Translational Science Proceedings},
	author = {Liu, Hongfang and Sohn, Sunghwan and Murphy, Sean and Lovely, Jenna and Burton, Matthew and Naessens, James and Larson, David W},
	month = apr,
	year = {2014},
	pmid = {25717405},
	pmcid = {PMC4333707},
	pages = {77--82},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/ERWR4D5Y/Liu et al. - 2014 - Facilitating post-surgical complication detection .pdf:application/pdf}
}

@article{elhadad_characterizing_2014-2,
	title = {Characterizing the {Sublanguage} of {Online} {Breast} {Cancer} {Forums} for {Medications}, {Symptoms}, and {Emotions}},
	volume = {2014},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4419934/},
	abstract = {Online health communities play an increasingly prevalent role for patients and are the source of a growing body of research. A lexicon that represents the sublanguage of an online community is an important resource to enable analysis and tool development over this data source. This paper investigates a method to generate a lexicon representative of the language of members in a given community with respect to specific semantic types. We experiment with a breast cancer community and detect terms that belong to three semantic types: medications, symptoms and side effects, and emotions. We assess the ability of our automatically generated lexicons to detect new terms, and show that a data-driven approach captures the sublanguage of members in these communities, all the while increasing coverage of general-purpose terminologies. The code and the generated lexicons are made available to the research community.},
	urldate = {2018-03-24},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Elhadad, Noémie and Zhang, Shaodian and Driscoll, Patricia and Brody, Samuel},
	month = nov,
	year = {2014},
	pmid = {25954356},
	pmcid = {PMC4419934},
	pages = {516--525},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/M5DEVUNH/Elhadad et al. - 2014 - Characterizing the Sublanguage of Online Breast Ca.pdf:application/pdf}
}

@article{doing-harris_document_2013-2,
	title = {Document {Sublanguage} {Clustering} to {Detect} {Medical} {Specialty} in {Cross}-institutional {Clinical} {Texts}},
	volume = {2013},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4827341/},
	doi = {10.1145/2512089.2512101},
	abstract = {This paper reports on a set of studies designed to identify sublanguages in documents for domain-specific processing across institutions. Psychological evidence indicates that humans use context-specific linguistic information when they read. Natural Language Processing (NLP) pipelines are successful within specific domains (i.e., contexts). To limit the number of domain-specific NLP systems, a natural focus would be on sublanguages. Sublanguages are identified by shared lexical and semantic features.[] Patterson and Hurdle[] developed a sublanguage identification system that functioned well for 12 clinical specialties at the University of Utah. The current work compares sublanguages across institutions. Using a clinical NLP pipeline augmented by a new document corpus from the University of Pittsburg (UPitt), new documents were assigned to clusters based on the minimum cosine-distance to a Utah cluster centroid. The UPitt documents were divided into a nine-group specialty corpus. Across institutions, five of the specialty groups fell within the expected clusters. We find that clustering encounters difficulty due to documents with mixed sublanguages; naming convention differences across institutions; and document types used across specialties. The findings indicate that clinical specialty sublanguages can be identified across institutions.},
	urldate = {2018-03-24},
	journal = {Proceedings of the ACM ... International Workshop on Data and Text Mining in Biomedical Informatics ACM International Workshop on Data and Text Mining in Biomedical Informatics},
	author = {Doing-Harris, Kristina and Patterson, Olga and Igo, Sean and Hurdle, John},
	year = {2013},
	pmid = {27077137},
	pmcid = {PMC4827341},
	pages = {9--12},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/72UUH8AU/Doing-Harris et al. - 2013 - Document Sublanguage Clustering to Detect Medical .pdf:application/pdf}
}

@article{temnikova_sublanguage_2014,
	title = {Sublanguage {Corpus} {Analysis} {Toolkit}: {A} tool for assessing the representativeness and sublanguage characteristics of corpora},
	volume = {2014},
	shorttitle = {Sublanguage {Corpus} {Analysis} {Toolkit}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860848/},
	abstract = {Sublanguages are varieties of language that form “subsets” of the general language, typically exhibiting particular types of lexical, semantic, and other restrictions and deviance. SubCAT, the Sublanguage Corpus Analysis Toolkit, assesses the representativeness and closure properties of corpora to analyze the extent to which they are either sublanguages, or representative samples of the general language. The current version of SubCAT contains scripts and applications for assessing lexical closure, morphological closure, sentence type closure, over-represented words, and syntactic deviance. Its operation is illustrated with three case studies concerning scientific journal articles, patents, and clinical records. Materials from two language families are analyzed—English (Germanic), and Bulgarian (Slavic). The software is available at sublanguage.sourceforge.net under a liberal Open Source license.},
	urldate = {2018-03-24},
	journal = {International Conference on Language Resources and Evaluation},
	author = {Temnikova, Irina P. and Baumgartner, William A. and Hailu, Negacy D. and Nikolova, Ivelina and McEnery, Tony and Kilgarriff, Adam and Angelova, Galia and Cohen, K. Bretonnel},
	month = may,
	year = {2014},
	pmid = {null},
	pmcid = {PMC5860848},
	keywords = {reproducibility},
	pages = {1714--1718},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/RDVI79A9/Temnikova et al. - 2014 - Sublanguage Corpus Analysis Toolkit A tool for as.pdf:application/pdf}
}

@book{fuchs_les_1996,
	title = {Les ambiguïtés du français},
	publisher = {Ophrys},
	author = {Fuchs, Catherine},
	year = {1996}
}

@article{shultz_development_1973,
	title = {Development of the {Ability} to {Detect} {Linguistic} {Ambiguity}},
	volume = {44},
	issn = {0009-3920},
	url = {http://www.jstor.org/stable/1127716},
	doi = {10.2307/1127716},
	abstract = {This study was conducted to assess the ability of children of 6, 9, 12, and 15 years of age to detect various types of linguistic ambiguity. The results suggested that the ability to detect linguistic ambiguity develops at different rates depending on the type of ambiguity. The ability to detect phonological ambiguity appeared first, with the largest improvement occurring between 6 and 9 years. Second to appear was the detection of lexical ambiguity, which exhibited a linear increase with age. Detection of surface- and deep-structure ambiguities did not occur until age 12.},
	number = {4},
	urldate = {2018-03-24},
	journal = {Child Development},
	author = {Shultz, Thomas R. and Pilon, Robert},
	year = {1973},
	pages = {728--733},
	file = {JSTOR Full Text PDF:/Users/transfer/Zotero/storage/K7XLWNKD/Shultz and Pilon - 1973 - Development of the Ability to Detect Linguistic Am.pdf:application/pdf}
}

@article{pepicello_linguistic_1980,
	title = {Linguistic {Strategies} in {Riddling}},
	volume = {39},
	issn = {0043-373X},
	url = {http://www.jstor.org/stable/1499760},
	doi = {10.2307/1499760},
	number = {1},
	urldate = {2018-03-24},
	journal = {Western Folklore},
	author = {Pepicello, W. J.},
	year = {1980},
	pages = {1--16},
	file = {JSTOR Full Text PDF:/Users/transfer/Zotero/storage/9U5RUMYJ/Pepicello - 1980 - Linguistic Strategies in Riddling.pdf:application/pdf}
}

@article{ioannidis_meta-research:_2018,
	title = {Meta-research: {Why} research on research matters},
	volume = {16},
	issn = {1545-7885},
	shorttitle = {Meta-research},
	url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005468},
	doi = {10.1371/journal.pbio.2005468},
	abstract = {Meta-research is the study of research itself: its methods, reporting, reproducibility, evaluation, and incentives. Given that science is the key driver of human progress, improving the efficiency of scientific investigation and yielding more credible and more useful research results can translate to major benefits. The research enterprise grows very fast. Both new opportunities for knowledge and innovation and new threats to validity and scientific integrity emerge. Old biases abound, and new ones continuously appear as novel disciplines emerge with different standards and challenges. Meta-research uses an interdisciplinary approach to study, promote, and defend robust science. Major disruptions are likely to happen in the way we pursue scientific investigation, and it is important to ensure that these disruptions are evidence based.},
	language = {en},
	number = {3},
	urldate = {2018-03-24},
	journal = {PLOS Biology},
	author = {Ioannidis, John P. A.},
	month = mar,
	year = {2018},
	pages = {e2005468},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/56X6THNW/Ioannidis - 2018 - Meta-research Why research on research matters.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MWJW2FA2/article.html:text/html}
}

@article{nakov_interpretation_nodate,
	title = {On the {Interpretation} of {Noun} {Compounds}: {Syntax}, {Semantics}, {Entailment}},
	abstract = {We discuss the problem of interpreting noun compounds such as colon cancer tumor suppressor protein, which pose major challenges for the automatic interpretation of English written text. We present an overview of the more general process of compounding and of noun compounds in particular, as well as of their syntax and semantics from both theoretical and computational linguistics viewpoint with an emphasis on the latter. Our main focus is on computational approaches to the syntax and semantics of noun compounds: we describe the problems, present the challenges, and discuss the most important lines of research. We also show how understanding noun compound syntax and semantics could help solve textual entailment problems, which would be potentially useful for a number of NLP applications, and which we believe to be an important direction for future research.},
	author = {NAKOV, PRESLAV},
	pages = {40},
	file = {NAKOV - On the Interpretation of Noun Compounds Syntax, S.pdf:/Users/transfer/Zotero/storage/IHFSX3IP/NAKOV - On the Interpretation of Noun Compounds Syntax, S.pdf:application/pdf}
}

@inproceedings{rosario_classifying_2004,
	title = {Classifying semantic relations in bioscience texts},
	url = {http://portal.acm.org/citation.cfm?doid=1218955.1219010},
	doi = {10.3115/1218955.1219010},
	abstract = {A crucial step toward the goal of automatic extraction of propositional information from natural language text is the identiﬁcation of semantic relations between constituents in sentences. We examine the problem of distinguishing among seven relation types that can occur between the entities “treatment” and “disease” in bioscience text, and the problem of identifying such entities. We compare ﬁve generative graphical models and a neural network, using lexical, syntactic, and semantic features, ﬁnding that the latter help achieve high classiﬁcation accuracy.},
	language = {en},
	urldate = {2018-03-24},
	publisher = {Association for Computational Linguistics},
	author = {Rosario, Barbara and Hearst, Marti A.},
	year = {2004},
	pages = {430--es},
	file = {Rosario and Hearst - 2004 - Classifying semantic relations in bioscience texts.pdf:/Users/transfer/Zotero/storage/5MEKUYAG/Rosario and Hearst - 2004 - Classifying semantic relations in bioscience texts.pdf:application/pdf}
}

@article{boutron_misrepresentation_2018,
	title = {Misrepresentation and distortion of research in biomedical literature},
	copyright = {© 2018 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/early/2018/03/08/1710755115},
	doi = {10.1073/pnas.1710755115},
	abstract = {Publication in peer-reviewed journals is an essential step in the scientific process. However, publication is not simply the reporting of facts arising from a straightforward analysis thereof. Authors have broad latitude when writing their reports and may be tempted to consciously or unconsciously “spin” their study findings. Spin has been defined as a specific intentional or unintentional reporting that fails to faithfully reflect the nature and range of findings and that could affect the impression the results produce in readers. This article, based on a literature review, reports the various practices of spin from misreporting by “beautification” of methods to misreporting by misinterpreting the results. It provides data on the prevalence of some forms of spin in specific fields and the possible effects of some types of spin on readers’ interpretation and research dissemination. We also discuss why researchers would spin their reports and possible ways to avoid it.},
	language = {en},
	urldate = {2018-03-24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Boutron, Isabelle and Ravaud, Philippe},
	month = mar,
	year = {2018},
	pmid = {29531025},
	keywords = {reproducibility, female first or senior, France},
	pages = {201710755},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/GD29R8CB/Boutron and Ravaud - 2018 - Misrepresentation and distortion of research in bi.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SQFHVHNL/1710755115.html:text/html}
}

@article{elhadad_comprehending_2006,
	title = {Comprehending {Technical} {Texts}: {Predicting} and {Defining} {Unfamiliar} {Terms}},
	volume = {2006},
	issn = {1942-597X},
	shorttitle = {Comprehending {Technical} {Texts}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1839621/},
	abstract = {We investigate how to improve access to medical literature for health consumers. Our focus is on medical terminology. We present a method to predict automatically in a given text which medical terms are unlikely to be understood by a lay reader. Our method, which is linguistically motivated and fully unsupervised, relies on how common a specific term is in texts that we already know are familiar to a lay reader. Once a term is identified as unfamiliar, an appropriate definition is mined from the Web to be provided to the reader. Our experiments show that the prediction and the addition of definitions significantly improve lay readers’ comprehension of sentences containing technical medical terms.},
	urldate = {2018-03-24},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Elhadad, Noemie},
	year = {2006},
	pmid = {17238339},
	pmcid = {PMC1839621},
	pages = {239--243},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/W7K6XWD9/Elhadad - 2006 - Comprehending Technical Texts Predicting and Defi.pdf:application/pdf}
}

@article{harris_theory_1976,
	title = {On a {Theory} of {Language}},
	volume = {73},
	issn = {0022-362X},
	url = {http://www.jstor.org/stable/2025530},
	doi = {10.2307/2025530},
	number = {10},
	urldate = {2018-03-24},
	journal = {The Journal of Philosophy},
	author = {Harris, Zellig},
	year = {1976},
	pages = {253--276}
}

@incollection{fuhr_test_2016,
	address = {Cham},
	title = {A {Test} {Collection} for {Research} on {Depression} and {Language} {Use}},
	volume = {9822},
	isbn = {978-3-319-44563-2 978-3-319-44564-9},
	url = {http://link.springer.com/10.1007/978-3-319-44564-9_3},
	abstract = {Several studies in the literature have shown that the words people use are indicative of their psychological states. In particular, depression was found to be associated with distinctive linguistic patterns. However, there is a lack of publicly available data for doing research on the interaction between language and depression. In this paper, we describe our ﬁrst steps to ﬁll this gap. We outline the methodology we have adopted to build and make publicly available a test collection on depression and language use. The resulting corpus includes a series of textual interactions written by diﬀerent subjects. The new collection not only encourages research on diﬀerences in language between depressed and non-depressed individuals, but also on the evolution of the language use of depressed individuals. Further, we propose a novel early detection task and deﬁne a novel eﬀectiveness measure to systematically compare early detection algorithms. This new measure takes into account both the accuracy of the decisions taken by the algorithm and the delay in detecting positive cases. We also present baseline results with novel detection methods that process users’ interactions in diﬀerent ways.},
	language = {en},
	urldate = {2018-03-25},
	booktitle = {Experimental {IR} {Meets} {Multilinguality}, {Multimodality}, and {Interaction}},
	publisher = {Springer International Publishing},
	author = {Losada, David E. and Crestani, Fabio},
	editor = {Fuhr, Norbert and Quaresma, Paulo and Gonçalves, Teresa and Larsen, Birger and Balog, Krisztian and Macdonald, Craig and Cappellato, Linda and Ferro, Nicola},
	year = {2016},
	doi = {10.1007/978-3-319-44564-9_3},
	pages = {28--39},
	file = {Losada and Crestani - 2016 - A Test Collection for Research on Depression and L.pdf:/Users/transfer/Zotero/storage/AQ39MH7N/Losada and Crestani - 2016 - A Test Collection for Research on Depression and L.pdf:application/pdf}
}

@incollection{dusterhoft_extensional_2012,
	address = {Berlin, Heidelberg},
	title = {Extensional {Logic} of {Hyperintensions}},
	volume = {7260},
	isbn = {978-3-642-28278-2 978-3-642-28279-9},
	url = {http://link.springer.com/10.1007/978-3-642-28279-9_19},
	abstract = {In this paper I describe an extensional logic of hyperintensions (Tichý’s Transparent Intensional Logic: TIL) preserving transparency and compositionality. TIL validates quantifying into all contexts, including intensional and hyperintensional ones. The availability of an extensional logic of hyperintensions defies the received view that an intensional (let alone hyperintensional) logic is one that fails to validate transparency, compositionality, and quantifying-in. The main features of our logic are that the senses and denotations of (non-indexical) terms and expressions remain invariant across contexts and that our ramified type theory enables quantification over any logical objects of any order. The syntax of TIL is the typed lambda calculus; its semantics is based on a procedural redefinition of, inter alia, functional abstraction and application. The only two non-standard features are a hyperintension (called Trivialization) that presents other hyperintensions and a four-place substitution function (called Sub) defined over hyperintensions.},
	language = {en},
	urldate = {2018-03-26},
	booktitle = {Conceptual {Modelling} and {Its} {Theoretical} {Foundations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Duží, Marie},
	editor = {Düsterhöft, Antje and Klettke, Meike and Schewe, Klaus-Dieter},
	year = {2012},
	doi = {10.1007/978-3-642-28279-9_19},
	pages = {268--290},
	file = {Duží - 2012 - Extensional Logic of Hyperintensions.pdf:/Users/transfer/Zotero/storage/YSMM7KCR/Duží - 2012 - Extensional Logic of Hyperintensions.pdf:application/pdf}
}

@article{albright_towards_2013,
	title = {Towards comprehensive syntactic and semantic annotations of the clinical narrative},
	volume = {20},
	issn = {1527-974X},
	doi = {10.1136/amiajnl-2012-001317},
	abstract = {OBJECTIVE: To create annotated clinical narratives with layers of syntactic and semantic labels to facilitate advances in clinical natural language processing (NLP). To develop NLP algorithms and open source components.
METHODS: Manual annotation of a clinical narrative corpus of 127 606 tokens following the Treebank schema for syntactic information, PropBank schema for predicate-argument structures, and the Unified Medical Language System (UMLS) schema for semantic information. NLP components were developed.
RESULTS: The final corpus consists of 13 091 sentences containing 1772 distinct predicate lemmas. Of the 766 newly created PropBank frames, 74 are verbs. There are 28 539 named entity (NE) annotations spread over 15 UMLS semantic groups, one UMLS semantic type, and the Person semantic category. The most frequent annotations belong to the UMLS semantic groups of Procedures (15.71\%), Disorders (14.74\%), Concepts and Ideas (15.10\%), Anatomy (12.80\%), Chemicals and Drugs (7.49\%), and the UMLS semantic type of Sign or Symptom (12.46\%). Inter-annotator agreement results: Treebank (0.926), PropBank (0.891-0.931), NE (0.697-0.750). The part-of-speech tagger, constituency parser, dependency parser, and semantic role labeler are built from the corpus and released open source. A significant limitation uncovered by this project is the need for the NLP community to develop a widely agreed-upon schema for the annotation of clinical concepts and their relations.
CONCLUSIONS: This project takes a foundational step towards bringing the field of clinical NLP up to par with NLP in the general domain. The corpus creation and NLP components provide a resource for research and application development that would have been previously impossible.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Albright, Daniel and Lanfranchi, Arrick and Fredriksen, Anwen and Styler, William F. and Warner, Colin and Hwang, Jena D. and Choi, Jinho D. and Dligach, Dmitriy and Nielsen, Rodney D. and Martin, James and Ward, Wayne and Palmer, Martha and Savova, Guergana K.},
	month = oct,
	year = {2013},
	pmid = {23355458},
	pmcid = {PMC3756257},
	pages = {922--930}
}

@article{friedman_towards_1997,
	title = {Towards a comprehensive medical language processing system: methods and issues},
	issn = {1091-8280},
	shorttitle = {Towards a comprehensive medical language processing system},
	abstract = {Natural language processing (NLP) systems can help solve the data entry problem by providing coded data from textual reports for clinical applications. A number of NLP systems have shown promise, but have not yet achieved wide-spread use for practical applications. In order to achieve such use, a system must have broad coverage of the clinical domain and not be restricted to limited applications. In addition, an NLP system must perform satisfactorily for real-world applications. This paper describes methods and issues associated with an ongoing extension of MedLEE, an operational NLP system, from a limited domain to a domain that encompasses comprehensive clinical information.},
	language = {eng},
	journal = {Proceedings: a conference of the American Medical Informatics Association. AMIA Fall Symposium},
	author = {Friedman, C.},
	year = {1997},
	pmid = {9357695},
	pmcid = {PMC2233560},
	pages = {595--599}
}

@article{stageberg_structural_1958,
	title = {Some structural ambiguities},
	volume = {47},
	number = {8},
	journal = {The English Journal},
	author = {Stageberg, Norman C.},
	year = {1958},
	pages = {479--486},
	file = {Snapshot:/Users/transfer/Zotero/storage/4ISEEBEQ/808990.html:text/html}
}

@article{bucaria_lexical_2004,
	title = {Lexical and syntactic ambiguity as a source of humor: {The} case of newspaper headlines},
	volume = {17},
	shorttitle = {Lexical and syntactic ambiguity as a source of humor},
	number = {3},
	journal = {Humor},
	author = {Bucaria, Chiara},
	year = {2004},
	pages = {279--310},
	file = {Fulltext:/Users/transfer/Zotero/storage/XH2EP9W3/Bucaria - 2004 - Lexical and syntactic ambiguity as a source of hum.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3KZBJE7R/humr.2004.013.html:text/html}
}

@article{sculley_machine_nodate,
	title = {Machine {Learning}: {The} {High}-{Interest} {Credit} {Card} of {Technical} {Debt}},
	abstract = {Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning speciﬁc risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.},
	language = {en},
	author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael},
	pages = {9},
	file = {Sculley et al. - Machine Learning The High-Interest Credit Card of.pdf:/Users/transfer/Zotero/storage/MFLAF2AZ/Sculley et al. - Machine Learning The High-Interest Credit Card of.pdf:application/pdf}
}

@article{rindflesch_informatics_2017,
	title = {Informatics {Support} for {Basic} {Research} in {Biomedicine}},
	volume = {58},
	issn = {1084-2020},
	url = {https://academic.oup.com/ilarjournal/article/58/1/80/4040992},
	doi = {10.1093/ilar/ilx004},
	abstract = {Informatics methodologies exploit computer-assisted techniques to help biomedical researchers manage large amounts of information. In this paper, we focus on the biomedical research literature (MEDLINE). We first provide an overview of some text mining techniques that offer assistance in research by identifying biomedical entities (e.g., genes, substances, and diseases) and relations between them in text.We then discuss Semantic MEDLINE, an application that integrates PubMed document retrieval, concept and relation identification, and visualization, thus enabling a user to explore concepts and relations from within a set of retrieved citations. Semantic MEDLINE provides a roadmap through content and helps users discern patterns in large numbers of retrieved citations. We illustrate its use with an informatics method we call “discovery browsing,” which provides a principled way of navigating through selected aspects of some biomedical research area. The method supports an iterative process that accommodates learning and hypothesis formation in which a user is provided with high level connections before delving into details.As a use case, we examine current developments in basic research on mechanisms of Alzheimer’s disease. Out of the nearly 90 000 citations returned by the PubMed query “Alzheimer’s disease,” discovery browsing led us to 73 citations on sortilin and that disorder. We provide a synopsis of the basic research reported in 15 of these. There is wide-spread consensus among researchers working with a range of animal models and human cells that increased sortilin expression and decreased receptor expression are associated with amyloid beta and/or amyloid precursor protein.},
	language = {en},
	number = {1},
	urldate = {2018-03-28},
	journal = {ILAR Journal},
	author = {Rindflesch, Thomas C. and Blake, Catherine L. and Fiszman, Marcelo and Kilicoglu, Halil and Rosemblat, Graciela and Schneider, Jodi and Zeiss, Caroline J.},
	month = jul,
	year = {2017},
	keywords = {reproducibility},
	pages = {80--89},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/ATKATD8T/Rindflesch et al. - 2017 - Informatics Support for Basic Research in Biomedic.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/N5LYG8R8/4040992.html:text/html}
}

@article{luo_natural_2017,
	title = {Natural {Language} {Processing} for {EHR}-{Based} {Pharmacovigilance}: {A} {Structured} {Review}},
	volume = {40},
	issn = {1179-1942},
	shorttitle = {Natural {Language} {Processing} for {EHR}-{Based} {Pharmacovigilance}},
	doi = {10.1007/s40264-017-0558-6},
	abstract = {The goal of pharmacovigilance is to detect, monitor, characterize and prevent adverse drug events (ADEs) with pharmaceutical products. This article is a comprehensive structured review of recent advances in applying natural language processing (NLP) to electronic health record (EHR) narratives for pharmacovigilance. We review methods of varying complexity and problem focus, summarize the current state-of-the-art in methodology advancement, discuss limitations and point out several promising future directions. The ability to accurately capture both semantic and syntactic structures in clinical narratives becomes increasingly critical to enable efficient and accurate ADE detection. Significant progress has been made in algorithm development and resource construction since 2000. Since 2012, statistical analysis and machine learning methods have gained traction in automation of ADE mining from EHR narratives. Current state-of-the-art methods for NLP-based ADE detection from EHRs show promise regarding their integration into production pharmacovigilance systems. In addition, integrating multifaceted, heterogeneous data sources has shown promise in improving ADE detection and has become increasingly adopted. On the other hand, challenges and opportunities remain across the frontier of NLP application to EHR-based pharmacovigilance, including proper characterization of ADE context, differentiation between off- and on-label drug-use ADEs, recognition of the importance of polypharmacy-induced ADEs, better integration of heterogeneous data sources, creation of shared corpora, and organization of shared-task challenges to advance the state-of-the-art.},
	language = {eng},
	number = {11},
	journal = {Drug Safety},
	author = {Luo, Yuan and Thompson, William K. and Herr, Timothy M. and Zeng, Zexian and Berendsen, Mark A. and Jonnalagadda, Siddhartha R. and Carson, Matthew B. and Starren, Justin},
	month = nov,
	year = {2017},
	pmid = {28643174},
	pages = {1075--1089}
}

@article{alvaro_twimed:_2017,
	title = {{TwiMed}: {Twitter} and {PubMed} {Comparable} {Corpus} of {Drugs}, {Diseases}, {Symptoms}, and {Their} {Relations}},
	volume = {3},
	issn = {2369-2960},
	shorttitle = {{TwiMed}},
	doi = {10.2196/publichealth.6396},
	abstract = {BACKGROUND: Work on pharmacovigilance systems using texts from PubMed and Twitter typically target at different elements and use different annotation guidelines resulting in a scenario where there is no comparable set of documents from both Twitter and PubMed annotated in the same manner.
OBJECTIVE: This study aimed to provide a comparable corpus of texts from PubMed and Twitter that can be used to study drug reports from these two sources of information, allowing researchers in the area of pharmacovigilance using natural language processing (NLP) to perform experiments to better understand the similarities and differences between drug reports in Twitter and PubMed.
METHODS: We produced a corpus comprising 1000 tweets and 1000 PubMed sentences selected using the same strategy and annotated at entity level by the same experts (pharmacists) using the same set of guidelines.
RESULTS: The resulting corpus, annotated by two pharmacists, comprises semantically correct annotations for a set of drugs, diseases, and symptoms. This corpus contains the annotations for 3144 entities, 2749 relations, and 5003 attributes.
CONCLUSIONS: We present a corpus that is unique in its characteristics as this is the first corpus for pharmacovigilance curated from Twitter messages and PubMed sentences using the same data selection and annotation strategies. We believe this corpus will be of particular interest for researchers willing to compare results from pharmacovigilance systems (eg, classifiers and named entity recognition systems) when using data from Twitter and from PubMed. We hope that given the comprehensive set of drug names and the annotated entities and relations, this corpus becomes a standard resource to compare results from different pharmacovigilance studies in the area of NLP.},
	language = {eng},
	number = {2},
	journal = {JMIR public health and surveillance},
	author = {Alvaro, Nestor and Miyao, Yusuke and Collier, Nigel},
	month = may,
	year = {2017},
	pmid = {28468748},
	pmcid = {PMC5438461},
	keywords = {annotation, corpus, natural language processing, pharmacovigilance, PubMed, text mining, Twitter},
	pages = {e24}
}

@article{demner-fushman_aspiring_2016,
	title = {Aspiring to {Unintended} {Consequences} of {Natural} {Language} {Processing}: {A} {Review} of {Recent} {Developments} in {Clinical} and {Consumer}-{Generated} {Text} {Processing}},
	issn = {2364-0502},
	shorttitle = {Aspiring to {Unintended} {Consequences} of {Natural} {Language} {Processing}},
	doi = {10.15265/IY-2016-017},
	abstract = {OBJECTIVES: This paper reviews work over the past two years in Natural Language Processing (NLP) applied to clinical and consumer-generated texts.
METHODS: We included any application or methodological publication that leverages text to facilitate healthcare and address the health-related needs of consumers and populations.
RESULTS: Many important developments in clinical text processing, both foundational and task-oriented, were addressed in community- wide evaluations and discussed in corresponding special issues that are referenced in this review. These focused issues and in-depth reviews of several other active research areas, such as pharmacovigilance and summarization, allowed us to discuss in greater depth disease modeling and predictive analytics using clinical texts, and text analysis in social media for healthcare quality assessment, trends towards online interventions based on rapid analysis of health-related posts, and consumer health question answering, among other issues.
CONCLUSIONS: Our analysis shows that although clinical NLP continues to advance towards practical applications and more NLP methods are used in large-scale live health information applications, more needs to be done to make NLP use in clinical applications a routine widespread reality. Progress in clinical NLP is mirrored by developments in social media text analysis: the research is moving from capturing trends to addressing individual health-related posts, thus showing potential to become a tool for precision medicine and a valuable addition to the standard healthcare quality evaluation tools.},
	language = {eng},
	number = {1},
	journal = {Yearbook of Medical Informatics},
	author = {Demner-Fushman, D. and Elhadad, N.},
	month = nov,
	year = {2016},
	pmid = {27830255},
	pmcid = {PMC5171557},
	keywords = {review, computing methodologies, Consumer Health Information, Electronic Health Records, Humans, medical informatics applications, Medical Informatics Applications, Natural Language Processing, Pharmacovigilance, Phenotype, social media},
	pages = {224--233}
}

@article{sarker_social_2016-1,
	title = {{SOCIAL} {MEDIA} {MINING} {SHARED} {TASK} {WORKSHOP}},
	volume = {21},
	issn = {2335-6936},
	abstract = {Social media has evolved into a crucial resource for obtaining large volumes of real-time information. The promise of social media has been realized by the public health domain, and recent research has addressed some important challenges in that domain by utilizing social media data. Tasks such as monitoring flu trends, viral disease outbreaks, medication abuse, and adverse drug reactions are some examples of studies where data from social media have been exploited. The focus of this workshop is to explore solutions to three important natural language processing challenges for domain-specific social media text: (i) text classification, (ii) information extraction, and (iii) concept normalization. To explore different approaches to solving these problems on social media data, we designed a shared task which was open to participants globally. We designed three tasks using our in-house annotated Twitter data on adverse drug reactions. Task 1 involved automatic classification of adverse drug reaction assertive user posts; Task 2 focused on extracting specific adverse drug reaction mentions from user posts; and Task 3, which was slightly ill-defined due to the complex nature of the problem, involved normalizing user mentions of adverse drug reactions to standardized concept IDs. A total of 11 teams participated, and a total of 24 (18 for Task 1, and 6 for Task 2) system runs were submitted. Following the evaluation of the systems, and an assessment of their innovation/novelty, we accepted 7 descriptive manuscripts for publication--5 for Task 1 and 2 for Task 2. We provide descriptions of the tasks, data, and participating systems in this paper.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Sarker, Abeed and Nikfarjam, Azadeh and Gonzalez, Graciela},
	year = {2016},
	pmid = {26776221},
	keywords = {Humans, Natural Language Processing, Pharmacovigilance, Adverse Drug Reaction Reporting Systems, Computational Biology, Data Mining, Drug-Related Side Effects and Adverse Reactions, Social Media, Supervised Machine Learning, Support Vector Machine},
	pages = {581--592}
}

@article{lardon_adverse_2015,
	title = {Adverse {Drug} {Reaction} {Identification} and {Extraction} in {Social} {Media}: {A} {Scoping} {Review}},
	volume = {17},
	issn = {1438-8871},
	shorttitle = {Adverse {Drug} {Reaction} {Identification} and {Extraction} in {Social} {Media}},
	doi = {10.2196/jmir.4304},
	abstract = {BACKGROUND: The underreporting of adverse drug reactions (ADRs) through traditional reporting channels is a limitation in the efficiency of the current pharmacovigilance system. Patients' experiences with drugs that they report on social media represent a new source of data that may have some value in postmarketing safety surveillance.
OBJECTIVE: A scoping review was undertaken to explore the breadth of evidence about the use of social media as a new source of knowledge for pharmacovigilance.
METHODS: Daubt et al's recommendations for scoping reviews were followed. The research questions were as follows: How can social media be used as a data source for postmarketing drug surveillance? What are the available methods for extracting data? What are the different ways to use these data? We queried PubMed, Embase, and Google Scholar to extract relevant articles that were published before June 2014 and with no lower date limit. Two pairs of reviewers independently screened the selected studies and proposed two themes of review: manual ADR identification (theme 1) and automated ADR extraction from social media (theme 2). Descriptive characteristics were collected from the publications to create a database for themes 1 and 2.
RESULTS: Of the 1032 citations from PubMed and Embase, 11 were relevant to the research question. An additional 13 citations were added after further research on the Internet and in reference lists. Themes 1 and 2 explored 11 and 13 articles, respectively. Ways of approaching the use of social media as a pharmacovigilance data source were identified.
CONCLUSIONS: This scoping review noted multiple methods for identifying target data, extracting them, and evaluating the quality of medical information from social media. It also showed some remaining gaps in the field. Studies related to the identification theme usually failed to accurately assess the completeness, quality, and reliability of the data that were analyzed from social media. Regarding extraction, no study proposed a generic approach to easily adding a new site or data source. Additional studies are required to precisely determine the role of social media in the pharmacovigilance system.},
	language = {eng},
	number = {7},
	journal = {Journal of Medical Internet Research},
	author = {Lardon, Jérémy and Abdellaoui, Redhouane and Bellet, Florelle and Asfari, Hadyl and Souvignet, Julien and Texier, Nathalie and Jaulent, Marie-Christine and Beyens, Marie-Noëlle and Burgun, Anita and Bousquet, Cédric},
	month = jul,
	year = {2015},
	pmid = {26163365},
	pmcid = {PMC4526988},
	keywords = {pharmacovigilance, text mining, Humans, Pharmacovigilance, social media, Drug-Related Side Effects and Adverse Reactions, Social Media, adverse drug reaction, adverse event, Internet, Reproducibility of Results, scoping review, Web 2.0},
	pages = {e171}
}

@article{segura-bedmar_exploring_2015,
	title = {Exploring {Spanish} health social media for detecting drug effects},
	volume = {15 Suppl 2},
	issn = {1472-6947},
	doi = {10.1186/1472-6947-15-S2-S6},
	abstract = {BACKGROUND: Adverse Drug reactions (ADR) cause a high number of deaths among hospitalized patients in developed countries. Major drug agencies have devoted a great interest in the early detection of ADRs due to their high incidence and increasing health care costs. Reporting systems are available in order for both healthcare professionals and patients to alert about possible ADRs. However, several studies have shown that these adverse events are underestimated. Our hypothesis is that health social networks could be a significant information source for the early detection of ADRs as well as of new drug indications.
METHODS: In this work we present a system for detecting drug effects (which include both adverse drug reactions as well as drug indications) from user posts extracted from a Spanish health forum. Texts were processed using MeaningCloud, a multilingual text analysis engine, to identify drugs and effects. In addition, we developed the first Spanish database storing drugs as well as their effects automatically built from drug package inserts gathered from online websites. We then applied a distant-supervision method using the database on a collection of 84,000 messages in order to extract the relations between drugs and their effects. To classify the relation instances, we used a kernel method based only on shallow linguistic information of the sentences.
RESULTS: Regarding Relation Extraction of drugs and their effects, the distant supervision approach achieved a recall of 0.59 and a precision of 0.48.
CONCLUSIONS: The task of extracting relations between drugs and their effects from social media is a complex challenge due to the characteristics of social media texts. These texts, typically posts or tweets, usually contain many grammatical errors and spelling mistakes. Moreover, patients use lay terminology to refer to diseases, symptoms and indications that is not usually included in lexical resources in languages other than English.},
	language = {eng},
	journal = {BMC medical informatics and decision making},
	author = {Segura-Bedmar, Isabel and Martínez, Paloma and Revert, Ricardo and Moreno-Schneider, Julián},
	year = {2015},
	pmid = {26100267},
	pmcid = {PMC4474583},
	keywords = {Humans, Natural Language Processing, Pharmacovigilance, Data Mining, Drug-Related Side Effects and Adverse Reactions, Social Media, Internet, Information Dissemination, Language, Machine Learning},
	pages = {S6}
}

@article{harpaz_text_2014,
	title = {Text mining for adverse drug events: the promise, challenges, and state of the art},
	volume = {37},
	issn = {1179-1942},
	shorttitle = {Text mining for adverse drug events},
	doi = {10.1007/s40264-014-0218-z},
	abstract = {Text mining is the computational process of extracting meaningful information from large amounts of unstructured text. It is emerging as a tool to leverage underutilized data sources that can improve pharmacovigilance, including the objective of adverse drug event (ADE) detection and assessment. This article provides an overview of recent advances in pharmacovigilance driven by the application of text mining, and discusses several data sources-such as biomedical literature, clinical narratives, product labeling, social media, and Web search logs-that are amenable to text mining for pharmacovigilance. Given the state of the art, it appears text mining can be applied to extract useful ADE-related information from multiple textual sources. Nonetheless, further research is required to address remaining technical challenges associated with the text mining methodologies, and to conclusively determine the relative contribution of each textual source to improving pharmacovigilance.},
	language = {eng},
	number = {10},
	journal = {Drug Safety},
	author = {Harpaz, Rave and Callahan, Alison and Tamang, Suzanne and Low, Yen and Odgers, David and Finlayson, Sam and Jung, Kenneth and LePendu, Paea and Shah, Nigam H.},
	month = oct,
	year = {2014},
	pmid = {25151493},
	pmcid = {PMC4217510},
	keywords = {Humans, Pharmacovigilance, Data Mining, Social Media, Internet, Data Collection, Databases, Factual, Drug Labeling, Periodicals as Topic},
	pages = {777--790}
}

@article{ben_abacha_text_2015,
	title = {Text mining for pharmacovigilance: {Using} machine learning for drug name recognition and drug-drug interaction extraction and classification},
	volume = {58},
	issn = {1532-0480},
	shorttitle = {Text mining for pharmacovigilance},
	doi = {10.1016/j.jbi.2015.09.015},
	abstract = {Pharmacovigilance (PV) is defined by the World Health Organization as the science and activities related to the detection, assessment, understanding and prevention of adverse effects or any other drug-related problem. An essential aspect in PV is to acquire knowledge about Drug-Drug Interactions (DDIs). The shared tasks on DDI-Extraction organized in 2011 and 2013 have pointed out the importance of this issue and provided benchmarks for: Drug Name Recognition, DDI extraction and DDI classification. In this paper, we present our text mining systems for these tasks and evaluate their results on the DDI-Extraction benchmarks. Our systems rely on machine learning techniques using both feature-based and kernel-based methods. The obtained results for drug name recognition are encouraging. For DDI-Extraction, our hybrid system combining a feature-based method and a kernel-based method was ranked second in the DDI-Extraction-2011 challenge, and our two-step system for DDI detection and classification was ranked first in the DDI-Extraction-2013 task at SemEval. We discuss our methods and results and give pointers to future work.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Ben Abacha, Asma and Chowdhury, Md Faisal Mahbub and Karanasiou, Aikaterini and Mrabet, Yassine and Lavelli, Alberto and Zweigenbaum, Pierre},
	month = dec,
	year = {2015},
	pmid = {26432353},
	keywords = {Pharmacovigilance, Data Mining, Machine Learning, Drug Interactions, Drug name recognition, Drug–drug interactions, Machine learning, Text mining},
	pages = {122--132}
}

@article{martin-sanchez_big_2014,
	title = {Big data in medicine is driving big changes},
	volume = {9},
	issn = {2364-0502},
	doi = {10.15265/IY-2014-0020},
	abstract = {OBJECTIVES: To summarise current research that takes advantage of "Big Data" in health and biomedical informatics applications.
METHODS: Survey of trends in this work, and exploration of literature describing how large-scale structured and unstructured data sources are being used to support applications from clinical decision making and health policy, to drug design and pharmacovigilance, and further to systems biology and genetics.
RESULTS: The survey highlights ongoing development of powerful new methods for turning that large-scale, and often complex, data into information that provides new insights into human health, in a range of different areas. Consideration of this body of work identifies several important paradigm shifts that are facilitated by Big Data resources and methods: in clinical and translational research, from hypothesis-driven research to data-driven research, and in medicine, from evidence-based practice to practice-based evidence.
CONCLUSIONS: The increasing scale and availability of large quantities of health data require strategies for data management, data linkage, and data integration beyond the limits of many existing information systems, and substantial effort is underway to meet those needs. As our ability to make sense of that data improves, the value of the data will continue to increase. Health systems, genetics and genomics, population and public health; all areas of biomedicine stand to benefit from Big Data and the associated technologies.},
	language = {eng},
	journal = {Yearbook of Medical Informatics},
	author = {Martin-Sanchez, F. and Verspoor, K.},
	month = aug,
	year = {2014},
	pmid = {25123716},
	pmcid = {PMC4287083},
	keywords = {text mining, Humans, Computational Biology, Data Mining, Social Media, Databases, Factual, Biomedical Research, data mining, information storage and retrieval, information systems, Medical informatics, Medical Informatics},
	pages = {14--20}
}

@article{liu_role_2014,
	title = {Role of text mining in early identification of potential drug safety issues},
	volume = {1159},
	issn = {1940-6029},
	doi = {10.1007/978-1-4939-0709-0_13},
	abstract = {Drugs are an important part of today's medicine, designed to treat, control, and prevent diseases; however, besides their therapeutic effects, drugs may also cause adverse effects that range from cosmetic to severe morbidity and mortality. To identify these potential drug safety issues early, surveillance must be conducted for each drug throughout its life cycle, from drug development to different phases of clinical trials, and continued after market approval. A major aim of pharmacovigilance is to identify the potential drug-event associations that may be novel in nature, severity, and/or frequency. Currently, the state-of-the-art approach for signal detection is through automated procedures by analyzing vast quantities of data for clinical knowledge. There exists a variety of resources for the task, and many of them are textual data that require text analytics and natural language processing to derive high-quality information. This chapter focuses on the utilization of text mining techniques in identifying potential safety issues of drugs from textual sources such as biomedical literature, consumer posts in social media, and narrative electronic medical records.},
	language = {eng},
	journal = {Methods in Molecular Biology (Clifton, N.J.)},
	author = {Liu, Mei and Hu, Yong and Tang, Buzhou},
	year = {2014},
	pmid = {24788270},
	keywords = {Humans, Data Mining, Social Media, Animals, Clinical Trials as Topic, Cosmetics, Databases, Bibliographic, Medical Records Systems, Computerized},
	pages = {227--251}
}

@article{wang_active_2009-1,
	title = {Active computerized pharmacovigilance using natural language processing, statistics, and electronic health records: a feasibility study},
	volume = {16},
	issn = {1067-5027},
	shorttitle = {Active computerized pharmacovigilance using natural language processing, statistics, and electronic health records},
	doi = {10.1197/jamia.M3028},
	abstract = {OBJECTIVE It is vital to detect the full safety profile of a drug throughout its market life. Current pharmacovigilance systems still have substantial limitations, however. The objective of our work is to demonstrate the feasibility of using natural language processing (NLP), the comprehensive Electronic Health Record (EHR), and association statistics for pharmacovigilance purposes. DESIGN Narrative discharge summaries were collected from the Clinical Information System at New York Presbyterian Hospital (NYPH). MedLEE, an NLP system, was applied to the collection to identify medication events and entities which could be potential adverse drug events (ADEs). Co-occurrence statistics with adjusted volume tests were used to detect associations between the two types of entities, to calculate the strengths of the associations, and to determine their cutoff thresholds. Seven drugs/drug classes (ibuprofen, morphine, warfarin, bupropion, paroxetine, rosiglitazone, ACE inhibitors) with known ADEs were selected to evaluate the system. RESULTS One hundred thirty-two potential ADEs were found to be associated with the 7 drugs. Overall recall and precision were 0.75 and 0.31 for known ADEs respectively. Importantly, qualitative evaluation using historic roll back design suggested that novel ADEs could be detected using our system. CONCLUSIONS This study provides a framework for the development of active, high-throughput and prospective systems which could potentially unveil drug safety profiles throughout their entire market life. Our results demonstrate that the framework is feasible although there are some challenging issues. To the best of our knowledge, this is the first study using comprehensive unstructured data from the EHR for pharmacovigilance.},
	language = {eng},
	number = {3},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Wang, Xiaoyan and Hripcsak, George and Markatou, Marianthi and Friedman, Carol},
	month = jun,
	year = {2009},
	pmid = {19261932},
	pmcid = {PMC2732239},
	keywords = {Humans, Natural Language Processing, Adverse Drug Reaction Reporting Systems, Drug-Related Side Effects and Adverse Reactions, Medical Records Systems, Computerized, Algorithms, Feasibility Studies, Information Storage and Retrieval, Software, Statistics as Topic},
	pages = {328--337}
}

@article{haerian_methods_2012-3,
	title = {Methods for identifying suicide or suicidal ideation in {EHRs}},
	volume = {2012},
	issn = {1942-597X},
	abstract = {Electronic health records contain important data elements for detection of novel adverse drug reactions, genotype/phenotype identification and psychosocial factor analysis, and the role of each of these as risk factors for suicidality warrants further investigation. Suicide and suicidal ideation are documented in clinical narratives. The specific purpose of this study was to define an algorithm for automated detection of this serious event. We found that ICD-9 E-Codes had the lowest positive predictive value: 0.55 (90\% CI: 0.42-0.67), while combining ICD-9 and NLP had the best PPV: 0.97 (90\% CI: 0.92-0.99). A qualitative analysis and classification of the types of errors by ICD-9 and NLP automated coding compared to manual review are also discussed.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Haerian, K. and Salmasian, H. and Friedman, C.},
	year = {2012},
	pmid = {23304402},
	pmcid = {PMC3540459},
	keywords = {Electronic Health Records, Humans, Natural Language Processing, Pharmacovigilance, Drug-Related Side Effects and Adverse Reactions, Algorithms, Adolescent, Child, International Classification of Diseases, Patient Discharge, Predictive Value of Tests, Suicidal Ideation, Suicide},
	pages = {1244--1253}
}

@article{delamarre_documentation_2010,
	title = {Documentation in pharmacovigilance: using an ontology to extend and normalize {Pubmed} queries},
	volume = {160},
	issn = {0926-9630},
	shorttitle = {Documentation in pharmacovigilance},
	abstract = {OBJECTIVES: To assess and understand adverse drug reactions (ADRs), a systematic review of reference databases like Pubmed is a necessary and mandatory step in Pharmacovigilance. In order to assist pharmacovigilance team with a computerized tool, we performed a comparative study of 4 different approaches to query Pubmed through ADR-drug terms. The aim of this study is to assess how an ontology of adverse effects, used to normalize and extend queries, could improve this search.
MATERIAL AND METHOD: The ontological resource OntoEIM contains 58,000 classes and integrates MedDRA terminology. The entry point is a ADR-Drug term and the four methods are (i) a direct search on Pubmed (ii) a search with a normalized query enhanced with domain-specific Mesh Heading criteria, (iii) a search with the same elaborated query extended to the MeSH sub-hierarchy of the adverse effect entry and (iv) a search with a set of MedDRA terms grouped by subsomption in the OntoEIM ontology. For each of the 16 queries performed and analysed, relevant publications are selected "manually" by two pharmacovigilant experts.
RESULTS: The recall is respectively of 63\%, 50\%, 67\% and 74\%, the precision of 13\%, 26\%, 29\% and 4\%. The best recall is provided by the ontology-based method, for 4 cases out of 16 this method returns relevant publications when the others return no results.
CONCLUSION: Results show that an ontology-based search tool improves the recall performance, but other tools and methods are needed to raise the precision.},
	language = {eng},
	number = {Pt 1},
	journal = {Studies in Health Technology and Informatics},
	author = {Delamarre, Denis and Lillo-Le Louët, Agnès and Guillot, Laetitia and Jamet, Anne and Sadou, Eric and Ouazine, Theo and Burgun, Anita and Jaulent, Marie-Christine},
	year = {2010},
	pmid = {20841741},
	keywords = {PubMed, Humans, Natural Language Processing, Data Mining, Drug-Related Side Effects and Adverse Reactions, Database Management Systems, Documentation, Terminology as Topic, Vocabulary, Controlled},
	pages = {518--522}
}

@article{chee_measuring_2009,
	title = {Measuring population health using personal health messages},
	volume = {2009},
	issn = {1942-597X},
	abstract = {Personal health messages - inter patient communications within online communities; represent a new path towards providing continuous information about patient derived health status. We apply natural language processing techniques to personal health messages from online message boards to demonstrate the ability to track trends in people's positive or negative opinion (sentiment) regarding particular drugs over time. The significant changes in sentiment correspond to FDA announcements and other publicity. We envision such analysis as a scalable tool for pharmacovigilance hypothesis generation for possible adverse drug reactions.},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Chee, Brant and Berlin, Richard and Schatz, Bruce},
	month = nov,
	year = {2009},
	pmid = {20351829},
	pmcid = {PMC2815419},
	keywords = {Humans, Natural Language Processing, Adverse Drug Reaction Reporting Systems, Drug-Related Side Effects and Adverse Reactions, Internet, Attitude to Health, Health Status, Patients, Population Surveillance, Self-Help Groups},
	pages = {92--96}
}

@article{rindflesch_informatics_2017-1,
	title = {Informatics {Support} for {Basic} {Research} in {Biomedicine}},
	volume = {58},
	issn = {1084-2020, 1930-6180},
	url = {http://academic.oup.com/ilarjournal/article/58/1/80/4040992/Informatics-Support-for-Basic-Research-in},
	doi = {10.1093/ilar/ilx004},
	abstract = {Informatics methodologies exploit computer-assisted techniques to help biomedical researchers manage large amounts of information. In this paper, we focus on the biomedical research literature (MEDLINE). We ﬁrst provide an overview of some text mining techniques that offer assistance in research by identifying biomedical entities (e.g., genes, substances, and diseases) and relations between them in text. We then discuss Semantic MEDLINE, an application that integrates PubMed document retrieval, concept and relation identiﬁcation, and visualization, thus enabling a user to explore concepts and relations from within a set of retrieved citations. Semantic MEDLINE provides a roadmap through content and helps users discern patterns in large numbers of retrieved citations. We illustrate its use with an informatics method we call “discovery browsing,” which provides a principled way of navigating through selected aspects of some biomedical research area. The method supports an iterative process that accommodates learning and hypothesis formation in which a user is provided with high level connections before delving into details. As a use case, we examine current developments in basic research on mechanisms of Alzheimer’s disease. Out of the nearly 90 000 citations returned by the PubMed query “Alzheimer’s disease,” discovery browsing led us to 73 citations on sortilin and that disorder. We provide a synopsis of the basic research reported in 15 of these. There is wide-spread consensus among researchers working with a range of animal models and human cells that increased sortilin expression and decreased receptor expression are associated with amyloid beta and/or amyloid precursor protein.},
	language = {en},
	number = {1},
	urldate = {2018-03-31},
	journal = {ILAR Journal},
	author = {Rindflesch, Thomas C. and Blake, Catherine L. and Fiszman, Marcelo and Kilicoglu, Halil and Rosemblat, Graciela and Schneider, Jodi and Zeiss, Caroline J.},
	year = {2017},
	pages = {80--89},
	file = {Rindflesch et al. - 2017 - Informatics Support for Basic Research in Biomedic.pdf:/Users/transfer/Zotero/storage/WBMW5SFY/Rindflesch et al. - 2017 - Informatics Support for Basic Research in Biomedic.pdf:application/pdf}
}

@article{kafkas_usage_2017,
	title = {Usage of cell nomenclature in biomedical literature},
	volume = {18},
	issn = {1471-2105},
	doi = {10.1186/s12859-017-1978-0},
	abstract = {BACKGROUND: Cell lines and cell types are extensively studied in biomedical research yielding to a significant amount of publications each year. Identifying cell lines and cell types precisely in publications is crucial for science reproducibility and knowledge integration. There are efforts for standardisation of the cell nomenclature based on ontology development to support FAIR principles of the cell knowledge. However, it is important to analyse the usage of cell nomenclature in publications at a large scale for understanding the level of uptake of cell nomenclature in literature by scientists. In this study, we analyse the usage of cell nomenclature, both in Vivo, and in Vitro in biomedical literature by using text mining methods and present our results.
RESULTS: We identified 59\% of the cell type classes in the Cell Ontology and 13\% of the cell line classes in the Cell Line Ontology in the literature. Our analysis showed that cell line nomenclature is much more ambiguous compared to the cell type nomenclature. However, trends indicate that standardised nomenclature for cell lines and cell types are being increasingly used in publications by the scientists.
CONCLUSIONS: Our findings provide an insight to understand how experimental cells are described in publications and may allow for an improved standardisation of cell type and cell line nomenclature as well as can be utilised to develop efficient text mining applications on cell types and cell lines. All data generated in this study is available at https://github.com/shenay/CellNomenclatureStudy.},
	language = {eng},
	number = {Suppl 17},
	journal = {BMC bioinformatics},
	author = {Kafkas, Şenay and Sarntivijai, Sirarat and Hoehndorf, Robert},
	month = dec,
	year = {2017},
	pmid = {29322912},
	pmcid = {PMC5763300},
	pages = {561}
}

@article{kafkas_usage_2017-1,
	title = {Usage of cell nomenclature in biomedical literature},
	volume = {18},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5763300/},
	doi = {10.1186/s12859-017-1978-0},
	abstract = {Background
Cell lines and cell types are extensively studied in biomedical research yielding to a significant amount of publications each year. Identifying cell lines and cell types precisely in publications is crucial for science reproducibility and knowledge integration. There are efforts for standardisation of the cell nomenclature based on ontology development to support FAIR principles of the cell knowledge. However, it is important to analyse the usage of cell nomenclature in publications at a large scale for understanding the level of uptake of cell nomenclature in literature by scientists. In this study, we analyse the usage of cell nomenclature, both in Vivo, and in Vitro in biomedical literature by using text mining methods and present our results.

Results
We identified 59\% of the cell type classes in the Cell Ontology and 13\% of the cell line classes in the Cell Line Ontology in the literature. Our analysis showed that cell line nomenclature is much more ambiguous compared to the cell type nomenclature. However, trends indicate that standardised nomenclature for cell lines and cell types are being increasingly used in publications by the scientists.

Conclusions
Our findings provide an insight to understand how experimental cells are described in publications and may allow for an improved standardisation of cell type and cell line nomenclature as well as can be utilised to develop efficient text mining applications on cell types and cell lines. All data generated in this study is available at https://github.com/shenay/CellNomenclatureStudy.},
	number = {Suppl 17},
	urldate = {2018-03-31},
	journal = {BMC Bioinformatics},
	author = {Kafkas, Şenay and Sarntivijai, Sirarat and Hoehndorf, Robert},
	month = dec,
	year = {2017},
	pmid = {29322912},
	pmcid = {PMC5763300},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/67ZE8EXQ/Kafkas et al. - 2017 - Usage of cell nomenclature in biomedical literatur.pdf:application/pdf}
}

@inproceedings{kilgarriff_measures_1998,
	title = {Measures for corpus similarity and homogeneity},
	author = {Kilgarriff, Adam and Rose, Tony},
	year = {1998},
	keywords = {reproducibility},
	pages = {46--52}
}

@article{ioannidis_why_2005,
	title = {Why {Most} {Published} {Research} {Findings} {Are} {False}},
	volume = {2},
	issn = {1549-1277},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/},
	doi = {10.1371/journal.pmed.0020124},
	abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research., Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
	number = {8},
	urldate = {2018-05-05},
	journal = {PLoS Medicine},
	author = {Ioannidis, John P. A.},
	month = aug,
	year = {2005},
	pmid = {16060722},
	pmcid = {PMC1182327},
	keywords = {reproducibility},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CJJMRU6E/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf:application/pdf}
}

@article{kelly_system_2013,
	title = {A {System} for {Extracting} {Study} {Design} {Parameters} from {Nutritional} {Genomics} {Abstracts}},
	volume = {10},
	issn = {1613-4516},
	url = {http://www.degruyter.com/view/j/jib.2013.10.issue-2/biecoll-jib-2013-222/biecoll-jib-2013-222.xml},
	doi = {10.1515/jib-2013-222},
	abstract = {The extraction of study design parameters from biomedical journal articles is an important problem in natural language processing (NLP). Such parameters deﬁne the characteristics of a study, such as the duration, the number of subjects, and their proﬁle. Here we present a system for extracting study design parameters from sentences in article abstracts. This system will be used as a component of a larger system for creating nutrigenomics networks from articles in the nutritional genomics domain. The algorithms presented consist of manually designed rules expressed either as regular expressions or in terms of sentence parse structure. A number of ﬁlters and NLP tools are also utilized within a pipelined algorithmic framework. Using this novel approach, our system performs extraction at a ﬁner level of granularity than comparable systems, while generating results that surpass the current state of the art.},
	language = {en},
	number = {2},
	urldate = {2018-05-11},
	journal = {Journal of Integrative Bioinformatics},
	author = {Kelly, Cassidy and Yang, Hui},
	month = jun,
	year = {2013},
	keywords = {reproducibility},
	file = {Kelly and Yang - 2013 - A System for Extracting Study Design Parameters fr.pdf:/Users/transfer/Zotero/storage/YNI5PVZF/Kelly and Yang - 2013 - A System for Extracting Study Design Parameters fr.pdf:application/pdf}
}

@article{zhao_improving_2010,
	title = {Improving {Search} for {Evidence}-based {Practice} using {Information} {Extraction}},
	volume = {2010},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041452/},
	abstract = {The search for applicable and valid research evidence-based practice articles is not supported well in common EBP resources, as some crucial study data, such as patient details, study design and results, are not available or presented explicitly. We propose to extract these data from research articles using a two-step supervised soft classification method. Compared to manual annotation, our approach is less labor-intensive and more flexible, hence opening up the possibility of utilizing these data to facilitate the evidence selection process in information seeking support systems.},
	urldate = {2018-05-11},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Zhao, Jin and Kan, Min-Yen and Procter, Paula M. and Zubaidah, Siti and Yip, Wai Kin and Li, Goh Mien},
	year = {2010},
	pmid = {21347116},
	pmcid = {PMC3041452},
	keywords = {reproducibility},
	pages = {937--941},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/F46TUSDN/Zhao et al. - 2010 - Improving Search for Evidence-based Practice using.pdf:application/pdf}
}

@article{mohammadi_developing_2016,
	title = {Developing a {Minimum} {Data} {Set} for an {Information} {Management} {System} to {Study} {Traffic} {Accidents} in {Iran}},
	volume = {18},
	issn = {2074-1804},
	doi = {10.5812/ircmj.23677},
	abstract = {BACKGROUND: Each year, around 1.2 million people die in the road traffic incidents. Reducing traffic accidents requires an exact understanding of the risk factors associated with traffic patterns and behaviors. Properly analyzing these factors calls for a comprehensive system for collecting and processing accident data.
OBJECTIVES: The aim of this study was to develop a minimum data set (MDS) for an information management system to study traffic accidents in Iran.
MATERIALS AND METHODS: This descriptive, cross-sectional study was performed in 2014. Data were collected from the traffic police, trauma centers, medical emergency centers, and via the internet. The investigated resources for this study were forms, databases, and documents retrieved from the internet. Forms and databases were identical, and one sample of each was evaluated. The related internet-sourced data were evaluated in their entirety. Data were collected using three checklists. In order to arrive at a consensus about the data elements, the decision Delphi technique was applied using questionnaires. The content validity and reliability of the questionnaires were assessed by experts' opinions and the test-retest method, respectively.
RESULTS: An (MDS) of a traffic accident information management system was assigned to three sections: a minimum data set for traffic police with six classes, including 118 data elements; a trauma center with five data classes, including 57 data elements; and a medical emergency center, with 11 classes, including 64 data elements.
CONCLUSIONS: Planning for the prevention of traffic accidents requires standardized data. As the foundation for crash prevention efforts, existing standard data infrastructures present policymakers and government officials with a great opportunity to strengthen and integrate existing accident information systems to better track road traffic injuries and fatalities.},
	language = {eng},
	number = {3},
	journal = {Iranian Red Crescent Medical Journal},
	author = {Mohammadi, Ali and Ahmadi, Maryam and Gharagozlu, Alireza},
	month = mar,
	year = {2016},
	pmid = {27247791},
	pmcid = {PMC4884271},
	pages = {e23677}
}

@article{davis_information_2016,
	title = {Information management for aged care provision in {Australia}: development of an aged care minimum dataset and strategies to improve quality and continuity of care},
	volume = {45},
	issn = {1833-3575},
	shorttitle = {Information management for aged care provision in {Australia}},
	doi = {10.1177/1833358316639453},
	abstract = {BACKGROUND: Efficient information systems support the provision of multi-disciplinary aged care and a variety of organisational purposes, including quality, funding, communication and continuity of care. Agreed minimum data sets enable accurate communication across multiple care settings. However, in aged care multiple and poorly integrated data collection frameworks are commonly used for client assessment, government reporting and funding purposes.
OBJECTIVE: To determine key information needs in aged care settings to improve information quality, information transfer, safety, quality and continuity of care to meet the complex needs of aged care clients.
METHOD: Modified Delphi methods involving five stages were employed by one aged care provider in Victoria, Australia, to establish stakeholder consensus for a derived minimum data set and address barriers to data quality.
RESULTS: Eleven different aged care programs were identified; with five related data dictionaries, three minimum data sets, five program standards or quality frameworks. The remaining data collection frameworks related to diseases classification, funding, service activity reporting, and statistical standards and classifications. A total of 170 different data items collected across seven internal information systems were consolidated to a derived set of 60 core data items and aligned with nationally consistent data collection frameworks. Barriers to data quality related to inconsistencies in data items, staff knowledge, workflow, system access and configuration.
CONCLUSION: The development an internal aged care minimum data set highlighted the critical role of primary data quality in the upstream and downstream use of client information; and presents a platform to build national consistency across the sector.},
	language = {eng},
	number = {1},
	journal = {Health Information Management: Journal of the Health Information Management Association of Australia},
	author = {Davis, Jenny and Morgans, Amee and Burgess, Stephen},
	month = apr,
	year = {2016},
	pmid = {28691563},
	pages = {27--35}
}

@article{merino-martinez_toward_2016,
	title = {Toward {Global} {Biobank} {Integration} by {Implementation} of the {Minimum} {Information} {About} {BIobank} {Data} {Sharing} ({MIABIS} 2.0 {Core})},
	volume = {14},
	issn = {1947-5543},
	doi = {10.1089/bio.2015.0070},
	abstract = {Biobanks are the biological back end of data-driven medicine, but lack standards and generic solutions for interoperability and information harmonization. The move toward a global information infrastructure for biobanking demands semantic interoperability through harmonized services and common ontologies. To tackle this issue, the Minimum Information About BIobank data Sharing (MIABIS) was developed in 2012 by the Biobanking and BioMolecular Resources Research Infrastructure of Sweden (BBMRI.se). The wide acceptance of the first version of MIABIS encouraged evolving it to a more structured and descriptive standard. In 2013 a working group was formed under the largest infrastructure for health in Europe, Biobanking and BioMolecular Resources Research Infrastructure (BBMRI-ERIC), with the remit to continue the development of MIABIS (version 2.0) through a multicountry governance process. MIABIS 2.0 Core has been developed with 22 attributes describing Biobanks, Sample Collections, and Studies according to a modular structure that makes it easier to adhere to and to extend the standard. This integration standard will make a great contribution to the discovery and exploitation of biobank resources and lead to a wider and more efficient use of valuable bioresources, thereby speeding up the research on human diseases. Many within the European Union have accepted MIABIS 2.0 Core as the "de facto" biobank information standard.},
	language = {eng},
	number = {4},
	journal = {Biopreservation and Biobanking},
	author = {Merino-Martinez, Roxana and Norlin, Loreana and van Enckevort, David and Anton, Gabriele and Schuffenhauer, Simone and Silander, Kaisa and Mook, Linda and Holub, Petr and Bild, Raffael and Swertz, Morris and Litton, Jan-Eric},
	month = aug,
	year = {2016},
	pmid = {26977825},
	pages = {298--306}
}

@article{alipour_need_2016,
	title = {The need for development a national minimum data set of the information management system for burns in {Iran}},
	volume = {42},
	issn = {1879-1409},
	doi = {10.1016/j.burns.2015.05.016},
	language = {eng},
	number = {3},
	journal = {Burns: Journal of the International Society for Burn Injuries},
	author = {Alipour, Jahanpour and Ahmadi, Maryam and Mohammadi, Ali},
	year = {2016},
	pmid = {26922246},
	pages = {710}
}

@article{jebraeily_hemodialysis_2015,
	title = {Hemodialysis {Adequacy} {Monitoring} {Information} {System}: {Minimum} {Data} {Set} and {Capabilities} {Required}},
	volume = {23},
	issn = {0353-8109},
	shorttitle = {Hemodialysis {Adequacy} {Monitoring} {Information} {System}},
	doi = {10.5455/aim.2015.23.239-242},
	abstract = {INTRODUCTION: In dialysis centers both nephrologists and nurses are faced with the challenge of ensuring reliable and efficient care accordance with the clinical guideline. Hemodialysis adequacy monitoring information system therefore enable the automation of tasks, which ultimately allows doctors and nursing staff more time to dedicate to the individual treatment of patients. Development of the information systems in healthcare has made the use of the Minimum data set inevitable. The purpose of this study was determined MDS and capabilities required in hemodialysis adequacy monitoring information system.
METHOD AND MATERIALS: This is a cross-sectional survey conducted with participation of 320 nephrology specialists in 2015. Data were collected using an electronic questionnaire which was estimated as both reliable and valid. The data were analyzed by SPSS software descriptive statistics and analytical statistics.
RESULTS: Overall 42 data elements were determined as final set in 4 major categories (patient demographics, medical history, treatment plan and hemodialysis adequacy). The most capabilities required of hemodialysis information system were related to calculate of dialysis adequacy Index (4.80), advice optimal dose of dialysis for each patient (4.63), Easy access to information system without restrictions of time and place (4.61), providing alerts when dialysis adequacy index below the standard (4.55) and Interchange to other information systems in hospitals (4.46) respectively.
CONCLUSION: In design and implementation of information systems focus on MDS and identification IS capabilities based on the users' needs, due to the wide participation users and also the success of the information system. Therefore it is necessary that MDS evaluated carefully with regard to the intended uses of the data. Also information systems based on capabilities the ability to meet the needs of their users.},
	language = {eng},
	number = {4},
	journal = {Acta informatica medica: AIM: journal of the Society for Medical Informatics of Bosnia \& Herzegovina: casopis Drustva za medicinsku informatiku BiH},
	author = {Jebraeily, Mohamad and Ghazisaeidi, Marjan and Safdari, Reza and Makhdoomi, Khadijeh and Rahimi, Bahlol},
	month = aug,
	year = {2015},
	pmid = {26483599},
	pmcid = {PMC4584089},
	pages = {239--242}
}

@article{mack_minimum_2015,
	title = {Minimum information for reporting next generation sequence genotyping ({MIRING}): {Guidelines} for reporting {HLA} and {KIR} genotyping via next generation sequencing},
	volume = {76},
	issn = {1879-1166},
	shorttitle = {Minimum information for reporting next generation sequence genotyping ({MIRING})},
	doi = {10.1016/j.humimm.2015.09.011},
	abstract = {The development of next-generation sequencing (NGS) technologies for HLA and KIR genotyping is rapidly advancing knowledge of genetic variation of these highly polymorphic loci. NGS genotyping is poised to replace older methods for clinical use, but standard methods for reporting and exchanging these new, high quality genotype data are needed. The Immunogenomic NGS Consortium, a broad collaboration of histocompatibility and immunogenetics clinicians, researchers, instrument manufacturers and software developers, has developed the Minimum Information for Reporting Immunogenomic NGS Genotyping (MIRING) reporting guidelines. MIRING is a checklist that specifies the content of NGS genotyping results as well as a set of messaging guidelines for reporting the results. A MIRING message includes five categories of structured information - message annotation, reference context, full genotype, consensus sequence and novel polymorphism - and references to three categories of accessory information - NGS platform documentation, read processing documentation and primary data. These eight categories of information ensure the long-term portability and broad application of this NGS data for all current histocompatibility and immunogenetics use cases. In addition, MIRING can be extended to allow the reporting of genotype data generated using pre-NGS technologies. Because genotyping results reported using MIRING are easily updated in accordance with reference and nomenclature databases, MIRING represents a bold departure from previous methods of reporting HLA and KIR genotyping results, which have provided static and less-portable data. More information about MIRING can be found online at miring.immunogenomics.org.},
	language = {eng},
	number = {12},
	journal = {Human Immunology},
	author = {Mack, Steven J. and Milius, Robert P. and Gifford, Benjamin D. and Sauter, Jürgen and Hofmann, Jan and Osoegawa, Kazutoyo and Robinson, James and Groeneweg, Mathijs and Turenchalk, Gregory S. and Adai, Alex and Holcomb, Cherie and Rozemuller, Erik H. and Penning, Maarten T. and Heuer, Michael L. and Wang, Chunlin and Salit, Marc L. and Schmidt, Alexander H. and Parham, Peter R. and Müller, Carlheinz and Hague, Tim and Fischer, Gottfried and Fernandez-Viňa, Marcelo and Hollenbach, Jill A. and Norman, Paul J. and Maiers, Martin},
	month = dec,
	year = {2015},
	pmid = {26407912},
	pmcid = {PMC4674382},
	pages = {954--962}
}

@article{scudamore_recommendations_2016,
	title = {Recommendations for minimum information for publication of experimental pathology data: {MINPEPA} guidelines},
	volume = {238},
	issn = {1096-9896},
	shorttitle = {Recommendations for minimum information for publication of experimental pathology data},
	doi = {10.1002/path.4642},
	abstract = {Animal models are essential research tools in modern biomedical research, but there are concerns about their lack of reproducibility and the failure of animal data to translate into advances in human medical therapy. A major factor in improving experimental reproducibility is thorough communication of research methodologies. The recently published ARRIVE guidelines outline basic information that should be provided when reporting animal studies. This paper builds on ARRIVE by providing the minimum information needed in reports to allow proper assessment of pathology data gathered from animal tissues. This guidance covers aspects of experimental design, technical procedures, data gathering, analysis, and presentation that are potential sources of variation when creating morphological, immunohistochemical (IHC) or in situ hybridization (ISH) datasets. This reporting framework will maximize the likelihood that pathology data derived from animal experiments can be reproduced by ensuring that sufficient information is available to allow for replication of the methods and facilitate inter-study comparison by identifying potential interpretative confounders.},
	language = {eng},
	number = {2},
	journal = {The Journal of Pathology},
	author = {Scudamore, Cheryl L. and Soilleux, Elizabeth J. and Karp, Natasha A. and Smith, Ken and Poulsom, Richard and Herrington, C. Simon and Day, Michael J. and Brayton, Cory F. and Bolon, Brad and Whitelaw, Bruce and White, Eric S. and Everitt, Jeffrey I. and Arends, Mark J.},
	month = jan,
	year = {2016},
	pmid = {26387837},
	pages = {359--367}
}

@article{medema_minimum_2015,
	title = {Minimum {Information} about a {Biosynthetic} {Gene} cluster},
	volume = {11},
	issn = {1552-4469},
	doi = {10.1038/nchembio.1890},
	language = {eng},
	number = {9},
	journal = {Nature Chemical Biology},
	author = {Medema, Marnix H. and Kottmann, Renzo and Yilmaz, Pelin and Cummings, Matthew and Biggins, John B. and Blin, Kai and de Bruijn, Irene and Chooi, Yit Heng and Claesen, Jan and Coates, R. Cameron and Cruz-Morales, Pablo and Duddela, Srikanth and Düsterhus, Stephanie and Edwards, Daniel J. and Fewer, David P. and Garg, Neha and Geiger, Christoph and Gomez-Escribano, Juan Pablo and Greule, Anja and Hadjithomas, Michalis and Haines, Anthony S. and Helfrich, Eric J. N. and Hillwig, Matthew L. and Ishida, Keishi and Jones, Adam C. and Jones, Carla S. and Jungmann, Katrin and Kegler, Carsten and Kim, Hyun Uk and Kötter, Peter and Krug, Daniel and Masschelein, Joleen and Melnik, Alexey V. and Mantovani, Simone M. and Monroe, Emily A. and Moore, Marcus and Moss, Nathan and Nützmann, Hans-Wilhelm and Pan, Guohui and Pati, Amrita and Petras, Daniel and Reen, F. Jerry and Rosconi, Federico and Rui, Zhe and Tian, Zhenhua and Tobias, Nicholas J. and Tsunematsu, Yuta and Wiemann, Philipp and Wyckoff, Elizabeth and Yan, Xiaohui and Yim, Grace and Yu, Fengan and Xie, Yunchang and Aigle, Bertrand and Apel, Alexander K. and Balibar, Carl J. and Balskus, Emily P. and Barona-Gómez, Francisco and Bechthold, Andreas and Bode, Helge B. and Borriss, Rainer and Brady, Sean F. and Brakhage, Axel A. and Caffrey, Patrick and Cheng, Yi-Qiang and Clardy, Jon and Cox, Russell J. and De Mot, René and Donadio, Stefano and Donia, Mohamed S. and van der Donk, Wilfred A. and Dorrestein, Pieter C. and Doyle, Sean and Driessen, Arnold J. M. and Ehling-Schulz, Monika and Entian, Karl-Dieter and Fischbach, Michael A. and Gerwick, Lena and Gerwick, William H. and Gross, Harald and Gust, Bertolt and Hertweck, Christian and Höfte, Monica and Jensen, Susan E. and Ju, Jianhua and Katz, Leonard and Kaysser, Leonard and Klassen, Jonathan L. and Keller, Nancy P. and Kormanec, Jan and Kuipers, Oscar P. and Kuzuyama, Tomohisa and Kyrpides, Nikos C. and Kwon, Hyung-Jin and Lautru, Sylvie and Lavigne, Rob and Lee, Chia Y. and Linquan, Bai and Liu, Xinyu and Liu, Wen and Luzhetskyy, Andriy and Mahmud, Taifo and Mast, Yvonne and Méndez, Carmen and Metsä-Ketelä, Mikko and Micklefield, Jason and Mitchell, Douglas A. and Moore, Bradley S. and Moreira, Leonilde M. and Müller, Rolf and Neilan, Brett A. and Nett, Markus and Nielsen, Jens and O'Gara, Fergal and Oikawa, Hideaki and Osbourn, Anne and Osburne, Marcia S. and Ostash, Bohdan and Payne, Shelley M. and Pernodet, Jean-Luc and Petricek, Miroslav and Piel, Jörn and Ploux, Olivier and Raaijmakers, Jos M. and Salas, José A. and Schmitt, Esther K. and Scott, Barry and Seipke, Ryan F. and Shen, Ben and Sherman, David H. and Sivonen, Kaarina and Smanski, Michael J. and Sosio, Margherita and Stegmann, Evi and Süssmuth, Roderich D. and Tahlan, Kapil and Thomas, Christopher M. and Tang, Yi and Truman, Andrew W. and Viaud, Muriel and Walton, Jonathan D. and Walsh, Christopher T. and Weber, Tilmann and van Wezel, Gilles P. and Wilkinson, Barrie and Willey, Joanne M. and Wohlleben, Wolfgang and Wright, Gerard D. and Ziemert, Nadine and Zhang, Changsheng and Zotchev, Sergey B. and Breitling, Rainer and Takano, Eriko and Glöckner, Frank Oliver},
	month = sep,
	year = {2015},
	pmid = {26284661},
	pmcid = {PMC5714517},
	pages = {625--631}
}

@article{hutchinson_minimum_2015,
	title = {Minimum information standards},
	volume = {99},
	issn = {1534-6080},
	doi = {10.1097/TP.0000000000000693},
	language = {eng},
	number = {3},
	journal = {Transplantation},
	author = {Hutchinson, James},
	month = mar,
	year = {2015},
	pmid = {25695783},
	pages = {464--465}
}

@article{ahmadi_development_2015,
	title = {Development a minimum data set of the information management system for burns},
	volume = {41},
	issn = {1879-1409},
	doi = {10.1016/j.burns.2014.12.009},
	abstract = {BACKGROUND: Burns are the most common and destructive injuries in across of the world and especially in developing countries. Nevertheless, a standard tool for collecting the data of burn injury has not been developed yet. The purpose of this study was to develop a minimum data set (MDS) of the information management system for burns in Iran.
MATERIALS AND METHODS: This descriptive and cross-sectional study was performed in 2014. Data were collected from hospitals affiliated with Hormozgan and Iran University of Medical Sciences and medical documents centers, emergency centers and legal medicine centers located in Bandar Abbas city, in addition to internet access and library. Investigated documents were burn injury records in 2013, and documents that retrieved from the internet, and printed materials. Records were selected randomly based on T20-T29 categories from ICD-10. Data were collected using a checklist. In order to make a consensus about the data elements the decision Delphi technique was applied using a questionnaire. The content validity and reliability of questionnaire were assessed by expert's opinions and test-retest method, respectively.
RESULTS: An MDS of burns was developed. This MDS divided into two categories: administrative and clinical with six and 17 section and 161 and 311 data elements respectively.
CONCLUSIONS: This study showed that comprehensive and uniform data elements about burns do not exist in Iran. Therefore a MDS was developed for burns in Iran. Development of an MDS will result in standardization and effective management of the data through providing uniform and comprehensive data elements for burns. Thus, comparability of the extracted information from different analyses and researches will be possible in various levels. In addition, establishment of policies and prevention and control of burns will be possible, which results in the improvement of the quality of care and containment of costs.},
	language = {eng},
	number = {5},
	journal = {Burns: Journal of the International Society for Burn Injuries},
	author = {Ahmadi, Maryam and Alipour, Jahanpour and Mohammadi, Ali and Khorami, Farid},
	month = aug,
	year = {2015},
	pmid = {25561018},
	pages = {1092--1099}
}

@article{ahmadi_developing_2014,
	title = {Developing a minimum data set of the information management system for orthopedic injuries in iran},
	volume = {16},
	issn = {2074-1804},
	doi = {10.5812/ircmj.17020},
	abstract = {BACKGROUND: Orthopedic injuries are the most common types of injuries. To identify the main causes of injuries, collecting data in a standard manner at the national level are needed, which justifies necessity of making a minimum data set (MDS).
OBJECTIVES: The aim of this study was to develop an MDS of the information management system for orthopedic injuries in Iran.
MATERIALS AND METHODS: This descriptive cross-sectional study was performed in 2013. Data were collected from hospitals affiliated with Tehran University of Medical Sciences that had orthopedic department, medical documents centers, legal medicine centers, emergency centers, internet access, and library. Investigated documents were orthopedic injury records in 2012, documents that retrieved from the internet, and printed materials. Records with Random sampling by S22-S99 categories from ICD-10 were selected and the related internet-sourced data were evaluated entirely. Data were collected using a checklist. In order to make a consensus about the data elements, the decision Delphi technique was applied by a questionnaire. The content validity and reliability of the questionnaire were assessed by expert's opinions and test-retest method, respectively.
RESULTS: AN MDS OF ORTHOPEDIC INJURIES WERE ASSIGNED TO TWO CATEGORIES: administrative category with six classes including 142 data elements, and clinical category with 17 classes including 250 data elements.
CONCLUSIONS: This study showed that some of the essential data elements included in other country's MDS or required for organizations and healthcare providers were not included. Therefore, a complete list of an MDS elements was created. Existence of comprehensive data concerning the causes and mechanisms of injuries informs public health policy-makers about injuries occurrence and enables them to take rationale measures to deal with these problems.},
	language = {eng},
	number = {7},
	journal = {Iranian Red Crescent Medical Journal},
	author = {Ahmadi, Maryam and Mohammadi, Ali and Chraghbaigi, Ramin and Fathi, Taimur and Shojaee Baghini, Mahdieh},
	month = jul,
	year = {2014},
	pmid = {25237576},
	pmcid = {PMC4166095},
	pages = {e17020}
}

@article{lemmon_minimum_2014,
	title = {Minimum information about a spinal cord injury experiment: a proposed reporting standard for spinal cord injury experiments},
	volume = {31},
	issn = {1557-9042},
	shorttitle = {Minimum information about a spinal cord injury experiment},
	doi = {10.1089/neu.2014.3400},
	abstract = {The lack of reproducibility in many areas of experimental science has a number of causes, including a lack of transparency and precision in the description of experimental approaches. This has far-reaching consequences, including wasted resources and slowing of progress. Additionally, the large number of laboratories around the world publishing articles on a given topic make it difficult, if not impossible, for individual researchers to read all of the relevant literature. Consequently, centralized databases are needed to facilitate the generation of new hypotheses for testing. One strategy to improve transparency in experimental description, and to allow the development of frameworks for computer-readable knowledge repositories, is the adoption of uniform reporting standards, such as common data elements (data elements used in multiple clinical studies) and minimum information standards. This article describes a minimum information standard for spinal cord injury (SCI) experiments, its major elements, and the approaches used to develop it. Transparent reporting standards for experiments using animal models of human SCI aim to reduce inherent bias and increase experimental value.},
	language = {eng},
	number = {15},
	journal = {Journal of Neurotrauma},
	author = {Lemmon, Vance P. and Ferguson, Adam R. and Popovich, Phillip G. and Xu, Xiao-Ming and Snow, Diane M. and Igarashi, Michihiro and Beattie, Christine E. and Bixby, John L. and {MIASCI Consortium}},
	month = aug,
	year = {2014},
	pmid = {24870067},
	pmcid = {PMC4120647},
	pages = {1354--1361}
}

@article{johnson_minimum_2014,
	title = {Minimum information necessary for quantitative real-time {PCR} experiments},
	volume = {1160},
	issn = {1940-6029},
	doi = {10.1007/978-1-4939-0733-5_2},
	abstract = {The MIQE (minimum information for the publication of quantitative real-time PCR) guidelines were published in 2009 with the twin aims of providing a blueprint for good real-time quantitative polymerase chain reaction (qPCR) assay design and encouraging the comprehensive reporting of qPCR protocols. It had become increasingly clear that variable pre-assay conditions, poor assay design, and incorrect data analysis were leading to the routine publication of data that were often inconsistent, inaccurate, and wrong. The problem was exacerbated by a lack of transparency of reporting, with the details of technical information inadequate for the purpose of assessing the validity of published qPCR data. This had, and continues to have serious implications for basic research, reducing the potential for translating findings into valuable applications and potentially devastating consequences for clinical practice. Today, the rationale underlying the MIQE guidelines has become widely accepted, with more than 2,200 citations by March 2014 and editorials in Nature and related publications acknowledging the enormity of the problem. However, the problem we now face is rather serious: thousands of publications that report suspect data are populating and corrupting the peer-reviewed scientific literature. It will be some time before the many contradictions apparent in every area of the life sciences are corrected.},
	language = {eng},
	journal = {Methods in Molecular Biology (Clifton, N.J.)},
	author = {Johnson, Gemma and Nour, Afif Abdel and Nolan, Tania and Huggett, Jim and Bustin, Stephen},
	year = {2014},
	pmid = {24740217},
	pages = {5--17}
}

@article{york_mirage:_2014,
	title = {{MIRAGE}: the minimum information required for a glycomics experiment},
	volume = {24},
	issn = {1460-2423},
	shorttitle = {{MIRAGE}},
	doi = {10.1093/glycob/cwu018},
	abstract = {The MIRAGE (minimum information required for a glycomics experiment) initiative was founded in Seattle, WA, in November 2011 in order to develop guidelines for reporting the qualitative and quantitative results obtained by diverse types of glycomics analyses, including the conditions and techniques that were applied to prepare the glycans for analysis and generate the primary data along with the tools and parameters that were used to process and annotate this data. These guidelines must address a broad range of issues, as glycomics data are inherently complex and are generated using diverse methods, including mass spectrometry (MS), chromatography, glycan array-binding assays, nuclear magnetic resonance (NMR) and other rapidly developing technologies. The acceptance of these guidelines by scientists conducting research on biological systems in which glycans have a significant role will facilitate the evaluation and reproduction of glycomics experiments and data that is reported in scientific journals and uploaded to glycomics databases. As a first step, MIRAGE guidelines for glycan analysis by MS have been recently published (Kolarich D, Rapp E, Struwe WB, Haslam SM, Zaia J., et al. 2013. The minimum information required for a glycomics experiment (MIRAGE) project - Improving the standards for reporting mass spectrometry-based glycoanalytic data. Mol. Cell Proteomics. 12:991-995), allowing them to be implemented and evaluated in the context of real-world glycobiology research. In this paper, we set out the historical context, organization structure and overarching objectives of the MIRAGE initiative.},
	language = {eng},
	number = {5},
	journal = {Glycobiology},
	author = {York, William S. and Agravat, Sanjay and Aoki-Kinoshita, Kiyoko F. and McBride, Ryan and Campbell, Matthew P. and Costello, Catherine E. and Dell, Anne and Feizi, Ten and Haslam, Stuart M. and Karlsson, Niclas and Khoo, Kay-Hooi and Kolarich, Daniel and Liu, Yan and Novotny, Milos and Packer, Nicolle H. and Paulson, James C. and Rapp, Erdmann and Ranzinger, Rene and Rudd, Pauline M. and Smith, David F. and Struwe, Weston B. and Tiemeyer, Michael and Wells, Lance and Zaia, Joseph and Kettner, Carsten},
	month = may,
	year = {2014},
	pmid = {24653214},
	pmcid = {PMC3976285},
	pages = {402--406}
}

@article{lourenco_minimum_2014,
	title = {Minimum information about a biofilm experiment ({MIABiE}): standards for reporting experiments and data on sessile microbial communities living at interfaces},
	volume = {70},
	issn = {2049-632X},
	shorttitle = {Minimum information about a biofilm experiment ({MIABiE})},
	doi = {10.1111/2049-632X.12146},
	abstract = {The minimum information about a biofilm experiment (MIABiE) initiative has arisen from the need to find an adequate and scientifically sound way to control the quality of the documentation accompanying the public deposition of biofilm-related data, particularly those obtained using high-throughput devices and techniques. Thereby, the MIABiE consortium has initiated the identification and organization of a set of modules containing the minimum information that needs to be reported to guarantee the interpretability and independent verification of experimental results and their integration with knowledge coming from other fields. MIABiE does not intend to propose specific standards on how biofilms experiments should be performed, because it is acknowledged that specific research questions require specific conditions which may deviate from any standardization. Instead, MIABiE presents guidelines about the data to be recorded and published in order for the procedure and results to be easily and unequivocally interpreted and reproduced. Overall, MIABiE opens up the discussion about a number of particular areas of interest and attempts to achieve a broad consensus about which biofilm data and metadata should be reported in scientific journals in a systematic, rigorous and understandable manner.},
	language = {eng},
	number = {3},
	journal = {Pathogens and Disease},
	author = {Lourenço, Anália and Coenye, Tom and Goeres, Darla M. and Donelli, Gianfranco and Azevedo, Andreia S. and Ceri, Howard and Coelho, Filipa L. and Flemming, Hans-Curt and Juhna, Talis and Lopes, Susana P. and Oliveira, Rosário and Oliver, Antonio and Shirtliff, Mark E. and Sousa, Ana M. and Stoodley, Paul and Pereira, Maria Olivia and Azevedo, Nuno F.},
	month = apr,
	year = {2014},
	pmid = {24478124},
	pmcid = {PMC4406403},
	pages = {250--256}
}

@article{taylor_state_2014,
	title = {The state of {RT}-quantitative {PCR}: firsthand observations of implementation of minimum information for the publication of quantitative real-time {PCR} experiments ({MIQE})},
	volume = {24},
	issn = {1660-2412},
	shorttitle = {The state of {RT}-quantitative {PCR}},
	doi = {10.1159/000356189},
	abstract = {In the past decade, the techniques of quantitative PCR (qPCR) and reverse transcription (RT)-qPCR have become accessible to virtually all research labs, producing valuable data for peer-reviewed publications and supporting exciting research conclusions. However, the experimental design and validation processes applied to the associated projects are the result of historical biases adopted by individual labs that have evolved and changed since the inception of the techniques and associated technologies. This has resulted in wide variability in the quality, reproducibility and interpretability of published data as a direct result of how each lab has designed their RT-qPCR experiments. The 'minimum information for the publication of quantitative real-time PCR experiments' (MIQE) was published to provide the scientific community with a consistent workflow and key considerations to perform qPCR experiments. We use specific examples to highlight the serious negative ramifications for data quality when the MIQE guidelines are not applied and include a summary of good and poor practices for RT-qPCR.},
	language = {eng},
	number = {1},
	journal = {Journal of Molecular Microbiology and Biotechnology},
	author = {Taylor, Sean C. and Mrkusich, Eli M.},
	year = {2014},
	pmid = {24296827},
	pages = {46--52}
}

@article{glass_mixs-be:_2014,
	title = {{MIxS}-{BE}: a {MIxS} extension defining a minimum information standard for sequence data from the built environment},
	volume = {8},
	issn = {1751-7370},
	shorttitle = {{MIxS}-{BE}},
	doi = {10.1038/ismej.2013.176},
	language = {eng},
	number = {1},
	journal = {The ISME journal},
	author = {Glass, Elizabeth M. and Dribinsky, Yekaterina and Yilmaz, Pelin and Levin, Hal and Van Pelt, Robert and Wendel, Doug and Wilke, Andreas and Eisen, Jonathan A. and Huse, Sue and Shipanova, Anna and Sogin, Mitch and Stajich, Jason and Knight, Rob and Meyer, Folker and Schriml, Lynn M.},
	month = jan,
	year = {2014},
	pmid = {24152717},
	pmcid = {PMC3869023},
	pages = {1--3}
}

@article{garciacaballero_diabetes_2013,
	title = {Diabetes surgery: minimum information on diabetic patients sample {BMI} 24-29 or {BMI} 30-34 for doing studies comparable},
	volume = {28 Suppl 2},
	issn = {1699-5198},
	shorttitle = {Diabetes surgery},
	doi = {10.3305/nh.2013.28.sup2.6706},
	language = {eng},
	journal = {Nutricion Hospitalaria},
	author = {Garcíacaballero, M.},
	month = mar,
	year = {2013},
	pmid = {23834039},
	pages = {1--2}
}

@article{fattirolli_[bare_2012,
	title = {[{The} bare minimum of information at discharge after acute coronary syndrome. {Part} 2: the quality improvement project]},
	volume = {78},
	issn = {1122-0643},
	shorttitle = {[{The} bare minimum of information at discharge after acute coronary syndrome. {Part} 2},
	doi = {10.4081/monaldi.2012.119},
	abstract = {An Acute Coronary Syndrome is a fine example of the communicative difficulties that precede and characterize hospital discharge. In recent years, due to the rapid changes in therapeutic approaches, hospitalizations have become extremely brief. This entails the risk of inadequate information at discharge, significantly affecting the quality of treatment compliance and the adoption of lifestyle modifications for an effective secondary prevention. There are a series of issues that the health practitioner should cover at discharge with the patient and family members: history of disease and prognosis, risk factors and strategies for their control, aims of treatment, instructions on drugs, diet and physical activity, need for medical check-up; and, last but not least, to verify that the information has been understood. Information on drug treatment is all too often left to patient's interpretation of hearsay or of the discharge letter, the new drug regime can easily be misunderstood or arbitrarily integrated into pre-existing drug regimes. Health practitioners must discuss issues, regardless of whether they are asked direct questions; and they should verify what imparted information has been correctly understood and assimilated. A rapid turn-over is crucial to the organization of acute units, therefore we need to identify a solution that ticks all the boxes of a good discharge in a reasonably brief time. Imparting information should be an integral component of care delivery, and the responsible practitioners (doctors and/or nurses) should be identified. We propose a standardized discharge form, containing the essential information, as a point of reference to be applied in different clinical settings.},
	language = {ita},
	number = {3},
	journal = {Monaldi Archives for Chest Disease = Archivio Monaldi Per Le Malattie Del Torace},
	author = {Fattirolli, Francesco and Angelino, Elisabetta},
	month = sep,
	year = {2012},
	pmid = {23614328},
	pages = {138--147}
}

@article{huggett_digital_2013,
	title = {The digital {MIQE} guidelines: {Minimum} {Information} for {Publication} of {Quantitative} {Digital} {PCR} {Experiments}},
	volume = {59},
	issn = {1530-8561},
	shorttitle = {The digital {MIQE} guidelines},
	doi = {10.1373/clinchem.2013.206375},
	abstract = {There is growing interest in digital PCR (dPCR) because technological progress makes it a practical and increasingly affordable technology. dPCR allows the precise quantification of nucleic acids, facilitating the measurement of small percentage differences and quantification of rare variants. dPCR may also be more reproducible and less susceptible to inhibition than quantitative real-time PCR (qPCR). Consequently, dPCR has the potential to have a substantial impact on research as well as diagnostic applications. However, as with qPCR, the ability to perform robust meaningful experiments requires careful design and adequate controls. To assist independent evaluation of experimental data, comprehensive disclosure of all relevant experimental details is required. To facilitate this process we present the Minimum Information for Publication of Quantitative Digital PCR Experiments guidelines. This report addresses known requirements for dPCR that have already been identified during this early stage of its development and commercial implementation. Adoption of these guidelines by the scientific community will help to standardize experimental protocols, maximize efficient utilization of resources, and enhance the impact of this promising new technology.},
	language = {eng},
	number = {6},
	journal = {Clinical Chemistry},
	author = {Huggett, Jim F. and Foy, Carole A. and Benes, Vladimir and Emslie, Kerry and Garson, Jeremy A. and Haynes, Ross and Hellemans, Jan and Kubista, Mikael and Mueller, Reinhold D. and Nolan, Tania and Pfaffl, Michael W. and Shipley, Gregory L. and Vandesompele, Jo and Wittwer, Carl T. and Bustin, Stephen A.},
	month = jun,
	year = {2013},
	pmid = {23570709},
	pages = {892--902}
}

@article{kolarich_minimum_2013,
	title = {The minimum information required for a glycomics experiment ({MIRAGE}) project: improving the standards for reporting mass-spectrometry-based glycoanalytic data},
	volume = {12},
	issn = {1535-9484},
	shorttitle = {The minimum information required for a glycomics experiment ({MIRAGE}) project},
	doi = {10.1074/mcp.O112.026492},
	abstract = {The MIRAGE guidelines are being developed in response to a critical need in the glycobiology community to clarify glycoanalytic results so that they are more readily evaluated (in terms of their scope and depth) and to facilitate the reproduction of important results in the laboratory. The molecular and biological complexity of the glycosylation process makes thorough reporting of the results of a glycomics experiment a highly challenging endeavor. The resulting data specify the identity and quantity of complex structures, the precise molecular features of which are sometimes inferred using prior knowledge, such as familiarity with a particular biosynthetic mechanism. Specifying the exact methods and assumptions that were used to assign and quantify reported structures allows the interested scientist to appreciate the scope and depth of the analysis. Mass spectrometry (MS) is the most widely used tool for glycomics experiments. The interpretation and reproducibility of MS-based glycomics data depend on comprehensive meta-data describing the instrumentation, instrument setup, and data acquisition protocols. The MIRAGE guidelines for MS-based glycomics have been designed to facilitate the collection and sharing of this critical information in order to assist the glycoanalyst in generating data sets with maximum information content and biological relevance.},
	language = {eng},
	number = {4},
	journal = {Molecular \& cellular proteomics: MCP},
	author = {Kolarich, Daniel and Rapp, Erdmann and Struwe, Weston B. and Haslam, Stuart M. and Zaia, Joseph and McBride, Ryan and Agravat, Sanjay and Campbell, Matthew P. and Kato, Masaki and Ranzinger, Rene and Kettner, Carsten and York, William S.},
	month = apr,
	year = {2013},
	pmid = {23378518},
	pmcid = {PMC3617344},
	pages = {991--995}
}

@article{angelino_[bare_2012,
	title = {[{The} bare minimum of information at discharge after acute coronary syndrome. {Part} 1: {Factors} that affect communication]},
	volume = {78},
	issn = {1122-0643},
	shorttitle = {[{The} bare minimum of information at discharge after acute coronary syndrome. {Part} 1},
	doi = {10.4081/monaldi.2012.127},
	abstract = {Hospital discharge after an Acute Coronary Syndrome represents a potential pitfall for patients. Strict adherence to discharge instructions is sometimes essential for recovery and prevention of complications and patients' knowledge of diagnosis and treatment plan is an integral component of patient education. Discharge communication is an integral part of high-quality, patient-centered care but patients leaving hospital often fail to understand important elements of their discharge and home care plan. This paper describes the existing literature on patient understanding and implementation of discharge instructions, discusses previous interventions aimed at improving the discharge process, and recommends best practices.},
	language = {ita},
	number = {2},
	journal = {Monaldi Archives for Chest Disease = Archivio Monaldi Per Le Malattie Del Torace},
	author = {Angelino, Elisabetta and Fattirolli, Francesco},
	month = jun,
	year = {2012},
	pmid = {23167149},
	pages = {79--84}
}

@article{lentini_shouldnt_2012,
	title = {Shouldn't enantiomeric purity be included in the 'minimum information about a bioactive entity'?},
	volume = {11},
	issn = {1474-1784},
	doi = {10.1038/nrd3503-c1},
	language = {eng},
	number = {9},
	journal = {Nature Reviews. Drug Discovery},
	author = {Lentini, Giovanni},
	month = sep,
	year = {2012},
	pmid = {22935805},
	pages = {730; author reply 730}
}

@article{norlin_minimum_2012,
	title = {A {Minimum} {Data} {Set} for {Sharing} {Biobank} {Samples}, {Information}, and {Data}: {MIABIS}},
	volume = {10},
	issn = {1947-5543},
	shorttitle = {A {Minimum} {Data} {Set} for {Sharing} {Biobank} {Samples}, {Information}, and {Data}},
	doi = {10.1089/bio.2012.0003},
	abstract = {Numerous successful scientific results have emerged from projects using shared biobanked samples and data. In order to facilitate the discovery of underutilized biobank samples, it would be helpful if a global biobank register containing descriptive information about the samples existed. But first, for shared data to be comparable, it needs to be harmonized. In compliance with the aim of BBMRI (Biobanking and Biomolecular Resources Research Infrastructure), to harmonize biobanking across Europe, and the conclusion that the move towards a universal information infrastructure for biobanking is directly connected to the issues of semantic interoperability through standardized message formats and controlled terminologies, we have developed an updated version of the minimum data set for biobanks and studies using human biospecimens. The data set called MIABIS (Minimum Information About BIobank data Sharing) consists of 52 attributes describing a biobank's content. The aim is to facilitate data discovery through harmonization of data elements describing a biobank at the aggregate level. As many biobanks across Europe possess a tremendous amount of samples that are underutilized, this would help pave the way for biobank networking on a national and international level, resulting in time and cost savings and faster emergence of new scientific results.},
	language = {eng},
	number = {4},
	journal = {Biopreservation and Biobanking},
	author = {Norlin, Loreana and Fransson, Martin N. and Eriksson, Mikael and Merino-Martinez, Roxana and Anderberg, Maria and Kurtovic, Sanela and Litton, Jan-Eric},
	month = aug,
	year = {2012},
	pmid = {24849882},
	pages = {343--348}
}

@article{spidlen_preparing_2012,
	title = {Preparing a {Minimum} {Information} about a {Flow} {Cytometry} {Experiment} ({MIFlowCyt}) compliant manuscript using the {International} {Society} for {Advancement} of {Cytometry} ({ISAC}) {FCS} file repository ({FlowRepository}.org)},
	volume = {Chapter 10},
	issn = {1934-9300},
	doi = {10.1002/0471142956.cy1018s61},
	abstract = {FlowRepository.org is a Web-based flow cytometry data repository provided by the International Society for Advancement of Cytometry (ISAC). It supports storage, annotation, analysis, and sharing of flow cytometry datasets. A fundamental tenet of scientific research is that published results should be open to independent validation and refutation. With FlowRepository, researchers can annotate their datasets in compliance with the Minimum Information about a Flow Cytometry Experiment (MIFlowCyt) standard, thus greatly facilitating third-party interpretation of their data. In this unit, we will mainly focus on the deposition, sharing, and annotation of flow cytometry data.},
	language = {eng},
	journal = {Current Protocols in Cytometry},
	author = {Spidlen, Josef and Breuer, Karin and Brinkman, Ryan},
	month = jul,
	year = {2012},
	pmid = {22752950},
	pages = {Unit 10.18}
}

@article{huang_minimum_2011,
	title = {Minimum {Information} about a {Genotyping} {Experiment} ({MIGEN})},
	volume = {5},
	issn = {1944-3277},
	doi = {10.4056/sigs.1994602},
	abstract = {Genotyping experiments are widely used in clinical and basic research laboratories to identify associations between genetic variations and normal/abnormal phenotypes. Genotyping assay techniques vary from single genomic regions that are interrogated using PCR reactions to high throughput assays examining genome-wide sequence and structural variation. The resulting genotype data may include millions of markers of thousands of individuals, requiring various statistical, modeling or other data analysis methodologies to interpret the results. To date, there are no standards for reporting genotyping experiments. Here we present the Minimum Information about a Genotyping Experiment (MIGen) standard, defining the minimum information required for reporting genotyping experiments. MIGen standard covers experimental design, subject description, genotyping procedure, quality control and data analysis. MIGen is a registered project under MIBBI (Minimum Information for Biological and Biomedical Investigations) and is being developed by an interdisciplinary group of experts in basic biomedical science, clinical science, biostatistics and bioinformatics. To accommodate the wide variety of techniques and methodologies applied in current and future genotyping experiment, MIGen leverages foundational concepts from the Ontology for Biomedical Investigations (OBI) for the description of the various types of planned processes and implements a hierarchical document structure. The adoption of MIGen by the research community will facilitate consistent genotyping data interpretation and independent data validation. MIGen can also serve as a framework for the development of data models for capturing and storing genotyping results and experiment metadata in a structured way, to facilitate the exchange of metadata.},
	language = {eng},
	number = {2},
	journal = {Standards in Genomic Sciences},
	author = {Huang, Jie and Mirel, Daniel and Pugh, Elizabeth and Xing, Chao and Robinson, Peter N. and Pertsemlidis, Alexander and Ding, Lianghao and Kozlitina, Julia and Maher, Joseph and Rios, Jonathan and Story, Michael and Marthandan, Nishanth and Scheuermann, Richard H.},
	month = nov,
	year = {2011},
	pmid = {22180825},
	pmcid = {PMC3235517},
	pages = {224--229}
}

@article{orchard_minimum_2011,
	title = {Minimum information about a bioactive entity ({MIABE})},
	volume = {10},
	issn = {1474-1784},
	doi = {10.1038/nrd3503},
	abstract = {Bioactive molecules such as drugs, pesticides and food additives are produced in large numbers by many commercial and academic groups around the world. Enormous quantities of data are generated on the biological properties and quality of these molecules. Access to such data - both on licensed and commercially available compounds, and also on those that fail during development - is crucial for understanding how improved molecules could be developed. For example, computational analysis of aggregated data on molecules that are investigated in drug discovery programmes has led to a greater understanding of the properties of successful drugs. However, the information required to perform these analyses is rarely published, and when it is made available it is often missing crucial data or is in a format that is inappropriate for efficient data-mining. Here, we propose a solution: the definition of reporting guidelines for bioactive entities - the Minimum Information About a Bioactive Entity (MIABE) - which has been developed by representatives of pharmaceutical companies, data resource providers and academic groups.},
	language = {eng},
	number = {9},
	journal = {Nature Reviews. Drug Discovery},
	author = {Orchard, Sandra and Al-Lazikani, Bissan and Bryant, Steve and Clark, Dominic and Calder, Elizabeth and Dix, Ian and Engkvist, Ola and Forster, Mark and Gaulton, Anna and Gilson, Michael and Glen, Robert and Grigorov, Martin and Hammond-Kosack, Kim and Harland, Lee and Hopkins, Andrew and Larminie, Christopher and Lynch, Nick and Mann, Romeena K. and Murray-Rust, Peter and Lo Piparo, Elena and Southan, Christopher and Steinbeck, Christoph and Wishart, David and Hermjakob, Henning and Overington, John and Thornton, Janet},
	month = aug,
	year = {2011},
	pmid = {21878981},
	pages = {661--669}
}

@article{quinn_minimum_2011,
	title = {Minimum {Information} about a {Cardiac} {Electrophysiology} {Experiment} ({MICEE}): standardised reporting for model reproducibility, interoperability, and data sharing},
	volume = {107},
	issn = {1873-1732},
	shorttitle = {Minimum {Information} about a {Cardiac} {Electrophysiology} {Experiment} ({MICEE})},
	doi = {10.1016/j.pbiomolbio.2011.07.001},
	abstract = {Cardiac experimental electrophysiology is in need of a well-defined Minimum Information Standard for recording, annotating, and reporting experimental data. As a step towards establishing this, we present a draft standard, called Minimum Information about a Cardiac Electrophysiology Experiment (MICEE). The ultimate goal is to develop a useful tool for cardiac electrophysiologists which facilitates and improves dissemination of the minimum information necessary for reproduction of cardiac electrophysiology research, allowing for easier comparison and utilisation of findings by others. It is hoped that this will enhance the integration of individual results into experimental, computational, and conceptual models. In its present form, this draft is intended for assessment and development by the research community. We invite the reader to join this effort, and, if deemed productive, implement the Minimum Information about a Cardiac Electrophysiology Experiment standard in their own work.},
	language = {eng},
	number = {1},
	journal = {Progress in Biophysics and Molecular Biology},
	author = {Quinn, T. A. and Granite, S. and Allessie, M. A. and Antzelevitch, C. and Bollensdorff, C. and Bub, G. and Burton, R. a. B. and Cerbai, E. and Chen, P. S. and Delmar, M. and Difrancesco, D. and Earm, Y. E. and Efimov, I. R. and Egger, M. and Entcheva, E. and Fink, M. and Fischmeister, R. and Franz, M. R. and Garny, A. and Giles, W. R. and Hannes, T. and Harding, S. E. and Hunter, P. J. and Iribe, G. and Jalife, J. and Johnson, C. R. and Kass, R. S. and Kodama, I. and Koren, G. and Lord, P. and Markhasin, V. S. and Matsuoka, S. and McCulloch, A. D. and Mirams, G. R. and Morley, G. E. and Nattel, S. and Noble, D. and Olesen, S. P. and Panfilov, A. V. and Trayanova, N. A. and Ravens, U. and Richard, S. and Rosenbaum, D. S. and Rudy, Y. and Sachs, F. and Sachse, F. B. and Saint, D. A. and Schotten, U. and Solovyova, O. and Taggart, P. and Tung, L. and Varró, A. and Volders, P. G. and Wang, K. and Weiss, J. N. and Wettwer, E. and White, E. and Wilders, R. and Winslow, R. L. and Kohl, P.},
	month = oct,
	year = {2011},
	pmid = {21745496},
	pmcid = {PMC3190048},
	pages = {4--10}
}

@article{waltemath_minimum_2011,
	title = {Minimum {Information} {About} a {Simulation} {Experiment} ({MIASE})},
	volume = {7},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1001122},
	language = {eng},
	number = {4},
	journal = {PLoS computational biology},
	author = {Waltemath, Dagmar and Adams, Richard and Beard, Daniel A. and Bergmann, Frank T. and Bhalla, Upinder S. and Britten, Randall and Chelliah, Vijayalakshmi and Cooling, Michael T. and Cooper, Jonathan and Crampin, Edmund J. and Garny, Alan and Hoops, Stefan and Hucka, Michael and Hunter, Peter and Klipp, Edda and Laibe, Camille and Miller, Andrew K. and Moraru, Ion and Nickerson, David and Nielsen, Poul and Nikolski, Macha and Sahle, Sven and Sauro, Herbert M. and Schmidt, Henning and Snoep, Jacky L. and Tolle, Dominic and Wolkenhauer, Olaf and Le Novère, Nicolas},
	month = apr,
	year = {2011},
	pmid = {21552546},
	pmcid = {PMC3084216},
	pages = {e1001122}
}

@article{yilmaz_minimum_2011,
	title = {Minimum information about a marker gene sequence ({MIMARKS}) and minimum information about any (x) sequence ({MIxS}) specifications},
	volume = {29},
	issn = {1546-1696},
	doi = {10.1038/nbt.1823},
	abstract = {Here we present a standard developed by the Genomic Standards Consortium (GSC) for reporting marker gene sequences--the minimum information about a marker gene sequence (MIMARKS). We also introduce a system for describing the environment from which a biological sample originates. The 'environmental packages' apply to any genome sequence of known origin and can be used in combination with MIMARKS and other GSC checklists. Finally, to establish a unified standard for describing sequence data and to provide a single point of entry for the scientific community to access and learn about GSC checklists, we present the minimum information about any (x) sequence (MIxS). Adoption of MIxS will enhance our ability to analyze natural genetic diversity documented by massive DNA sequencing efforts from myriad ecosystems in our ever-changing biosphere.},
	language = {eng},
	number = {5},
	journal = {Nature Biotechnology},
	author = {Yilmaz, Pelin and Kottmann, Renzo and Field, Dawn and Knight, Rob and Cole, James R. and Amaral-Zettler, Linda and Gilbert, Jack A. and Karsch-Mizrachi, Ilene and Johnston, Anjanette and Cochrane, Guy and Vaughan, Robert and Hunter, Christopher and Park, Joonhong and Morrison, Norman and Rocca-Serra, Philippe and Sterk, Peter and Arumugam, Manimozhiyan and Bailey, Mark and Baumgartner, Laura and Birren, Bruce W. and Blaser, Martin J. and Bonazzi, Vivien and Booth, Tim and Bork, Peer and Bushman, Frederic D. and Buttigieg, Pier Luigi and Chain, Patrick S. G. and Charlson, Emily and Costello, Elizabeth K. and Huot-Creasy, Heather and Dawyndt, Peter and DeSantis, Todd and Fierer, Noah and Fuhrman, Jed A. and Gallery, Rachel E. and Gevers, Dirk and Gibbs, Richard A. and San Gil, Inigo and Gonzalez, Antonio and Gordon, Jeffrey I. and Guralnick, Robert and Hankeln, Wolfgang and Highlander, Sarah and Hugenholtz, Philip and Jansson, Janet and Kau, Andrew L. and Kelley, Scott T. and Kennedy, Jerry and Knights, Dan and Koren, Omry and Kuczynski, Justin and Kyrpides, Nikos and Larsen, Robert and Lauber, Christian L. and Legg, Teresa and Ley, Ruth E. and Lozupone, Catherine A. and Ludwig, Wolfgang and Lyons, Donna and Maguire, Eamonn and Methé, Barbara A. and Meyer, Folker and Muegge, Brian and Nakielny, Sara and Nelson, Karen E. and Nemergut, Diana and Neufeld, Josh D. and Newbold, Lindsay K. and Oliver, Anna E. and Pace, Norman R. and Palanisamy, Giriprakash and Peplies, Jörg and Petrosino, Joseph and Proctor, Lita and Pruesse, Elmar and Quast, Christian and Raes, Jeroen and Ratnasingham, Sujeevan and Ravel, Jacques and Relman, David A. and Assunta-Sansone, Susanna and Schloss, Patrick D. and Schriml, Lynn and Sinha, Rohini and Smith, Michelle I. and Sodergren, Erica and Spo, Aymé and Stombaugh, Jesse and Tiedje, James M. and Ward, Doyle V. and Weinstock, George M. and Wendel, Doug and White, Owen and Whiteley, Andrew and Wilke, Andreas and Wortman, Jennifer R. and Yatsunenko, Tanya and Glöckner, Frank Oliver},
	month = may,
	year = {2011},
	pmid = {21552244},
	pmcid = {PMC3367316},
	pages = {415--420}
}

@article{kettner_meeting_2010,
	title = {Meeting {Report} from the {Second} "{Minimum} {Information} for {Biological} and {Biomedical} {Investigations}" ({MIBBI}) workshop},
	volume = {3},
	issn = {1944-3277},
	doi = {10.4056/sigs.147362},
	abstract = {This report summarizes the proceedings of the second workshop of the 'Minimum Information for Biological and Biomedical Investigations' (MIBBI) consortium held on Dec 1-2, 2010 in Rüdesheim, Germany through the sponsorship of the Beilstein-Institute. MIBBI is an umbrella organization uniting communities developing Minimum Information (MI) checklists to standardize the description of data sets, the workflows by which they were generated and the scientific context for the work. This workshop brought together representatives of more than twenty communities to present the status of their MI checklists and plans for future development. Shared challenges and solutions were identified and the role of MIBBI in MI checklist development was discussed. The meeting featured some thirty presentations, wide-ranging discussions and breakout groups. The top outcomes of the two-day workshop as defined by the participants were: 1) the chance to share best practices and to identify areas of synergy; 2) defining a series of tasks for updating the MIBBI Portal; 3) reemphasizing the need to maintain independent MI checklists for various communities while leveraging common terms and workflow elements contained in multiple checklists; and 4) revision of the concept of the MIBBI Foundry to focus on the creation of a core set of MIBBI modules intended for reuse by individual MI checklist projects while maintaining the integrity of each MI project. Further information about MIBBI and its range of activities can be found at http://mibbi.org/.},
	language = {eng},
	number = {3},
	journal = {Standards in Genomic Sciences},
	author = {Kettner, Carsten and Field, Dawn and Sansone, Susanna-Assunta and Taylor, Chris and Aerts, Jan and Binns, Nigel and Blake, Andrew and Britten, Cedrik M. and de Marco, Ario and Fostel, Jennifer and Gaudet, Pascale and González-Beltrán, Alejandra and Hardy, Nigel and Hellemans, Jan and Hermjakob, Henning and Juty, Nick and Leebens-Mack, Jim and Maguire, Eamonn and Neumann, Steffen and Orchard, Sandra and Parkinson, Helen and Piel, William and Ranganathan, Shoba and Rocca-Serra, Philippe and Santarsiero, Annapaola and Shotton, David and Sterk, Peter and Untergasser, Andreas and Whetzel, Patricia L.},
	month = dec,
	year = {2010},
	pmid = {21304730},
	pmcid = {PMC3035314},
	pages = {259--266}
}

@article{tan_advancing_2010,
	title = {Advancing standards for bioinformatics activities: persistence, reproducibility, disambiguation and {Minimum} {Information} {About} a {Bioinformatics} investigation ({MIABi})},
	volume = {11 Suppl 4},
	issn = {1471-2164},
	shorttitle = {Advancing standards for bioinformatics activities},
	doi = {10.1186/1471-2164-11-S4-S27},
	abstract = {The 2010 International Conference on Bioinformatics, InCoB2010, which is the annual conference of the Asia-Pacific Bioinformatics Network (APBioNet) has agreed to publish conference papers in compliance with the proposed Minimum Information about a Bioinformatics investigation (MIABi), proposed in June 2009. Authors of the conference supplements in BMC Bioinformatics, BMC Genomics and Immunome Research have consented to cooperate in this process, which will include the procedures described herein, where appropriate, to ensure data and software persistence and perpetuity, database and resource re-instantiability and reproducibility of results, author and contributor identity disambiguation and MIABi-compliance. Wherever possible, datasets and databases will be submitted to depositories with standardized terminologies. As standards are evolving, this process is intended as a prelude to the 100 BioDatabases (BioDB100) initiative whereby APBioNet collaborators will contribute exemplar databases to demonstrate the feasibility of standards-compliance and participate in refining the process for peer-review of such publications and validation of scientific claims and standards compliance. This testbed represents another step in advancing standards-based processes in the bioinformatics community which is essential to the growing interoperability of biological data, information, knowledge and computational resources.},
	language = {eng},
	journal = {BMC genomics},
	author = {Tan, Tin Wee and Tong, Joo Chuan and Khan, Asif M. and de Silva, Mark and Lim, Kuan Siong and Ranganathan, Shoba},
	month = dec,
	year = {2010},
	pmid = {21143811},
	pmcid = {PMC3005918},
	pages = {S27}
}

@misc{pubmeddev_minimum[ti]_nodate,
	title = {minimum[ti] information[ti] - {PubMed} - {NCBI}},
	url = {https://www.ncbi.nlm.nih.gov/pubmed},
	abstract = {PubMed comprises more than 28 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full-text content from PubMed Central and publisher web sites.},
	urldate = {2018-05-13},
	author = {pubmeddev},
	file = {Snapshot:/Users/transfer/Zotero/storage/V7QDDBPZ/pubmed.html:text/html}
}

@article{nagle_supporting_2006,
	title = {Supporting continuity of information in the patient transfer process should there be a minimum data set across care settings?},
	volume = {122},
	issn = {0926-9630},
	abstract = {Existing clinical information systems do not facilitate the easy transfer of relevant clinical information; hence there are significant disparities in both the type and timeliness of information that accompanies a patient transfer between care settings. Patient data is commonly fragmented between various health care settings and providers, further contributing to a reduction in the quality of information that is shared. Delineating a transfer minimum data set would provide the basis for communicating consistent information between care settings.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Nagle, Lynn M. and Judd, Julie Moffat},
	year = {2006},
	pmid = {17102364},
	pages = {746--748}
}

@article{sermeus_revision_2006,
	title = {Revision of the {Belgian} {Nursing} {Minimum} {Dataset}: {From} data to information},
	volume = {122},
	issn = {0926-9630},
	shorttitle = {Revision of the {Belgian} {Nursing} {Minimum} {Dataset}},
	abstract = {The Ministry of Public Health commissioned a research project to the Catholic University of Leuven and the University Hospital of Liège to revise the Belgian Nursing Minimum Dataset (B-NMDS). The study started in 2000 and will end with the implementation of the revised B-NMDS in January 2007. The study entailed four major phases. The first phase involved the development of a conceptual framework based on a literature review and secondary data analysis. The second phase focused on language development and development of a data collection tool. The third phase focused on data collection and validation of the new tool. In the fourth phase the validity and reliability of the dataset was tested. The new dataset is without avail if it is not leading to new information. Four applications of the dataset has been defined from the beginning: evaluation of the appropriateness of stay (AEP) in the hospital, nurse staffing, hospital financing and quality management. The aim of this paper is to describe how the B-NMDS can contribute to each of these applications.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Sermeus, Walter and Van den Heede, Koen and Michiels, Dominik and Van Herck, Pieter and Delesie, Luc and Codognotto, Jean and Thonon, Olivier and Van Boven, Caroline and Gillet, Pierre and Gillain, Daniel and Laport, Nancy and Vandenboer, Guy and Tambeur, Wim},
	year = {2006},
	pmid = {17102335},
	pages = {616--618}
}

@article{leebens-mack_taking_2006,
	title = {Taking the first steps towards a standard for reporting on phylogenies: {Minimum} {Information} {About} a {Phylogenetic} {Analysis} ({MIAPA})},
	volume = {10},
	issn = {1536-2310},
	shorttitle = {Taking the first steps towards a standard for reporting on phylogenies},
	doi = {10.1089/omi.2006.10.231},
	abstract = {In the eight years since phylogenomics was introduced as the intersection of genomics and phylogenetics, the field has provided fundamental insights into gene function, genome history and organismal relationships. The utility of phylogenomics is growing with the increase in the number and diversity of taxa for which whole genome and large transcriptome sequence sets are being generated. We assert that the synergy between genomic and phylogenetic perspectives in comparative biology would be enhanced by the development and refinement of minimal reporting standards for phylogenetic analyses. Encouraged by the development of the Minimum Information About a Microarray Experiment (MIAME) standard, we propose a similar roadmap for the development of a Minimal Information About a Phylogenetic Analysis (MIAPA) standard. Key in the successful development and implementation of such a standard will be broad participation by developers of phylogenetic analysis software, phylogenetic database developers, practitioners of phylogenomics, and journal editors.},
	language = {eng},
	number = {2},
	journal = {Omics: A Journal of Integrative Biology},
	author = {Leebens-Mack, Jim and Vision, Todd and Brenner, Eric and Bowers, John E. and Cannon, Steven and Clement, Mark J. and Cunningham, Clifford W. and dePamphilis, Claude and deSalle, Rob and Doyle, Jeff J. and Eisen, Jonathan A. and Gu, Xun and Harshman, John and Jansen, Robert K. and Kellogg, Elizabeth A. and Koonin, Eugene V. and Mishler, Brent D. and Philippe, Hervé and Pires, J. Chris and Qiu, Yin-Long and Rhee, Seung Y. and Sjölander, Kimmen and Soltis, Douglas E. and Soltis, Pamela S. and Stevenson, Dennis W. and Wall, Kerr and Warnow, Tandy and Zmasek, Christian},
	year = {2006},
	pmid = {16901231},
	pmcid = {PMC3167193},
	pages = {231--237}
}

@article{deutsch_development_2006,
	title = {Development of the {Minimum} {Information} {Specification} for {In} {Situ} {Hybridization} and {Immunohistochemistry} {Experiments} ({MISFISHIE})},
	volume = {10},
	issn = {1536-2310},
	doi = {10.1089/omi.2006.10.205},
	abstract = {We describe the creation process of the Minimum Information Specification for In Situ Hybridization and Immunohistochemistry Experiments (MISFISHIE). Modeled after the existing minimum information specification for microarray data, we created a new specification for gene expression localization experiments, initially to facilitate data sharing within a consortium. After successful use within the consortium, the specification was circulated to members of the wider biomedical research community for comment and refinement. After a period of acquiring many new suggested requirements, it was necessary to enter a final phase of excluding those requirements that were deemed inappropriate as a minimum requirement for all experiments. The full specification will soon be published as a version 1.0 proposal to the community, upon which a more full discussion must take place so that the final specification may be achieved with the involvement of the whole community.},
	language = {eng},
	number = {2},
	journal = {Omics: A Journal of Integrative Biology},
	author = {Deutsch, Eric W. and Ball, Catherine A. and Bova, G. Steven and Brazma, Alvis and Bumgarner, Roger E. and Campbell, David and Causton, Helen C. and Christiansen, Jeff and Davidson, Duncan and Eichner, Lillian J. and Goo, Young Ah and Grimmond, Sean and Henrich, Thorsten and Johnson, Michael H. and Korb, Martin and Mills, Jason C. and Oudes, Asa and Parkinson, Helen E. and Pascal, Laura E. and Quackenbush, John and Ramialison, Mirana and Ringwald, Martin and Sansone, Susanna-A. and Sherlock, Gavin and Stoeckert, Christian J. and Swedlow, Jason and Taylor, Ronald C. and Walashek, Laura and Zhou, Yi and Liu, Alvin Y. and True, Lawrence D.},
	year = {2006},
	pmid = {16901227},
	pages = {205--208}
}

@article{le_novere_minimum_2005,
	title = {Minimum information requested in the annotation of biochemical models ({MIRIAM})},
	volume = {23},
	issn = {1087-0156},
	doi = {10.1038/nbt1156},
	abstract = {Most of the published quantitative models in biology are lost for the community because they are either not made available or they are insufficiently characterized to allow them to be reused. The lack of a standard description format, lack of stringent reviewing and authors' carelessness are the main causes for incomplete model descriptions. With today's increased interest in detailed biochemical models, it is necessary to define a minimum quality standard for the encoding of those models. We propose a set of rules for curating quantitative models of biological systems. These rules define procedures for encoding and annotating models represented in machine-readable form. We believe their application will enable users to (i) have confidence that curated models are an accurate reflection of their associated reference descriptions, (ii) search collections of curated models with precision, (iii) quickly identify the biological phenomena that a given curated model or model constituent represents and (iv) facilitate model reuse and composition into large subcellular models.},
	language = {eng},
	number = {12},
	journal = {Nature Biotechnology},
	author = {Le Novère, Nicolas and Finney, Andrew and Hucka, Michael and Bhalla, Upinder S. and Campagne, Fabien and Collado-Vides, Julio and Crampin, Edmund J. and Halstead, Matt and Klipp, Edda and Mendes, Pedro and Nielsen, Poul and Sauro, Herbert and Shapiro, Bruce and Snoep, Jacky L. and Spence, Hugh D. and Wanner, Barry L.},
	month = dec,
	year = {2005},
	pmid = {16333295},
	pages = {1509--1515}
}

@article{zhou_[establishment_2003,
	title = {[{Establishment} of minimum medical geographic information systems database in {China}]},
	volume = {24},
	issn = {0254-6450},
	abstract = {OBJECTIVE: To establish a minimum medical geographic information systems (GIS) database as a spatial decision supporting system (SDSS), and to use the database into public health practice in China.
METHODS: Spatial data collected from different sources were standardized as decimal degree format, including: (1) satellite images covering areas of China; (2) digital maps of China in vector files; (3) diseases database and relevant models.
RESULTS: Necessary satellite images for the database have been collected from NOAA AVHRR, Landsat TM, etc., including the normalized difference vegetation index (NDVI) images from AVHRR, earth surface temperature images from AVHRR, GTOPO30 DEM images from USGS and landuse images from USGS. The digital vector files for GIS analysis were collected including political (county, provinces, country) boundaries file, environmental (drainage, land cover, soil type) vector file, population data and climate data; Data on diseases mainly generated from survey or case reporting. Relevant models on transmission of Schistosoma japonicum and Plasmodium vivax, and models of Oncomelania hupensis and Anophores sinansis were developed, and the relevant environmental factors related to incidence of cancers were mapped, to test and verify those database.
CONCLUSION: The database unified the data from different sources for users. Minimum medical data included in the database could be used in the practice of public health. It is expected that this database be used in a wider range.},
	language = {chi},
	number = {4},
	journal = {Zhonghua Liu Xing Bing Xue Za Zhi = Zhonghua Liuxingbingxue Zazhi},
	author = {Zhou, Xiao-nong and Hu, Xiao-shu and Yang, Guo-jing and Sun, Ning-sheng and Wang, Tian-ping and Malone, J. and McCarroll, J. and Lin, Dan-dan and Hong, Qing-biao and Sun, Le-ping and Zhang, Zhi-ying and Xu, De-zhong},
	month = apr,
	year = {2003},
	pmid = {12820938},
	pages = {253--256}
}

@article{distler_minimum_2003,
	title = {Minimum information about a microarray experiment: comment on the editorial by {Firestein} and {Pisetsky}},
	volume = {48},
	issn = {0004-3591},
	shorttitle = {Minimum information about a microarray experiment},
	doi = {10.1002/art.10756},
	language = {eng},
	number = {3},
	journal = {Arthritis and Rheumatism},
	author = {Distler, Oliver and Gay, Steffen and Neumann, Elena and Müller-Ladner, Ulf},
	month = mar,
	year = {2003},
	pmid = {12632450},
	pages = {861; author reply 862}
}

@article{brazma_minimum_2001,
	title = {Minimum information about a microarray experiment ({MIAME})-toward standards for microarray data},
	volume = {29},
	issn = {1061-4036},
	doi = {10.1038/ng1201-365},
	abstract = {Microarray analysis has become a widely used tool for the generation of gene expression data on a genomic scale. Although many significant results have been derived from microarray studies, one limitation has been the lack of standards for presenting and exchanging such data. Here we present a proposal, the Minimum Information About a Microarray Experiment (MIAME), that describes the minimum information required to ensure that microarray data can be easily interpreted and that results derived from its analysis can be independently verified. The ultimate goal of this work is to establish a standard for recording and reporting microarray-based gene expression data, which will in turn facilitate the establishment of databases and public repositories and enable the development of data analysis tools. With respect to MIAME, we concentrate on defining the content and structure of the necessary information rather than the technical format for capturing it.},
	language = {eng},
	number = {4},
	journal = {Nature Genetics},
	author = {Brazma, A. and Hingamp, P. and Quackenbush, J. and Sherlock, G. and Spellman, P. and Stoeckert, C. and Aach, J. and Ansorge, W. and Ball, C. A. and Causton, H. C. and Gaasterland, T. and Glenisson, P. and Holstege, F. C. and Kim, I. F. and Markowitz, V. and Matese, J. C. and Parkinson, H. and Robinson, A. and Sarkans, U. and Schulze-Kremer, S. and Stewart, J. and Taylor, R. and Vilo, J. and Vingron, M.},
	month = dec,
	year = {2001},
	pmid = {11726920},
	pages = {365--371}
}

@article{calle_quality_2000,
	title = {Quality of the information contained in the minimum basic data set: results from an evaluation in eight hospitals},
	volume = {16},
	issn = {0393-2990},
	shorttitle = {Quality of the information contained in the minimum basic data set},
	abstract = {To assess the quality of the information included in the minimum basic data set (MBDS) of the eight public hospitals of the Murcia region in order to ascertain what should be improved to be valid and reliable. An external encoder performed a recoding of a random sample of hospital discharges, using the patients hospital records and comparing afterwards the information obtained with the one reflected in the MBDS databases. Quality was assessed using 12 criteria. The reviewed discharges sample consisted at least of 96 cases per hospital (Type I error = 0.05, Type II = 0.10, for the most unfavorable case). A total of 796 cases were reviewed. The MBDS disagreement percentages with the patient record data were higher for the clinical data, with 41.6\% for the main diagnosis and 33.5\% for the main surgical procedure, being in both cases higher in those hospitals that had used to codify just the discharge record with regard to those that did so with the complete patient record. The variation rate in the diagnosis-related group (DRG) assignment was of 29.6\%, and there was a decrease in the case-mix index of 1.07397 when reviewing with the patient record to 1.05555 in the MBDS. Within the administrative data, the highest disagreement rate was for the physician that signs the discharge (60.5\%) and the patient's address (31.6\%). In many of these assessed aspects there are significant differences between hospitals. A reliability problem was identified in the collected data, which mainly affects the clinical variables. It is therefore advisable to carefully assess the use of this information (both the MBDS directly as well as its grouping through the use of patient classification systems), and the indicators derived from it as its quality is not guaranteed. Systematic assessment and quality control of the MBDS production is advised.},
	language = {eng},
	number = {11},
	journal = {European Journal of Epidemiology},
	author = {Calle, J. E. and Saturno, P. J. and Parra, P. and Rodenas, J. and Pérez, M. J. and Eustaquio, F. S. and Aguinaga, E.},
	year = {2000},
	pmid = {11421479},
	pages = {1073--1080}
}

@article{alba_moratilla_[minimum_1999,
	title = {[{Minimum} basic set of data of hospital discharges as a source of information for a study of congenital abnormalities]},
	volume = {73},
	issn = {1135-5727},
	abstract = {BACKGROUND: The purpose of this study is that of assessing the validity of the computerized diagnoses of hospital discharges of congenital defects by comparing them with the information included in the medical history.
METHODS: Based on the discharge records generated over a one-year period at 7 hospitals in the Autonomous Region of Valencia, 100 children were selected at random from each hospital. As a standard, the diagnoses stated in the medical histories were indexed and coded. Solely those discharges having taken place during the first year of life were considered. A study was also made of the type, seriousness and individual or combinations of congenital defects. A calculation was made of the sensitivity, specificity, predictive values and the 95\% confidence intervals thereof by the exact binomial method for the case studies (children) and the positive predictive value and sensitivity for the study of diagnoses.
RESULTS: 126 children were detected as having congenital defects, and 201 diagnoses in medical records, and 83 children with congenital defects and 108 diagnoses on record. For the detection of cases, the records showed a 64\% sensitivity, a 99.1\% specificity and some positive and negative predictive values of over 90\%. With regard to the detection of diagnoses, the sensitivity was 46\% and the positive predictive value 83\%. The sensitivity varied a great deal depending upon the diagnoses.
CONCLUSIONS: The hospital discharge records revealed a high degree of specificity and high predictive values, but a low degree of sensitivity. These facts must be considered when these records are used as a source of cases for the epidemiological studies of congenital defects.},
	language = {spa},
	number = {1},
	journal = {Revista Espanola De Salud Publica},
	author = {Alba Moratilla, N. and García García, A. M. and Benavides, F. G.},
	month = feb,
	year = {1999},
	pmid = {10224881},
	pages = {61--69}
}

@article{salvador_olivan_[limitations_1999,
	title = {[{The} limitations on the minimum basic data set as an information system for the hospital services of a university center]},
	volume = {112},
	issn = {0025-7753},
	language = {spa},
	number = {5},
	journal = {Medicina Clinica},
	author = {Salvador Oliván, J. A. and Aragüés, G. M. and Rubio Calvo, E. and Callau Puente, J.},
	month = feb,
	year = {1999},
	pmid = {10091214},
	pages = {198}
}

@article{klar_minimum_1995,
	title = {The minimum basic data set as the core of the {Freiburg} {University} {Hospital} information system},
	volume = {8 Pt 1},
	issn = {1569-6332},
	abstract = {At the University Hospital Freiburg (1,927 beds; 53,000 inpatients/year), we developed and ran a Medical Information, Retrieval, and Archives System (MIRA) by integrating the Minimum Basic Data Set into the self developed patient administration system and all the other parts of our hospital information system. Especially for the physicians, MIRA offers access to basic medical data of all patients treated in all medical departments and separate buildings since 1986. MIRA is mainly used in cases of readmission and for scientific and managerial purposes. The privacy controlled access to the central patient data bases (records of 450,000 patients) of MIRA is possible via 610 online PCs and dialog terminals. Because of the many easy-to-use standard functions and special extensions for different clinical departments, MIRA became one of the best accepted edp systems for physicians, nurses and administrators.},
	language = {eng},
	journal = {Medinfo. MEDINFO},
	author = {Klar, R. and Zaiss, A. and Binder, M. and Schrögendorfer, I.},
	year = {1995},
	pmid = {8591270},
	pages = {586--589}
}

@article{on_[minimum_1989,
	title = {[{The} minimum standard for nursing information at abolition of the system of information transfer between shifts]},
	volume = {53},
	issn = {0386-9830},
	language = {jpn},
	number = {7},
	journal = {Kangogaku Zasshi},
	author = {On, S. and Okano, H.},
	month = jul,
	year = {1989},
	pmid = {2632848},
	pages = {667--671}
}

@article{noauthor_minimum_1978,
	title = {Minimum information needed by prescribers},
	volume = {2},
	issn = {0007-1447},
	language = {eng},
	number = {6152},
	journal = {British Medical Journal},
	month = dec,
	year = {1978},
	pmid = {728771},
	pmcid = {PMC1608885},
	pages = {1646}
}

@article{golightly_minimum_1978,
	title = {Minimum information needed by prescribers},
	volume = {2},
	issn = {0007-1447},
	language = {eng},
	number = {6148},
	journal = {British Medical Journal},
	author = {Golightly, P. W. and Banks, D. C.},
	month = nov,
	year = {1978},
	pmid = {719393},
	pmcid = {PMC1608420},
	pages = {1366}
}

@article{hermann_package_1978,
	title = {Package inserts for prescribed medicines: what minimum information do patients need?},
	volume = {2},
	issn = {0007-1447},
	shorttitle = {Package inserts for prescribed medicines},
	abstract = {The information a patient needs about a prescribed medicine can be determined by considering what responsibilities he can assume in relation to taking medicine. When the medicine has been dispensed the patient needs to know how to take the drug; how to store the drug; how it is expected to help; and how to recognise problems and what to do about them. A guide was designed to specify what information is required to meet these needs. Using this guide, a set of minimum information on tetracycline was prepared that aimed at being brief, specific, and readable. The best format for the information remains to be determined. Since leaflets produced by professional organisations are generally unsuitable for these purposes, information sets should be put together by small independent groups consisting of clinical pharmacologists, clinicians, pharmacists, and consumers. Each country should produce its own sets, adapting model sets to the circumstances of local practice.},
	language = {eng},
	number = {6145},
	journal = {British Medical Journal},
	author = {Hermann, F. and Herxheimer, A. and Lionel, N. D.},
	month = oct,
	year = {1978},
	pmid = {709267},
	pmcid = {PMC1608236},
	pages = {1132--1135}
}

@article{herxheimer_minimum_1978,
	title = {Minimum information needed by prescribers},
	volume = {2},
	issn = {0007-1447},
	abstract = {The prescriber needs adequate and concise information about each product that he uses, to allow him to obtain optimal effects while minimising harm. Neither the present UK data sheets nor their equivalents in other countries have succeeded in providing such information clearly or completely. This paper develops the proposals on the arrangement of drug information made in the WHO report "The selection of essential drugs." Three sets of minimum information (on tetracycline, propranolol, and aspirin) which illustrate this approach were compared with the manufacturers' data sheets: the latter were incomplete. The information content of our proposals was worked out with a group of clinical pharmacologists, general practitioners, and specialists, and we suggest that this approach should be extended to other drugs.},
	language = {eng},
	number = {6145},
	journal = {British Medical Journal},
	author = {Herxheimer, A. and Lionel, N. D.},
	month = oct,
	year = {1978},
	pmid = {709266},
	pmcid = {PMC1608232},
	pages = {1129--1132}
}

@article{bowers_corrigendum:_2018,
	title = {Corrigendum: {Minimum} information about a single amplified genome ({MISAG}) and a metagenome-assembled genome ({MIMAG}) of bacteria and archaea},
	volume = {36},
	issn = {1546-1696},
	shorttitle = {Corrigendum},
	doi = {10.1038/nbt0218-196a},
	language = {eng},
	number = {2},
	journal = {Nature Biotechnology},
	author = {Bowers, Robert M. and Kyrpides, Nikos C. and Stepanauskas, Ramunas and Harmon-Smith, Miranda and Doud, Devin and Reddy, T. B. K. and Schulz, Frederik and Jarett, Jessica and Rivers, Adam R. and Eloe-Fadrosh, Emiley A. and Tringe, Susannah G. and Ivanova, Natalia N. and Copeland, Alex and Clum, Alicia and Becraft, Eric D. and Malmstrom, Rex R. and Birren, Bruce and Podar, Mircea and Bork, Peer and Weinstock, George M. and Garrity, George M. and Dodsworth, Jeremy A. and Yooseph, Shibu and Sutton, Granger and Glöckner, Frank O. and Gilbert, Jack A. and Nelson, William C. and Hallam, Steven J. and Jungbluth, Sean P. and Ettema, Thijs J. G. and Tighe, Scott and Konstantinidis, Konstantinos T. and Liu, Wen-Tso and Baker, Brett J. and Rattei, Thomas and Eisen, Jonathan A. and Hedlund, Brian and McMahon, Katherine D. and Fierer, Noah and Knight, Rob and Finn, Rob and Cochrane, Guy and Karsch-Mizrachi, Ilene and Tyson, Gene W. and Rinke, Christian and {Genome Standards Consortium} and Lapidus, Alla and Meyer, Folker and Yilmaz, Pelin and Parks, Donovan H. and Eren, A. Murat and Schriml, Lynn and Banfield, Jillian F. and Hugenholtz, Philip and Woyke, Tanja},
	month = feb,
	year = {2018},
	pmid = {29406516},
	pages = {196}
}

@article{fuchs_minimum_2017,
	title = {Minimum {Information} about {T} {Regulatory} {Cells}: {A} {Step} toward {Reproducibility} and {Standardization}},
	volume = {8},
	issn = {1664-3224},
	shorttitle = {Minimum {Information} about {T} {Regulatory} {Cells}},
	doi = {10.3389/fimmu.2017.01844},
	abstract = {Cellular therapies with CD4+ T regulatory cells (Tregs) hold promise of efficacious treatment for the variety of autoimmune and allergic diseases as well as posttransplant complications. Nevertheless, current manufacturing of Tregs as a cellular medicinal product varies between different laboratories, which in turn hampers precise comparisons of the results between the studies performed. While the number of clinical trials testing Tregs is already substantial, it seems to be crucial to provide some standardized characteristics of Treg products in order to minimize the problem. We have previously developed reporting guidelines called minimum information about tolerogenic antigen-presenting cells, which allows the comparison between different preparations of tolerance-inducing antigen-presenting cells. Having this experience, here we describe another minimum information about Tregs (MITREG). It is important to note that MITREG does not dictate how investigators should generate or characterize Tregs, but it does require investigators to report their Treg data in a consistent and transparent manner. We hope this will, therefore, be a useful tool facilitating standardized reporting on the manufacturing of Tregs, either for research purposes or for clinical application. This way MITREG might also be an important step toward more standardized and reproducible testing of the Tregs preparations in clinical applications.},
	language = {eng},
	journal = {Frontiers in Immunology},
	author = {Fuchs, Anke and Gliwiński, Mateusz and Grageda, Nathali and Spiering, Rachel and Abbas, Abul K. and Appel, Silke and Bacchetta, Rosa and Battaglia, Manuela and Berglund, David and Blazar, Bruce and Bluestone, Jeffrey A. and Bornhäuser, Martin and Ten Brinke, Anja and Brusko, Todd M. and Cools, Nathalie and Cuturi, Maria Cristina and Geissler, Edward and Giannoukakis, Nick and Gołab, Karolina and Hafler, David A. and van Ham, S. Marieke and Hester, Joanna and Hippen, Keli and Di Ianni, Mauro and Ilic, Natasa and Isaacs, John and Issa, Fadi and Iwaszkiewicz-Grześ, Dorota and Jaeckel, Elmar and Joosten, Irma and Klatzmann, David and Koenen, Hans and van Kooten, Cees and Korsgren, Olle and Kretschmer, Karsten and Levings, Megan and Marek-Trzonkowska, Natalia Maria and Martinez-Llordella, Marc and Miljkovic, Djordje and Mills, Kingston H. G. and Miranda, Joana P. and Piccirillo, Ciriaco A. and Putnam, Amy L. and Ritter, Thomas and Roncarolo, Maria Grazia and Sakaguchi, Shimon and Sánchez-Ramón, Silvia and Sawitzki, Birgit and Sofronic-Milosavljevic, Ljiljana and Sykes, Megan and Tang, Qizhi and Vives-Pi, Marta and Waldmann, Herman and Witkowski, Piotr and Wood, Kathryn J. and Gregori, Silvia and Hilkens, Catharien M. U. and Lombardi, Giovanna and Lord, Phillip and Martinez-Caceres, Eva M. and Trzonkowski, Piotr},
	year = {2017},
	pmid = {29379498},
	pmcid = {PMC5775516},
	pages = {1844}
}

@article{matentzoglu_miro:_2018,
	title = {{MIRO}: guidelines for minimum information for the reporting of an ontology},
	volume = {9},
	issn = {2041-1480},
	shorttitle = {{MIRO}},
	doi = {10.1186/s13326-017-0172-7},
	abstract = {BACKGROUND: Creation and use of ontologies has become a mainstream activity in many disciplines, in particular, the biomedical domain. Ontology developers often disseminate information about these ontologies in peer-reviewed ontology description reports. There appears to be, however, a high degree of variability in the content of these reports. Often, important details are omitted such that it is difficult to gain a sufficient understanding of the ontology, its content and method of creation.
RESULTS: We propose the Minimum Information for Reporting an Ontology (MIRO) guidelines as a means to facilitate a higher degree of completeness and consistency between ontology documentation, including published papers, and ultimately a higher standard of report quality. A draft of the MIRO guidelines was circulated for public comment in the form of a questionnaire, and we subsequently collected 110 responses from ontology authors, developers, users and reviewers. We report on the feedback of this consultation, including comments on each guideline, and present our analysis on the relative importance of each MIRO information item. These results were used to update the MIRO guidelines, mainly by providing more detailed operational definitions of the individual items and assigning degrees of importance. Based on our revised version of MIRO, we conducted a review of 15 recently published ontology description reports from three important journals in the Semantic Web and Biomedical domain and analysed them for compliance with the MIRO guidelines. We found that only 41.38\% of the information items were covered by the majority of the papers (and deemed important by the survey respondents) and a large number of important items are not covered at all, like those related to testing and versioning policies.
CONCLUSIONS: We believe that the community-reviewed MIRO guidelines can contribute to improving significantly the quality of ontology description reports and other documentation, in particular by increasing consistent reporting of important ontology features that are otherwise often neglected.},
	language = {eng},
	number = {1},
	journal = {Journal of Biomedical Semantics},
	author = {Matentzoglu, Nicolas and Malone, James and Mungall, Chris and Stevens, Robert},
	month = jan,
	year = {2018},
	pmid = {29347969},
	pmcid = {PMC5774126},
	pages = {6}
}

@article{gooding_should_2017,
	title = {Should {There} {Be} {Minimum} {Information} {Reporting} {Standards} for {Sensors}?},
	volume = {2},
	issn = {2379-3694},
	doi = {10.1021/acssensors.7b00737},
	language = {eng},
	number = {10},
	journal = {ACS sensors},
	author = {Gooding, J. Justin and Bakker, Eric and Kelley, Shana and Long, Yitao and Merkx, Maarten and Sailor, Michael and Tao, Nongjian},
	month = oct,
	year = {2017},
	pmid = {29073765},
	pages = {1377--1379}
}

@article{spicer_compliance_2017,
	title = {Compliance with minimum information guidelines in public metabolomics repositories},
	volume = {4},
	issn = {2052-4463},
	doi = {10.1038/sdata.2017.137},
	abstract = {The Metabolomics Standards Initiative (MSI) guidelines were first published in 2007. These guidelines provided reporting standards for all stages of metabolomics analysis: experimental design, biological context, chemical analysis and data processing. Since 2012, a series of public metabolomics databases and repositories, which accept the deposition of metabolomic datasets, have arisen. In this study, the compliance of 399 public data sets, from four major metabolomics data repositories, to the biological context MSI reporting standards was evaluated. None of the reporting standards were complied with in every publicly available study, although adherence rates varied greatly, from 0 to 97\%. The plant minimum reporting standards were the most complied with and the microbial and in vitro were the least. Our results indicate the need for reassessment and revision of the existing MSI reporting standards.},
	language = {eng},
	journal = {Scientific Data},
	author = {Spicer, Rachel A. and Salek, Reza and Steinbeck, Christoph},
	year = {2017},
	pmid = {28949328},
	pmcid = {PMC5613734},
	pages = {170137}
}

@article{sheykhotayefeh_development_2017,
	title = {Development of a {Minimum} {Data} {Set} ({MDS}) for {C}-{Section} {Anesthesia} {Information} {Management} {System} ({AIMS})},
	volume = {7},
	issn = {2228-7523},
	doi = {10.5812/aapm.44132},
	abstract = {BACKGROUND: Caesarean section, also known as C-section, is a very common procedure in the world. Minimum data set (MDS) is defined as a set of data elements holding information regarding a series of target entities to provide a basis for planning, management, and performance evaluation. MDS has found a great use in health care information systems. Also, it can be considered as a basis for medical information management and has shown a great potential for contributing to the provision of high quality care and disease control measures.
OBJECTIVES: The principal aim of this research was to determine MDS and required capabilities for Anesthesia information management system (AIMS) in C-section in Iran.
METHODS: Data items collected from several selected AIMS were studied to establish an initial set of data. The population of this study composed of 115 anesthesiologists was asked to review the proposed data elements and score them in order of importance by using a five-point Likert scale. The items scored as important or highly important by at least 75\% of the experts were included in the final list of minimum data set.
RESULTS: Overall 8 classes of data (consisted of 81 key data elements) were determined as final set. Also, the most important required capabilities were related to airway management and hypertension and hypotension management.
CONCLUSIONS: In the development of information system (IS) based on MDS and identification, because of the broad involvement of users, IS capabilities must focus on the users' needs to form a successful system. Therefore, it is essential to assess MDS watchfully by considering the planned uses of data. Also, IS should have essential capabilities to meet the needs of its users.},
	language = {eng},
	number = {2},
	journal = {Anesthesiology and Pain Medicine},
	author = {Sheykhotayefeh, Mostafa and Safdari, Reza and Ghazisaeedi, Marjan and Khademi, Seyed Hossein and Seyed Farajolah, Seyedeh Sedigheh and Maserat, Elham and Jebraeily, Mohamad and Torabi, Vahid},
	month = apr,
	year = {2017},
	pmid = {28824861},
	pmcid = {PMC5556329},
	pages = {e44132}
}

@article{bowers_minimum_2017,
	title = {Minimum information about a single amplified genome ({MISAG}) and a metagenome-assembled genome ({MIMAG}) of bacteria and archaea},
	volume = {35},
	issn = {1546-1696},
	doi = {10.1038/nbt.3893},
	abstract = {We present two standards developed by the Genomic Standards Consortium (GSC) for reporting bacterial and archaeal genome sequences. Both are extensions of the Minimum Information about Any (x) Sequence (MIxS). The standards are the Minimum Information about a Single Amplified Genome (MISAG) and the Minimum Information about a Metagenome-Assembled Genome (MIMAG), including, but not limited to, assembly quality, and estimates of genome completeness and contamination. These standards can be used in combination with other GSC checklists, including the Minimum Information about a Genome Sequence (MIGS), Minimum Information about a Metagenomic Sequence (MIMS), and Minimum Information about a Marker Gene Sequence (MIMARKS). Community-wide adoption of MISAG and MIMAG will facilitate more robust comparative genomic analyses of bacterial and archaeal diversity.},
	language = {eng},
	number = {8},
	journal = {Nature Biotechnology},
	author = {Bowers, Robert M. and Kyrpides, Nikos C. and Stepanauskas, Ramunas and Harmon-Smith, Miranda and Doud, Devin and Reddy, T. B. K. and Schulz, Frederik and Jarett, Jessica and Rivers, Adam R. and Eloe-Fadrosh, Emiley A. and Tringe, Susannah G. and Ivanova, Natalia N. and Copeland, Alex and Clum, Alicia and Becraft, Eric D. and Malmstrom, Rex R. and Birren, Bruce and Podar, Mircea and Bork, Peer and Weinstock, George M. and Garrity, George M. and Dodsworth, Jeremy A. and Yooseph, Shibu and Sutton, Granger and Glöckner, Frank O. and Gilbert, Jack A. and Nelson, William C. and Hallam, Steven J. and Jungbluth, Sean P. and Ettema, Thijs J. G. and Tighe, Scott and Konstantinidis, Konstantinos T. and Liu, Wen-Tso and Baker, Brett J. and Rattei, Thomas and Eisen, Jonathan A. and Hedlund, Brian and McMahon, Katherine D. and Fierer, Noah and Knight, Rob and Finn, Rob and Cochrane, Guy and Karsch-Mizrachi, Ilene and Tyson, Gene W. and Rinke, Christian and {Genome Standards Consortium} and Lapidus, Alla and Meyer, Folker and Yilmaz, Pelin and Parks, Donovan H. and Eren, A. M. and Schriml, Lynn and Banfield, Jillian F. and Hugenholtz, Philip and Woyke, Tanja},
	month = aug,
	year = {2017},
	pmid = {28787424},
	pages = {725--731}
}

@article{murray_minimum_2017,
	title = {Minimum {Information} for {Studies} {Evaluating} {Biologics} in {Orthopaedics} ({MIBO}): {Platelet}-{Rich} {Plasma} and {Mesenchymal} {Stem} {Cells}},
	volume = {99},
	issn = {1535-1386},
	shorttitle = {Minimum {Information} for {Studies} {Evaluating} {Biologics} in {Orthopaedics} ({MIBO})},
	doi = {10.2106/JBJS.16.00793},
	abstract = {BACKGROUND: A comprehensive approach to the evaluation of biologic therapies for musculoskeletal conditions is required to guide appropriate future use. Clinical studies evaluating platelet-rich plasma (PRP) and mesenchymal stem cells (MSCs) are limited by inadequate reporting of scientific details critical to outcome. We developed minimum reporting requirements for clinical studies evaluating PRP and MSCs using Delphi consensus methods.
METHODS: The need for consensus on the minimum reporting requirements for studies evaluating biologics was identified at the American Academy of Orthopaedic Surgeons/Orthopaedic Research Society (AAOS/ORS) Biologic Treatments for Orthopaedic Injuries Symposium in 2015 and the American Orthopaedic Society for Sports Medicine (AOSSM) Biologic Treatments for Sports Injuries II Think Tank in 2015. A working group facilitated the development of 2 expert consensus statements for PRP and MSCs using Delphi techniques. Exhaustive lists of items that could be reported on by clinical studies evaluating PRP or MSCs were generated by searching the published literature and protocols. PRP and MSC expert groups, each made up of 24 invited speakers at the AAOS and AOSSM symposia, were surveyed on 3 occasions to establish consensus on the inclusion of each item within minimum reporting guidelines. In addition to rating their agreement, the experts were encouraged to propose further items or modifications. Predefined criteria were used to refine item lists after each survey. Final lists were compiled into checklist statements by the working group.
RESULTS: For PRP, the working group identified 93 experimental information items from the literature. Twenty-three experts (96\%) completed 3 rounds of surveys. After 3 rounds, 58 items generated consensus with {\textgreater}75\% agreement and {\textless}5\% disagreement. These items were compiled into a 23-statement checklist. For MSCs, 103 items were identified from the published literature. Twenty-three experts (96\%) completed 3 rounds of surveys. After 3 rounds, the 61 items for which consensus was reached were compiled into a 25-statement checklist.
CONCLUSIONS: This study has established expert consensus on the minimum reporting requirements for clinical studies evaluating PRP and MSCs.
CLINICAL RELEVANCE: These checklists provide specifications for the minimum information that should be reported by clinical studies evaluating PRP or MSCs.},
	language = {eng},
	number = {10},
	journal = {The Journal of Bone and Joint Surgery. American Volume},
	author = {Murray, Iain R. and Geeslin, Andrew G. and Goudie, Ewan B. and Petrigliano, Frank A. and LaPrade, Robert F.},
	month = may,
	year = {2017},
	pmid = {28509821},
	pages = {809--819}
}

@article{liu_minimum_2016,
	title = {The minimum information required for a glycomics experiment ({MIRAGE}) project: improving the standards for reporting glycan microarray-based data},
	issn = {1460-2423},
	shorttitle = {The minimum information required for a glycomics experiment ({MIRAGE}) project},
	doi = {10.1093/glycob/cww118},
	abstract = {MIRAGE (Minimum Information Required for A Glycomics Experiment) is an initiative that was created by experts in the fields of glycobiology, glycoanalytics and glycoinformatics to produce guidelines for reporting results from the diverse types of experiments and analyses used in structural and functional studies of glycans in the scientific literature. As a sequel to the guidelines for sample preparation (Struwe et al. 2016, Glycobiology, 26:907-910) and mass spectrometry  data (Kolarich et al. 2013, Mol. Cell Proteomics, 12:991-995), here we present the first version of guidelines intended to improve the standards for reporting data from glycan microarray analyses. For each of eight areas in the workflow of a glycan microarray experiment, we provide guidelines for the minimal information that should be provided in reporting results. We hope that the MIRAGE glycan microarray guidelines proposed here will gain broad acceptance by the community, and will facilitate interpretation and reproducibility of the glycan microarray results with implications in comparison of data from different laboratories and eventual deposition of glycan microarray data in international databases.},
	language = {eng},
	journal = {Glycobiology},
	author = {Liu, Yan and McBride, Ryan and Stoll, Mark and Palma, Angelina S. and Silva, Lisete and Agravat, Sanjay and Aoki-Kinoshita, Kiyoko F. and Campbell, Matthew P. and Costello, Catherine E. and Dell, Anne and Haslam, Stuart M. and Karlsson, Niclas G. and Khoo, Kay-Hooi and Kolarich, Daniel and Novotny, Milos V. and Packer, Nicolle H. and Ranzinger, Rene and Rapp, Erdmann and Rudd, Pauline M. and Struwe, Weston B. and Tiemeyer, Michael and Wells, Lance and York, William S. and Zaia, Joseph and Kettner, Carsten and Paulson, James C. and Feizi, Ten and Smith, David F.},
	month = nov,
	year = {2016},
	pmid = {27993942},
	pmcid = {PMC5444268}
}

@article{cwiek-kupczynska_measures_2016,
	title = {Measures for interoperability of phenotypic data: minimum information requirements and formatting},
	volume = {12},
	issn = {1746-4811},
	shorttitle = {Measures for interoperability of phenotypic data},
	doi = {10.1186/s13007-016-0144-4},
	abstract = {BACKGROUND: Plant phenotypic data shrouds a wealth of information which, when accurately analysed and linked to other data types, brings to light the knowledge about the mechanisms of life. As phenotyping is a field of research comprising manifold, diverse and time-consuming experiments, the findings can be fostered by reusing and combining existing datasets. Their correct interpretation, and thus replicability, comparability and interoperability, is possible provided that the collected observations are equipped with an adequate set of metadata. So far there have been no common standards governing phenotypic data description, which hampered data exchange and reuse.
RESULTS: In this paper we propose the guidelines for proper handling of the information about plant phenotyping experiments, in terms of both the recommended content of the description and its formatting. We provide a document called "Minimum Information About a Plant Phenotyping Experiment", which specifies what information about each experiment should be given, and a Phenotyping Configuration for the ISA-Tab format, which allows to practically organise this information within a dataset. We provide examples of ISA-Tab-formatted phenotypic data, and a general description of a few systems where the recommendations have been implemented.
CONCLUSIONS: Acceptance of the rules described in this paper by the plant phenotyping community will help to achieve findable, accessible, interoperable and reusable data.},
	language = {eng},
	journal = {Plant Methods},
	author = {Ćwiek-Kupczyńska, Hanna and Altmann, Thomas and Arend, Daniel and Arnaud, Elizabeth and Chen, Dijun and Cornut, Guillaume and Fiorani, Fabio and Frohmberg, Wojciech and Junker, Astrid and Klukas, Christian and Lange, Matthias and Mazurek, Cezary and Nafissi, Anahita and Neveu, Pascal and van Oeveren, Jan and Pommier, Cyril and Poorter, Hendrik and Rocca-Serra, Philippe and Sansone, Susanna-Assunta and Scholz, Uwe and van Schriek, Marco and Seren, Ümit and Usadel, Björn and Weise, Stephan and Kersey, Paul and Krajewski, Paweł},
	year = {2016},
	pmid = {27843484},
	pmcid = {PMC5103589},
	pages = {44}
}

@article{melendez_frigola_[data_2016,
	title = {[{Data} {Analysis} of {Subacute} {Patients} with {Registered} {Information} in the {Minimum} {Basic} {Data} {Set} for {Social}-{Healthcare} ({CMBD}-{RSS}), {Spain}]},
	volume = {90},
	issn = {2173-9110},
	abstract = {OBJECTIVE: It is necessary to deepen in the knowledge of the Basic Minimum Set of Data (CMBD-RSS) of patients with chronic pathology associated and frequent hospitalisations (the subacute care). The aim of this study was to analyse the sanitary information of these patients, once initiated the subacute program.
METHODS: We used data of 660 patients hospitalised in the subacute care unit at the Santa Caterina Hospital, sanitary region of Girona, from October 2013 to December 2014. The CMBD data base was analysed using SPSS Statistics 15.0. We verified the relationship between variables i.e. length of stay and age; origin of the patient admission and length of stay (Mann-Whitney U Test); main diagnosis and length of stay (Kruskal-Wallis). We also studied the relationship between origin of the patient admission and main diagnosis (Chi-square test and Cramer's V).
RESULTS: The average age of patients was 83 years old, and mainly female profile (55\%). Five illnesses concentrated 80\% of all patients' diagnosed diseases (mental health problems, nervous system diseases, circulatory problems, respiratory system problems and genitourinary infections). Patients admitted from hospitals had a shorter length of stay (8 days) than patients admitted from home (9 days). 80\% of cases patients come back home after the hospital discharge.
CONCLUSIONS: People with chronic pathology associated and frequent hospitalisations are an important group of risk. Elderly and clinical decompensations add complexity to these cases. The evaluation of these patients at the admission and discharge procedures optimise the use of the resources.},
	language = {spa},
	journal = {Revista Espanola De Salud Publica},
	author = {Meléndez Frigola, Cristina and Arroyo Borrell, Elena and Saez, Marc},
	month = oct,
	year = {2016},
	pmid = {27708254},
	pages = {e1--e7}
}

@article{struwe_minimum_2016,
	title = {The minimum information required for a glycomics experiment ({MIRAGE}) project: sample preparation guidelines for reliable reporting of glycomics datasets},
	volume = {26},
	issn = {1460-2423},
	shorttitle = {The minimum information required for a glycomics experiment ({MIRAGE}) project},
	doi = {10.1093/glycob/cww082},
	abstract = {The minimum information required for a glycomics experiment (MIRAGE) project was established in 2011 to provide guidelines to aid in data reporting from all types of experiments in glycomics research including mass spectrometry (MS), liquid chromatography, glycan arrays, data handling and sample preparation. MIRAGE is a concerted effort of the wider glycomics community that considers the adaptation of reporting guidelines as an important step towards critical evaluation and dissemination of datasets as well as broadening of experimental techniques worldwide. The MIRAGE Commission published reporting guidelines for MS data and here we outline guidelines for sample preparation. The sample preparation guidelines include all aspects of sample generation, purification and modification from biological and/or synthetic carbohydrate material. The application of MIRAGE sample preparation guidelines will lead to improved recording of experimental protocols and reporting of understandable and reproducible glycomics datasets.},
	language = {eng},
	number = {9},
	journal = {Glycobiology},
	author = {Struwe, Weston B. and Agravat, Sanjay and Aoki-Kinoshita, Kiyoko F. and Campbell, Matthew P. and Costello, Catherine E. and Dell, Anne and Ten Feizi, null and Haslam, Stuart M. and Karlsson, Niclas G. and Khoo, Kay-Hooi and Kolarich, Daniel and Liu, Yan and McBride, Ryan and Novotny, Milos V. and Packer, Nicolle H. and Paulson, James C. and Rapp, Erdmann and Ranzinger, Rene and Rudd, Pauline M. and Smith, David F. and Tiemeyer, Michael and Wells, Lance and York, William S. and Zaia, Joseph and Kettner, Carsten},
	year = {2016},
	pmid = {27654115},
	pmcid = {PMC5045532},
	pages = {907--910}
}

@article{lord_minimum_2016,
	title = {Minimum information about tolerogenic antigen-presenting cells ({MITAP}): a first step towards reproducibility and standardisation of cellular therapies},
	volume = {4},
	issn = {2167-8359},
	shorttitle = {Minimum information about tolerogenic antigen-presenting cells ({MITAP})},
	doi = {10.7717/peerj.2300},
	abstract = {Cellular therapies with tolerogenic antigen-presenting cells (tolAPC) show great promise for the treatment of autoimmune diseases and for the prevention of destructive immune responses after transplantation. The methodologies for generating tolAPC vary greatly between different laboratories, making it difficult to compare data from different studies; thus constituting a major hurdle for the development of standardised tolAPC therapeutic products. Here we describe an initiative by members of the tolAPC field to generate a minimum information model for tolAPC (MITAP), providing a reporting framework that will make differences and similarities between tolAPC products transparent. In this way, MITAP constitutes a first but important step towards the production of standardised and reproducible tolAPC for clinical application.},
	language = {eng},
	journal = {PeerJ},
	author = {Lord, Phillip and Spiering, Rachel and Aguillon, Juan C. and Anderson, Amy E. and Appel, Silke and Benitez-Ribas, Daniel and Ten Brinke, Anja and Broere, Femke and Cools, Nathalie and Cuturi, Maria Cristina and Diboll, Julie and Geissler, Edward K. and Giannoukakis, Nick and Gregori, Silvia and van Ham, S. Marieke and Lattimer, Staci and Marshall, Lindsay and Harry, Rachel A. and Hutchinson, James A. and Isaacs, John D. and Joosten, Irma and van Kooten, Cees and Lopez Diaz de Cerio, Ascension and Nikolic, Tatjana and Oral, Haluk Barbaros and Sofronic-Milosavljevic, Ljiljana and Ritter, Thomas and Riquelme, Paloma and Thomson, Angus W. and Trucco, Massimo and Vives-Pi, Marta and Martinez-Caceres, Eva M. and Hilkens, Catharien M. U.},
	year = {2016},
	pmid = {27635311},
	pmcid = {PMC5012269},
	pages = {e2300}
}

@article{kumuthini_minimum_2016,
	title = {Minimum information required for a {DMET} experiment reporting},
	volume = {17},
	issn = {1744-8042},
	doi = {10.2217/pgs-2016-0015},
	abstract = {AIM: To provide pharmacogenomics reporting guidelines, the information and tools required for reporting to public omic databases.
MATERIAL \& METHODS: For effective DMET data interpretation, sharing, interoperability, reproducibility and reporting, we propose the Minimum Information required for a DMET Experiment (MIDE) reporting.
RESULTS: MIDE provides reporting guidelines and describes the information required for reporting, data storage and data sharing in the form of XML.
CONCLUSION: The MIDE guidelines will benefit the scientific community with pharmacogenomics experiments, including reporting pharmacogenomics data from other technology platforms, with the tools that will ease and automate the generation of such reports using the standardized MIDE XML schema, facilitating the sharing, dissemination, reanalysis of datasets through accessible and transparent pharmacogenomics data reporting.},
	language = {eng},
	number = {14},
	journal = {Pharmacogenomics},
	author = {Kumuthini, Judit and Mbiyavanga, Mamana and Chimusa, Emile R. and Pathak, Jyotishman and Somervuo, Panu and Van Schaik, Ron Hn and Dolzan, Vita and Mizzi, Clint and Kalideen, Kusha and Ramesar, Raj S. and Macek, Milan and Patrinos, George P. and Squassina, Alessio},
	month = sep,
	year = {2016},
	pmid = {27548815},
	pages = {1533--1545}
}

@article{sakurai_first_2016,
	title = {First {Proposal} of {Minimum} {Information} {About} a {Cellular} {Assay} for {Regenerative} {Medicine}},
	volume = {5},
	issn = {2157-6564},
	doi = {10.5966/sctm.2015-0393},
	abstract = {: Advances in stem cell research have triggered scores of studies in regenerative medicine in a large number of institutions and companies around the world. However, reproducibility and data exchange among laboratories or cell banks are constrained by the lack of a standardized format for experiments. To enhance information flow in stem cell and derivative cell research, here we propose a minimum information standard to describe cellular assay data to facilitate practical regenerative medicine. Based on the existing Minimum Information About a Cellular Assay, we developed Minimum Information About a Cellular Assay for Regenerative Medicine (MIACARM), which allows for the description of advanced cellular experiments with defined taxonomy of human cell types. By using controlled terms, such as ontologies, MIACARM will provide a platform for cellular assay data exchange among cell banks or registries that have been established at more than 20 sites in the world.
SIGNIFICANCE: Currently, there are more than 20 human cell information storage sites around the world. However, reproducibility and data exchange among different laboratories or cell information providers are usually inadequate or nonexistent because of the lack of a standardized format for experiments. This study, which is the fruit of collaborative work by scientists at stem cell banks and cellular information registries worldwide, including those in the U.S., the U.K., Europe, and Japan, proposes new minimum information guidelines, Minimum Information About a Cellular Assay for Regenerative Medicine (MIACARM), for cellular assay data deposition. MIACARM is intended to promote data exchange and facilitation of practical regenerative medicine.},
	language = {eng},
	number = {10},
	journal = {Stem Cells Translational Medicine},
	author = {Sakurai, Kunie and Kurtz, Andreas and Stacey, Glyn and Sheldon, Michael and Fujibuchi, Wataru},
	year = {2016},
	pmid = {27405781},
	pmcid = {PMC5031183},
	pages = {1345--1361}
}

@misc{noauthor_reproducibility_nodate,
	title = {Reproducibility of studies on text mining for citation screening in systematic reviews: {Evaluation} and checklist},
	url = {https://reader.elsevier.com/reader/sd/4AA00D266E3577572D1B31C75DECEFD982AFC6EF1A1D4798B0EBA8423DB9534F31690AE558554DC87E13DCDEFB9287C6},
	urldate = {2018-05-13},
	file = {Reproducibility of studies on text mining for citation screening in systematic reviews\: Evaluation and checklist:/Users/transfer/Zotero/storage/C38LTLKQ/4AA00D266E3577572D1B31C75DECEFD982AFC6EF1A1D4798B0EBA8423DB9534F31690AE558554DC87E13DCDEFB9287C.html:text/html}
}

@article{conley_effective_2011,
	title = {Effective surgical safety checklist implementation},
	volume = {212},
	number = {5},
	journal = {Journal of the American College of Surgeons},
	author = {Conley, Dante M. and Singer, Sara J. and Edmondson, Lizabeth and Berry, William R. and Gawande, Atul A.},
	year = {2011},
	pages = {873--879},
	file = {Fulltext:/Users/transfer/Zotero/storage/RWPC5MMM/Conley et al. - 2011 - Effective surgical safety checklist implementation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/EL2U8XFC/Conley et al. - 2011 - Effective surgical safety checklist implementation:}
}

@article{duff_simple_2010,
	title = {A simple checklist for preventing major complications associated with cesarean delivery},
	volume = {116},
	number = {6},
	journal = {Obstetrics \& Gynecology},
	author = {Duff, Patrick},
	year = {2010},
	pages = {1393--1396},
	file = {Fulltext:/Users/transfer/Zotero/storage/8Q4PCEGL/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/2FU7ET2R/A_Simple_Checklist_for_Preventing_Major.24.html:text/html}
}

@book{gawande_checklist_2010,
	title = {The checklist manifesto: {How} to get things right},
	volume = {200},
	shorttitle = {The checklist manifesto},
	publisher = {Metropolitan Books New York},
	author = {Gawande, Atul and Lloyd, John Bedford},
	year = {2010},
	file = {Fulltext:/Users/transfer/Zotero/storage/NYH28SDH/Gawande and Lloyd - 2010 - The checklist manifesto How to get things right.pdf:application/pdf}
}

@article{mahaffey_seductions_2010,
	title = {Seductions of the {WHO} safe surgery checklist},
	volume = {340},
	journal = {BMJ: British Medical Journal (Online)},
	author = {Mahaffey, Peter J.},
	year = {2010},
	file = {Snapshot:/Users/transfer/Zotero/storage/LVNI4TB4/1.html:text/html}
}

@article{salzwedel_effect_2013,
	title = {The effect of a checklist on the quality of post-anaesthesia patient handover: a randomized controlled trial},
	volume = {25},
	shorttitle = {The effect of a checklist on the quality of post-anaesthesia patient handover},
	number = {2},
	journal = {International journal for quality in health care},
	author = {Salzwedel, Cornelie and Bartz, Hans-Jürgen and Kühnelt, Ina and Appel, Daniel and Haupt, Oliver and Maisch, Stefan and Schmidt, Gunter Nils},
	year = {2013},
	pages = {176--181},
	file = {Fulltext:/Users/transfer/Zotero/storage/SZ7255VZ/1856171.html:text/html;Snapshot:/Users/transfer/Zotero/storage/FLEL9AJX/1856171.html:text/html}
}

@article{anthes_trouble_2015,
	title = {The trouble with checklists},
	volume = {523},
	number = {7562},
	journal = {Nature},
	author = {Anthes, Emily},
	year = {2015},
	pages = {516},
	file = {Fulltext:/Users/transfer/Zotero/storage/GUQSK6MK/Anthes - 2015 - The trouble with checklists.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YGFZ5I9L/Anthes - 2015 - The trouble with checklists.pdf:application/pdf}
}

@article{zipple_review_2010,
	title = {Review of {The} checklist manifesto: {How} to get things right.},
	shorttitle = {Review of {The} checklist manifesto},
	author = {Zipple, Anthony},
	year = {2010},
	file = {Fulltext:/Users/transfer/Zotero/storage/534NFLYE/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/TDBRXZI3/2010-15320-015.html:text/html}
}

@article{weiser_perspectives_2010,
	title = {Perspectives in quality: designing the {WHO} {Surgical} {Safety} {Checklist}},
	volume = {22},
	shorttitle = {Perspectives in quality},
	number = {5},
	journal = {International journal for quality in health care},
	author = {Weiser, Thomas G. and Haynes, Alex B. and Lashoher, Angela and Dziekan, Gerald and Boorman, Daniel J. and Berry, William R. and Gawande, Atul A.},
	year = {2010},
	pages = {365--370},
	file = {Fulltext:/Users/transfer/Zotero/storage/8B782PJH/1787019.html:text/html;Snapshot:/Users/transfer/Zotero/storage/E6PDDG4U/1787019.html:text/html}
}

@book{johnson_feature_nodate,
	title = {Feature {Engineering} and {Selection}: {A} {Practical} {Approach} for {Predictive} {Models}},
	shorttitle = {Feature {Engineering} and {Selection}},
	url = {http://www.feat.engineering/},
	abstract = {Feature Engineering and Selection: A Practical Approach for Predictive Models},
	urldate = {2018-06-02},
	author = {Johnson, Max Kuhn {and} Kjell},
	file = {Snapshot:/Users/transfer/Zotero/storage/XRLZPG2Q/www.feat.engineering.html:text/html}
}

@article{brammen_comparing_2018,
	title = {Comparing the {German} {Emergency} {Department} {Medical} {Record} with the {US} {HL}7 {Data} {Elements} for {Emergency} {Department} {Systems}},
	volume = {247},
	issn = {0926-9630},
	abstract = {Interoperability between emergency department (ED) information systems requires a shared data specification. In 2013 Health Level Seven International, an international standards body, approved a specification for Data Elements for Emergency Department Systems (DEEDS) for use in the United States. A similar specification was created in Germany for national employment, defining data elements and forms. This study presents the first step in the efforts to harmonize the two data definitions for International approval by comparing the meaning of the German Emergency Department Medical Record (GEDMR) data element definitions with the US DEEDS using a methodology for terminology mapping from ISO/TR 12300. The comparison between GEDMR and DEEDS did show significant differences in certain domains. The results support development of an international standard for ED data elements.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Brammen, Dominik and Eggert, Paul and Lucas, Benjamin and Heermann-Langford, Laura and McClay, James C.},
	year = {2018},
	pmid = {29677954},
	pages = {216--220}
}

@article{mcclay_standard_2015,
	title = {Standard for improving emergency information interoperability: the {HL}7 data elements for emergency department systems},
	volume = {22},
	issn = {1527-974X},
	shorttitle = {Standard for improving emergency information interoperability},
	doi = {10.1093/jamia/ocu040},
	abstract = {BACKGROUND: Emergency departments in the United States service over 130 million visits per year. The demands for information from these visits require interoperable data exchange standards. While multiple data exchange specifications are in use, none have undergone rigorous standards review. This paper describes the creation and balloting of the Health Level Seven (HL7) Data Elements for Emergency Department Systems (DEEDS).
METHODS: Existing data exchange specifications were collected and organized into categories reflecting the workflow of emergency care. The concepts were then mapped to existing standards for vocabulary, data types, and the HL7 information model. The HL7 community then processed the specification through the normal balloting process addressing all comments and concerns. The resulting specification was then submitted for publication as an HL7 informational standard.
RESULTS: The resulting specification contains 525 concepts related to emergency care required for operations and reporting to external agencies. An additional 200 of the most commonly ordered laboratory tests were included. Each concept was given a unique identifier and mapped to Logical Observation Identifiers, Names, and Codes (LOINC). HL7 standard data types were applied.
DISCUSSION: The HL7 DEEDS specification represents the first set of common ED related data elements to undergo rigorous standards development. The availability of this standard will contribute to improved interoperability of emergency care data.},
	language = {eng},
	number = {3},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {McClay, James C. and Park, Peter J. and Janczewski, Mark G. and Langford, Laura Heermann},
	month = may,
	year = {2015},
	pmid = {25769684},
	pages = {529--535}
}

@article{innes_consensus-based_2001,
	title = {A consensus-based process to define standard national data elements for a {Canadian} emergency department information system},
	volume = {3},
	issn = {1481-8035},
	abstract = {Canadian hospitals gather few emergency department (ED) data, and most cannot track their case mix, care processes, utilization or outcomes. A standard national ED data set would enhance clinical care, quality improvement and research at a local, regional and national level. The Canadian Association of Emergency Physicians, the National Emergency Nurses Affiliation and l'Association des médecins d'urgence du Québec established a joint working group whose objective was to develop a standard national ED data set that meets the information needs of Canadian EDs. The working group reviewed data elements derived from Australia's Victorian Emergency Minimum Dataset, the US Data Elements for Emergency Department Systems document, the Ontario Hospital Emergency Department Working Group data set and the Canadian Institute for Health Information's National Ambulatory Care Reporting System data set. By consensus, the group defined each element as mandatory, preferred or optional, and modified data definitions to increase their relevance to the ED context. The working group identified 69 mandatory elements, 5 preferred elements and 29 optional elements representing demographic, process, clinical and utilization measures. The Canadian Emergency Department Information System data set is a feasible, relevant ED data set developed by emergency physicians and nurses and tailored to the needs of Canadian EDs. If widely adopted, it represents an important step toward a national ED information system that will enable regional, provincial and national comparisons and enhance clinical care, quality improvement and research applications in both rural and urban settings.},
	language = {eng},
	number = {4},
	journal = {CJEM},
	author = {Innes, G. and Murray, M. and Grafstein, E.},
	month = oct,
	year = {2001},
	pmid = {17610770},
	pages = {277--284}
}

@article{mann_use_2004,
	title = {The use of national highway traffic safety administration uniform prehospital data elements in state emergency medical services data collection systems},
	volume = {8},
	issn = {1090-3127},
	abstract = {OBJECTIVE: Although the concept of emergency medical services (EMS) has existed for 30 years, there is little scientific evidence validating its impact on morbidity and mortality. A significant barrier to conducting meaningful assessments relates to the lack of reliable and uniform EMS data. The objective of this study was to determine the extent to which states incorporate the Uniform Prehospital EMS Data Elements into statewide EMS data collection systems.
METHODS: Study investigators requested and compared data elements from all states with a statewide prehospital data collection system.
RESULTS: During the study period, 43 states with statewide EMS data collection systems captured, on average, 79\% of the Uniform Prehospital EMS Data Set. Variables considered essential to EMS evaluation were more likely collected (84\%) than variables considered desirable (72\%). Only eight (10\%) of the 81 uniform data elements are collected by all 43 participating states.
CONCLUSIONS: Findings suggest that related EMS data variables are collected by the majority of states across the country. This degree of similarity provides a foundation for establishing common fields that can be used to develop a national EMS registry.},
	language = {eng},
	number = {1},
	journal = {Prehospital emergency care: official journal of the National Association of EMS Physicians and the National Association of State EMS Directors},
	author = {Mann, N. Clay and Dean, J. Michael and Mobasher, Helal and Mears, Greg and Ely, Michael},
	month = mar,
	year = {2004},
	pmid = {14691784},
	pages = {29--33}
}

@article{pollock_data_1998,
	title = {Data elements for emergency department systems, release 1.0 ({DEEDS}): a summary report. {DEEDS} {Writing} {Committee}},
	volume = {24},
	issn = {0099-1767},
	shorttitle = {Data elements for emergency department systems, release 1.0 ({DEEDS})},
	abstract = {Variations in the way that data are entered in ED record systems impede the use of ED records for direct patient care and deter their reuse for many other legitimate purposes. To foster more uniform ED data, the Centers for Disease Control and Prevention's (CDC) National Center for Injury Prevention and Control is coordinating a public-private partnership that has developed recommended specifications for many observations, actions, instructions, conclusions, and identifiers that are entered in ED records. The partnership's initial product. Data Elements for Emergency Department Systems, Release 1.0 (DEEDS), is intended for use by individuals and organizations responsible for ED record systems. If the recommended specifications are widely adopted, then problems--such as data incompatibility and high costs of collecting, linking, and using data--can be substantially reduced. The collaborative effort that led to DEEDS, Release 1.0 sets a precedent for future review and revision of the initial recommendations.},
	language = {eng},
	number = {1},
	journal = {Journal of emergency nursing: JEN: official publication of the Emergency Department Nurses Association},
	author = {Pollock, D. A. and Adams, D. L. and Bernardo, L. M. and Bradley, V. and Brandt, M. D. and Davis, T. E. and Garrison, H. G. and Iseke, R. M. and Johnson, S. and Kaufmann, C. R. and Kidd, P. and Leon-Chisen, N. and MacLean, S. and Manton, A. and McClain, P. W. and Michelson, E. A. and Pickett, D. and Rosen, R. A. and Schwartz, R. J. and Smith, M. and Snyder, J. A. and Wright, J. L.},
	month = feb,
	year = {1998},
	pmid = {9534532},
	pages = {35--44}
}

@article{noauthor_data_1998,
	title = {Data {Elements} for {Emergency} {Department} {Systems}, {Release} 1.0 ({DEEDS}): a summary report},
	volume = {5},
	issn = {1069-6563},
	shorttitle = {Data {Elements} for {Emergency} {Department} {Systems}, {Release} 1.0 ({DEEDS})},
	language = {eng},
	number = {2},
	journal = {Academic Emergency Medicine: Official Journal of the Society for Academic Emergency Medicine},
	month = feb,
	year = {1998},
	pmid = {9492143},
	pages = {185--193}
}

@article{pollock_data_1998-1,
	title = {Data elements for emergency department systems, release 1.0 ({DEEDS}): a summary report. {DEEDS} {Writing} {Committee}},
	volume = {31},
	issn = {0196-0644},
	shorttitle = {Data elements for emergency department systems, release 1.0 ({DEEDS})},
	abstract = {Variations in the way that data are entered in emergency department record systems impede the use of ED records for direct patient care and deter their reuse for many other legitimate purposes. To foster more uniform ED data, the Centers for Disease Control and Prevention's National Center for Injury Prevention and Control is coordinating a public-private partnership that has developed recommended specifications for many observations, actions, instructions, conclusions, and identifiers that are entered in ED records. The partnership's initial product, Data Elements for Emergency Department Systems, Release 1.0 (DEEDS), is intended for use by individuals and organizations responsible for ED record systems. If the recommended specifications are widely adopted, then problems--such as data incompatibility and high costs of collecting, linking, and using data--can be substantially reduced. The collaborative effort that led to DEEDS, Release 1.0 sets a precedent for future review and revision of the initial recommendations.},
	language = {eng},
	number = {2},
	journal = {Annals of Emergency Medicine},
	author = {Pollock, D. A. and Adams, D. L. and Bernardo, L. M. and Bradley, V. and Brandt, M. D. and Davis, T. E. and Garrison, H. G. and Iseke, R. M. and Johnson, S. and Kaufmann, C. R. and Kidd, P. and Leon-Chisen, N. and MacLean, S. and Manton, A. and McClain, P. W. and Michelson, E. A. and Pickett, D. and Rosen, R. A. and Schwartz, R. J. and Smith, M. and Snyder, J. A. and Wright, J. L.},
	month = feb,
	year = {1998},
	pmid = {9472191},
	pages = {264--273}
}

@article{pollock_data_1998-2,
	title = {Data {Elements} for {Emergency} {Department} {Systems}, {Release} 1.0 ({DEEDS}): {A} {Summary} {Report}},
	volume = {31},
	issn = {1097-6760},
	shorttitle = {Data {Elements} for {Emergency} {Department} {Systems}, {Release} 1.0 ({DEEDS})},
	doi = {10.1016/S0196-0644(98)70317-8},
	abstract = {See editorial, p 274. Variations in the way that data are entered in emergency department record systems impede the use of ED records for direct patient care and deter their reuse for many other legitimate purposes. To foster more uniform ED data, the Centers for Disease Control and Prevention's National Center for Injury Prevention and Control is coordinating a public-private partnership that has developed recommended specifications for many observations, actions, instructions, conclusions, and identifiers that are entered in ED records. The partnership's initial product, Data Elements for Emergency Department Systems, Release 1.0 (DEEDS), is intended for use by individuals and organizations responsible for ED record systems. If the recommended specifications are widely adopted, then problems-such as data incompatibility and high costs of collecting, linking, and using data-can be substantially reduced. The collaborative effort that led to DEEDS, Release 1.0 sets a precedent for future review and revision of the initial recommendations. [DEEDS Writing Committee: Data Elements for Emergency Department Systems, Release 1.0 (DEEDS): A summary report. Ann Emerg Med February 1998;31:264-273.].},
	language = {eng},
	number = {2},
	journal = {Annals of Emergency Medicine},
	author = {Pollock, Daniel A. and Adams, Diane L. and Bernardo, Lisa Marie and Bradley, Vicky and Brandt, Mary D. and Davis, Timothy E. and Garrison, Herbert G. and Iseke, Richard M. and Johnson, Sandra and Kaufmann, Christoph R. and Kidd, Pamela and Leon-Chisen, Nelly and MacLean, Susan and Manton, Anne and McClain, Philip W. and Michelson, Edward A. and Pickett, Donna and Rosen, Robert A. and Schwartz, Robert J. and Smith, Mark and Snyder, Joan A. and Wright, Joseph L.},
	month = feb,
	year = {1998},
	pmid = {28139995},
	pages = {264--273}
}

@article{spaite_uniform_1995,
	title = {Uniform prehospital data elements and definitions: a report from the uniform prehospital emergency medical services data conference},
	volume = {25},
	issn = {0196-0644},
	shorttitle = {Uniform prehospital data elements and definitions},
	abstract = {One of the district and universal aspects of emergency medical service (EMS) is the belief that before its implementation many people were dying or being killed by ill-equipped, poorly trained "hearse drivers" and that this tragic state of affairs has been rectified by the advances in the prehospital phase of care. Except for cases of nontraumatic, out-of-hospital cardiac arrest there is almost no convincing scientific evidence to prove that prehospital care has had an impact on morbidity or mortality. At the very foundation of this problem is the lack of a set of broad-based, well-conceived, accurate, reliable, uniform EMS data. Many attempts have been made to develop a uniform EMS data set, but without a national consensus these have not achieved wide distribution. In 1992, with the assistance of the National Highway Traffic Safety Administration, the national consensus process began with a series of meetings involving many EMS agencies and organizations. This culminated in August 1994 with the development of an 81-item uniform EMS data set. We detail the prior attempts at data set development and outline the process leading to the this uniform, national EMS data set.},
	language = {eng},
	number = {4},
	journal = {Annals of Emergency Medicine},
	author = {Spaite, D. and Benoit, R. and Brown, D. and Cales, R. and Dawson, D. and Glass, C. and Kaufmann, C. and Pollock, D. and Ryan, S. and Yano, E. M.},
	month = apr,
	year = {1995},
	pmid = {7710161},
	pages = {525--534}
}

@book{cohen_biomedical_2014,
	title = {Biomedical natural language processing},
	volume = {11},
	publisher = {John Benjamins Publishing Company},
	author = {Cohen, Kevin Bretonnel and Demner-Fushman, Dina},
	year = {2014},
	file = {Snapshot:/Users/transfer/Zotero/storage/LSSD4RYS/books.html:text/html}
}

@inproceedings{cohen_software_2008,
	title = {Software testing and the naturally occurring data assumption in natural language processing},
	booktitle = {Software engineering, testing, and quality assurance for natural language processing},
	publisher = {Association for Computational Linguistics},
	author = {Cohen, K. Bretonnel and Baumgartner Jr, William A. and Hunter, Lawrence},
	year = {2008},
	keywords = {reproducibility},
	pages = {23--30},
	file = {Fulltext:/Users/transfer/Zotero/storage/YRWHIASL/Cohen et al. - 2008 - Software testing and the naturally occurring data .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3TMNVBV7/citation.html:text/html}
}

@inproceedings{temnikova_measuring_2013,
	title = {Measuring closure properties of patent sublanguages},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	author = {Temnikova, Irina and Hailu, Negacy and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2013},
	pages = {659--666},
	file = {Fulltext:/Users/transfer/Zotero/storage/78A5ZU9F/Temnikova et al. - 2013 - Measuring closure properties of patent sublanguage.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YZSNNBIQ/Temnikova et al. - 2013 - Measuring closure properties of patent sublanguage.pdf:application/pdf}
}

@inproceedings{temnikova_sublanguage_2014-1,
	title = {Sublanguage {Corpus} {Analysis} {Toolkit}: {A} tool for assessing the representativeness and sublanguage characteristics of corpora},
	volume = {2014},
	shorttitle = {Sublanguage {Corpus} {Analysis} {Toolkit}},
	booktitle = {International {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {NIH Public Access},
	author = {Temnikova, Irina P. and Baumgartner Jr, William A. and Hailu, Negacy D. and Nikolova, Ivelina and McEnery, Tony and Kilgarriff, Adam and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2014},
	pages = {1714},
	file = {Fulltext:/Users/transfer/Zotero/storage/HZT8B9P4/PMC5860848.html:text/html;Snapshot:/Users/transfer/Zotero/storage/RGPFTTDS/PMC5860848.html:text/html}
}

@inproceedings{cohen_supercat:_2016,
	title = {{SuperCAT}: {The} ({New} and {Improved}) {Corpus} {Analysis} {Toolkit}},
	volume = {2016},
	shorttitle = {{SuperCAT}},
	booktitle = {International {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {NIH Public Access},
	author = {Cohen, K. Bretonnel and Baumgartner Jr, William A. and Temnikova, Irina},
	year = {2016},
	pages = {2784},
	file = {Fulltext:/Users/transfer/Zotero/storage/YQQ985ID/PMC5860820.html:text/html;Snapshot:/Users/transfer/Zotero/storage/RK8IVIBG/PMC5860820.html:text/html}
}

@inproceedings{temnikova_recognizing_2013,
	title = {Recognizing sublanguages in scientific journal articles through closure properties},
	booktitle = {Proceedings of the 2013 {Workshop} on {Biomedical} {Natural} {Language} {Processing}},
	author = {Temnikova, Irina and Cohen, Kevin},
	year = {2013},
	pages = {72--79},
	file = {Fulltext:/Users/transfer/Zotero/storage/MMI3A5VC/Temnikova and Cohen - 2013 - Recognizing sublanguages in scientific journal art.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LPHK5ZGE/Temnikova and Cohen - 2013 - Recognizing sublanguages in scientific journal art.pdf:application/pdf}
}

@inproceedings{temnikova_closure_2013,
	title = {Closure properties of {Bulgarian} clinical text},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	author = {Temnikova, Irina and Nikolova, Ivelina and Baumgartner, William A. and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2013},
	pages = {667--675},
	file = {Fulltext:/Users/transfer/Zotero/storage/JRRA35CX/Temnikova et al. - 2013 - Closure properties of Bulgarian clinical text.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MTP985QN/Temnikova et al. - 2013 - Closure properties of Bulgarian clinical text.pdf:application/pdf}
}

@article{pestian_controlled_2016,
	title = {A controlled trial using natural language processing to examine the language of suicidal adolescents in the emergency department},
	volume = {46},
	number = {2},
	journal = {Suicide and Life-Threatening Behavior},
	author = {Pestian, John P. and Grupp-Phelan, Jacqueline and Bretonnel Cohen, Kevin and Meyers, Gabriel and Richey, Linda A. and Matykiewicz, Pawel and Sorter, Michael T.},
	year = {2016},
	pages = {154--159},
	file = {Fulltext:/Users/transfer/Zotero/storage/3VSMXF8D/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/Y8CGCI8Z/sltb.html:text/html}
}

@article{pestian_machine_2017,
	title = {A machine learning approach to identifying the thought markers of suicidal subjects: a prospective multicenter trial},
	volume = {47},
	shorttitle = {A machine learning approach to identifying the thought markers of suicidal subjects},
	number = {1},
	journal = {Suicide and Life-Threatening Behavior},
	author = {Pestian, John P. and Sorter, Michael and Connolly, Brian and Bretonnel Cohen, Kevin and McCullumsmith, Cheryl and Gee, Jeffry T. and Morency, Louis-Philippe and Scherer, Stefan and Rohlfs, Lesley and Group, STM Research},
	year = {2017},
	pages = {112--121},
	file = {Fulltext:/Users/transfer/Zotero/storage/W5D8HCAY/Pestian et al. - 2017 - A machine learning approach to identifying the tho.pdf:application/pdf;Fulltext:/Users/transfer/Zotero/storage/ID3LAN8A/Pestian et al. - 2017 - A machine learning approach to identifying the tho.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/MTLPHDA3/sltb.html:text/html;Snapshot:/Users/transfer/Zotero/storage/ISRHHZEU/sltb.html:text/html}
}

@article{connolly_nonparametric_2017,
	title = {A nonparametric {Bayesian} method of translating machine learning scores to probabilities in clinical decision support},
	volume = {18},
	number = {1},
	journal = {BMC bioinformatics},
	author = {Connolly, Brian and Cohen, K. Bretonnel and Santel, Daniel and Bayram, Ulya and Pestian, John},
	year = {2017},
	pages = {361},
	file = {Fulltext:/Users/transfer/Zotero/storage/53IZ5P4S/s12859-017-1736-3.html:text/html;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/56AST4Z4/Connolly et al. - 2017 - A nonparametric Bayesian method of translating mac.pdf:application/pdf;PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/CL3Q4KVB/Connolly et al. - 2017 - A nonparametric Bayesian method of translating mac.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ER5TA8G7/s12859-017-1736-3.html:text/html}
}

@inproceedings{cohen_annotateurs_2015,
	title = {Annotateurs volontaires investis et éthique de l'annotation de lettres de suicidés},
	booktitle = {{ETeRNAL} ({Ethique} et {Traitement} {Automatique} des {Langues})},
	author = {Cohen, Kevin Bretonnel and Pestian, John and Fort, Karën},
	year = {2015},
	file = {Fulltext:/Users/transfer/Zotero/storage/JVVIX4DK/Cohen et al. - 2015 - Annotateurs volontaires investis et éthique de l'a.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/UDIF5RAN/hal-01159052.html:text/html}
}

@article{petkovic_machine_2018,
	title = {Machine learning and deep analytics for biocomputing: call for better explainability},
	volume = {23},
	issn = {2335-6936},
	shorttitle = {Machine learning and deep analytics for biocomputing},
	abstract = {The goals of this workshop are to discuss challenges in explainability of current Machine Leaning and Deep Analytics (MLDA) used in biocomputing and to start the discussion on ways to improve it. We define explainability in MLDA as easy to use information explaining why and how the MLDA approach made its decisions. We believe that much greater effort is needed to address the issue of MLDA explainability because of: 1) the ever increasing use and dependence on MLDA in biocomputing including the need for increased adoption by non-MLD experts; 2) the diversity, complexity and scale of biocomputing data and MLDA algorithms; 3) the emerging importance of MLDA-based decisions in patient care, in daily research, as well as in the development of new costly medical procedures and drugs. This workshop aims to: a) analyze and challenge the current level of explainability of MLDA methods and practices in biocomputing; b) explore benefits of improvements in this area; and c) provide useful and practical guidance to the biocomputing community on how to address these challenges and how to develop improvements. The workshop format is designed to encourage a lively discussion with panelists to first motivate and understand the problem and then to define next steps and solutions needed to improve MLDA explainability.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Petkovic, Dragutin and Kobzik, Lester and Re, Christopher},
	year = {2018},
	pmid = {29218921},
	pages = {623--627}
}

@incollection{petkovic_machine_2017,
	title = {Machine learning and deep analytics for biocomputing: call for better explainability},
	isbn = {978-981-323-552-6},
	shorttitle = {Machine learning and deep analytics for biocomputing},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789813235533_0058},
	urldate = {2018-08-13},
	booktitle = {Biocomputing 2018},
	publisher = {WORLD SCIENTIFIC},
	author = {Petkovic, Dragutin and Kobzik, Lester and Re, Christopher},
	month = oct,
	year = {2017},
	doi = {10.1142/9789813235533_0058},
	pages = {623--627},
	file = {Snapshot:/Users/transfer/Zotero/storage/DPUKNAEP/9789813235533_0058.html:text/html}
}

@misc{noauthor_what_nodate,
	title = {"{What} is relevant in a text document?": {An} interpretable machine learning approach},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5553725/},
	urldate = {2018-08-13},
	keywords = {reproducibility},
	file = {"What is relevant in a text document?"\: An interpretable machine learning approach:/Users/transfer/Zotero/storage/IYNHDAHK/PMC5553725.html:text/html}
}

@article{petkovic_machine_2018-1,
	title = {Machine learning and deep analytics for biocomputing: call for better explainability},
	volume = {23},
	issn = {2335-6936},
	shorttitle = {Machine learning and deep analytics for biocomputing},
	abstract = {The goals of this workshop are to discuss challenges in explainability of current Machine Leaning and Deep Analytics (MLDA) used in biocomputing and to start the discussion on ways to improve it. We define explainability in MLDA as easy to use information explaining why and how the MLDA approach made its decisions. We believe that much greater effort is needed to address the issue of MLDA explainability because of: 1) the ever increasing use and dependence on MLDA in biocomputing including the need for increased adoption by non-MLD experts; 2) the diversity, complexity and scale of biocomputing data and MLDA algorithms; 3) the emerging importance of MLDA-based decisions in patient care, in daily research, as well as in the development of new costly medical procedures and drugs. This workshop aims to: a) analyze and challenge the current level of explainability of MLDA methods and practices in biocomputing; b) explore benefits of improvements in this area; and c) provide useful and practical guidance to the biocomputing community on how to address these challenges and how to develop improvements. The workshop format is designed to encourage a lively discussion with panelists to first motivate and understand the problem and then to define next steps and solutions needed to improve MLDA explainability.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Petkovic, Dragutin and Kobzik, Lester and Re, Christopher},
	year = {2018},
	pmid = {29218921},
	keywords = {reproducibility},
	pages = {623--627}
}

@article{arras_what_2017,
	title = {"{What} is relevant in a text document?": {An} interpretable machine learning approach},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {"{What} is relevant in a text document?},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5553725/},
	doi = {10.1371/journal.pone.0181142},
	abstract = {Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text’s category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.},
	number = {8},
	urldate = {2018-08-13},
	journal = {PLoS ONE},
	author = {Arras, Leila and Horn, Franziska and Montavon, Grégoire and Müller, Klaus-Robert and Samek, Wojciech},
	month = aug,
	year = {2017},
	pmid = {28800619},
	pmcid = {PMC5553725},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/45X74YF2/Arras et al. - 2017 - What is relevant in a text document An interpr.pdf:application/pdf}
}

@article{doubal_big_2017,
	title = {Big data and data repurposing - using existing data to answer new questions in vascular dementia research},
	volume = {17},
	issn = {1471-2377},
	url = {https://doi.org/10.1186/s12883-017-0841-2},
	doi = {10.1186/s12883-017-0841-2},
	abstract = {Traditional approaches to clinical research have, as yet, failed to provide effective treatments for vascular dementia (VaD). Novel approaches to collation and synthesis of data may allow for time and cost efficient hypothesis generating and testing. These approaches may have particular utility in helping us understand and treat a complex condition such as VaD.},
	number = {1},
	urldate = {2018-08-14},
	journal = {BMC Neurology},
	author = {Doubal, Fergus N. and Ali, Myzoon and Batty, G. David and Charidimou, Andreas and Eriksdotter, Maria and Hofmann-Apitius, Martin and Kim, Yun-Hee and Levine, Deborah A. and Mead, Gillian and Mucke, Hermann A. M. and Ritchie, Craig W. and Roberts, Charlotte J. and Russ, Tom C. and Stewart, Robert and Whiteley, William and Quinn, Terence J.},
	month = apr,
	year = {2017},
	keywords = {Data Science},
	pages = {72},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/SYITP9AU/Doubal et al. - 2017 - Big data and data repurposing - using existing dat.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/S2JC5SMI/s12883-017-0841-2.html:text/html}
}

@misc{noauthor_frontiers_nodate,
	title = {Frontiers {\textbar} {Big} {Data} and {Dementia}: {Charting} the {Route} {Ahead} for {Research}, {Ethics}, and {Policy} {\textbar} {Medicine}},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2018.00013/full},
	urldate = {2018-08-14},
	keywords = {Data Science},
	file = {Frontiers | Big Data and Dementia\: Charting the Route Ahead for Research, Ethics, and Policy | Medicine:/Users/transfer/Zotero/storage/53KUQ6NV/full.html:text/html}
}

@article{geerts_big_2016,
	title = {Big data to smart data in {Alzheimer}'s disease: {The} brain health modeling initiative to foster actionable knowledge},
	volume = {12},
	issn = {1552-5260, 1552-5279},
	shorttitle = {Big data to smart data in {Alzheimer}'s disease},
	url = {https://www.alzheimersanddementia.com/article/S1552-5260(16)30246-1/fulltext},
	doi = {10.1016/j.jalz.2016.04.008},
	language = {English},
	number = {9},
	urldate = {2018-08-14},
	journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
	author = {Geerts, Hugo and Dacks, Penny A. and Devanarayan, Viswanath and Haas, Magali and Khachaturian, Zaven S. and Gordon, Mark Forrest and Maudsley, Stuart and Romero, Klaus and Stephenson, Diane},
	month = sep,
	year = {2016},
	pmid = {27238630},
	keywords = {Data Science},
	pages = {1014--1021},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/HI6DBENS/Geerts et al. - 2016 - Big data to smart data in Alzheimer's disease The.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/2L33VRBM/fulltext.html:text/html}
}

@article{haas_big_2016,
	title = {Big data to smart data in {Alzheimer}'s disease: {Real}-world examples of advanced modeling and simulation},
	volume = {12},
	issn = {1552-5260, 1552-5279},
	shorttitle = {Big data to smart data in {Alzheimer}'s disease},
	url = {https://www.alzheimersanddementia.com/article/S1552-5260(16)30279-5/fulltext},
	doi = {10.1016/j.jalz.2016.05.005},
	language = {English},
	number = {9},
	urldate = {2018-08-14},
	journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
	author = {Haas, Magali and Stephenson, Diane and Romero, Klaus and Gordon, Mark Forrest and Zach, Neta and Geerts, Hugo},
	month = sep,
	year = {2016},
	pmid = {27327540},
	keywords = {Data Science},
	pages = {1022--1030},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/XA8SJM8A/Haas et al. - 2016 - Big data to smart data in Alzheimer's disease Rea.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/WI8ZDSG4/fulltext.html:text/html}
}

@article{hofmann-apitius_is_2015,
	title = {Is dementia research ready for big data approaches?},
	volume = {13},
	issn = {1741-7015},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4476175/},
	doi = {10.1186/s12916-015-0367-7},
	abstract = {The “big data” paradigm has gained a lot of attention recently, in particular in those areas of biomedicine where we face clear unmet medical needs. Coined as a new paradigm for complex problem solving, big data approaches seem to open promising perspectives in particular for a better understanding of complex diseases such as Alzheimer’s disease and other dementias. In this commentary, we will provide a brief overview on big data principles and the potential they may bring to dementia research, and - most importantly - we will do a reality check in order to provide an answer to the question of whether dementia research is ready for big data approaches.},
	urldate = {2018-08-14},
	journal = {BMC Medicine},
	author = {Hofmann-Apitius, Martin},
	month = jun,
	year = {2015},
	pmid = {26099627},
	pmcid = {PMC4476175},
	keywords = {Data Science},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/D6RKVP88/Hofmann-Apitius - 2015 - Is dementia research ready for big data approaches.pdf:application/pdf}
}

@article{khachaturian_big_2013,
	title = {Big data, aging, and dementia: {Pathways} for international harmonization on data sharing},
	volume = {9},
	issn = {1552-5260, 1552-5279},
	shorttitle = {Big data, aging, and dementia},
	url = {https://www.alzheimersanddementia.com/article/S1552-5260(13)02821-5/fulltext},
	doi = {10.1016/j.jalz.2013.09.001},
	language = {English},
	number = {5},
	urldate = {2018-08-14},
	journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
	author = {Khachaturian, Ara S. and Meranus, Dana H. and Kukull, Walter A. and Khachaturian, Zaven S.},
	month = oct,
	year = {2013},
	pmid = {24125464},
	keywords = {Data Science},
	pages = {S61--S62},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/X9QVVCWE/Khachaturian et al. - 2013 - Big data, aging, and dementia Pathways for intern.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/TDXBASD4/fulltext.html:text/html}
}

@misc{noauthor_q&adam_nodate,
	title = {Q\&{A} {Adam} {Russell}: {The} search for automated tools to rate research reproducibility},
	shorttitle = {Q\&{A} {Adam} {Russell}},
	url = {https://www.natureindex.com/news-blog/adam-russell-the-search-for-automated-tools-to-rate-research-reproducibility},
	abstract = {A US project is exploring the use of software to assign confidence levels to published research.},
	urldate = {2018-08-14},
	keywords = {reproducibility},
	file = {Snapshot:/Users/transfer/Zotero/storage/FS5T3JHJ/adam-russell-the-search-for-automated-tools-to-rate-research-reproducibility.html:text/html}
}

@inproceedings{matykiewicz_earlier_2013,
	title = {Earlier identification of epilepsy surgery candidates using natural language processing},
	booktitle = {Proceedings of the 2013 {Workshop} on {Biomedical} {Natural} {Language} {Processing}},
	author = {Matykiewicz, Pawel and Cohen, Kevin and Holland, Katherine D. and Glauser, Tracy A. and Standridge, Shannon M. and Verspoor, Karen M. and Pestian, John},
	year = {2013},
	pages = {1--9},
	file = {Fulltext:/Users/transfer/Zotero/storage/K6VWGYUD/Matykiewicz et al. - 2013 - Earlier identification of epilepsy surgery candida.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/JWKU97YL/Matykiewicz et al. - 2013 - Earlier identification of epilepsy surgery candida.pdf:application/pdf}
}

@article{connolly_assessing_2014,
	title = {Assessing the similarity of surface linguistic features related to epilepsy across pediatric hospitals},
	volume = {21},
	number = {5},
	journal = {Journal of the American Medical Informatics Association},
	author = {Connolly, Brian and Matykiewicz, Pawel and Bretonnel Cohen, K. and Standridge, Shannon M. and Glauser, Tracy A. and Dlugos, Dennis J. and Koh, Susan and Tham, Eric and Pestian, John},
	year = {2014},
	pages = {866--870},
	file = {Fulltext:/Users/transfer/Zotero/storage/4N8WJF4S/2909273.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7VKJM5UE/2909273.html:text/html}
}

@inproceedings{cohen_contrast_2002,
	title = {Contrast and variability in gene names},
	booktitle = {Proceedings of the {ACL}-02 workshop on {Natural} language processing in the biomedical domain-{Volume} 3},
	publisher = {Association for Computational Linguistics},
	author = {Cohen, K. Bretonnel and Acquaah-Mensah, George K. and Dolbey, Andrew E. and Hunter, Lawrence},
	year = {2002},
	pages = {14--20},
	file = {Fulltext:/Users/transfer/Zotero/storage/82LD2IVN/Cohen et al. - 2002 - Contrast and variability in gene names.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CSUX7UL3/citation.html:text/html}
}

@inproceedings{cohen_resource_2004,
	title = {A resource for constructing customized test suites for molecular biology entity identification systems},
	booktitle = {{HLT}-{NAACL} 2004 {Workshop}: {Linking} {Biological} {Literature}, {Ontologies} and {Databases}},
	author = {Cohen, K. Bretonnel and Tanabe, Lorraine and Kinoshita, Shuhei and Hunter, Lawrence},
	year = {2004},
	keywords = {reproducibility},
	file = {Fulltext:/Users/transfer/Zotero/storage/N76UKTKU/Cohen et al. - 2004 - A resource for constructing customized test suites.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/CYYW2H9M/Cohen et al. - 2004 - A resource for constructing customized test suites.pdf:application/pdf}
}

@inproceedings{cohen_test_2010,
	title = {Test suite design for biomedical ontology concept recognition systems},
	booktitle = {Proceedings of the {Seventh} conference on {International} {Language} {Resources} and {Evaluation} ({LREC}'10)},
	author = {Cohen, K. Bretonnel and Roeder, Christophe and Baumgartner Jr, William A. and Hunter, Lawrence E. and Verspoor, Karin},
	year = {2010},
	keywords = {reproducibility},
	file = {Snapshot:/Users/transfer/Zotero/storage/XSZWGMZP/l10-1014.html:text/html}
}

@inproceedings{cohen_assessment_2012,
	title = {Assessment of software testing and quality assurance in natural language processing applications and a linguistically inspired approach to improving it},
	booktitle = {International {Workshop} on {Eternal} {Systems}},
	publisher = {Springer},
	author = {Cohen, K. Bretonnel and Hunter, Lawrence E. and Palmer, Martha},
	year = {2012},
	keywords = {reproducibility},
	pages = {77--90},
	file = {Fulltext:/Users/transfer/Zotero/storage/2IRVX82R/Cohen et al. - 2012 - Assessment of software testing and quality assuran.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/KRR8L5G2/978-3-642-45260-4_6.html:text/html}
}

@article{boguslav_improving_2018-5,
	title = {Improving precision in concept normalization},
	volume = {23},
	issn = {2335-6936},
	abstract = {Most natural language processing applications exhibit a trade-off between precision and recall. In some use cases for natural language processing, there are reasons to prefer to tilt that trade-off toward high precision. Relying on the Zipfian distribution of false positive results, we describe a strategy for increasing precision, using a variety of both pre-processing and post-processing methods. They draw on both knowledge-based and frequentist approaches to modeling language. Based on an existing high-performance biomedical concept recognition pipeline and a previously published manually annotated corpus, we apply this hybrid rationalist/empiricist strategy to concept normalization for eight different ontologies. Which approaches did and did not improve precision varied widely between the ontologies.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Boguslav, Mayla and Cohen, K. Bretonnel and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2018},
	pmid = {29218915},
	pmcid = {PMC5730334},
	pages = {566--577}
}

@article{kano_u-compare:_2011,
	title = {U-{Compare}: {A} modular {NLP} workflow construction and evaluation system},
	volume = {55},
	shorttitle = {U-{Compare}},
	number = {3},
	journal = {IBM Journal of Research and Development},
	author = {Kano, Yoshinobu and Miwa, Makoto and Cohen, K. Bretonnel and Hunter, Lawrence E. and Ananiadou, Sophia and Tsujii, Jun’ichi},
	year = {2011},
	keywords = {reproducibility},
	pages = {11--1},
	file = {Fulltext:/Users/transfer/Zotero/storage/WIAC84KP/Kano et al. - 2011 - U-Compare A modular NLP workflow construction and.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/NPP62FVC/5730625.html:text/html}
}

@article{leaman_taggerone:_2016,
	title = {{TaggerOne}: joint named entity recognition and normalization with semi-{Markov} {Models}},
	volume = {32},
	issn = {1367-4803},
	shorttitle = {{TaggerOne}},
	url = {https://academic.oup.com/bioinformatics/article/32/18/2839/1744190},
	doi = {10.1093/bioinformatics/btw343},
	abstract = {Abstract.  Motivation: Text mining is increasingly used to manage the accelerating pace of the biomedical literature. Many text mining applications depend on ac},
	language = {en},
	number = {18},
	urldate = {2018-09-07},
	journal = {Bioinformatics},
	author = {Leaman, Robert and Lu, Zhiyong},
	month = sep,
	year = {2016},
	pages = {2839--2846},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/NFYJCZGV/Leaman and Lu - 2016 - TaggerOne joint named entity recognition and norm.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/5MJYU3AM/1744190.html:text/html}
}

@article{du_extracting_2018,
	title = {Extracting psychiatric stressors for suicide from social media using deep learning},
	volume = {18},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/s12911-018-0632-8},
	doi = {10.1186/s12911-018-0632-8},
	abstract = {Suicide has been one of the leading causes of deaths in the United States. One major cause of suicide is psychiatric stressors. The detection of psychiatric stressors in an at risk population will facilitate the early prevention of suicidal behaviors and suicide. In recent years, the widespread popularity and real-time information sharing flow of social media allow potential early intervention in a large-scale population. However, few automated approaches have been proposed to extract psychiatric stressors from Twitter. The goal of this study was to investigate techniques for recognizing suicide related psychiatric stressors from Twitter using deep learning based methods and transfer learning strategy which leverages an existing annotation dataset from clinical text.},
	number = {2},
	urldate = {2018-09-07},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Du, Jingcheng and Zhang, Yaoyun and Luo, Jianhong and Jia, Yuxi and Wei, Qiang and Tao, Cui and Xu, Hua},
	month = jul,
	year = {2018},
	pages = {43},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/66X7KMPQ/Du et al. - 2018 - Extracting psychiatric stressors for suicide from .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/P37W47LF/s12911-018-0632-8.html:text/html}
}

@article{caliskan_semantics_2017,
	title = {Semantics derived automatically from language corpora contain human-like biases},
	volume = {356},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aal4230},
	doi = {10.1126/science.aal4230},
	language = {en},
	number = {6334},
	urldate = {2018-09-11},
	journal = {Science},
	author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
	month = apr,
	year = {2017},
	keywords = {female first or senior, ethics, gender, bias},
	pages = {183--186},
	file = {Caliskan et al. - 2017 - Semantics derived automatically from language corp.pdf:/Users/transfer/Zotero/storage/8KP3QNU4/Caliskan et al. - 2017 - Semantics derived automatically from language corp.pdf:application/pdf}
}

@article{garg_word_2018,
	title = {Word embeddings quantify 100 years of gender and ethnic stereotypes},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1720347115},
	doi = {10.1073/pnas.1720347115},
	language = {en},
	number = {16},
	urldate = {2018-09-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Garg, Nikhil and Schiebinger, Londa and Jurafsky, Dan and Zou, James},
	month = apr,
	year = {2018},
	keywords = {ethics, gender, bias},
	pages = {E3635--E3644},
	file = {Garg et al. - 2018 - Word embeddings quantify 100 years of gender and e.pdf:/Users/transfer/Zotero/storage/L7TQSDEF/Garg et al. - 2018 - Word embeddings quantify 100 years of gender and e.pdf:application/pdf}
}

@inproceedings{hovy_demographic_2015,
	address = {Beijing, China},
	title = {Demographic {Factors} {Improve} {Classification} {Performance}},
	url = {http://www.aclweb.org/anthology/P15-1073},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hovy, Dirk},
	month = jul,
	year = {2015},
	keywords = {ethics, gender, bias},
	pages = {752--762},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/ABXAMPTS/Hovy - 2015 - Demographic Factors Improve Classification Perform.pdf:application/pdf}
}

@inproceedings{cohen_fast_2011,
	address = {Portland, Oregon, USA},
	title = {Fast and simple semantic class assignment for biomedical text},
	url = {http://www.aclweb.org/anthology/W11-0205},
	urldate = {2018-10-05},
	booktitle = {Proceedings of {BioNLP} 2011 {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Cohen, K. Bretonnel and Christiansen, Thomas and Baumgartner Jr., William and Verspoor, Karin and Hunter, Lawrence},
	month = jun,
	year = {2011},
	pages = {38--45},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/GCDNHMBW/Cohen et al. - 2011 - Fast and simple semantic class assignment for biom.pdf:application/pdf}
}

@article{pressman_neuroanatomy_2018,
	title = {Neuroanatomy of {Shared} {Conversational} {Laughter} in {Neurodegenerative} {Disease}},
	volume = {9},
	issn = {1664-2295},
	url = {https://www.frontiersin.org/articles/10.3389/fneur.2018.00464/full},
	doi = {10.3389/fneur.2018.00464},
	abstract = {Perceiving another person's emotional expression often sparks a corresponding signal in the observer. Shared conversational laughter is a familiar example. Prior studies of shared laughter have made use of task-based functional neuroimaging. While these methods offer insight in a controlled setting, the ecological validity of such controlled tasks has limitations. Here, we investigate the neural correlates of shared laughter in patients with one of a variety of neurodegenerative disease syndromes (N=75), including Alzheimer's disease (AD), behavioral variant frontotemporal dementia (bvFTD), right and left temporal variants of semantic dementia (rtvFTD, svPPA), nonfluent/agrammatic primary progressive aphasia (nfvPPA), corticobasal syndrome (CBS), and progressive supranuclear palsy (PSP). Patients were recorded in a brief unrehearsed conversation with a partner (e.g. a friend or family member). Laughter was manually labeled, and an automated system was used to assess the timing of that laughter relative to the partner's laughter. The probability of each participant with neurodegenerative disease laughing during or shortly after his or her partners' laughter was compared to differences in brain morphology using voxel-based morphometry, thresholded based on cluster size and a permutation method and including age, sex, magnet strength, disease-specific atrophy and total intracranial volumes as covariates. While no significant correlations were found at the critical T value, at a corrected voxelwise threshold of p {\textless} 0.005, a cluster in the left posterior cingulate gyrus demonstrated a trend at p = 0.08 (T=4.54). Exploratory analysis with a voxelwise threshold of p = 0.001 also suggests involvement of the left precuneus (T=3.91) and right fusiform gyrus (T=3.86). The precuneus has been previously implicated in the detection of socially complex laughter, and the fusiform gyrus has a well-described role in the recognition and processing of others' emotional cues. This study is limited by a relatively small sample size given the number of covariates. While further investigation is needed, these results support our understanding of the neural underpinnings of shared conversational laughter.},
	language = {English},
	urldate = {2018-10-05},
	journal = {Frontiers in Neurology},
	author = {Pressman, Peter S. and Shdo, Suzanne and Simpson, Michaela and Chen, Kuan-Hua and Mielke, Clinton and Miller, Bruce L. and Rankin, Katherine P. and Levenson, Robert W.},
	year = {2018},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/NS4MRYRA/Pressman et al. - 2018 - Neuroanatomy of Shared Conversational Laughter in .pdf:application/pdf}
}

@article{pressman_observing_2017,
	title = {Observing conversational laughter in frontotemporal dementia},
	volume = {88},
	copyright = {© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved. No commercial use is permitted unless otherwise expressly granted.},
	issn = {0022-3050, 1468-330X},
	url = {https://jnnp.bmj.com/content/88/5/418},
	doi = {10.1136/jnnp-2016-314931},
	abstract = {Background We performed an observational study of laughter during seminaturalistic conversations between patients with dementia and familial caregivers. Patients were diagnosed with (1) behavioural variant frontotemporal dementia (bvFTD), (2) right temporal variant frontotemporal dementia (rtFTD), (3) semantic variant of primary progressive aphasia (svPPA), (4) non-fluent variant primary progressive aphasia (nfvPPA) or (5) early onset Alzheimer’s disease (eoAD). We hypothesised that those with bvFTD would laugh less in response to their own speech than other dementia groups or controls, while those with rtFTD would laugh less regardless of who was speaking.
Methods Patients with bvFTD (n=39), svPPA (n=19), rtFTD (n=14), nfvPPA (n=16), eoAD (n=17) and healthy controls (n=156) were recorded (video and audio) while discussing a problem in their relationship with a healthy control companion. Using the audio track only, laughs were identified by trained coders and then further classed by an automated algorithm as occurring during or shortly after the participant’s own vocalisation ('self' context) or during or shortly after the partner’s vocalisation ('partner' context).
Results Individuals with bvFTD, eoAD or rtFTD laughed less across both contexts of self and partner than the other groups. Those with bvFTD laughed less relative to their own speech comparedwith healthy controls. Those with nfvPPA laughed more in the partner context compared with healthy controls.
Conclusions Laughter in response to one’s own vocalisations or those of a conversational partner may be a clinically useful measure in dementia diagnosis.},
	language = {en},
	number = {5},
	urldate = {2018-10-05},
	journal = {J Neurol Neurosurg Psychiatry},
	author = {Pressman, Peter S. and Simpson, Michaela and Gola, Kelly and Shdo, Suzanne M. and Spinelli, Edoardo G. and Miller, Bruce L. and Gorno-Tempini, Maria Luisa and Rankin, Katherine and Levenson, Robert W.},
	month = may,
	year = {2017},
	pmid = {28235777},
	pages = {418--424},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/XXMBUGLE/Pressman et al. - 2017 - Observing conversational laughter in frontotempora.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LM23N4GW/418.html:text/html}
}

@article{binney_reading_2016,
	title = {Reading words and other people: a comparison of exception word, familiar face and affect processing in the left and right temporal variants of primary progressive aphasia},
	volume = {82},
	issn = {0010-9452},
	shorttitle = {Reading words and other people},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4969161/},
	doi = {10.1016/j.cortex.2016.05.014},
	abstract = {Semantic variant primary progressive aphasia (svPPA) typically presents with left-hemisphere predominant rostral temporal lobe atrophy and the most significant complaints within the language domain. Less frequently, patients present with right-hemisphere predominant temporal atrophy coupled with marked impairments in processing of famous faces and emotions. Few studies have objectively compared these patient groups in both domains and therefore it is unclear to what extent the syndromes overlap. Clinically diagnosed svPPA patients were characterized as left- (n= 21) or right-predominant (n = 12) using imaging and compared along with 14 healthy controls. Regarding language, our primary focus was upon two hallmark features of svPPA; confrontation naming and surface dyslexia. Both groups exhibited naming deficits and surface dyslexia although the impairments were more severe in the left-predominant group. Familiarity judgments on famous faces and affect processing were more profoundly impaired in the right-predominant group. Our findings suggest that the two syndromes overlap significantly but that early cases at the tail ends of the continuum constitute a challenge for current clinical criteria. Correlational neuroimaging analyses implicated a mid portion of the left lateral temporal lobe in exception word reading impairments in line with proposals that this region is an interface between phonology and semantic knowledge.},
	urldate = {2018-10-05},
	journal = {Cortex; a journal devoted to the study of the nervous system and behavior},
	author = {Binney, Richard J. and Henry, Maya L. and Babiak, Miranda and Pressman, Peter S. and Santos-Santos, Miguel A. and Narvid, Jared and Mandelli, Maria Luisa and Strain, Paul J. and Miller, Bruce L. and Rankin, Katherine P. and Rosen, Howard J. and Gorno-Tempini, Maria Luisa},
	month = sep,
	year = {2016},
	pmid = {27389800},
	pmcid = {PMC4969161},
	pages = {147--163},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/U2CFG6UE/Binney et al. - 2016 - Reading words and other people a comparison of ex.pdf:application/pdf}
}

@article{ranasinghe_distinct_2016,
	title = {Distinct subtypes of behavioral-variant frontotemporal dementia based on patterns of network degeneration},
	volume = {73},
	issn = {2168-6149},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5024785/},
	doi = {10.1001/jamaneurol.2016.2016},
	abstract = {Importance
Clearer delineation of the phenotypic heterogeneity within behavioral variant frontotemporal dementia (bvFTD) will help uncover underlying biological mechanisms, and will improve clinicians’ ability to predict disease course and design targeted management strategies.

Objective
To identify subtypes of bvFTD syndrome based on distinctive patterns of atrophy defined by selective vulnerability of specific functional networks targeted in bvFTD, using statistical classification approaches.

Design, Setting and Participants
In this retrospective observational study, 104 patients meeting the Frontotemporal Dementia Consortium consensus criteria for bvFTD were evaluated at the Memory and Aging Center of Department of Neurology at University of California, San Francisco. Patients underwent a multidisciplinary clinical evaluation, including clinical demographics, genetic testing, symptom evaluation, neurological exam, neuropsychological bedside testing, and socioemotional assessments. Ninety patients underwent structural Magnetic Resonance Imaging at their earliest evaluation at the memory clinic. From each patients’ structural imaging, the mean volumes of 18 regions of interest (ROI) comprising the functional networks specifically vulnerable in bvFTD, including the ‘salience network’ (SN), with key nodes in the frontoinsula and pregenual anterior cingulate, and the ‘semantic appraisal network’ (SAN) anchored in the anterior temporal lobe and subgenual cingulate, were estimated. Principal component and cluster analyses of ROI volumes were used to identify patient clusters with anatomically distinct atrophy patterns.

Main Outcome Measures
We evaluated brain morphology and other clinical features including presenting symptoms, neurologic exam signs, neuropsychological performance, rate of dementia progression, and socioemotional function in each patient cluster.

Results
We identified four subgroups of bvFTD patients with distinct anatomic patterns of network degeneration, including two separate salience network–predominant subgroups: frontal/temporal (SN-FT), and frontal (SN-F), and a semantic appraisal network–predominant group (SAN), and a subcortical–predominant group. Subgroups demonstrated distinct patterns of cognitive, socioemotional, and motor symptoms, as well as genetic compositions and estimated rates of disease progression.

Conclusions
Divergent patterns of vulnerability in specific functional network components make an important contribution to clinical heterogeneity of bvFTD. The data-driven anatomical classification identifies biologically meaningful phenotypes and provides a replicable approach to disambiguate the bvFTD syndrome.},
	number = {9},
	urldate = {2018-10-05},
	journal = {JAMA neurology},
	author = {Ranasinghe, Kamalini G and Rankin, Katherine P and Pressman, Peter S and Perry, David C and Lobach, Iryna V and Seeley, William W and Coppola, Giovanni and Karydas, Anna M and Grinberg, Lea T and Shany-Ur, Tal and Lee, Suzee E and Rabinovici, Gil D and Rosen, Howard J and Gorno-Tempini, Maria Luisa and Boxer, Adam L and Miller, Zachary A and Chiong, Winston and DeMay, Mary and Kramer, Joel H and Possin, Katherine L and Sturm, Virginia E and Bettcher, Brianne M and Neylan, Michael and Zackey, Diana D and Nguyen, Lauren A and Ketelle, Robin and Block, Nikolas and Wu, Teresa Q and Dallich, Alison and Russek, Natanya and Caplan, Alyssa and Geschwind, Daniel H and Vossel, Keith A and Miller, Bruce L},
	month = sep,
	year = {2016},
	pmid = {27429218},
	pmcid = {PMC5024785},
	pages = {1078--1088},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/PCJKL42Y/Ranasinghe et al. - 2016 - Distinct subtypes of behavioral-variant frontotemp.pdf:application/pdf}
}

@article{richards_type/token_1987-1,
	title = {Type/{Token} {Ratios}: what do they really tell us?},
	volume = {14},
	issn = {0305-0009, 1469-7602},
	shorttitle = {Type/{Token} {Ratios}},
	url = {http://www.journals.cambridge.org/abstract_S0305000900012885},
	doi = {10.1017/S0305000900012885},
	abstract = {Type/Token Ratios have been extensively used in child language research as an index of lexical diversity. This paper shows that the measure has frequently failed to discriminate between children at widely different stages of language development, and that the ratio may in fact fall as children get older. It is suggested here that such effects are caused by a negative, though non-linear, relationship between sample size (i.e. number of tokens) and Type/Token Ratio. Effects of open and closed class items are considered and an alternative Verbal Diversity measure is examined. Standardization of the number of tokens before computing Type/Token Ratios is recommended.},
	language = {en},
	number = {02},
	urldate = {2018-10-05},
	journal = {Journal of Child Language},
	author = {Richards, Brian},
	month = jun,
	year = {1987},
	pages = {201},
	file = {Richards - 1987 - TypeToken Ratios what do they really tell us.pdf:/Users/transfer/Zotero/storage/IT5P8HTN/Richards - 1987 - TypeToken Ratios what do they really tell us.pdf:application/pdf}
}

@article{bullinaria_extracting_2012,
	title = {Extracting semantic representations from word co-occurrence statistics: stop-lists, stemming, and {SVD}},
	volume = {44},
	issn = {1554-3528},
	shorttitle = {Extracting semantic representations from word co-occurrence statistics},
	url = {https://doi.org/10.3758/s13428-011-0183-8},
	doi = {10.3758/s13428-011-0183-8},
	abstract = {In a previous article, we presented a systematic computational study of the extraction of semantic representations from the word–word co-occurrence statistics of large text corpora. The conclusion was that semantic vectors of pointwise mutual information values from very small co-occurrence windows, together with a cosine distance measure, consistently resulted in the best representations across a range of psychologically relevant semantic tasks. This article extends that study by investigating the use of three further factors—namely, the application of stop-lists, word stemming, and dimensionality reduction using singular value decomposition (SVD)—that have been used to provide improved performance elsewhere. It also introduces an additional semantic task and explores the advantages of using a much larger corpus. This leads to the discovery and analysis of improved SVD-based methods for generating semantic representations (that provide new state-of-the-art performance on a standard TOEFL task) and the identification and discussion of problems and misleading results that can arise without a full systematic study.},
	language = {en},
	number = {3},
	urldate = {2018-10-05},
	journal = {Behavior Research Methods},
	author = {Bullinaria, John A. and Levy, Joseph P.},
	month = sep,
	year = {2012},
	pages = {890--907},
	file = {Springer Full Text PDF:/Users/transfer/Zotero/storage/3SLJ335D/Bullinaria and Levy - 2012 - Extracting semantic representations from word co-o.pdf:application/pdf}
}

@article{bhamidipati_stemming_2007,
	title = {Stemming via distribution-based word segregation for classification and retrieval},
	volume = {37},
	issn = {1083-4419},
	abstract = {A novel corpus-based method for stemmer refinement, which can provide improvement in both classification and retrieval, is described. The method models the given words as generated from a multinomial distribution over the topics available in the corpus and includes a procedurelike sequential hypothesis testing that enables grouping together distributionally similar words. The system can refine any stemmer, and its strength can be controlled with parameters that reflect the amount of tolerance to be allowed in computing the similarity between the distributions of two words. Although obtaining the morphological roots of the given words is not the primary objective, the algorithm automatically does that to some extent. Despite a huge reduction in dictionary size, classification accuracies are seen to improve significantly when the proposed system is applied on some existing stemmers for classifying 20 Newsgroups and WebKB data. The refinements obtained are also suitable for cross-corpus stemming. Regarding retrieval, its superiority is extensively demonstrated with respect to four existing methods.},
	language = {eng},
	number = {2},
	journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics: a publication of the IEEE Systems, Man, and Cybernetics Society},
	author = {Bhamidipati, Narayan L. and Pal, Sankar K.},
	month = apr,
	year = {2007},
	pmid = {17416163},
	pages = {350--360}
}

@article{boyer_automated_2015-1,
	title = {Automated {Detection} of {Health} {Websites}' {HONcode} {Conformity}: {Can} {N}-gram {Tokenization} {Replace} {Stemming}?},
	volume = {216},
	issn = {0926-9630},
	shorttitle = {Automated {Detection} of {Health} {Websites}' {HONcode} {Conformity}},
	abstract = {Authors evaluated supervised automatic classification algorithms for determination of health related web-page compliance with individual HONcode criteria of conduct using varying length character n-gram vectors to represent healthcare web page documents. The training/testing collection comprised web page fragments extracted by HONcode experts during the manual certification process. The authors compared automated classification performance of n-gram tokenization to the automated classification performance of document words and Porter-stemmed document words using a Naive Bayes classifier and DF (document frequency) dimensionality reduction metrics. The study attempted to determine whether the automated, language-independent approach might safely replace word-based classification. Using 5-grams as document features, authors also compared the baseline DF reduction function to Chi-square and Z-score dimensionality reductions. Overall study results indicate that n-gram tokenization provided a potentially viable alternative to document word stemming.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Boyer, Célia and Dolamic, Ljiljana and Grabar, Natalia},
	year = {2015},
	pmid = {26262363},
	pages = {1064}
}

@article{dai_enhancing_2015,
	title = {Enhancing of chemical compound and drug name recognition using representative tag scheme and fine-grained tokenization},
	volume = {7},
	issn = {1758-2946},
	url = {https://doi.org/10.1186/1758-2946-7-S1-S14},
	doi = {10.1186/1758-2946-7-S1-S14},
	abstract = {The functions of chemical compounds and drugs that affect biological processes and their particular effect on the onset and treatment of diseases have attracted increasing interest with the advancement of research in the life sciences. To extract knowledge from the extensive literatures on such compounds and drugs, the organizers of BioCreative IV administered the CHEMical Compound and Drug Named Entity Recognition (CHEMDNER) task to establish a standard dataset for evaluating state-of-the-art chemical entity recognition methods.},
	number = {1},
	urldate = {2018-10-05},
	journal = {Journal of Cheminformatics},
	author = {Dai, Hong-Jie and Lai, Po-Ting and Chang, Yung-Chun and Tsai, Richard Tzong-Han},
	month = jan,
	year = {2015},
	pages = {S14},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/TMVIWXLQ/Dai et al. - 2015 - Enhancing of chemical compound and drug name recog.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/V4JZBMUB/1758-2946-7-S1-S14.html:text/html}
}

@article{covington_cutting_2010,
	title = {Cutting the {Gordian} {Knot}: {The} {Moving}-{Average} {Type}–{Token} {Ratio} ({MATTR})},
	volume = {17},
	issn = {0929-6174, 1744-5035},
	shorttitle = {Cutting the {Gordian} {Knot}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09296171003643098},
	doi = {10.1080/09296171003643098},
	abstract = {Type–token ratio (TTR), or vocabulary size divided by text length (V/N), is a timehonoured but unsatisfactory measure of lexical diversity. The problem is that the TTR of a text sample is aﬀected by its length. We present an algorithm for rapidly computing TTR through a moving window that is independent of text length, and we demonstrate that this measurement can detect changes within a text as well as diﬀerences between texts.},
	language = {en},
	number = {2},
	urldate = {2018-10-05},
	journal = {Journal of Quantitative Linguistics},
	author = {Covington, Michael A. and McFall, Joe D.},
	month = may,
	year = {2010},
	pages = {94--100},
	file = {Covington and McFall - 2010 - Cutting the Gordian Knot The Moving-Average Type–.pdf:/Users/transfer/Zotero/storage/R3WQ8E7Y/Covington and McFall - 2010 - Cutting the Gordian Knot The Moving-Average Type–.pdf:application/pdf}
}

@article{hess_sample_1986-1,
	title = {Sample {Size} and {Type}-{Token} {Ratios} for {Oral} {Language} of {Preschool} {Children}},
	volume = {29},
	issn = {1092-4388},
	url = {https://jslhr.pubs.asha.org/article.aspx?articleid=1778176},
	doi = {10.1044/jshr.2901.129},
	language = {en},
	number = {1},
	urldate = {2018-10-05},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Hess, Carla W. and Sefton, Karen M. and Landry, Richard G.},
	month = mar,
	year = {1986},
	pages = {129--134},
	file = {Snapshot:/Users/transfer/Zotero/storage/48QK3IBC/article.html:text/html}
}

@article{bucks_analysis_2000,
	title = {Analysis of spontaneous, conversational speech in dementia of {Alzheimer} type: {Evaluation} of an objective technique for analysing lexical performance},
	volume = {14},
	issn = {0268-7038},
	shorttitle = {Analysis of spontaneous, conversational speech in dementia of {Alzheimer} type},
	url = {https://doi.org/10.1080/026870300401603},
	doi = {10.1080/026870300401603},
	abstract = {Spontaneous, conversational speech in probable dementia of Alzheimer type (DAT) participants and healthy older controls was analysed using eight linguistic measures. These were evaluated for their usefulness in discriminating between healthy and demented individuals. The measures were; noun rate, pronounrate, verb rate, adjective rate, clause-like semantic unit rate (all per 100 words), including three lexical richness measures; type token ratio (TTR), Brunet's Index (W) and Honore's statistic (R). Results suggest that these measures offer a sensitive method of assessing spontaneous speech output in DAT. Comparison between DAT and healthy older participants demonstrates that these measures discriminate well between these groups. This method shows promise as a diagnostic and prognostic tool, and as a measure for use in clinical trials. Further validation in a large sample of patient versus control ‘norms’ in addition to evaluation in other types of dementia is considered.},
	number = {1},
	urldate = {2018-10-05},
	journal = {Aphasiology},
	author = {Bucks, R. S. and Singh, S. and Cuerden, J. M. and Wilcock, G. K.},
	month = jan,
	year = {2000},
	pages = {71--91},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/MYNRXDQP/Bucks et al. - 2000 - Analysis of spontaneous, conversational speech in .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/F4J2B2Y8/026870300401603.html:text/html}
}

@article{fraser_linguistic_2015,
	title = {Linguistic {Features} {Identify} {Alzheimer}’s {Disease} in {Narrative} {Speech}},
	volume = {49},
	issn = {13872877, 18758908},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JAD-150520},
	doi = {10.3233/JAD-150520},
	abstract = {Background: Although memory impairment is the main symptom of Alzheimer’s disease (AD), language impairment can be an important marker. Relatively few studies of language in AD quantify the impairments in connected speech using computational techniques.
Objective: We aim to demonstrate state-of-the-art accuracy in automatically identifying Alzheimer’s disease from short narrative samples elicited with a picture description task, and to uncover the salient linguistic factors with a statistical factor analysis.
Methods: Data are derived from the DementiaBank corpus, from which 167 patients diagnosed with “possible” or “probable” AD provide 240 narrative samples, and 97 controls provide an additional 233. We compute a number of linguistic variables from the transcripts, and acoustic variables from the associated audio ﬁles, and use these variables to train a machine learning classiﬁer to distinguish between participants with AD and healthy controls. To examine the degree of heterogeneity of linguistic impairments in AD, we follow an exploratory factor analysis on these measures of speech and language with an oblique promax rotation, and provide interpretation for the resulting factors.
Results: We obtain state-of-the-art classiﬁcation accuracies of over 81\% in distinguishing individuals with AD from those without based on short samples of their language on a picture description task. Four clear factors emerge: semantic impairment, acoustic abnormality, syntactic impairment, and information impairment.
Conclusion: Modern machine learning and linguistic analysis will be increasingly useful in assessment and clustering of suspected AD.},
	language = {en},
	number = {2},
	urldate = {2018-10-05},
	journal = {Journal of Alzheimer's Disease},
	author = {Fraser, Kathleen C. and Meltzer, Jed A. and Rudzicz, Frank},
	editor = {Garrard, Peter},
	month = oct,
	year = {2015},
	pages = {407--422},
	file = {Fraser et al. - 2015 - Linguistic Features Identify Alzheimer’s Disease i.pdf:/Users/transfer/Zotero/storage/Y2PZGZRE/Fraser et al. - 2015 - Linguistic Features Identify Alzheimer’s Disease i.pdf:application/pdf}
}

@misc{noauthor_13_nodate,
	title = {(13) {Temporal} features of spontaneous speech in {Alzheimer}’s disease {\textbar} {Request} {PDF}},
	url = {https://www.researchgate.net/publication/43097276_Temporal_features_of_spontaneous_speech_in_Alzheimer%27s_disease},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-10-05},
	journal = {ResearchGate},
	file = {Snapshot:/Users/transfer/Zotero/storage/P4YTG3I5/43097276_Temporal_features_of_spontaneous_speech_in_Alzheimer's_disease.html:text/html}
}

@article{singh_evaluation_2001,
	title = {Evaluation of an objective technique for analysing temporal variables in {DAT} spontaneous speech},
	volume = {15},
	issn = {0268-7038},
	url = {https://doi.org/10.1080/02687040143000041},
	doi = {10.1080/02687040143000041},
	abstract = {This paper describes a technique for quantifying the degree of speech deficits in probable dementia of Alzheimer's type (DAT). The technique involves interviewing individuals with DAT and transcribing their speech. From these transcripts five measurements that reflect the physical characteristics of this speech can be calculated, each measure being dependent on speech fluency and pauses. Eight patients with DAT and eight healthy participants were interviewed and their conversational speech analysed. The paper discusses statistical results obtained with these parameters and explores their usefulness for quantifying speech deficits in DAT. The paper recommends similar analysis with a larger sample and its integration with other linguistic methods of analysing the language deficits experienced by people with DAT.},
	number = {6},
	urldate = {2018-10-05},
	journal = {Aphasiology},
	author = {Singh, Sameer and Bucks, Romola S. and Cuerden, Joanne M.},
	month = jun,
	year = {2001},
	pages = {571--583},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/IESCW565/Singh et al. - 2001 - Evaluation of an objective technique for analysing.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/FXYVK8L5/02687040143000041.html:text/html}
}

@book{cohen_metamap_nodate,
	title = {Metamap is a superior baseline to a standard document retrieval engine for the task of finding patient cohorts in clinical free text},
	author = {Cohen, K. Bretonnel and Christiansen, Tom and Hunter, Lawrence E.},
	file = {Citeseer - Full Text PDF:/Users/transfer/Zotero/storage/RKN3GJZL/Cohen et al. - the task of.pdf:application/pdf;Citeseer - Snapshot:/Users/transfer/Zotero/storage/6LIZW6GP/summary.html:text/html}
}

@article{poyatos_cross-cultural_1975,
	title = {Cross-cultural study of paralinguistic “alternants” in face-to-face interaction},
	journal = {Organization of Behavior in Face-to-Face Interaction},
	author = {Poyatos, Fernando},
	year = {1975},
	pages = {285--314},
	file = {Snapshot:/Users/transfer/Zotero/storage/YPL95BUE/books.html:text/html}
}

@article{dressler_transcribing_2000,
	title = {Transcribing oral discourse: {A} survey and a model system},
	volume = {29},
	shorttitle = {Transcribing oral discourse},
	number = {1},
	journal = {Discourse Processes},
	author = {Dressler, Richard A. and Kreuz, Roger J.},
	year = {2000},
	pages = {25--36},
	file = {Fulltext:/Users/transfer/Zotero/storage/55KCA693/Dressler and Kreuz - 2000 - Transcribing oral discourse A survey and a model .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ULGR8HK2/S15326950dp2901_2.html:text/html}
}

@inproceedings{schuller_interspeech_2010,
	title = {The {INTERSPEECH} 2010 paralinguistic challenge},
	booktitle = {Proc. {INTERSPEECH} 2010, {Makuhari}, {Japan}},
	author = {Schuller, Björn and Steidl, Stefan and Batliner, Anton and Burkhardt, Felix and Devillers, Laurence and Müller, Christian and Narayanan, Shrikanth},
	year = {2010},
	pages = {2794--2797},
	file = {Fulltext:/Users/transfer/Zotero/storage/DY966NZP/Schuller et al. - 2010 - The INTERSPEECH 2010 paralinguistic challenge.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/N988W8S4/Schuller et al. - 2010 - The INTERSPEECH 2010 paralinguistic challenge.pdf:application/pdf}
}

@article{roach_transcription_1998,
	title = {Transcription of prosodic and paralinguistic features of emotional speech},
	volume = {28},
	number = {1-2},
	journal = {Journal of the International Phonetic Association},
	author = {Roach, Peter and Stibbard, Richard and Osborne, Jane and Arnfield, Simon and Setter, Jane},
	year = {1998},
	pages = {83--94},
	file = {Fulltext:/Users/transfer/Zotero/storage/FIA8L3N3/Roach et al. - 1998 - Transcription of prosodic and paralinguistic featu.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/T8NVPJTI/345FE30573DD45AB1BA3F49A0FEA536C.html:text/html}
}

@book{lantz_machine_2015,
	title = {Machine learning with {R}},
	publisher = {Packt Publishing Ltd},
	author = {Lantz, Brett},
	year = {2015},
	file = {Snapshot:/Users/transfer/Zotero/storage/XNAUD4L5/books.html:text/html}
}

@article{xie_knitr:_2014,
	title = {knitr: a comprehensive tool for reproducible research in {R}},
	volume = {1},
	shorttitle = {knitr},
	journal = {Implement Reprod Res},
	author = {Xie, Yihui},
	year = {2014},
	pages = {20},
	file = {Fulltext:/Users/transfer/Zotero/storage/FTAPS4UX/Xie - 2014 - knitr a comprehensive tool for reproducible resea.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/TVVLHR5X/books.html:text/html}
}

@article{peng_reproducible_2011,
	title = {Reproducible research in computational science},
	volume = {334},
	number = {6060},
	journal = {Science},
	author = {Peng, Roger D.},
	year = {2011},
	pages = {1226--1227},
	file = {Fulltext:/Users/transfer/Zotero/storage/EXX8TUPU/Peng - 2011 - Reproducible research in computational science.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/ARS9MNWN/1226.html:text/html}
}

@article{sandve_ten_2013,
	title = {Ten simple rules for reproducible computational research},
	volume = {9},
	number = {10},
	journal = {PLoS computational biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	year = {2013},
	pages = {e1003285},
	file = {Fulltext:/Users/transfer/Zotero/storage/RERMVBYQ/article.html:text/html;Snapshot:/Users/transfer/Zotero/storage/4GD9LD8L/article.html:text/html}
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	number = {3},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	year = {2010},
	pages = {385--388},
	file = {Fulltext:/Users/transfer/Zotero/storage/WWHZDP9L/Donoho - 2010 - An invitation to reproducible computational resear.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SU2H2X6N/257703.html:text/html}
}

@book{gandrud_reproducible_2016,
	title = {Reproducible research with {R} and {R} studio},
	publisher = {Chapman and Hall/CRC},
	author = {Gandrud, Christopher},
	year = {2016},
	file = {Snapshot:/Users/transfer/Zotero/storage/8BZK5972/9781498715386.html:text/html}
}

@article{sasaki_truth_nodate,
	title = {The truth of the {F}-measure},
	abstract = {It has been past more than 15 years since the F-measure was ﬁrst introduced to evaluation tasks of information extraction technology at the Fourth Message Understanding Conference (MUC-4) in 1992. Recently, sometimes I see some confusion with the deﬁnition of the Fmeasure, which seems to be triggered by lack of background knowledge about how the F-measure was derived. Since I was not involved in the process of the introduction or device of the F-measure, I might not be the best person to explain this but I hope this note would be a little help for those who are wondering what the F-measure really is. This introduction is devoted to provide brief but suﬃcient information on the F-measure.},
	language = {en},
	author = {Sasaki, Yutaka},
	pages = {5},
	file = {Sasaki - The truth of the F-measure.pdf:/Users/transfer/Zotero/storage/7JCRJUCF/Sasaki - The truth of the F-measure.pdf:application/pdf}
}

@article{li_exploring_2018,
	title = {Exploring the characteristics, global distribution and reasons for retraction of published articles involving human research participants: a literature survey},
	volume = {11},
	shorttitle = {Exploring the characteristics, global distribution and reasons for retraction of published articles involving human research participants},
	journal = {Journal of multidisciplinary healthcare},
	author = {Li, Guowei and Kamel, Mariam and Jin, Yanling and Xu, Michael Kuan and Mbuagbaw, Lawrence and Samaan, Zainab and Levine, Mitchell AH and Thabane, Lehana},
	year = {2018},
	keywords = {reproducibility},
	pages = {39},
	file = {Fulltext:/Users/transfer/Zotero/storage/DEJJTM4Q/PMC5779311.html:text/html;Snapshot:/Users/transfer/Zotero/storage/RJTYJR82/PMC5779311.html:text/html}
}

@article{xu_retraction_2018,
	title = {Retraction {Notices}: {Who} {Authored} {Them}?},
	volume = {6},
	shorttitle = {Retraction {Notices}},
	number = {1},
	journal = {Publications},
	author = {Xu, Shaoxiong Brian and Hu, Guangwei},
	year = {2018},
	keywords = {reproducibility},
	pages = {2},
	file = {Fulltext:/Users/transfer/Zotero/storage/LXHAQJGX/html.html:text/html;Snapshot:/Users/transfer/Zotero/storage/RQJIR4UJ/html.html:text/html}
}

@incollection{chen_visual_2017,
	title = {Visual {Analytic} {Observatory} of {Scientific} {Knowledge}},
	booktitle = {Representing {Scientific} {Knowledge}},
	publisher = {Springer},
	author = {Chen, Chaomei and Song, Min},
	year = {2017},
	keywords = {reproducibility},
	pages = {337--375},
	file = {Snapshot:/Users/transfer/Zotero/storage/ZQ7JB6RL/978-3-319-62543-0_9.html:text/html}
}

@article{gray_why_2018,
	title = {Why {Are} {So} {Few} {Nursing} {Science} {Papers} {Retracted}?},
	volume = {28},
	number = {3},
	journal = {Nurse Author \& Editor},
	author = {Gray, Richard},
	year = {2018},
	keywords = {reproducibility},
	pages = {2},
	file = {Fulltext:/Users/transfer/Zotero/storage/QG74RAF5/2018-2-3-2.html:text/html;Snapshot:/Users/transfer/Zotero/storage/XMQVRNQ8/2018-2-3-2.html:text/html}
}

@book{chen_representing_2017,
	title = {Representing scientific knowledge: {The} role of uncertainty},
	shorttitle = {Representing scientific knowledge},
	publisher = {Springer},
	author = {Chen, Chaomei and Song, Min},
	year = {2017},
	keywords = {reproducibility},
	file = {Snapshot:/Users/transfer/Zotero/storage/5UZ4RDMX/books.html:text/html}
}

@book{ranjan_publish_2018,
	title = {Publish first, retract later. {Is} it time for introspection?},
	publisher = {Elsevier},
	author = {Ranjan, C. K.},
	year = {2018},
	keywords = {reproducibility},
	file = {Fulltext:/Users/transfer/Zotero/storage/W6LZKSSR/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/999QQB55/S037712371830025X.html:text/html}
}

@article{wang_retracted_2018,
	title = {Retracted {Publications} in the {Biomedical} {Literature} from {Open} {Access} {Journals}},
	journal = {Science and engineering ethics},
	author = {Wang, Tao and Xing, Qin-Rui and Wang, Hui and Chen, Wei},
	year = {2018},
	keywords = {reproducibility},
	pages = {1--14},
	file = {Fulltext:/Users/transfer/Zotero/storage/SYZIIAP2/s11948-018-0040-6.html:text/html;Snapshot:/Users/transfer/Zotero/storage/3PRL2G6U/s11948-018-0040-6.html:text/html}
}

@article{wasiak_surveying_2018,
	title = {Surveying retracted studies and notices within the field of radiation oncology},
	journal = {International Journal of Radiation Oncology• Biology• Physics},
	author = {Wasiak, Jason and Hamilton, Daniel George and Foroudi, Farshad and Faggion, Clovis M.},
	year = {2018},
	keywords = {reproducibility},
	file = {Fulltext:/Users/transfer/Zotero/storage/IJXH7MW4/scholar.html:text/html}
}

@incollection{ferris_scientific_2018,
	title = {Scientific {Fraud} and {Other} {Types} of {Scientific} {Misconduct}},
	booktitle = {Reporting and {Publishing} {Research} in the {Biomedical} {Sciences}},
	publisher = {Springer},
	author = {Ferris, Lorraine},
	year = {2018},
	keywords = {reproducibility, female first or senior},
	pages = {241--254},
	file = {Snapshot:/Users/transfer/Zotero/storage/RURRDW9L/978-981-10-7062-4_24.html:text/html}
}

@article{wray_retractions_2018,
	title = {Retractions in {Science}},
	author = {Wray, K. Brad and Andersen, Line Edslev},
	year = {2018},
	keywords = {reproducibility},
	file = {Fulltext:/Users/transfer/Zotero/storage/RZA62E66/Wray and Andersen - 2018 - Retractions in Science.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/SG9VF3Y3/14778.html:text/html}
}

@incollection{gogtay_redundant_2018,
	title = {Redundant {Publications}},
	booktitle = {Reporting and {Publishing} {Research} in the {Biomedical} {Sciences}},
	publisher = {Springer},
	author = {Gogtay, Nithya},
	year = {2018},
	keywords = {reproducibility},
	pages = {233--240},
	file = {Snapshot:/Users/transfer/Zotero/storage/X783BZSY/978-981-10-7062-4_23.html:text/html}
}

@article{deculllier_correcting_2018,
	title = {Correcting the literature: {Improvement} trends seen in contents of retraction notices},
	volume = {11},
	shorttitle = {Correcting the literature},
	number = {1},
	journal = {BMC research notes},
	author = {Deculllier, Evelyne and Maisonneuve, Hervé},
	year = {2018},
	keywords = {reproducibility, female first or senior, France},
	pages = {490},
	file = {Fulltext:/Users/transfer/Zotero/storage/99Z3Q2VU/s13104-018-3576-2.html:text/html;Snapshot:/Users/transfer/Zotero/storage/SZPXBWTN/s13104-018-3576-2.html:text/html}
}

@article{ajiferuke_correction_2018,
	title = {Correction and retraction practices in library and information science journals},
	journal = {Journal of Librarianship and Information Science},
	author = {Ajiferuke, Isola and Adekannbi, Janet O.},
	year = {2018},
	keywords = {reproducibility, female first or senior},
	pages = {0961000618785408},
	file = {Fulltext:/Users/transfer/Zotero/storage/JCJAH8PT/Ajiferuke and Adekannbi - 2018 - Correction and retraction practices in library and.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/IUUMT5EG/0961000618785408.html:text/html}
}

@article{buljan_how_2018,
	title = {How researchers perceive research misconduct in biomedicine and how they would prevent it: {A} qualitative study in a small scientific community},
	volume = {25},
	shorttitle = {How researchers perceive research misconduct in biomedicine and how they would prevent it},
	number = {4},
	journal = {Accountability in research},
	author = {Buljan, Ivan and Barać, Lana and Marušić, Ana},
	year = {2018},
	keywords = {reproducibility, female first or senior},
	pages = {220--238},
	file = {Fulltext:/Users/transfer/Zotero/storage/DZ4IVIR9/scholar.html:text/html;Snapshot:/Users/transfer/Zotero/storage/2BWJ29YZ/08989621.2018.html:text/html}
}

@article{cassao_retracted_2018,
	title = {Retracted articles in surgery journals. {What} are surgeons doing wrong?},
	volume = {163},
	number = {6},
	journal = {Surgery},
	author = {Cassão, Bruna Dell'Acqua and Herbella, Fernando AM and Schlottmann, Francisco and Patti, Marco G.},
	year = {2018},
	keywords = {reproducibility},
	pages = {1201--1206},
	file = {Fulltext:/Users/transfer/Zotero/storage/D2RMZK6E/Cassão et al. - 2018 - Retracted articles in surgery journals. What are s.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PEWMX96D/S003960601830031X.html:text/html}
}

@article{wager_why_2011,
	title = {Why and how do journals retract articles? {An} analysis of {Medline} retractions 1988-2008},
	volume = {37},
	issn = {0306-6800},
	shorttitle = {Why and how do journals retract articles?},
	url = {http://jme.bmj.com/cgi/doi/10.1136/jme.2010.040964},
	doi = {10.1136/jme.2010.040964},
	abstract = {Background Journal editors are responsible for what they publish and therefore have a duty to correct the record if published work is found to be unreliable. One method for such correction is retraction of an article. Anecdotal evidence suggested a lack of consistency in journal policies and practices regarding retraction. In order to develop guidelines, we reviewed retractions in Medline to discover how and why articles were retracted.
Methods We retrieved all available Medline retractions from 2005 to 2008 and a one-in-three random selection of those from 1988 to 2004. This yielded 312 retractions (from a total of 870). Details of the retraction including the reason for retraction were recorded by two investigators.
Results Medline retractions have increased sharply since 1980 and currently represent 0.02\% of included articles. Retractions were issued by authors (63\%), editors (21\%), journals (6\%), publishers (2\%) and institutions (1\%). Reasons for retraction included honest error or non-replicable ﬁndings (40\%), research misconduct (28\%), redundant publication (17\%) and unstated/unclear (5\%). Some of the stated reasons might have been addressed by corrections.
Conclusions Journals’ retraction practices are not uniform. Some retractions fail to state the reason, and therefore fail to distinguish error from misconduct. We have used our ﬁndings to inform guidelines on retractions.},
	language = {en},
	number = {9},
	urldate = {2018-10-08},
	journal = {Journal of Medical Ethics},
	author = {Wager, E. and Williams, P.},
	month = sep,
	year = {2011},
	keywords = {reproducibility, female first or senior},
	pages = {567--570},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/96ZAD4X2/Wager and Williams - 2011 - Why and how do journals retract articles An analy.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3WBQN53U/567.html:text/html;Wager and Williams - 2011 - Why and how do journals retract articles An analy.pdf:/Users/transfer/Zotero/storage/S9ERFJZ2/Wager and Williams - 2011 - Why and how do journals retract articles An analy.pdf:application/pdf}
}

@article{markowitz_linguistic_2014,
	title = {Linguistic {Traces} of a {Scientific} {Fraud}: {The} {Case} of {Diederik} {Stapel}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Linguistic {Traces} of a {Scientific} {Fraud}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0105937},
	doi = {10.1371/journal.pone.0105937},
	abstract = {When scientists report false data, does their writing style reflect their deception? In this study, we investigated the linguistic patterns of fraudulent (N = 24; 170,008 words) and genuine publications (N = 25; 189,705 words) first-authored by social psychologist Diederik Stapel. The analysis revealed that Stapel's fraudulent papers contained linguistic changes in science-related discourse dimensions, including more terms pertaining to methods, investigation, and certainty than his genuine papers. His writing style also matched patterns in other deceptive language, including fewer adjectives in fraudulent publications relative to genuine publications. Using differences in language dimensions we were able to classify Stapel's publications with above chance accuracy. Beyond these discourse dimensions, Stapel included fewer co-authors when reporting fake data than genuine data, although other evidentiary claims (e.g., number of references and experiments) did not differ across the two article types. This research supports recent findings that language cues vary systematically with deception, and that deception can be revealed in fraudulent scientific discourse.},
	language = {en},
	number = {8},
	urldate = {2018-10-08},
	journal = {PLOS ONE},
	author = {Markowitz, David M. and Hancock, Jeffrey T.},
	month = aug,
	year = {2014},
	keywords = {reproducibility},
	pages = {e105937},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/TDAKMU9L/Markowitz and Hancock - 2014 - Linguistic Traces of a Scientific Fraud The Case .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/X5823BDR/article.html:text/html}
}

@article{goodman_what_2016-1,
	title = {What does research reproducibility mean?},
	volume = {8},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {1946-6234, 1946-6242},
	url = {http://stm.sciencemag.org/content/8/341/341ps12},
	doi = {10.1126/scitranslmed.aaf5027},
	abstract = {The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for “truth.”
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.},
	language = {en},
	number = {341},
	urldate = {2018-10-08},
	journal = {Science Translational Medicine},
	author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
	month = jun,
	year = {2016},
	pmid = {27252173},
	keywords = {reproducibility},
	pages = {341ps12--341ps12},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/IHDDQRIP/Goodman et al. - 2016 - What does research reproducibility mean.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/6VKPFCB2/341ps12.html:text/html}
}

@article{holman_evidence_2015,
	title = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}: {Why} {We} {Need} {Blind} {Data} {Recording}},
	volume = {13},
	issn = {1545-7885},
	shorttitle = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}},
	url = {http://dx.plos.org/10.1371/journal.pbio.1002190},
	doi = {10.1371/journal.pbio.1002190},
	language = {en},
	number = {7},
	urldate = {2018-10-08},
	journal = {PLOS Biology},
	author = {Holman, Luke and Head, Megan L. and Lanfear, Robert and Jennions, Michael D.},
	month = jul,
	year = {2015},
	keywords = {reproducibility},
	pages = {e1002190},
	file = {Holman et al. - 2015 - Evidence of Experimental Bias in the Life Sciences.pdf:/Users/transfer/Zotero/storage/2MEV46TM/Holman et al. - 2015 - Evidence of Experimental Bias in the Life Sciences.pdf:application/pdf}
}

@misc{noauthor_relationship_nodate,
	title = {relationship between reproducibility and retractions - {Recherche} {Google}},
	url = {https://www.google.com/search?q=relationship+between+reproducibility+and+retractions&oq=relationship+between+reproducibility+and+retractions&aqs=chrome..69i57j0l2.10685j0j4&sourceid=chrome&ie=UTF-8},
	urldate = {2018-10-08},
	keywords = {reproducibility},
	file = {relationship between reproducibility and retractions - Recherche Google:/Users/transfer/Zotero/storage/GCBYR8ZB/search.html:text/html}
}

@article{bustin_reproducibility_2014,
	title = {The reproducibility of biomedical research: {Sleepers} awake!},
	volume = {2},
	issn = {22147535},
	shorttitle = {The reproducibility of biomedical research},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214753515000030},
	doi = {10.1016/j.bdq.2015.01.002},
	abstract = {There is increasing concern about the reliability of biomedical research, with recent articles suggesting that up to 85\% of research funding is wasted. This article argues that an important reason for this is the inappropriate use of molecular techniques, particularly in the ﬁeld of RNA biomarkers, coupled with a tendency to exaggerate the importance of research ﬁndings.},
	language = {en},
	urldate = {2018-10-08},
	journal = {Biomolecular Detection and Quantification},
	author = {Bustin, Stephen A.},
	month = dec,
	year = {2014},
	keywords = {reproducibility},
	pages = {35--42},
	file = {Bustin - 2014 - The reproducibility of biomedical research Sleepe.pdf:/Users/transfer/Zotero/storage/QD4WUHKV/Bustin - 2014 - The reproducibility of biomedical research Sleepe.pdf:application/pdf}
}

@article{sasaki_truth_nodate-1,
	title = {The truth of the {F}-measure},
	abstract = {It has been past more than 15 years since the F-measure was ﬁrst introduced to evaluation tasks of information extraction technology at the Fourth Message Understanding Conference (MUC-4) in 1992. Recently, sometimes I see some confusion with the deﬁnition of the Fmeasure, which seems to be triggered by lack of background knowledge about how the F-measure was derived. Since I was not involved in the process of the introduction or device of the F-measure, I might not be the best person to explain this but I hope this note would be a little help for those who are wondering what the F-measure really is. This introduction is devoted to provide brief but suﬃcient information on the F-measure.},
	language = {en},
	author = {Sasaki, Yutaka},
	pages = {5},
	file = {Sasaki - The truth of the F-measure.pdf:/Users/transfer/Zotero/storage/BR7PZCTE/Sasaki - The truth of the F-measure.pdf:application/pdf}
}

@article{hripcsak_agreement_2005,
	title = {Agreement, the f-measure, and reliability in information retrieval},
	volume = {12},
	issn = {1067-5027},
	doi = {10.1197/jamia.M1733},
	abstract = {Information retrieval studies that involve searching the Internet or marking phrases usually lack a well-defined number of negative cases. This prevents the use of traditional interrater reliability metrics like the kappa statistic to assess the quality of expert-generated gold standards. Such studies often quantify system performance as precision, recall, and F-measure, or as agreement. It can be shown that the average F-measure among pairs of experts is numerically identical to the average positive specific agreement among experts and that kappa approaches these measures as the number of negative cases grows large. Positive specific agreement-or the equivalent F-measure-may be an appropriate way to quantify interrater reliability and therefore to assess the reliability of a gold standard in these studies.},
	language = {eng},
	number = {3},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Hripcsak, George and Rothschild, Adam S.},
	month = jun,
	year = {2005},
	pmid = {15684123},
	pmcid = {PMC1090460},
	pages = {296--298}
}

@book{jackson_natural_2007,
	title = {Natural language processing for online applications: {Text} retrieval, extraction and categorization},
	volume = {5},
	shorttitle = {Natural language processing for online applications},
	publisher = {John Benjamins Publishing},
	author = {Jackson, Peter and Moulinier, Isabelle},
	year = {2007},
	file = {Snapshot:/Users/transfer/Zotero/storage/HFNZAK6L/books.html:text/html}
}

@book{martin_speech_2009,
	title = {Speech and language processing: {An} introduction to natural language processing, computational linguistics, and speech recognition},
	shorttitle = {Speech and language processing},
	publisher = {Pearson/Prentice Hall},
	author = {Martin, James H. and Jurafsky, Daniel},
	year = {2009}
}

@book{manning_foundations_1999,
	title = {Foundations of statistical natural language processing},
	publisher = {MIT press},
	author = {Manning, Christopher D. and Manning, Christopher D. and Schütze, Hinrich},
	year = {1999},
	file = {Snapshot:/Users/transfer/Zotero/storage/W7TC4XXZ/books.html:text/html}
}

@article{kave_age-related_2012,
	title = {Age-related differences in word-retrieval but not in meaning generation},
	volume = {19},
	number = {4},
	journal = {Aging, Neuropsychology, and Cognition},
	author = {Kavé, Gitit and Mashal, Nira},
	year = {2012},
	keywords = {aphasia-dementia},
	pages = {515--529},
	file = {Fulltext:/Users/transfer/Zotero/storage/627I5HXZ/13825585.2011.html:text/html;Snapshot:/Users/transfer/Zotero/storage/LZXW5NJQ/13825585.2011.html:text/html}
}

@article{kave_multilingualism_2008,
	title = {Multilingualism and cognitive state in the oldest old.},
	volume = {23},
	number = {1},
	journal = {Psychology and aging},
	author = {Kavé, Gitit and Eyal, Nitza and Shorek, Aviva and Cohen-Mansfield, Jiska},
	year = {2008},
	keywords = {aphasia-dementia},
	pages = {70},
	file = {Fulltext:/Users/transfer/Zotero/storage/LXYVFNWU/Kavé et al. - 2008 - Multilingualism and cognitive state in the oldest .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/PNZSHXDR/2008-02853-009.html:text/html}
}

@article{kave_morphology_2003,
	title = {Morphology in picture descriptions provided by persons with {Alzheimer}'s disease},
	volume = {46},
	number = {2},
	journal = {Journal of speech, language, and hearing research},
	author = {Kavé, Gitit and Levy, Yonata},
	year = {2003},
	keywords = {aphasia-dementia},
	pages = {341--352},
	file = {Fulltext:/Users/transfer/Zotero/storage/DHHMQIGJ/Kavé and Levy - 2003 - Morphology in picture descriptions provided by per.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/4R9ZZW32/article.html:text/html}
}

@article{hardy_which_2017,
	title = {Which {Point}-of-{Care} {Tests} {Would} {Be} {Most} {Beneficial} to {Add} to {Clinical} {Practice}?},
	volume = {16},
	issn = {1533-029X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5737459/},
	doi = {10.1097/POC.0000000000000151},
	abstract = {Background
Point-of-care tests (POCTs) are increasingly used in family medicine to facilitate screening, diagnosis, monitoring, treatment, and referral decisions for a variety of conditions. Point-of-care tests that clinicians believe might be beneficial to add to clinical practice and the conditions for which they would be most useful in family medicine remain poorly understood in the United States.

Methods
Forty-two clinicians at 3 family medicine residency clinics completed a brief survey asking which POCTs they believed would be beneficial to add to their clinical practice and the conditions POCTs would be most useful for. We calculated frequencies of reported POCTs and conditions using descriptive statistics.

Results
Clinicians identified 34 POCTs that would be beneficial to add to family medicine, of which hemoglobin A1c, chemistry panels, and human immunodeficiency virus and gonococcal and/or chlamydia were most frequently reported and anticipated would be used weekly. Clinicians reported 30 conditions for which they considered POCTs would be useful. Diabetes mellitus, sexually transmitted infections, and respiratory tract infections were the most often reported and were identified as benefiting diagnosis, monitoring, and treatment decisions.

Conclusions
Clinicians identified a number of POCTs they viewed as being beneficial to add to their routine clinical practice, mostly to inform diagnosis and treatment planning. Some POCTs identified are available in the United States; thus, understanding barriers to implementation of these POCTs in primary care settings is necessary to optimize adoption.},
	number = {4},
	urldate = {2018-10-10},
	journal = {Point of Care},
	author = {Hardy, Victoria and Alto, William and Keppel, Gina A. and Baldwin, Laura-Mae and Thompson, Matthew},
	month = dec,
	year = {2017},
	pmid = {29333106},
	pmcid = {PMC5737459},
	keywords = {aphasia-dementia},
	pages = {168--172},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/JHN7TTVR/Hardy et al. - 2017 - Which Point-of-Care Tests Would Be Most Beneficial.pdf:application/pdf}
}

@article{goldberg_neural_2017,
	title = {Neural network methods for natural language processing},
	volume = {10},
	number = {1},
	journal = {Synthesis Lectures on Human Language Technologies},
	author = {Goldberg, Yoav},
	year = {2017},
	keywords = {aphasia-dementia},
	pages = {1--309},
	file = {Snapshot:/Users/transfer/Zotero/storage/6C52UF2X/S00762ED1V01Y201703HLT037.html:text/html}
}

@article{felgner_physicians_2018,
	title = {Physicians' {Decision} {Making} on {Adoption} of {New} {Technologies} and {Role} of {Coverage} with {Evidence} {Development}: {A} {Qualitative} {Study}},
	volume = {21},
	issn = {1524-4733},
	shorttitle = {Physicians' {Decision} {Making} on {Adoption} of {New} {Technologies} and {Role} of {Coverage} with {Evidence} {Development}},
	doi = {10.1016/j.jval.2018.03.006},
	abstract = {OBJECTIVES: To foster value-based pricing and coverage with evidence development in Germany, certain new diagnostic and treatment methods have been subject to a benefit assessment since 2016 to determine their reimbursement. Although this is a paradigm shift, the German approach is limited to some few specific technologies for which reimbursement is requested. As physicians encounter this regulatory instrument, the aim of the study was to understand physicians' decision making regarding the adoption of new medical technologies and to identify their perspectives on the evidence base and financing with additional reimbursement systems.
METHODS: From April to August 2017, semistructured interviews with chief and senior physicians of vascular surgery and cardiology in inpatient care in Germany were conducted (N = 23). The interviews were carried out by one researcher in one-to-one appointments or via telephone. Data were analyzed inductively to identify factors and generate thematic categories using qualitative content analysis.
RESULTS: We identified 52 factors in eight categories influencing physicians' adoption of new technologies. The evidence base for new technologies was criticized (e.g., lack of available studies). Physicians' knowledge of the regulation of market approval and innovation payments varied. They recommended the utilization of new technologies in certain specialist centers and the facilitation of observational studies.
CONCLUSIONS: Physicians saw the need for the new approach and supported its aim. However, its design and implementation appeared to be questionable from their medical perspective. The provision of summarized information on the benefit of technologies might be a possibility to assist physicians' decision making.},
	language = {eng},
	number = {9},
	journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
	author = {Felgner, Susanne and Ex, Patricia and Henschke, Cornelia},
	year = {2018},
	pmid = {30224111},
	keywords = {aphasia-dementia},
	pages = {1069--1076}
}

@article{fraser_linguistic_2016,
	title = {Linguistic {Features} {Identify} {Alzheimer}'s {Disease} in {Narrative} {Speech}},
	volume = {49},
	issn = {1875-8908},
	doi = {10.3233/JAD-150520},
	abstract = {BACKGROUND: Although memory impairment is the main symptom of Alzheimer's disease (AD), language impairment can be an important marker. Relatively few studies of language in AD quantify the impairments in connected speech using computational techniques.
OBJECTIVE: We aim to demonstrate state-of-the-art accuracy in automatically identifying Alzheimer's disease from short narrative samples elicited with a picture description task, and to uncover the salient linguistic factors with a statistical factor analysis.
METHODS: Data are derived from the DementiaBank corpus, from which 167 patients diagnosed with "possible" or "probable" AD provide 240 narrative samples, and 97 controls provide an additional 233. We compute a number of linguistic variables from the transcripts, and acoustic variables from the associated audio files, and use these variables to train a machine learning classifier to distinguish between participants with AD and healthy controls. To examine the degree of heterogeneity of linguistic impairments in AD, we follow an exploratory factor analysis on these measures of speech and language with an oblique promax rotation, and provide interpretation for the resulting factors.
RESULTS: We obtain state-of-the-art classification accuracies of over 81\% in distinguishing individuals with AD from those without based on short samples of their language on a picture description task. Four clear factors emerge: semantic impairment, acoustic abnormality, syntactic impairment, and information impairment.
CONCLUSION: Modern machine learning and linguistic analysis will be increasingly useful in assessment and clustering of suspected AD.},
	language = {eng},
	number = {2},
	journal = {Journal of Alzheimer's disease: JAD},
	author = {Fraser, Kathleen C. and Meltzer, Jed A. and Rudzicz, Frank},
	year = {2016},
	pmid = {26484921},
	keywords = {aphasia-dementia},
	pages = {407--422}
}

@article{prudhommeaux_graph-based_2015,
	title = {Graph-based word alignment for clinical language evaluation},
	volume = {41},
	number = {4},
	journal = {Computational Linguistics},
	author = {Prud'hommeaux, Emily and Roark, Brian},
	year = {2015},
	keywords = {aphasia-dementia},
	pages = {549--578},
	file = {Fulltext:/Users/transfer/Zotero/storage/WU4H6RSS/COLI_a_00232.html:text/html;Snapshot:/Users/transfer/Zotero/storage/KQYPBUKM/COLI_a_00232.html:text/html}
}

@inproceedings{prudhommeaux_graph-based_2012,
	title = {Graph-based alignment of narratives for automated neurological assessment},
	booktitle = {Proceedings of the 2012 {Workshop} on {Biomedical} {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Prud'hommeaux, Emily T. and Roark, Brian},
	year = {2012},
	keywords = {aphasia-dementia},
	pages = {1--10},
	file = {Fulltext:/Users/transfer/Zotero/storage/LHZBIBZF/Prud'hommeaux and Roark - 2012 - Graph-based alignment of narratives for automated .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/E8XDTYX5/citation.html:text/html}
}

@inproceedings{prudhommeaux_extraction_2011,
	title = {Extraction of narrative recall patterns for neuropsychological assessment},
	booktitle = {Twelfth {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Prud'hommeaux, Emily T. and Roark, Brian},
	year = {2011},
	keywords = {aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/ECYR6CY5/Prud'hommeaux and Roark - 2011 - Extraction of narrative recall patterns for neurop.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/2ASW2XPP/i11_3021.html:text/html}
}

@inproceedings{prudhommeaux_computational_2014,
	title = {Computational analysis of trajectories of linguistic development in autism},
	booktitle = {Spoken {Language} {Technology} {Workshop} ({SLT}), 2014 {IEEE}},
	publisher = {IEEE},
	author = {Prud'hommeaux, Emily and Morley, Eric and Rouhizadeh, Masoud and Silverman, Laura and van Santeny, Jan and Roarkz, Brian and Sproatz, Richard and Kauper, Sarah and DeLaHunta, Rachel},
	year = {2014},
	keywords = {aphasia-dementia},
	pages = {266--271},
	file = {Fulltext:/Users/transfer/Zotero/storage/5YTJ438W/PMC5648018.html:text/html;Snapshot:/Users/transfer/Zotero/storage/LDQCN6LF/7078585.html:text/html}
}

@inproceedings{rouhizadeh_distributional_2013,
	title = {Distributional semantic models for the evaluation of disordered language},
	volume = {2013},
	booktitle = {Proceedings of the conference. association for computational linguistics. north american chapter. meeting},
	publisher = {NIH Public Access},
	author = {Rouhizadeh, Masoud and Prud'Hommeaux, Emily and Roark, Brian and Van Santen, Jan},
	year = {2013},
	keywords = {aphasia-dementia},
	pages = {709},
	file = {Fulltext:/Users/transfer/Zotero/storage/4EW6XD3Z/PMC4237315.html:text/html;Snapshot:/Users/transfer/Zotero/storage/B8QAQMWU/PMC4237315.html:text/html}
}

@inproceedings{prudhommeaux_classification_2011,
	title = {Classification of atypical language in autism},
	booktitle = {Proceedings of the 2nd workshop on cognitive modeling and computational linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Prud'hommeaux, Emily T. and Roark, Brian and Black, Lois M. and Van Santen, Jan},
	year = {2011},
	keywords = {aphasia-dementia},
	pages = {88--96},
	file = {Snapshot:/Users/transfer/Zotero/storage/F2UHCQN2/citation.html:text/html}
}

@inproceedings{lehr_fully_2012,
	title = {Fully automated neuropsychological assessment for detecting mild cognitive impairment},
	booktitle = {Thirteenth {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Lehr, Maider and Prud'hommeaux, Emily and Shafran, Izhak and Roark, Brian},
	year = {2012},
	keywords = {aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/ANANVKCM/Lehr et al. - 2012 - Fully automated neuropsychological assessment for .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YMNC8BS2/i12_1039.html:text/html}
}

@inproceedings{prudhommeaux_alignment_2011,
	title = {Alignment of spoken narratives for automated neuropsychological assessment},
	booktitle = {Automatic {Speech} {Recognition} and {Understanding} ({ASRU}), 2011 {IEEE} {Workshop} on},
	publisher = {IEEE},
	author = {Prud'hommeaux, Emily T. and Roark, Brian},
	year = {2011},
	keywords = {aphasia-dementia},
	pages = {484--489},
	file = {Fulltext:/Users/transfer/Zotero/storage/5KSSUARY/Prud'hommeaux and Roark - 2011 - Alignment of spoken narratives for automated neuro.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/4ANSF4C4/6163979.html:text/html}
}

@inproceedings{rouhizadeh_detecting_2014,
	title = {Detecting linguistic idiosyncratic interests in autism using distributional semantic models},
	booktitle = {Proceedings of the {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
	author = {Rouhizadeh, Masoud and Prud'hommeaux, Emily and van Santen, Jan and Sproat, Richard},
	year = {2014},
	keywords = {aphasia-dementia},
	pages = {46--50},
	file = {Fulltext:/Users/transfer/Zotero/storage/YSBI9SYP/Rouhizadeh et al. - 2014 - Detecting linguistic idiosyncratic interests in au.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/YM4B2XJH/Rouhizadeh et al. - 2014 - Detecting linguistic idiosyncratic interests in au.pdf:application/pdf}
}

@inproceedings{rouhizadeh_measuring_2015,
	title = {Measuring idiosyncratic interests in children with autism},
	volume = {2015},
	booktitle = {Proceedings of the conference. {Association} for {Computational} {Linguistics}. {Meeting}},
	publisher = {NIH Public Access},
	author = {Rouhizadeh, Masoud and Prud’Hommeaux, Emily and Van Santen, Jan and Sproat, Richard},
	year = {2015},
	keywords = {aphasia-dementia},
	pages = {212},
	file = {Fulltext:/Users/transfer/Zotero/storage/6RRLKVRZ/PMC5715463.html:text/html;Snapshot:/Users/transfer/Zotero/storage/VJMI9RP9/PMC5715463.html:text/html}
}

@inproceedings{prudhommeaux_automatic_2012,
	title = {Automatic detection of pragmatic deficits in children with autism},
	volume = {2012},
	booktitle = {The... {Workshop} on {Child}, {Computer} and {Interaction}},
	publisher = {NIH Public Access},
	author = {Prud’hommeaux, Emily and Rouhizadeh, Masoud},
	year = {2012},
	keywords = {aphasia-dementia},
	pages = {1},
	file = {Fulltext:/Users/transfer/Zotero/storage/IN452E4S/PMC5500165.html:text/html;Snapshot:/Users/transfer/Zotero/storage/G69GBZB6/PMC5500165.html:text/html}
}

@article{el_hachioui_screening_2017,
	title = {Screening tests for aphasia in patients with stroke: a systematic review},
	volume = {264},
	issn = {0340-5354},
	shorttitle = {Screening tests for aphasia in patients with stroke},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5306063/},
	doi = {10.1007/s00415-016-8170-8},
	abstract = {Aphasia has a large impact on the quality of life and adds significantly to the costs of stroke care. Early recognition of aphasia in stroke patients is important for prognostication and well-timed treatment planning. We aimed to identify available screening tests for differentiating between aphasic and non-aphasic stroke patients, and to evaluate test accuracy, reliability, and feasibility. We searched PubMed, EMbase, Web of Science, and PsycINFO for published studies on screening tests aimed at assessing aphasia in stroke patients. The reference lists of the selected articles were scanned, and several experts were contacted to detect additional references. Of each screening test, we estimated the sensitivity, specificity, likelihood ratio of a positive test, likelihood ratio of a negative test, and diagnostic odds ratio (DOR), and rated the degree of bias of the validation method. We included ten studies evaluating eight screening tests. There was a large variation across studies regarding sample size, patient characteristics, and reference tests used for validation. Many papers failed to report on the consecutiveness of patient inclusion, time between aphasia onset and administration of the screening test, and blinding. Of the three studies that were rated as having an intermediate or low risk of bias, the DOR was highest for the Language Screening Test and ScreeLing. Several screening tools for aphasia in stroke are available, but many tests have not been verified properly. Methodologically sound validation studies of aphasia screening tests are needed to determine their usefulness in clinical practice.},
	number = {2},
	urldate = {2018-10-11},
	journal = {Journal of Neurology},
	author = {El Hachioui, Hanane and Visch-Brink, Evy G. and de Lau, Lonneke M. L. and van de Sandt-Koenderman, Mieke W. M. E. and Nouwens, Femke and Koudstaal, Peter J. and Dippel, Diederik W. J.},
	year = {2017},
	pmid = {27260296},
	pmcid = {PMC5306063},
	keywords = {aphasia-dementia},
	pages = {211--220},
	file = {PubMed Central Full Text PDF:/Users/transfer/Zotero/storage/QWADU3FC/El Hachioui et al. - 2017 - Screening tests for aphasia in patients with strok.pdf:application/pdf}
}

@article{weissberger_diagnostic_2017,
	title = {Diagnostic accuracy of memory measures in {Alzheimer}’s dementia and mild cognitive impairment: {A} systematic review and meta-analysis},
	shorttitle = {Diagnostic accuracy of memory measures in {Alzheimer}’s dementia and mild cognitive impairment},
	journal = {Neuropsychology review},
	author = {Weissberger, Gali H. and Strong, Jessica V. and Stefanidis, Kayla B. and Summers, Mathew J. and Bondi, Mark W. and Stricker, Nikki H.},
	year = {2017},
	keywords = {aphasia-dementia},
	pages = {1--35},
	file = {Fulltext:/Users/transfer/Zotero/storage/UGPAGKLG/s11065-017-9360-6.html:text/html;Snapshot:/Users/transfer/Zotero/storage/K4GWZJF2/s11065-017-9360-6.html:text/html}
}

@book{agronin_alzheimers_2014,
	title = {Alzheimer's disease and other dementias: a practical guide},
	shorttitle = {Alzheimer's disease and other dementias},
	publisher = {Routledge},
	author = {Agronin, Marc E.},
	year = {2014},
	keywords = {aphasia-dementia},
	file = {Snapshot:/Users/transfer/Zotero/storage/TTB3S9PA/9781135074739.html:text/html}
}

@article{font-clos_log-log_2015-1,
	title = {Log-{Log} {Convexity} of {Type}-{Token} {Growth} in {Zipf}'s {Systems}},
	volume = {114},
	issn = {1079-7114},
	doi = {10.1103/PhysRevLett.114.238701},
	abstract = {It is traditionally assumed that Zipf's law implies the power-law growth of the number of different elements with the total number of elements in a system-the so-called Heaps' law. We show that a careful definition of Zipf's law leads to the violation of Heaps' law in random systems, with growth curves that have a convex shape in log-log scale. These curves fulfill universal data collapse that only depends on the value of Zipf's exponent. We observe that real books behave very much in the same way as random systems, despite the presence of burstiness in word occurrence. We advance an explanation for this unexpected correspondence.},
	language = {eng},
	number = {23},
	journal = {Physical Review Letters},
	author = {Font-Clos, Francesc and Corral, Álvaro},
	month = jun,
	year = {2015},
	pmid = {26196834},
	keywords = {aphasia-dementia},
	pages = {238701},
	file = {Submitted Version:/Users/transfer/Zotero/storage/F2R7JYEQ/Font-Clos and Corral - 2015 - Log-Log Convexity of Type-Token Growth in Zipf's S.pdf:application/pdf}
}

@article{manschreck_type--token_1984-1,
	title = {The type--token ratio in schizophrenic disorders: clinical and research value},
	volume = {14},
	issn = {0033-2917},
	shorttitle = {The type--token ratio in schizophrenic disorders},
	abstract = {Prior research has indicated that the type-token ratio (TTR), a measure of repetition in language, correlates with clinical judgements of thought disorder when spoken language was examined, and differentiates statistically thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. We replicated this finding and examined the clinical sensitivity and specificity of the TTR measure in the diagnosis and in the assessment of thought disorder. The current clinical value of the TTR is limited, but further investigations of the nature of repetition in schizophrenic language are warranted.},
	language = {eng},
	number = {1},
	journal = {Psychological Medicine},
	author = {Manschreck, T. C. and Maher, B. A. and Hoover, T. M. and Ames, D.},
	month = feb,
	year = {1984},
	pmid = {6709781},
	keywords = {aphasia-dementia},
	pages = {151--157}
}

@article{endress_influence_2011-1,
	title = {The influence of type and token frequency on the acquisition of affixation patterns: implications for language processing},
	volume = {37},
	issn = {1939-1285},
	shorttitle = {The influence of type and token frequency on the acquisition of affixation patterns},
	doi = {10.1037/a0020210},
	abstract = {Rules, and exceptions to such rules, are ubiquitous in many domains, including language. Here we used simple artificial grammars to investigate the influence of 2 factors on the acquisition of rules and their exceptions, namely type frequency (the relative numbers of different exceptions to different regular items) and token frequency (the number of exception tokens relative to the number of regular tokens). We familiarized participants to either a prefixation pattern (where regulars started with /ZaI/ and exceptions ended with /ZaI/) or a suffixation pattern (where regulars ended with /ZaI/ and exceptions started with /ZaI/). We show that the type and the token frequency of regular items and exceptions influence in different ways what participants can learn. For the exceptions to be learned, they have to occur sufficiently often so that participants can memorize them; this can be achieved by a high token frequency. However, a high token frequency of the exceptions also impaired the acquisition of the regular pattern. In contrast, the type frequency of the patterns seemed to determine whether the regular pattern could be learned: When the type frequency of the regular items was sufficiently high, participants successfully learned the regular pattern even when the exceptions were played so often that 66\% of the familiarization items were exceptions. We discuss these findings in the context of general learning mechanisms and the role they may play in language acquisition.},
	language = {eng},
	number = {1},
	journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
	author = {Endress, Ansgar D. and Hauser, Marc D.},
	month = jan,
	year = {2011},
	pmid = {20804286},
	keywords = {aphasia-dementia},
	pages = {77--95}
}

@article{lazaro_written_2016-1,
	title = {Written {Type} and {Token} {Frequency} {Measures} of {Fifty} {Spanish} {Derivational} {Morphemes}},
	volume = {19},
	issn = {1988-2904},
	doi = {10.1017/sjp.2016.75},
	abstract = {Several databases of written language exist in Spanish that manage important information on the lexical and sublexical characteristics of words. However, there is no database with information on the productivity and frequency of use of derivational suffixes: sublexical units with an essential role in the formation of orthographic representations and lexical access. This work examines these two measures, known as type and token frequencies, for a series of 50 derivational suffixes and their corresponding orthographic endings. Derivational suffixes are differentiated from orthographic endings by eliminating pseudoaffixed words from the list of orthographic endings (cerveza [beer] is a simple word despite its ending in -eza). We provide separate data for child and adult populations, using two databases commonly accessed by psycholinguists conducting research in Spanish. We describe the filtering process used to obtain descriptive data that will provide information for future research on token and type frequencies of morphemes. This database is an important development for researchers focusing on the role of morphology in lexical acquisition and access.},
	language = {eng},
	journal = {The Spanish Journal of Psychology},
	author = {Lázaro, Miguel and Acha, Joana and Illera, Víctor and Sainz, Javier S.},
	month = nov,
	year = {2016},
	pmid = {27821213},
	keywords = {aphasia-dementia},
	pages = {E75}
}

@article{richtsmeier_contributions_2011,
	title = {Contributions of phonetic token variability and word-type frequency to phonological representations},
	volume = {38},
	issn = {1469-7602},
	doi = {10.1017/S0305000910000371},
	abstract = {The experiments here build on the widely reported finding that children are most accurate when producing phonotactic sequences with high ambient-language frequency. What remains controversial is a description of the input that children must be tracking for this effect to arise. We present a series of experiments that compare two ambient-language properties, token and type frequency, as they contribute to phonotactic learning. Token frequency is the raw number of exposures children have to a particular pattern; type frequency refers to a count of abstract entities, such as unique words. Our results suggest that children's production accuracy is most sensitive to a combination of type and token frequency: children were able to generalize a target phonotactic sequence to a new word when familiarized with multiple word-types across tokens from multiple talkers, but not when presented with either word-types with no talker variability or multiple talker-tokens of a single word.},
	language = {eng},
	number = {5},
	journal = {Journal of Child Language},
	author = {Richtsmeier, Peter and Gerken, Louann and Ohala, Diane},
	month = nov,
	year = {2011},
	pmid = {21126387},
	keywords = {aphasia-dementia},
	pages = {951--978}
}

@article{richards_type/token_1987-2,
	title = {Type/{Token} {Ratios}: what do they really tell us?},
	volume = {14},
	issn = {0305-0009},
	shorttitle = {Type/{Token} {Ratios}},
	language = {eng},
	number = {2},
	journal = {Journal of Child Language},
	author = {Richards, B.},
	month = jun,
	year = {1987},
	pmid = {3611238},
	keywords = {aphasia-dementia},
	pages = {201--209}
}

@article{hanson_frequency_1988,
	title = {Frequency encoding of token and type information},
	volume = {14},
	issn = {0278-7393},
	abstract = {Two experiments examined how attention to stimulus attributes affects knowledge of frequency of occurrence. In Experiment 1, orienting tasks were used to direct subjects' attention to either the category membership or the initial letters of words. In Experiment 2, subjects' attention to words, category membership, and initial letters was directed with explicit instructions. The results of these two experiments suggest that attention to specific stimulus attributes may be necessary to initiate the encoding of frequency information. We discuss the implications of these results for claims that the encoding of frequency of occurrence is automatic.},
	language = {eng},
	number = {2},
	journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
	author = {Hanson, C. and Hirst, W.},
	month = apr,
	year = {1988},
	pmid = {2967345},
	keywords = {aphasia-dementia},
	pages = {289--297}
}

@article{hess_sample_1986-2,
	title = {Sample size and type-token ratios for oral language of preschool children},
	volume = {29},
	issn = {0022-4685},
	abstract = {This study investigated the stability of five type-token ratios (TTRs) in 50-utterance oral language samples segmented into nine lengths. The samples were obtained from 83 children, 3, 4, and 5 years of age. The five TTRs included the basic type-token ratio, the corrected type-token ratio, the root type-token ratio, the bilogarithmic type-token ratio, and the Characteristic K. The sample segment sizes consisted of the first, second, third, and fourth 50-word segments; the first and second 100-word segments; the first 150-word segment; the first 200-word segment; and the total 50-utterance sample. Based on the results of this study, TTR measures on the language of young children should not be compared for samples that differ in number of words. Further, TTR measures for sample size of 50 and 100 words have reliabilities that are judged to be inadequate for research or clinical purposes. The size of the language sample needed for minimum reliability of .70 is 350 words. Greater reliability requires larger word-sample size.},
	language = {eng},
	number = {1},
	journal = {Journal of Speech and Hearing Research},
	author = {Hess, C. W. and Sefton, K. M. and Landry, R. G.},
	month = mar,
	year = {1986},
	pmid = {3702374},
	keywords = {aphasia-dementia},
	pages = {129--134}
}

@article{baracchini_[language_1970-2,
	title = {[{Language} in mental retardates: the {Type}-{Token} ratio]},
	volume = {16},
	issn = {0035-6336},
	shorttitle = {[{Language} in mental retardates},
	language = {ita},
	number = {2},
	journal = {Rivista Di Neurobiologia: Organo Ufficiale Della Societa Dei Neurologi, Neuroradiologi E Neurochirurghi Ospedalieri},
	author = {Baracchini, G. and Bickel, J. and Bertocchini, M.},
	month = jun,
	year = {1970},
	pmid = {5505861},
	keywords = {aphasia-dementia},
	pages = {235--240}
}

@article{leung_type_2004,
	title = {Type and token frequencies of phonological units in {Hong} {Kong} {Cantonese}},
	volume = {36},
	issn = {0743-3808},
	abstract = {This article reports, for the first time, type and token frequencies of tones, onsets, codas, rimes, and syllables of Hong Kong Cantonese. The information is derived from a computerized spoken corpus, the Hong Kong Cantonese adult language corpus (HKCAC; Leung \& Law, 2001), consisting of more than 140,000 character-syllable units. Since the HKCAC is based on recordings of connected speech, comparisons are made with respect to the inventories of various phonological units between the HKCAC and standard descriptions of the Cantonese phonological system--in particular, Fok (1974) and Bauer and Benedict (1997). It is hoped that the frequency information presented here will become a valuable tool for future psycholinguistic and linguistic research in this language. The full set of these frequency counts may be downloaded from the Psychonomic Society Web archive at www.psychonomic.org/ archive/.},
	language = {eng},
	number = {3},
	journal = {Behavior Research Methods, Instruments, \& Computers: A Journal of the Psychonomic Society, Inc},
	author = {Leung, Man-Tak and Law, Sam-Po and Fung, Suk-Yee},
	month = aug,
	year = {2004},
	pmid = {15641438},
	keywords = {aphasia-dementia},
	pages = {500--505}
}

@article{chen_type-token_1946-1,
	title = {The type-token ratio applied to infant speech sounds},
	volume = {11},
	language = {eng},
	journal = {The Journal of Speech Disorders},
	author = {Chen, H. P. and Irwin, O. C.},
	month = jun,
	year = {1946},
	pmid = {20986559},
	keywords = {aphasia-dementia},
	pages = {126--130}
}

@article{nicoladis_role_2007,
	title = {The role of type and token frequency in using past tense morphemes correctly},
	volume = {10},
	issn = {1363-755X},
	doi = {10.1111/j.1467-7687.2007.00582.x},
	abstract = {Type and token frequency have been thought to be important in the acquisition of past tense morphology, particularly in differentiating regular and irregular forms. In this study we tested the role of frequency in two ways: (1) in bilingual children, who typically use and hear either language less often than monolingual children and (2) cross-linguistically: French and English have different patterns of frequency of regular/irregular verbs. Ten French-English bilingual children, 10 French monolingual and 10 English monolingual children between 4 and 6 years watched a cartoon and re-told the story. The results demonstrated that the bilingual children were less accurate than the monolingual children. Their accuracy in both French and English regular and irregular verbs corresponded to frequency in the input language. These results are consistent with the hypothesis that children learn past tense morphemes by analogy with other words in their vocabularies. We propose a developmental sequence based on conservative generalization across a growing set of verbs.},
	language = {eng},
	number = {2},
	journal = {Developmental Science},
	author = {Nicoladis, Elena and Palmer, Andrea and Marentette, Paula},
	month = mar,
	year = {2007},
	pmid = {17286847},
	keywords = {aphasia-dementia},
	pages = {237--254}
}

@article{hess_reliability_1989,
	title = {The reliability of type-token ratios for the oral language of school age children},
	volume = {32},
	issn = {0022-4685},
	abstract = {This study investigated the alternate forms reliability of four type-token ratios (TTRs) of oral language samples obtained from 52 elementary school children (9 through 12 years of age). The four TTRs included the basic type-token ratio, the corrected type-token ratio, the root type-token ratio, and the bilogarithmic type-token ratio. Language samples of 600 words were segmented into 50-word, 100-word, and 200-word samples. Within each TTR measure, there were no significant differences among the means for samples of the same size, but all means for a given sample size differed significantly from the means of all other sample sizes. Further, for samples of the same size the reliability coefficients calculated for each TTR measure were neither consistent nor significant. These findings indicate that under the conditions of the present study TTRs are not comparable when calculated for different sample sizes ranging from 50 to 600 words, and further, that they are not reliable measures of the language performance of individual elementary school children from regular classrooms for language samples of 50 to 200 words.},
	language = {eng},
	number = {3},
	journal = {Journal of Speech and Hearing Research},
	author = {Hess, C. W. and Haug, H. T. and Landry, R. G.},
	month = sep,
	year = {1989},
	pmid = {2779198},
	keywords = {aphasia-dementia},
	pages = {536--540}
}

@article{manschreck_formal_1981-3,
	title = {Formal thought disorder, the type-token ratio and disturbed voluntary motor movement in schizophrenia},
	volume = {139},
	issn = {0007-1250},
	abstract = {Little work has been done to determine objective, reliable differences in formal characteristics of the actual utterances of thought-disordered and non-thought-disordered subjects. The type-token ratio (TTR), a quantitative measure of repetition in language, correlated highly with clinical judgments of thought disorder when spoken language was examined, and statistically differentiated thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. Elicited and spontaneous motor abnormalities were associated with reduced TTRs both in schizophrenics and in affective subjects with motor disturbance. The TTR is a reliable, objective indicator of language deviance and thought disorder, and strongly associated with motor disturbances.},
	language = {eng},
	journal = {The British Journal of Psychiatry: The Journal of Mental Science},
	author = {Manschreck, T. C. and Maher, B. A. and Ader, D. N.},
	month = jul,
	year = {1981},
	pmid = {6117348},
	keywords = {aphasia-dementia},
	pages = {7--15}
}

@article{manschreck_type--token_1984-2,
	title = {The type--token ratio in schizophrenic disorders: clinical and research value},
	volume = {14},
	issn = {0033-2917},
	shorttitle = {The type--token ratio in schizophrenic disorders},
	abstract = {Prior research has indicated that the type-token ratio (TTR), a measure of repetition in language, correlates with clinical judgements of thought disorder when spoken language was examined, and differentiates statistically thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. We replicated this finding and examined the clinical sensitivity and specificity of the TTR measure in the diagnosis and in the assessment of thought disorder. The current clinical value of the TTR is limited, but further investigations of the nature of repetition in schizophrenic language are warranted.},
	language = {eng},
	number = {1},
	journal = {Psychological Medicine},
	author = {Manschreck, T. C. and Maher, B. A. and Hoover, T. M. and Ames, D.},
	month = feb,
	year = {1984},
	pmid = {6709781},
	keywords = {aphasia-dementia},
	pages = {151--157}
}

@article{manschreck_formal_1981-4,
	title = {Formal thought disorder, the type-token ratio and disturbed voluntary motor movement in schizophrenia},
	volume = {139},
	issn = {0007-1250},
	abstract = {Little work has been done to determine objective, reliable differences in formal characteristics of the actual utterances of thought-disordered and non-thought-disordered subjects. The type-token ratio (TTR), a quantitative measure of repetition in language, correlated highly with clinical judgments of thought disorder when spoken language was examined, and statistically differentiated thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. Elicited and spontaneous motor abnormalities were associated with reduced TTRs both in schizophrenics and in affective subjects with motor disturbance. The TTR is a reliable, objective indicator of language deviance and thought disorder, and strongly associated with motor disturbances.},
	language = {eng},
	journal = {The British Journal of Psychiatry: The Journal of Mental Science},
	author = {Manschreck, T. C. and Maher, B. A. and Ader, D. N.},
	month = jul,
	year = {1981},
	pmid = {6117348},
	keywords = {aphasia-dementia},
	pages = {7--15}
}

@article{manschreck_type--token_1984-3,
	title = {The type--token ratio in schizophrenic disorders: clinical and research value},
	volume = {14},
	issn = {0033-2917},
	shorttitle = {The type--token ratio in schizophrenic disorders},
	abstract = {Prior research has indicated that the type-token ratio (TTR), a measure of repetition in language, correlates with clinical judgements of thought disorder when spoken language was examined, and differentiates statistically thought-disordered from non-thought-disordered schizophrenics and psychiatric and normal controls. We replicated this finding and examined the clinical sensitivity and specificity of the TTR measure in the diagnosis and in the assessment of thought disorder. The current clinical value of the TTR is limited, but further investigations of the nature of repetition in schizophrenic language are warranted.},
	language = {eng},
	number = {1},
	journal = {Psychological Medicine},
	author = {Manschreck, T. C. and Maher, B. A. and Hoover, T. M. and Ames, D.},
	month = feb,
	year = {1984},
	pmid = {6709781},
	keywords = {aphasia-dementia},
	pages = {151--157}
}

@article{zannino_contribution_2015,
	title = {The contribution of neurodegenerative diseases to the modelling of semantic memory: {A} new proposal and a review of the literature},
	volume = {75},
	issn = {1873-3514},
	shorttitle = {The contribution of neurodegenerative diseases to the modelling of semantic memory},
	doi = {10.1016/j.neuropsychologia.2015.06.023},
	abstract = {This paper provides a focused review of the literature on semantic impairment in semantic dementia (SD) and Alzheimer's disease (AD). An attempt is made to interpret the most relevant phenomena in the light of a new model of semantic memory. This model comprises a language-based component (disrupted in SD and AD), which supports our ability to establish reliable token vs. type relationships in the service of propositional thinking, and a philogenetically older sensorimotor component, which is needed to categorize our environment in a more implicit way. Extant neuropsychological models of semantic memory are also reviewed and compared with the new model in terms of their ability to explain the observed phenomena and to deal with the problem of establishing token vs. type relationships starting from inconsistent cross modal input representations and arbitrary category boundaries.},
	language = {eng},
	journal = {Neuropsychologia},
	author = {Zannino, Gian Daniele and Caltagirone, Carlo and Carlesimo, Giovanni A.},
	month = aug,
	year = {2015},
	pmid = {26102188},
	keywords = {aphasia-dementia},
	pages = {274--290}
}

@article{sohlberg_evaluation_2014,
	title = {An evaluation of reading comprehension of expository text in adults with traumatic brain injury},
	volume = {23},
	issn = {1558-9110},
	doi = {10.1044/2013_AJSLP-12-0005},
	abstract = {PURPOSE: This project was conducted to obtain information about reading problems of adults with traumatic brain injury (TBI) with mild-to-moderate cognitive impairments and to investigate how these readers respond to reading comprehension strategy prompts integrated into digital versions of text.
METHOD: Participants from 2 groups, adults with TBI (n = 15) and matched controls (n = 15), read 4 different 500-word expository science passages linked to either a strategy prompt condition or a no-strategy prompt condition. The participants' reading comprehension was evaluated using sentence verification and free recall tasks.
RESULTS: The TBI and control groups exhibited significant differences on 2 of the 5 reading comprehension measures: paraphrase statements on a sentence verification task and communication units on a free recall task. Unexpected group differences were noted on the participants' prerequisite reading skills. For the within-group comparison, participants showed significantly higher reading comprehension scores on 2 free recall measures: words per communication unit and type-token ratio. There were no significant interactions.
CONCLUSION: The results help to elucidate the nature of reading comprehension in adults with TBI with mild-to-moderate cognitive impairments and endorse further evaluation of reading comprehension strategies as a potential intervention option for these individuals. Future research is needed to better understand how individual differences influence a person's reading and response to intervention.},
	language = {eng},
	number = {2},
	journal = {American Journal of Speech-Language Pathology},
	author = {Sohlberg, McKay Moore and Griffiths, Gina G. and Fickas, Stephen},
	month = may,
	year = {2014},
	pmid = {24687229},
	keywords = {aphasia-dementia},
	pages = {160--175}
}

@article{baracchini_[language_1970-3,
	title = {[{Language} in mental retardates: the {Type}-{Token} ratio]},
	volume = {16},
	issn = {0035-6336},
	shorttitle = {[{Language} in mental retardates},
	language = {ita},
	number = {2},
	journal = {Rivista Di Neurobiologia: Organo Ufficiale Della Societa Dei Neurologi, Neuroradiologi E Neurochirurghi Ospedalieri},
	author = {Baracchini, G. and Bickel, J. and Bertocchini, M.},
	month = jun,
	year = {1970},
	pmid = {5505861},
	keywords = {aphasia-dementia},
	pages = {235--240}
}

@article{kave_word_2016,
	title = {Word retrieval in picture descriptions produced by individuals with {Alzheimer}'s disease},
	volume = {38},
	issn = {1744-411X},
	doi = {10.1080/13803395.2016.1179266},
	abstract = {What can tests of single-word production tell us about word retrieval in connected speech? We examined this question in 20 people with Alzheimer's disease (AD) and in 20 cognitively intact individuals. All participants completed tasks of picture naming and semantic fluency and provided connected speech through picture descriptions. Picture descriptions were analyzed for total word output, percentages of content words, percentages of nouns, and percentages of pronouns out of all words, type-token ratio of all words and type-token ratio of nouns alone, mean frequency of all words and mean frequency of nouns alone, and mean word length. Individuals with AD performed worse than did cognitively intact individuals on the picture naming and semantic fluency tasks. They also produced a lower proportion of content words overall, a lower proportion of nouns, and a higher proportion of pronouns, as well as more frequent and shorter words on picture descriptions. Group differences in total word output and type-token ratios did not reach significance. Correlations between scores on tasks of single-word retrieval and measures of retrieval in picture descriptions emerged in the AD group but not in the control group. Scores on a picture naming task were associated with difficulties in word retrieval in connected speech in AD, while scores on a task of semantic verbal fluency were less useful in predicting measures of retrieval in context in this population.},
	language = {eng},
	number = {9},
	journal = {Journal of Clinical and Experimental Neuropsychology},
	author = {Kavé, Gitit and Goral, Mira},
	month = nov,
	year = {2016},
	pmid = {27171756},
	pmcid = {PMC4983450},
	keywords = {aphasia-dementia},
	pages = {958--966},
	file = {Accepted Version:/Users/transfer/Zotero/storage/VI4BHPGV/Kavé and Goral - 2016 - Word retrieval in picture descriptions produced by.pdf:application/pdf}
}

@article{stead_effect_2015,
	title = {Effect of time of day on language in healthy ageing and {Alzheimer}'s disease},
	volume = {27},
	issn = {1472-0795},
	doi = {10.7748/nop.27.3.31.e667},
	abstract = {AIM: To investigate whether narrative discourse followed a diurnal pattern across one ten-hour day in healthy ageing people and those with mild to moderate Alzheimer's disease (AD).
METHOD: Ten healthy ageing people and ten clinically labelled with probable AD were recruited. Measurements of language and cognition were collected across one day at 9am, 12pm, 3pm and 6pm. Language samples were evaluated for quantity (total utterances and words per minute) and quality: mazes or fillers, repetitions and revisions, abandoned utterances and type token ratio or percentage of different words to total words.
RESULTS: The healthy ageing group performed significantly better on cognitive measures across the day than the AD group. At all times the healthy ageing group produced significantly longer narrative samples that were significantly less aborted and revised than the AD group. Additionally, both groups demonstrated declining narrative performance as the day progressed.
CONCLUSION: Based on these results, time of day may be an additional factor that moderates narrative performance. This change in narrative ability may have an effect on making a proper diagnosis, therapeutic effectiveness and patient interactions, therefore affecting quality of care.},
	language = {eng},
	number = {3},
	journal = {Nursing Older People},
	author = {Stead, Amanda and Donovan, Neila and Hoffman, Paul},
	month = apr,
	year = {2015},
	pmid = {25809050},
	keywords = {aphasia-dementia},
	pages = {31--38}
}

@article{adewuya_flexibility_2008-1,
	title = {Flexibility and variability in lexicon usage among {Yoruba}-speaking {Nigerian} outpatients with schizophrenia: a controlled study},
	volume = {41},
	issn = {1423-033X},
	shorttitle = {Flexibility and variability in lexicon usage among {Yoruba}-speaking {Nigerian} outpatients with schizophrenia},
	doi = {10.1159/000141924},
	abstract = {BACKGROUND: The studies on language dysfunction in schizophrenia are few, inconclusive and have all been done in the western culture. There may be cross-cultural and cross-lingual differences in problems with speeches of patients with schizophrenia. This study aims to examine the flexibility or variability in the use of words among a group of Nigerian patients with schizophrenia compared with healthy controls.
SAMPLING AND METHODS: The spoken samples of 48 outpatients with schizophrenia and 48 matched controls were assessed using the mean segmental type-token ratio (MSTTR). The sociodemographic and clinical variables of the patients with schizophrenia were also compared with their MSTTR scores.
RESULTS: The MSTTR score for the patients with schizophrenia was significantly lower compared with that of healthy controls (p {\textless} 0.001). The factors independently associated with a lower MSTTR in patients with schizophrenia include younger age at onset of illness, presence of negative formal thought disorder and simple or hebephrenic subtype of schizophrenia.
CONCLUSIONS: The problem with flexibility and variability in lexicon usage among patients with schizophrenia is a cross-cultural phenomenon. The MSTTR may have value in predicting clinical judgements of thought disorder or in identifying deviant language. These may have broad potentials for application in longitudinal and pathogenetic studies of schizophrenia.},
	language = {eng},
	number = {5},
	journal = {Psychopathology},
	author = {Adewuya, Abiola O. and Adewuya, Abiodun O.},
	year = {2008},
	pmid = {18594164},
	keywords = {aphasia-dementia},
	pages = {294--299}
}

@article{de_boer_linguistic_2016,
	title = {A linguistic comparison between auditory verbal hallucinations in patients with a psychotic disorder and in nonpsychotic individuals: {Not} just what the voices say, but how they say it},
	volume = {162},
	issn = {1090-2155},
	shorttitle = {A linguistic comparison between auditory verbal hallucinations in patients with a psychotic disorder and in nonpsychotic individuals},
	doi = {10.1016/j.bandl.2016.07.011},
	abstract = {BACKGROUND: Auditory verbal hallucinations (AVH) in psychotic patients are associated with activation of right hemisphere language areas, although this hemisphere is non-dominant in most people. Language generated in the right hemisphere can be observed in aphasia patients with left hemisphere damage. It is called "automatic speech", characterized by low syntactic complexity and negative emotional valence. AVH in nonpsychotic individuals, by contrast, predominantly have a neutral or positive emotional content and may be less dependent on right hemisphere activity. We hypothesize that right hemisphere language characteristics can be observed in the language of AVH, differentiating psychotic from nonpsychotic individuals.
METHOD: 17 patients with a psychotic disorder and 19 nonpsychotic individuals were instructed to repeat their AVH verbatim directly upon hearing them. Responses were recorded, transcribed and analyzed for total words, mean length of utterance, proportion of grammatical utterances, proportion of negations, literal and thematic perseverations, abuses, type-token ratio, embeddings, verb complexity, noun-verb ratio, and open-closed class ratio.
RESULTS: Linguistic features of AVH overall differed between groups F(13,24)=3.920, p=0.002; Pillai's Trace 0.680. AVH of psychotic patients compared with AVH of nonpsychotic individuals had a shorter mean length of utterance, lower verb complexity, and more verbal abuses and perseverations (all p{\textless}0.05). Other features were similar between groups.
CONCLUSION: AVH of psychotic patients showed lower syntactic complexity and higher levels of repetition and abuses than AVH of nonpsychotic individuals. These differences are in line with a stronger involvement of the right hemisphere in the origination of AVH in patients than in nonpsychotic voice hearers.},
	language = {eng},
	journal = {Brain and Language},
	author = {de Boer, J. N. and Heringa, S. M. and van Dellen, E. and Wijnen, F. N. K. and Sommer, I. E. C.},
	year = {2016},
	pmid = {27501385},
	keywords = {aphasia-dementia},
	pages = {10--18}
}

@article{st-pierre_reproduction_2010,
	title = {Reproduction of inflectional markers in {French}-speaking children with reading impairment},
	volume = {53},
	issn = {1558-9102},
	doi = {10.1044/1092-4388(2009/07-0251)},
	abstract = {PURPOSE: Children with reading impairment (RI) experience difficulties in oral and written production of inflectional markers. The origin of these difficulties is not well documented in French. According to some authors, acquisition of irregular items by typically developing children is predicted by token frequency, whereas acquisition of regular items is predicted by type frequency. The authors hypothesized that acquisition of inflectional markers in French depends on the distribution of irregular, invariable, and regular (transparent) items within a grammatical category.
METHOD: Fifteen children with RI age matched with 15 children with typical reading development repeated and read aloud sentences containing adjectives inflected for gender and verbs inflected for number. Inflected adjectives and verbs were matched for token frequency and phonological complexity, whereas distribution of invariable, transparent, and irregular items differed within each grammatical category.
RESULTS: Results show higher error rates in the RI group, who produced more errors in reading than repetition, and more errors on inflected verbs than adjectives. Error distribution varied with the proportion of invariable, irregular, and transparent items within each grammatical category, confirming the authors' hypothesis.
CONCLUSION: The authors concluded that morphological difficulties of children with RI group originated from a delay in extracting systematicity in verb and adjective inflectional marking.},
	language = {eng},
	number = {2},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {St-Pierre, Marie-Catherine and Béland, Renée},
	month = apr,
	year = {2010},
	pmid = {20360467},
	keywords = {aphasia-dementia},
	pages = {469--489}
}

@article{faber-langendoen_aphasia_1988,
	title = {Aphasia in senile dementia of the {Alzheimer} type},
	volume = {23},
	issn = {0364-5134},
	doi = {10.1002/ana.410230409},
	abstract = {We assessed language function, using a brief clinical Aphasia Battery and psychometric measures, in 150 subjects with senile dementia of the Alzheimer type (SDAT) and 83 elderly controls. Aphasia occurred only in demented subjects, and its prevalence increased with severity of dementia. Aphasia in mildly demented subjects was associated with both an earlier age of onset and more rapid progression of SDAT than in similarly demented nonaphasics. Language dysfunction in SDAT subjects was characterized by early decline in measures of comprehension and written expression, whereas other components, including oral naming, were less profoundly affected. Performance on the verbal psychometric measures, the Sentence Repetition and the Token tests, correlated strongly with Aphasia Battery scores and declined only minimally in nonaphasics, despite increasing dementia. We conclude that aphasia is a common feature of SDAT subjects and identifies a subgroup with more rapid progression of dementia. Furthermore, it represents language-specific dysfunction beyond the global cognitive impairment of SDAT.},
	language = {eng},
	number = {4},
	journal = {Annals of Neurology},
	author = {Faber-Langendoen, K. and Morris, J. C. and Knesevich, J. W. and LaBarge, E. and Miller, J. P. and Berg, L.},
	month = apr,
	year = {1988},
	pmid = {3382172},
	keywords = {aphasia-dementia},
	pages = {365--370}
}

@article{linscott_thought_2005-1,
	title = {Thought disorder, pragmatic language impairment, and generalized cognitive decline in schizophrenia},
	volume = {75},
	issn = {0920-9964},
	doi = {10.1016/j.schres.2004.10.007},
	abstract = {BACKGROUND: Schizophrenia is associated with pragmatic language impairment (PLI), a reduced ability to communicate intention in a rule-governed fashion. Two explanations for PLI include that PLI is equivalent to thought disorder and that PLI is secondary to generalized cognitive decline.
OBJECTIVES: The aims of this study were to demonstrate PLI in schizophrenia and to test which of these explanations best accounts for the relationships among thought disorder, PLI, and generalized cognitive decline.
METHOD: Schizophrenia (n=20) and control (n=26) participants provided speech samples that were scored for thought disorder (type-token ratio and Cloze procedure) and PLI [Profile of Pragmatic Impairment in Communication (PPIC)]. Generalized cognitive decline was determined from discrepancies between current and premorbid verbal IQ.
RESULTS: Patients with schizophrenia exhibited significant PLI and generalized cognitive decline. There was no evidence of an association between thought disorder and PLI. Moreover, generalized cognitive decline predicted PLI (r(2)=0.33 to 0.59) but not thought disorder (r(2)=0.02 to 0.06).
CONCLUSIONS: The results conformed to a predicted pattern of associations based on the notion that PLI in schizophrenia is secondary to generalized cognitive decline.},
	language = {eng},
	number = {2-3},
	journal = {Schizophrenia Research},
	author = {Linscott, Richard J.},
	month = jun,
	year = {2005},
	pmid = {15885514},
	keywords = {aphasia-dementia},
	pages = {225--232}
}

@article{andreasen_linguistic_1976,
	title = {Linguistic analysis of speech in affective disorders},
	volume = {33},
	issn = {0003-990X},
	abstract = {Various aspects of speech and language were compared, using psycholinguistic techniques, in a group of 15 depressed patients and 16 manic patients: lexical diversity, syntactical complexity, syntactical elements, and content analysis. Contrary to anticipation, the manic patients did not show more varied word choice or complexity of sentence structure than the depressives. In particular, they did not differ significantly in type-token ratio. The greatest difference was in syntactical elements, with manics using more action verbs, adjectives, and concrete nouns, while the depressed patients used more state of being verbs, modifying adverbs, first-person pronouns, and personal pronouns. When compared by content analysis, the manics used more words reflecting a concern with power and achievement. These results imply that depressive speech tends to be more vague and qualified and to show considerable self-preoccupation, while manic speech tends to be colorful and concrete and to show more concern with things than with people.},
	language = {eng},
	number = {11},
	journal = {Archives of General Psychiatry},
	author = {Andreasen, N. G. and Pfohl, B.},
	month = nov,
	year = {1976},
	pmid = {985047},
	keywords = {aphasia-dementia},
	pages = {1361--1367}
}

@article{bandera_discrimination_1985,
	title = {Discrimination between senile dementia {Alzheimer} type patients and -education matched normal controls by means of a 6-test set},
	volume = {6},
	issn = {0392-0461},
	abstract = {Discrimination between senile dementia Alzheimer type (SDAT) patients (N = 30) and Normal Controls (N = 60) by means of a 6-test set was assessed. Performances on Word Fluency (FL), Memory for Prose (PM) and Finger Agnosia (FA) nearly exhaust the discriminant power of the whole battery, including Constructional Apraxia (CA), Token Test (TT) and Weigl's Sorting Test (WT). The battery, however, leaves some facets of the difference between SDAT patients and Controls unexplored, misclassifying almost 20\% of the SDAT patients and 10\% of the Controls. We emphasize the role of discriminant analysis in the evaluation of any neuropsychological battery of tests which has to be used for diagnostic purposes.},
	language = {eng},
	number = {3},
	journal = {Italian Journal of Neurological Sciences},
	author = {Bandera, R. and Capitani, E. and Della Sala, S. and Spinnler, H.},
	month = sep,
	year = {1985},
	pmid = {4066269},
	keywords = {aphasia-dementia},
	pages = {339--344}
}

@article{akyurek_aspects_1986,
	title = {Aspects of the behavioral repertoire of an autistic/epileptic child},
	volume = {62},
	issn = {0031-5125},
	doi = {10.2466/pms.1986.62.3.843},
	abstract = {The behavior of an autistic/epileptic child was investigated through indoor, outdoor, and laboratory contexts to acquire a catalog of behavior for the autistic condition, which to date was only partially available, and to provide the parameters of the units composing it. The catalog obtained is composed of 111 units of behavior whose descriptions and quantitative characteristics are also given. The study has also dealt with the subject's global behavioral output and lexical aspects of her repertoire. The results appear to admit the conclusion that the child's behavior was operating under a tendency to return to a stereotypic output state from other, short-lasting states of behavior. This observation needs a subsequent confirmatory analysis of behavioral output states involved. Moreover, the search for the orderly type/token relationship, proposed in 1977 by Fagen and Goldman to hold for behavior, has led to equivocal results.},
	language = {eng},
	number = {3},
	journal = {Perceptual and Motor Skills},
	author = {Akyürek, A. and Kalverboer, A. F.},
	month = jun,
	year = {1986},
	pmid = {3725521},
	keywords = {aphasia-dementia},
	pages = {843--858}
}

@article{travniczek-marterer_ideomotor_1993,
	title = {Ideomotor apraxia in {Alzheimer}'s disease},
	volume = {88},
	issn = {0001-6314},
	abstract = {Ideomotor apraxia, tested on verbal command and by imitation, was checked in 23 patients suffering from dementia of Alzheimer's type of different severity and in 17 age-matched controls. A significant deterioration of ideomotor praxis could be shown even in mild dementia. Correlations of ideomotor apraxia and aphasia, tested by the Token test were found to be significant.},
	language = {eng},
	number = {1},
	journal = {Acta Neurologica Scandinavica},
	author = {Travniczek-Marterer, A. and Danielczyk, W. and Simanyi, M. and Fischer, P.},
	month = jul,
	year = {1993},
	pmid = {8372621},
	keywords = {aphasia-dementia},
	pages = {1--4}
}

@article{ikeda_horse_2006,
	title = {A horse of a different colour: do patients with semantic dementia recognise different versions of the same object as the same?},
	volume = {44},
	issn = {0028-3932},
	shorttitle = {A horse of a different colour},
	doi = {10.1016/j.neuropsychologia.2005.07.006},
	abstract = {Ten patients with semantic dementia resulting from bilateral anterior temporal lobe atrophy, and 10 matched controls, were tested on an object recognition task in which they were invited to choose (from a four-item array) the picture representing "the same thing" as an object picture that they had just inspected and attempted to name. The target in the response array was never physically identical to the studied picture but differed from it - in the various conditions - in size, angle of view, colour or exemplar (e.g. a different breed of dog). In one test block for each patient, the response array was presented immediately after the studied picture was removed; in another block, a 2 min filled delay was inserted between study and test. The patients performed relatively well when the studied object and target response differed only in the size of the picture on the page, but were significantly impaired as a group in the other three type-of-change conditions, even with no delay between study and test. The five patients whose structural brain imaging revealed major right-temporal atrophy were more impaired overall, and also more affected by the 2 min delay, than the five patients with an asymmetric pattern characterised by predominant left-sided atrophy. These results are interpreted in terms of a hypothesis that successful classification of an object token as an object type is not a pre-semantic ability but rather results from interaction of perceptual and conceptual processing.},
	language = {eng},
	number = {4},
	journal = {Neuropsychologia},
	author = {Ikeda, M. and Patterson, K. and Graham, K. S. and Ralph, M. A. Lambon and Hodges, J. R.},
	year = {2006},
	pmid = {16115656},
	keywords = {aphasia-dementia},
	pages = {566--575}
}

@article{damba_[biological_1990-1,
	title = {[{Biological} and behavioral rhythms of patients with schizophrenia. {Preliminary} study]},
	volume = {16},
	issn = {0013-7006},
	abstract = {Relying on the ethological model for the collection of data (ethogram), psycholinguistic methods (Cloze procedure, type token ratio) and chronobiological techniques, the present study tests the hypothesis of behavioural, speech and biological ultradian or circadian rhythms in certain types of schizophrenic patients after a 2 week study. Six daily, direct and meticulous 25 minutes observations of the behaviour and speech of four schizophrenics show that stereotyped motor or verbal behaviour does not always fluctuate at random; certain behavioural patterns recur regularly at fixed intervals, according to a set time structure. Most of the behavioural, verbal and biological variables have their acrophase at 10 a.m. and/or at 4 p.m. Instability in the rhythm of the sleep/wake cycle and the oral temperature observed in schizophrenics could be the result of desynchronization of the central pacemakers or of the resynchronization, or even of hypersynchronization with a delay of one phase. It is difficult to ascribe this desynchronization to the illness or the treatment.},
	language = {fre},
	number = {1},
	journal = {L'Encephale},
	author = {Damba, D. B.},
	month = feb,
	year = {1990},
	pmid = {2328681},
	keywords = {aphasia-dementia},
	pages = {3--12}
}

@article{delaney-black_expressive_2000,
	title = {Expressive language development of children exposed to cocaine prenatally: literature review and report of a prospective cohort study},
	volume = {33},
	issn = {0021-9924},
	shorttitle = {Expressive language development of children exposed to cocaine prenatally},
	abstract = {It was hypothesized that prenatal exposure to cocaine and other substances would be related to delayed expressive language development. Speech and language data were available for 458 6-year olds (204 were exposed to cocaine). No significant univariate or multivariate differences by cocaine exposure group were observed. Classification and regression tree modeling was then used to identify language variable composites predictive of cocaine exposure status. Meaningful cut points for two language measures were identified and validated. Children with a type token ratio of less than 0.42 and with fewer than 97 word types were classified into a low language group. Low language children (n = 57) were more likely to be cocaine exposed (63.1\%), with cocaine-exposed children 2.4 times more likely to be in the low language group compared with control children after adjustment for covariates. Prenatal cigarette, but not alcohol exposure, was also significantly related to expressive language delays.},
	language = {eng},
	number = {6},
	journal = {Journal of Communication Disorders},
	author = {Delaney-Black, V. and Covington, C. and Templin, T. and Kershaw, T. and Nordstrom-Klee, B. and Ager, J. and Clark, N. and Surendran, A. and Martier, S. and Sokol, R. J.},
	month = dec,
	year = {2000},
	pmid = {11141028},
	keywords = {aphasia-dementia},
	pages = {463--480; quiz 480--481}
}

@article{lang_[psychometric_1991,
	title = {[{Psychometric} speech studies in {Alzheimer}'s dementia with the {Aachen} aphasia test]},
	volume = {62},
	issn = {0028-2804},
	abstract = {Dementias of the Alzheimer type seem to be frequently accompanied by language disturbances. These may represent a feature which can be of help in distinguishing them from other types of dementias. We used the Aachen aphasia test in 32 patients suffering from Alzheimer dementia according to research criteria, and a mixed sample of 35 patients suffering from other dementias. From these 2 groups 2 subsamples of 21 patients each were gathered which were comparable with regard to age, disease onset, level of education, verbal intelligence and severity of senility. Nevertheless it was possible to distinguish the groups to a certain degree on grounds of psychometric language criteria alone. Alzheimer patients were more severely handicapped communicatively, less dysarthric, produced more automatisms and discretely more phonemic paraphasias with fluent speech which was sometimes paragrammatic. A relatively better level of repetition compared to the Token test and written language was fairly specific. A computer-assisted classification yielded language disturbances similar to Wernicke's aphasia more often than with non-Alzheimer dementias. We found no Alzheimer patients with a Broca's type of language disorder, while amnestic and global types were bound to the level of overall impairment to a certain degree. The significance of these results with regard to the use of psychometric language test in the dementias, particularly Alzheimer's dementia, and to differential diagnostic considerations are reviewed briefly.},
	language = {ger},
	number = {10},
	journal = {Der Nervenarzt},
	author = {Lang, C. and Bozikake-Leisch, E. and Spambalg, M. and Bartelsen, P. and Treig, T.},
	month = oct,
	year = {1991},
	pmid = {1721109},
	keywords = {aphasia-dementia},
	pages = {621--628}
}

@article{rausch_effect_2017,
	title = {The effect of methylphenidate-{OROS}$^{\textrm{®}}$ on the narrative ability of children with attention-deficit hyperactivity disorder},
	volume = {64},
	issn = {2225-4765},
	abstract = {BACKGROUND AND OBJECTIVE: Children with attention-deficit hyperactivity disorder (ADHD) experience difficulty with expressive language, including form (e.g. grammatical construction) and content (e.g. coherence). The current study aimed to investigate the effect of methylphenidate-Osmotic Release Oral System® (MPH-OROS®) on the narrative ability of children with ADHD and language impairment, through the analysis of microstructure and macrostructure narrative elements.
METHOD: In a single group off-on medication test design, narratives were obtained from 12 children with ADHD, aged 7-13 years, using wordless picture books. For microstructure, number of words, type-token ratio and mean length of utterance were derived from narrative samples using Systematic Analysis of Language Transcripts conventions. For macrostructure, the narratives were coded according to the Narrative Scoring Scheme, which includes seven narrative characteristics, as well as a composite score reflecting the child's overall narrative ability.
RESULTS: The administration of MPH-OROS® resulted in a significant difference in certain aspects of language macrostructure: cohesion and overall narrative ability. Little effect was noted in microstructure elements.
CONCLUSION: We observed a positive effect of stimulant medication on the macrostructure, but not on the microstructure, of narrative production. Although stimulant medication improves attention and concentration, it does not improve all aspects of language abilities in children with ADHD. Language difficulties associated with ADHD related to language content and use may be more responsive to stimulant medication than language form, which is likely to be affected by cascading effects of inattention, hyperactivity and impulsivity beginning very early in life and to progress over a more protracted period. Therefore, a combination of treatments is advocated to ensure that children with ADHD are successful in reaching their full potential.},
	language = {eng},
	number = {1},
	journal = {The South African Journal of Communication Disorders = Die Suid-Afrikaanse Tydskrif Vir Kommunikasieafwykings},
	author = {Rausch, Tessa L. and Kendall, Diane L. and Kover, Sara T. and Louw, Elizabeth M. and Zsilavecz, Ursula L. and Van der Merwe, Anita},
	month = feb,
	year = {2017},
	pmid = {28281767},
	pmcid = {PMC5843053},
	keywords = {aphasia-dementia},
	pages = {e1--e12}
}

@article{andreasen_linguistic_1976-1,
	title = {Linguistic analysis of speech in affective disorders},
	volume = {33},
	issn = {0003-990X},
	abstract = {Various aspects of speech and language were compared, using psycholinguistic techniques, in a group of 15 depressed patients and 16 manic patients: lexical diversity, syntactical complexity, syntactical elements, and content analysis. Contrary to anticipation, the manic patients did not show more varied word choice or complexity of sentence structure than the depressives. In particular, they did not differ significantly in type-token ratio. The greatest difference was in syntactical elements, with manics using more action verbs, adjectives, and concrete nouns, while the depressed patients used more state of being verbs, modifying adverbs, first-person pronouns, and personal pronouns. When compared by content analysis, the manics used more words reflecting a concern with power and achievement. These results imply that depressive speech tends to be more vague and qualified and to show considerable self-preoccupation, while manic speech tends to be colorful and concrete and to show more concern with things than with people.},
	language = {eng},
	number = {11},
	journal = {Archives of General Psychiatry},
	author = {Andreasen, N. G. and Pfohl, B.},
	month = nov,
	year = {1976},
	pmid = {985047},
	keywords = {aphasia-dementia},
	pages = {1361--1367}
}

@article{andreasen_linguistic_1976-2,
	title = {Linguistic analysis of speech in affective disorders},
	volume = {33},
	issn = {0003-990X},
	abstract = {Various aspects of speech and language were compared, using psycholinguistic techniques, in a group of 15 depressed patients and 16 manic patients: lexical diversity, syntactical complexity, syntactical elements, and content analysis. Contrary to anticipation, the manic patients did not show more varied word choice or complexity of sentence structure than the depressives. In particular, they did not differ significantly in type-token ratio. The greatest difference was in syntactical elements, with manics using more action verbs, adjectives, and concrete nouns, while the depressed patients used more state of being verbs, modifying adverbs, first-person pronouns, and personal pronouns. When compared by content analysis, the manics used more words reflecting a concern with power and achievement. These results imply that depressive speech tends to be more vague and qualified and to show considerable self-preoccupation, while manic speech tends to be colorful and concrete and to show more concern with things than with people.},
	language = {eng},
	number = {11},
	journal = {Archives of General Psychiatry},
	author = {Andreasen, N. G. and Pfohl, B.},
	month = nov,
	year = {1976},
	pmid = {985047},
	keywords = {aphasia-dementia},
	pages = {1361--1367}
}

@article{pan_maternal_2005,
	title = {Maternal correlates of growth in toddler vocabulary production in low-income families},
	volume = {76},
	issn = {0009-3920},
	doi = {10.1111/j.1467-8624.2005.00876.x},
	abstract = {This study investigated predictors of growth in toddlers' vocabulary production between the ages of 1 and 3 years by analyzing mother-child communication in 108 low-income families. Individual growth modeling was used to describe patterns of growth in children's observed vocabulary production and predictors of initial status and between-person change. Results indicate large variation in growth across children. Observed variation was positively related to diversity of maternal lexical input and maternal language and literacy skills, and negatively related to maternal depression. Maternal talkativeness was not related to growth in children's vocabulary production in this sample. Implications of the examination of longitudinal data from this relatively large sample of low-income families are discussed.},
	language = {eng},
	number = {4},
	journal = {Child Development},
	author = {Pan, Barbara Alexander and Rowe, Meredith L. and Singer, Judith D. and Snow, Catherine E.},
	month = aug,
	year = {2005},
	pmid = {16026495},
	keywords = {aphasia-dementia},
	pages = {763--782},
	file = {Full Text:/Users/transfer/Zotero/storage/35MY42ZS/Pan et al. - 2005 - Maternal correlates of growth in toddler vocabular.pdf:application/pdf}
}

@article{park_harnessing_2018,
	title = {Harnessing {Reddit} to {Understand} the {Written}-{Communication} {Challenges} {Experienced} by {Individuals} {With} {Mental} {Health} {Disorders}: {Analysis} of {Texts} {From} {Mental} {Health} {Communities}},
	volume = {20},
	issn = {1438-8871},
	shorttitle = {Harnessing {Reddit} to {Understand} the {Written}-{Communication} {Challenges} {Experienced} by {Individuals} {With} {Mental} {Health} {Disorders}},
	doi = {10.2196/jmir.8219},
	abstract = {BACKGROUND: Mental disorders such as depression, bipolar disorder, and schizophrenia are common, incapacitating, and have the potential to be fatal. Despite the prevalence and gravity of mental disorders, our knowledge concerning everyday challenges associated with them is relatively limited. One of the most studied deficits related to everyday challenges is language impairment, yet we do not know how mental disorders can impact common forms of written communication, for example, social media.
OBJECTIVE: The aims of this study were to investigate written communication challenges manifest in online mental health communities focusing on depression, bipolar disorder, and schizophrenia, as well as the impact of participating in these online mental health communities on written communication. As the control, we selected three online health communities focusing on positive emotion, exercising, and weight management.
METHODS: We examined lexical diversity and readability, both important features for measuring the quality of writing. We used four well-established readability metrics that consider word frequencies and syntactic complexity to measure writers' written communication ability. We then measured the lexical diversity by calculating the percentage of unique words in posts. To compare lexical diversity and readability among communities, we first applied pairwise independent sample t tests, followed by P value adjustments using the prespecified Hommel procedure to adjust for multiple comparison. To measure the changes, we applied linear least squares regression to the readability and lexical diversity scores against the interaction sequence for each member, followed by pairwise independent sample t tests and P value adjustments. Given the large sample of members, we also report effect sizes and 95\% CIs for the pairwise comparisons.
RESULTS: On average, members of depression, bipolar disorder, and schizophrenia communities showed indications of difficulty expressing their ideas compared with three other online health communities. Our results also suggest that participating in these platforms has the potential to improve members' written communication. For example, members of all three mental health communities showed statistically significant improvement in both lexical diversity and readability compared with members of the OHC focusing on positive emotion.
CONCLUSIONS: We provide new insights into the written communication challenges faced by individuals suffering from depression, bipolar disorder, and schizophrenia. A comparison with three other online health communities suggests that written communication in mental health communities is significantly more difficult to read, while also consisting of a significantly less diverse lexicon. We contribute practical suggestions for utilizing our findings in Web-based communication settings to enhance members' communicative experience. We consider these findings to be an important step toward understanding and addressing everyday written communication challenges among individuals suffering from mental disorders.},
	language = {eng},
	number = {4},
	journal = {Journal of Medical Internet Research},
	author = {Park, Albert and Conway, Mike},
	month = apr,
	year = {2018},
	pmid = {29636316},
	pmcid = {PMC5915669},
	keywords = {aphasia-dementia},
	pages = {e121}
}

@article{resnik_evaluation_nodate,
	title = {Evaluation of {NLP} {Systems}},
	language = {en},
	author = {Resnik, Philip and Lin, Jimmy},
	keywords = {aphasia-dementia},
	pages = {31},
	file = {Resnik and Lin - Evaluation of NLP Systems.pdf:/Users/transfer/Zotero/storage/SEDZ9AL3/Resnik and Lin - Evaluation of NLP Systems.pdf:application/pdf}
}

@article{jones_reflections_1995,
	title = {Reflections on {TREC}.},
	volume = {31},
	number = {3},
	journal = {Inf. Process. Manage.},
	author = {Jones, Karen Sparck},
	year = {1995},
	keywords = {aphasia-dementia},
	pages = {291--314},
	file = {Fulltext:/Users/transfer/Zotero/storage/8LQLJGQC/Jones - 1995 - Reflections on TREC..pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3G8TARYS/Jones - 1995 - Reflections on TREC..pdf:application/pdf}
}

@book{jones_evaluating_1995,
	title = {Evaluating natural language processing systems: {An} analysis and review},
	volume = {1083},
	shorttitle = {Evaluating natural language processing systems},
	publisher = {Springer Science \& Business Media},
	author = {Jones, Karen Sparck and Galliers, Julia R.},
	year = {1995},
	keywords = {aphasia-dementia},
	file = {Snapshot:/Users/transfer/Zotero/storage/CX4DFZ9B/books.html:text/html}
}

@inproceedings{jones_towards_1994,
	title = {Towards better {NLP} system evaluation},
	booktitle = {Proceedings of the workshop on {Human} {Language} {Technology}},
	publisher = {Association for Computational Linguistics},
	author = {Jones, Karen Sparck},
	year = {1994},
	keywords = {aphasia-dementia},
	pages = {102--107},
	file = {Fulltext:/Users/transfer/Zotero/storage/QU6P387J/Jones - 1994 - Towards better NLP system evaluation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LN39G5RL/citation.html:text/html}
}

@article{jones_further_2000,
	title = {Further reflections on {TREC}},
	volume = {36},
	number = {1},
	journal = {Information Processing \& Management},
	author = {Jones, Karen Sparck},
	year = {2000},
	keywords = {aphasia-dementia},
	pages = {37--85},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZAP8ICZ9/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/6WCMNETC/chooseorg.html:text/html}
}

@incollection{jones_natural_1994,
	title = {Natural language processing: a historical review},
	shorttitle = {Natural language processing},
	booktitle = {Current issues in computational linguistics: in honour of {Don} {Walker}},
	publisher = {Springer},
	author = {Jones, Karen Sparck},
	year = {1994},
	keywords = {aphasia-dementia},
	pages = {3--16},
	file = {Fulltext:/Users/transfer/Zotero/storage/NI2D3YBT/Jones - 1994 - Natural language processing a historical review.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/N8EMLTTL/978-0-585-35958-8_1.html:text/html}
}

@article{hirschman_overview_1997,
	title = {Overview of evaluation in speech and natural language processing},
	author = {Hirschman, Lynette and Thompson, Henry S.},
	year = {1997},
	keywords = {aphasia-dementia},
	file = {Snapshot:/Users/transfer/Zotero/storage/AGVPSX23/summary.html:text/html}
}

@article{paroubek_principles_2007-1,
	title = {Principles of evaluation in natural language processing},
	volume = {48},
	number = {1},
	journal = {Traitement Automatique des Langues},
	author = {Paroubek, Patrick and Chaudiron, Stéphane and Hirschman, Lynette},
	year = {2007},
	keywords = {aphasia-dementia},
	pages = {7--31},
	file = {Fulltext:/Users/transfer/Zotero/storage/83R8SJ8D/Paroubek et al. - 2007 - Principles of evaluation in natural language proce.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/VZ3RPGJ7/hal-00502700.html:text/html}
}

@article{hirschman_evolution_1998,
	title = {The evolution of evaluation: {Lessons} from the message understanding conferences},
	volume = {12},
	shorttitle = {The evolution of evaluation},
	number = {4},
	journal = {Computer Speech \& Language},
	author = {Hirschman, Lynette},
	year = {1998},
	keywords = {aphasia-dementia},
	pages = {281--305},
	file = {Fulltext:/Users/transfer/Zotero/storage/GSIIHDGU/openurl.html:text/html;Snapshot:/Users/transfer/Zotero/storage/JE27PFS8/chooseorg.html:text/html}
}

@book{voorhees_trec:_2005,
	title = {{TREC}: {Experiment} and evaluation in information retrieval},
	volume = {1},
	shorttitle = {{TREC}},
	publisher = {MIT press Cambridge},
	author = {Voorhees, Ellen M. and Harman, Donna K.},
	year = {2005},
	keywords = {aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/Y6FFMWK9/Voorhees and Harman - 2005 - TREC Experiment and evaluation in information ret.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/L6Q9KW5G/Voorhees and Harman - 2005 - TREC Experiment and evaluation in information ret.pdf:application/pdf}
}

@article{burck_needed:_1975,
	title = {Needed: {More} evaluation, not research},
	volume = {53},
	shorttitle = {Needed},
	number = {8},
	journal = {The Personnel and Guidance Journal},
	author = {Burck, Harman D. and Peterson, Gary W.},
	year = {1975},
	keywords = {aphasia-dementia},
	pages = {563--569},
	file = {Fulltext:/Users/transfer/Zotero/storage/ENXKVXW7/openurl.html:text/html;Snapshot:/Users/transfer/Zotero/storage/75FFHAGH/j.2164-4918.1975.tb04584.html:text/html}
}

@inproceedings{voorhees_philosophy_2001,
	title = {The philosophy of information retrieval evaluation},
	booktitle = {Workshop of the cross-language evaluation forum for european languages},
	publisher = {Springer},
	author = {Voorhees, Ellen M.},
	year = {2001},
	keywords = {aphasia-dementia},
	pages = {355--370},
	file = {Fulltext:/Users/transfer/Zotero/storage/RTS75CDV/Voorhees - 2001 - The philosophy of information retrieval evaluation.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GRCINJ5D/3-540-45691-0_34.html:text/html}
}

@inproceedings{buckley_retrieval_2004,
	title = {Retrieval evaluation with incomplete information},
	booktitle = {Proceedings of the 27th annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {ACM},
	author = {Buckley, Chris and Voorhees, Ellen M.},
	year = {2004},
	keywords = {aphasia-dementia},
	pages = {25--32},
	file = {Fulltext:/Users/transfer/Zotero/storage/6CMSP6FD/Buckley and Voorhees - 2004 - Retrieval evaluation with incomplete information.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/2TIV98SP/citation.html:text/html}
}

@techreport{buckley_retrieval_2005,
	title = {Retrieval system evaluation},
	author = {Buckley, C. E. and Voorhees, Ellen M.},
	year = {2005},
	keywords = {aphasia-dementia}
}

@inproceedings{buckley_evaluating_2017,
	title = {Evaluating evaluation measure stability},
	volume = {51},
	booktitle = {{ACM} {SIGIR} {Forum}},
	publisher = {ACM},
	author = {Buckley, Chris and Voorhees, Ellen M.},
	year = {2017},
	keywords = {aphasia-dementia},
	pages = {235--242}
}

@article{cohen_three_2018,
	title = {Three {Dimensions} of {Reproducibility} in {Natural} {Language} {Processing}},
	volume = {2018},
	abstract = {Despite considerable recent attention to problems with reproducibility of scientific research, there is a striking lack of agreement about the definition of the term. That is a problem, because the lack of a consensus definition makes it difficult to compare studies of reproducibility, and thus to have even a broad overview of the state of the issue in natural language processing. This paper proposes an ontology of reproducibility in that field. Its goal is to enhance both future research and communication about the topic, and retrospective meta-analyses. We show that three dimensions of reproducibility, corresponding to three kinds of claims in natural language processing papers, can account for a variety of types of research reports. These dimensions are reproducibility of a conclusion, of a finding, and of a value. Three biomedical natural language processing papers by the authors of this paper are analyzed with respect to these dimensions.},
	language = {eng},
	journal = {LREC ... International Conference on Language Resources \& Evaluation: [proceedings]. International Conference on Language Resources and Evaluation},
	author = {Cohen, K. Bretonnel and Xia, Jingbo and Zweigenbaum, Pierre and Callahan, Tiffany J. and Hargraves, Orin and Goss, Foster and Ide, Nancy and Névéol, Aurélie and Grouin, Cyril and Hunter, Lawrence E.},
	month = may,
	year = {2018},
	pmid = {29911205},
	pmcid = {PMC5998676},
	keywords = {reproducibility, aphasia-dementia},
	pages = {156--165}
}

@article{baumer_r_2014,
	title = {R {Markdown}: {Integrating} a reproducible analysis tool into introductory statistics},
	shorttitle = {R {Markdown}},
	journal = {arXiv preprint arXiv:1402.1894},
	author = {Baumer, Ben and Cetinkaya-Rundel, Mine and Bray, Andrew and Loi, Linda and Horton, Nicholas J.},
	year = {2014},
	keywords = {aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/IJXSD4IX/Baumer et al. - 2014 - R Markdown Integrating a reproducible analysis to.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/BC2GHQN4/1402.html:text/html}
}

@article{baumer_r_2015,
	title = {R markdown},
	volume = {7},
	number = {3},
	journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
	author = {Baumer, Benjamin and Udwin, Dana},
	year = {2015},
	keywords = {aphasia-dementia},
	pages = {167--177},
	file = {Fulltext:/Users/transfer/Zotero/storage/GJ5766ME/openurl.html:text/html;Snapshot:/Users/transfer/Zotero/storage/MDYWXAKQ/wics.html:text/html}
}

@misc{noauthor_speech_nodate,
	title = {Speech {Recognition} {Interfaces} {Improve} {Flight} {Safety}},
	url = {https://spinoff.nasa.gov/Spinoff2012/t_4.html},
	urldate = {2018-10-11},
	keywords = {aphasia-dementia},
	file = {Speech Recognition Interfaces Improve Flight Safety:/Users/transfer/Zotero/storage/3WQV88IA/t_4.html:text/html}
}

@article{libbrecht_machine_2015,
	title = {Machine learning applications in genetics and genomics},
	volume = {16},
	issn = {1471-0064},
	doi = {10.1038/nrg3920},
	abstract = {The field of machine learning, which aims to develop computer algorithms that improve with experience, holds promise to enable computers to assist humans in the analysis of large, complex data sets. Here, we provide an overview of machine learning applications for the analysis of genome sequencing data sets, including the annotation of sequence elements and epigenetic, proteomic or metabolomic data. We present considerations and recurrent challenges in the application of supervised, semi-supervised and unsupervised machine learning methods, as well as of generative and discriminative modelling approaches. We provide general guidelines to assist in the selection of these machine learning methods and their practical application for the analysis of genetic and genomic data sets.},
	language = {eng},
	number = {6},
	journal = {Nature Reviews. Genetics},
	author = {Libbrecht, Maxwell W. and Noble, William Stafford},
	month = jun,
	year = {2015},
	pmid = {25948244},
	pmcid = {PMC5204302},
	keywords = {aphasia-dementia},
	pages = {321--332},
	file = {Accepted Version:/Users/transfer/Zotero/storage/HVXDZ3BQ/Libbrecht and Noble - 2015 - Machine learning applications in genetics and geno.pdf:application/pdf}
}

@article{parmar_machine_2015,
	title = {Machine {Learning} methods for {Quantitative} {Radiomic} {Biomarkers}},
	volume = {5},
	issn = {2045-2322},
	doi = {10.1038/srep13087},
	abstract = {Radiomics extracts and mines large number of medical imaging features quantifying tumor phenotypic characteristics. Highly accurate and reliable machine-learning approaches can drive the success of radiomic applications in clinical care. In this radiomic study, fourteen feature selection methods and twelve classification methods were examined in terms of their performance and stability for predicting overall survival. A total of 440 radiomic features were extracted from pre-treatment computed tomography (CT) images of 464 lung cancer patients. To ensure the unbiased evaluation of different machine-learning methods, publicly available implementations along with reported parameter configurations were used. Furthermore, we used two independent radiomic cohorts for training (n = 310 patients) and validation (n = 154 patients). We identified that Wilcoxon test based feature selection method WLCX (stability = 0.84 ± 0.05, AUC = 0.65 ± 0.02) and a classification method random forest RF (RSD = 3.52\%, AUC = 0.66 ± 0.03) had highest prognostic performance with high stability against data perturbation. Our variability analysis indicated that the choice of classification method is the most dominant source of performance variation (34.21\% of total variance). Identification of optimal machine-learning methods for radiomic applications is a crucial step towards stable and clinically relevant radiomic biomarkers, providing a non-invasive way of quantifying and monitoring tumor-phenotypic characteristics in clinical practice.},
	language = {eng},
	journal = {Scientific Reports},
	author = {Parmar, Chintan and Grossmann, Patrick and Bussink, Johan and Lambin, Philippe and Aerts, Hugo J. W. L.},
	month = aug,
	year = {2015},
	pmid = {26278466},
	pmcid = {PMC4538374},
	keywords = {aphasia-dementia},
	pages = {13087},
	file = {Full Text:/Users/transfer/Zotero/storage/ZHMSFSUD/Parmar et al. - 2015 - Machine Learning methods for Quantitative Radiomic.pdf:application/pdf}
}

@misc{noauthor_machine_nodate,
	title = {Machine learning applications in cancer prognosis and prediction. - {PubMed} - {NCBI}},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/25750696},
	urldate = {2018-10-11},
	keywords = {aphasia-dementia},
	file = {Machine learning applications in cancer prognosis and prediction. - PubMed - NCBI:/Users/transfer/Zotero/storage/FED4M4SF/25750696.html:text/html}
}

@article{wang_machine_2012,
	title = {Machine learning and radiology},
	volume = {16},
	issn = {1361-8423},
	doi = {10.1016/j.media.2012.02.005},
	abstract = {In this paper, we give a short introduction to machine learning and survey its applications in radiology. We focused on six categories of applications in radiology: medical image segmentation, registration, computer aided detection and diagnosis, brain function or activity analysis and neurological disease diagnosis from fMR images, content-based image retrieval systems for CT or MRI images, and text analysis of radiology reports using natural language processing (NLP) and natural language understanding (NLU). This survey shows that machine learning plays a key role in many radiology applications. Machine learning identifies complex patterns automatically and helps radiologists make intelligent decisions on radiology data such as conventional radiographs, CT, MRI, and PET images and radiology reports. In many applications, the performance of machine learning-based automatic detection and diagnosis systems has shown to be comparable to that of a well-trained and experienced radiologist. Technology development in machine learning and radiology will benefit from each other in the long run. Key contributions and common characteristics of machine learning techniques in radiology are discussed. We also discuss the problem of translating machine learning applications to the radiology clinical setting, including advantages and potential barriers.},
	language = {eng},
	number = {5},
	journal = {Medical Image Analysis},
	author = {Wang, Shijun and Summers, Ronald M.},
	month = jul,
	year = {2012},
	pmid = {22465077},
	pmcid = {PMC3372692},
	keywords = {aphasia-dementia},
	pages = {933--951},
	file = {Accepted Version:/Users/transfer/Zotero/storage/P4H6SH6R/Wang and Summers - 2012 - Machine learning and radiology.pdf:application/pdf}
}

@article{khalili_contact-induced_2016,
	title = {Contact-{Induced} {Cross}-{Dialectal} {Phonetic} {Variability} in an {Endangered} {Iranian} {Language}: the {Case} of {Taleshi}},
	shorttitle = {Contact-{Induced} {Cross}-{Dialectal} {Phonetic} {Variability} in an {Endangered} {Iranian} {Language}},
	author = {Khalili, Niloofar Nathalie},
	year = {2016},
	keywords = {Statistics as Topic, aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/M54CW5I9/Khalili - 2016 - Contact-Induced Cross-Dialectal Phonetic Variabili.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/TFXFINAJ/60.html:text/html}
}

@inproceedings{aralova_acoustic_2011,
	title = {The acoustic correlates of tongue root vowel harmony in {Even} ({Tungusic})},
	booktitle = {Proceedings of the 17th {International} {Congress} of {Phonetic} {Sciences} ({ICPhS} {XVII})},
	author = {Aralova, Natalia and Grawunder, Sven and Winter, Bodo},
	year = {2011},
	keywords = {Statistics as Topic, aphasia-dementia},
	pages = {240--243},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZK6X4EI8/Aralova et al. - 2011 - The acoustic correlates of tongue root vowel harmo.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HGFKVYGD/Aralova et al. - 2011 - The acoustic correlates of tongue root vowel harmo.pdf:application/pdf}
}

@article{kirby_mixed-effects_2018,
	title = {Mixed-effects design analysis for experimental phonetics},
	volume = {70},
	journal = {Journal of Phonetics},
	author = {Kirby, James and Sonderegger, Morgan},
	year = {2018},
	keywords = {Statistics as Topic, aphasia-dementia},
	pages = {70--85},
	file = {Fulltext:/Users/transfer/Zotero/storage/HI7ENITB/openurl.html:text/html;Snapshot:/Users/transfer/Zotero/storage/UWMBGHW6/S0095447017301390.html:text/html}
}

@article{winter_very_2013,
	title = {A very basic tutorial for performing linear mixed effects analyses},
	journal = {arXiv preprint arXiv:1308.5499},
	author = {Winter, Bodo},
	year = {2013},
	keywords = {Statistics as Topic, aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/GNFH3UZ6/Winter - 2013 - A very basic tutorial for performing linear mixed .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/TMITZ94U/Winter - 2013 - A very basic tutorial for performing linear mixed .pdf:application/pdf}
}

@inproceedings{winter_pseudoreplication_2011,
	title = {Pseudoreplication in phonetic research},
	booktitle = {Proceedings of the international congress of phonetic science},
	author = {Winter, Bodo},
	year = {2011},
	keywords = {Statistics as Topic, aphasia-dementia},
	pages = {2137--2140},
	file = {Fulltext:/Users/transfer/Zotero/storage/H8DEF7DL/Winter - 2011 - Pseudoreplication in phonetic research.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LSGPPQML/Winter - 2011 - Pseudoreplication in phonetic research.pdf:application/pdf}
}

@inproceedings{winter_other_2015,
	title = {The other {N}: the role of repetitions and items in the design of phonetic experiments},
	shorttitle = {The other {N}},
	booktitle = {Proceedings of the 18th {International} {Congress} of {Phonetic} {Sciences}. {Glasgow}: {The} {University} of {Glasgow}},
	author = {Winter, Bodo},
	year = {2015},
	keywords = {Statistics as Topic, aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/2ND7EV28/Winter - 2015 - The other N the role of repetitions and items in .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/V7GI4C3L/Winter - 2015 - The other N the role of repetitions and items in .pdf:application/pdf}
}

@article{winter_linear_2013,
	title = {Linear models and linear mixed effects models in {R} with linguistic applications},
	journal = {arXiv preprint arXiv:1308.5499},
	author = {Winter, Bodo},
	year = {2013},
	keywords = {Statistics as Topic, aphasia-dementia},
	file = {Fulltext:/Users/transfer/Zotero/storage/HHR68FTE/Winter - 2013 - Linear models and linear mixed effects models in R.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/GD5ZXD5S/1308.html:text/html}
}

@article{meilan_speech_2014,
	title = {Speech in {Alzheimer}'s disease: can temporal and acoustic parameters discriminate dementia?},
	volume = {37},
	issn = {1421-9824},
	shorttitle = {Speech in {Alzheimer}'s disease},
	doi = {10.1159/000356726},
	abstract = {AIMS: The study explores how speech measures may be linked to language profiles in participants with Alzheimer's disease (AD) and how these profiles could distinguish AD from changes associated with normal aging.
METHODS: We analysed simple sentences spoken by older adults with and without AD. Spectrographic analysis of temporal and acoustic characteristics was carried out using the Praat software.
RESULTS: We found that measures of speech, such as variations in the percentage of voice breaks, number of periods of voice, number of voice breaks, shimmer (amplitude perturbation quotient), and noise-to-harmonics ratio, characterise people with AD with an accuracy of 84.8\%.
DISCUSSION: These measures offer a sensitive method of assessing spontaneous speech output in AD, and they discriminate well between people with AD and healthy older adults. This method of evaluation is a promising tool for AD diagnosis and prognosis, and it could be used as a dependent measure in clinical trials.},
	language = {eng},
	number = {5-6},
	journal = {Dementia and Geriatric Cognitive Disorders},
	author = {Meilán, Juan José G. and Martínez-Sánchez, Francisco and Carro, Juan and López, Dolores E. and Millian-Morell, Lymarie and Arana, José M.},
	year = {2014},
	pmid = {24481220},
	keywords = {aphasia-dementia},
	pages = {327--334}
}

@article{martinez-sanchez_[expressive_2012,
	title = {[{Expressive} prosodic patterns in individuals with {Alzheimer}'s disease]},
	volume = {24},
	issn = {1886-144X},
	abstract = {This paper describes a useful technique for quantifying the degree of speech deficits in dementia of GDS 4 Alzheimer's type (DAT). Production of prosodic speech in DAT patients and healthy older controls was analysed using variation in fundamental frequency (F0) measures on a reading task. The prosogram computational model was used to analyze the prosodic contours of the speech samples, using melodic styling of F0 based on perceptual principles and prominence detection of spectral and amplitude fluctuations in the speech signal. Results revealed significant differences in most of these prosodic parameters among the DAT group. Normal pitch variation in speech and variations in syllable timing were reduced in the DAT group, these features cause "flat" speech prosody in these patients. These speech parameters may have diagnostic and prognostic value for Alzheimer's disease and therefore could be a useful aid in clinical trials.},
	language = {spa},
	number = {1},
	journal = {Psicothema},
	author = {Martínez-Sánchez, Francisco and García Meilán, Juan José and Pérez, Enrique and Carro, Juan and Arana, José María},
	month = feb,
	year = {2012},
	pmid = {22269358},
	keywords = {aphasia-dementia},
	pages = {16--21}
}

@article{meilan_acoustic_2012,
	title = {Acoustic markers associated with impairment in language processing in {Alzheimer}'s {Disease}},
	volume = {15},
	issn = {1138-7416},
	abstract = {This study broaches in a novel way the analysis of cognitive impairment characteristic of the early stages of Alzheimer's Disease (AD). Specifically, we attempt to determine the acoustic speech parameters that are sensitive to the onset of the disease, and their association with the language deficit characteristic of AD. Speech analysis was carried out on 21 elderly patients with AD using Praat software, which analyzes the acoustic components of speech. The data obtained were subjected to stepwise regression, using the overall scores obtained in the test as the criterion variable, and the scores on the frequency, amplitude and periodicity variables as predictors of performance. We found that the percentage of voiceless segments explains a significant portion of the variance in the overall scores obtained in the neuropsychological test. This component seems to be related mainly to the patient's ability in phonological fluency. This finding could permit the creation of a diagnostic test for AD through analysis of the acoustic speech parameters at very low cost in terms of both time and resources.},
	language = {eng},
	number = {2},
	journal = {The Spanish Journal of Psychology},
	author = {Meilán, Juan J. G. and Martínez-Sánchez, Francisco and Carro, Juan and Sánchez, José A. and Pérez, Enrique},
	month = jul,
	year = {2012},
	pmid = {22774422},
	keywords = {aphasia-dementia},
	pages = {487--494}
}

@article{small_role_2009,
	title = {The role of caregiver prosody in conversations with persons who have {Alzheimer}'s disease},
	volume = {24},
	issn = {1938-2731},
	doi = {10.1177/1533317509342981},
	abstract = {This research was supported in part by funding from the British Columbia Medical Services Foundation (BCM02-0115). The funding source had no role in the design, methods, participant recruitment, data collection, interpretation of the study, or in the preparation of the manuscript for publication. Approval for the study was granted by the University of British Columbia Behavioural Ethics Review Board, and participants provided informed consent. This study investigated whether aspects of family caregivers' prosody (pitch and loudness) would be associated with successful or unsuccessful conversations with spouses who have Alzheimer's disease (AD). Secondary analysis was conducted of 12 caregivers' speech when interacting with spouses who have AD. Acoustic analyses were conducted to calculate the fundamental frequency (pitch) and intensity (loudness) of caregivers' speech. The results showed no significant overall differences between the caregivers' pitch or loudness in either successful or unsuccessful conversations. However, for 1 subgroup of caregivers, an increase in pitch variation and loudness was associated with unsuccessful communication, whereas for another subgroup the opposite pattern was observed-reduced pitch variation and loudness with unsuccessful communication. The results provide preliminary directions for helping family caregivers become aware of how characteristics of their speech prosody may relate to the quality of communication when interacting with persons who have AD.},
	language = {eng},
	number = {6},
	journal = {American Journal of Alzheimer's Disease and Other Dementias},
	author = {Small, Jeff A. and Huxtable, Angela and Walsh, Martina},
	month = jan,
	year = {2009},
	pmid = {19759253},
	keywords = {aphasia-dementia},
	pages = {469--475}
}

@article{boelen_[speech_1999,
	title = {[{Speech} comprehension by patients with {Alzheimer} disease. {Possibilities} for improvement]},
	volume = {30},
	issn = {0167-9228},
	abstract = {Ten patients with the Alzheimer's disease and a mild hearing loss were tested with an audiotape with speech discrimination tests. The low frequency sounds on this audiotape had a delay of respectively 1, 2, 3 and 4 milliseconds with regard to the high frequency sounds. With a delay of 3 milliseconds the patients had a significant improvement in their speech understanding compared to the normal speech discrimination test. Patients with the Alzheimer's disease have a significant loss of haircells in the basal turn of the cochlea. This loss disturbs the function of the traveling wave of sound vibration in the basilar membrane of the cochlea. The traveling wave has no inhibition on its way through this disturbed basilar membrane. When the effect of the too fast running traveling wave was compensated by presenting the above-mentioned tape, the improvement of the speech intelligibility was significant.},
	language = {dut},
	number = {4},
	journal = {Tijdschrift Voor Gerontologie En Geriatrie},
	author = {Boelen, H. J. and Veen, C.},
	month = aug,
	year = {1999},
	pmid = {10486621},
	keywords = {aphasia-dementia},
	pages = {164--167}
}

@article{garrard_motif_2017,
	title = {Motif {Discovery} in {Speech}: {Application} to {Monitoring} {Alzheimer}'s {Disease}},
	volume = {14},
	issn = {1875-5828},
	shorttitle = {Motif {Discovery} in {Speech}},
	doi = {10.2174/1567205014666170309121025},
	abstract = {BACKGROUND: Perseveration - repetition of words, phrases or questions in speech - is commonly described in Alzheimer's disease (AD). Measuring perseveration is difficult, but may index cognitive performance, aiding diagnosis and disease monitoring. Continuous recording of speech would produce a large quantity of data requiring painstaking manual analysis, and risk violating patients' and others' privacy. A secure record and an automated approach to analysis are required.
OBJECTIVES: To record bone-conducted acoustic energy fluctuations from a subject's vocal apparatus using an accelerometer, to describe the recording and analysis stages in detail, and demonstrate that the approach is feasible in AD.
METHODS: Speech-related vibration was captured by an accelerometer, affixed above the temporomandibular joint. Healthy subjects read a script with embedded repetitions. Features were extracted from recorded signals and combined using Principal Component Analysis to obtain a one-dimensional representation of the feature vector. Motif discovery techniques were used to detect repeated segments. The equipment was tested in AD patients to determine device acceptability and recording quality.
RESULTS: Comparison with the known location of embedded motifs suggests that, with appropriate parameter tuning, the motif discovery method can detect repetitions. The device was acceptable to patients and produced adequate signal quality in their home environments.
CONCLUSION: We established that continuously recording bone-conducted speech and detecting perseverative patterns were both possible. In future studies we plan to associate the frequency of verbal repetitions with stage, progression and type of dementia. It is possible that the method could contribute to the assessment of disease-modifying treatments.},
	language = {eng},
	number = {9},
	journal = {Current Alzheimer Research},
	author = {Garrard, Peter and Nemes, Vanda and Nikolic, Dragana and Barney, Anna},
	year = {2017},
	pmid = {28290243},
	keywords = {aphasia-dementia},
	pages = {951--959},
	file = {Submitted Version:/Users/transfer/Zotero/storage/Z5R8JZI8/Garrard et al. - 2017 - Motif Discovery in Speech Application to Monitori.pdf:application/pdf}
}

@article{lieberman_mount_2005,
	title = {Mount {Everest}: a space analogue for speech monitoring of cognitive deficits and stress},
	volume = {76},
	issn = {0095-6562},
	shorttitle = {Mount {Everest}},
	abstract = {In deep-space missions, the basal ganglia and hippocampus, subcortical structures of the brain that play critical roles in motor activity, cognition, and memory, will be vulnerable to damage from cosmic rays. These metabolically active structures are also sensitive to damage arising from the low oxygen content of air at extreme altitudes. We have, therefore, used Mount Everest as an analogue for deep space, where astronauts will be subject to danger and stress as well as neural damage. We can ethically obtain data because our climber-subjects already intend to climb Mt. Everest. We record speech and test cognitive and linguistic performance before, during, and after exposure to hypoxic conditions. From these data we have derived and validated computer-implemented acoustic voice measures that track slight as well as profound cognitive impairment. Vowel duration and speech motor sequencing errors increase as climbers ascend, reflecting degraded basal ganglia activity. These metrics detect deficits in language comprehension and the ability to change plans in changing circumstances. Preliminary analyses also reveal memory deficits reflecting hippocampal damage. Our speech metrics are unobtrusive and do not reveal the content of a verbal message; they could be derived automatically, allowing space crews to detect subtle motor and cognitive deficits and invoke countermeasures before performance is profoundly impaired. In future work we will be validating the voice metrics of stress in collaboration with the Dinges NSBRI laboratory study of task-induced stress. Our procedures can also be applied in general aviation and in the treatment of Parkinson's disease, Alzheimer's dementia, and other neurological disorders.},
	language = {eng},
	number = {6 Suppl},
	journal = {Aviation, Space, and Environmental Medicine},
	author = {Lieberman, Philip and Morey, Angie and Hochstadt, Jesse and Larson, Mara and Mather, Sandra},
	month = jun,
	year = {2005},
	pmid = {15943213},
	keywords = {aphasia-dementia},
	pages = {B198--207}
}

@article{ulatowska_production_2013,
	title = {Production and comprehension in aphasia: gains and pitfalls in using macrostructure tasks in {Aesop}'s fables},
	volume = {15},
	issn = {1754-9515},
	shorttitle = {Production and comprehension in aphasia},
	doi = {10.3109/17549507.2013.794476},
	abstract = {Macrostructures provide the global meaning of a text. Using Aesop's fables, the main goal of this study has been to identify the advantages and limitations in using the macrostructure tasks of retell, summary, lesson, and gist as clinical tools in understanding 16 patients with mild-to-moderate aphasia. Results suggest that all of the macrostructure tasks are important in determining the production skills of patients with aphasia. Comprehension, on the other hand, is best determined through the macrostructure tasks of retell and lesson. In addition to the language processing skills of patients with aphasia, macrostructures also provide a cognitive picture of how patients manipulate information from stories (i.e., reducing information, making inferences, and generalizing didactic information). Inherent limitations, however, are seen when interpreting possible reasons why patients with aphasia are unable to perform some of these tasks. Given that the potential gains of using macrostructure tasks outweigh the limitations, this study suggests that macrostructures may have clinical value as a diagnostic tool in understanding the cognitive-linguistic processes of patients with brain injury.},
	language = {eng},
	number = {6},
	journal = {International Journal of Speech-Language Pathology},
	author = {Ulatowska, Hanna K. and Reyes, Belinda and Olea Santos, Tricia and Garst, Diane and Mak, Kelly and Graham, Kelly},
	month = dec,
	year = {2013},
	pmid = {23721371},
	keywords = {aphasia-dementia},
	pages = {634--642}
}

@article{leheckova_assessment_2012,
	title = {Assessment and treatment of aphasia in czech},
	volume = {64},
	issn = {1421-9972},
	doi = {10.1159/000340013},
	abstract = {Intervention approaches to aphasia differ in different countries. The aim of this paper is to give an overview of the situation in the Czech Republic. The following topics are summarized: (1) Czech logopedics in aphasiology; (2) the assessment of aphasia; (3) the treatment of aphasia; (4) Czech aphasiologic material; (5) the qualification of clinical logopedists, and (6) regulations of aphasiologic care. Czech is a very intricate language, both phonetically and grammatically. The prevalence of consonants appearing in long sequences (a whole sentence can be constructed purely of consonants) makes it difficult to pronounce. The strong inflecting character with hundreds of grammatical forms for each inflected word makes it difficult to use correct morphology and syntax. These facts make Czech a real challenge both for aphasics and logopedists. An overview of aphasia tests and treatment methods used in the Czech Republic, as well as conditions of logopedic care are given. The paper will allow comparison with the situation in other countries.},
	language = {eng},
	number = {4},
	journal = {Folia phoniatrica et logopaedica: official organ of the International Association of Logopedics and Phoniatrics (IALP)},
	author = {Lehečková, Helena},
	year = {2012},
	pmid = {23108445},
	keywords = {aphasia-dementia},
	pages = {165--168}
}

@article{vukovic_analysis_2012,
	title = {Analysis of voice impairment in aphasia after stroke-underlying neuroanatomical substrates},
	volume = {123},
	issn = {1090-2155},
	doi = {10.1016/j.bandl.2012.06.008},
	abstract = {Phonation is a fundamental feature of human communication. Control of phonation in the context of speech-language disturbances has traditionally been considered a characteristic of lesions to subcortical structures and pathways. Evidence suggests however, that cortical lesions may also implicate phonation. We carried out acoustic and perceptual analyses of the phonation of /a/ in 60 males with aphasia (20 Wernicke's, 20 Broca's, 20 subcortical aphasia) and 20 males matched in age with no neurological or speech-language disturbances. All groups with aphasia were significantly more impaired on the majority of acoustic and perceptual measures as compared with the control speakers. Within the subjects with aphasia, subjects with subcortical aphasia were more impaired on most measures compared to subjects with Broca's aphasia, and they, in turn, more impaired than those with Wernicke's aphasia. Lesions in regions involved in sound production-perception result in dysfunction of the entire neurocognitive system of articulation-phonological language processing.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Vuković, Mile and Sujić, Radmila and Petrović-Lazić, Mirjana and Miller, Nick and Milutinović, Dejan and Babac, Snežana and Vuković, Irena},
	month = oct,
	year = {2012},
	pmid = {22863300},
	keywords = {aphasia-dementia},
	pages = {22--29}
}

@article{wilson_inflectional_2014,
	title = {Inflectional morphology in primary progressive aphasia: an elicited production study},
	volume = {136},
	issn = {1090-2155},
	shorttitle = {Inflectional morphology in primary progressive aphasia},
	doi = {10.1016/j.bandl.2014.07.001},
	abstract = {Inflectional morphology lies at the intersection of phonology, syntax and the lexicon, three language domains that are differentially impacted in the three main variants of primary progressive aphasia (PPA). To characterize spared and impaired aspects of inflectional morphology in PPA, we elicited inflectional morphemes in 48 individuals with PPA and 13 healthy age-matched controls. We varied the factors of regularity, frequency, word class, and lexicality, and used voxel-based morphometry to identify brain regions where atrophy was predictive of deficits on particular conditions. All three PPA variants showed deficits in inflectional morphology, with the specific nature of the deficits dependent on the anatomical and linguistic features of each variant. Deficits in inflecting low-frequency irregular words were associated with semantic PPA, with lexical/semantic deficits, and with left temporal atrophy. Deficits in inflecting pseudowords were associated with non-fluent/agrammatic and logopenic variants, with phonological deficits, and with left frontal and parietal atrophy.},
	language = {eng},
	journal = {Brain and Language},
	author = {Wilson, Stephen M. and Brandt, Temre H. and Henry, Maya L. and Babiak, Miranda and Ogar, Jennifer M. and Salli, Chelsey and Wilson, Lisa and Peralta, Karen and Miller, Bruce L. and Gorno-Tempini, Maria Luisa},
	month = sep,
	year = {2014},
	pmid = {25129631},
	pmcid = {PMC4159758},
	keywords = {aphasia-dementia},
	pages = {58--68},
	file = {Accepted Version:/Users/transfer/Zotero/storage/TMVG7T8Q/Wilson et al. - 2014 - Inflectional morphology in primary progressive aph.pdf:application/pdf}
}

@article{sang_agrammatic_2015,
	title = {Agrammatic aphasia verb and argument patterns in {Kiswahili}-{English} spontaneous language},
	volume = {62},
	issn = {2225-4765},
	abstract = {BACKGROUND: The spontaneous and narrative language of Kiswahili agrammatic aphasic and non-brain-damaged speakers was analysed. The bilingual participants were also tested in English to enable comparisons of verb production in the two languages. The significance of this study was to characterise bilingual Kiswahili-English spontaneous agrammatic output. This was done by describing Kiswahili-English bilingual output data with a specific focus on the production of verbs. The description involves comparison of verb and argument production in Kiswahili and English.
METHODS AND PROCEDURES: The participants recruited for this study were drawn from two groups of participants (six non-fluent aphasic/agrammatic speakers and six non-brain-damaged). From each participant, a sample of spontaneous output was tape-recorded in English and Kiswahili based on the description and narration of the Flood rescue picture' and the 'Cookie theft picture'. The data elicited were compared for each subject and between the participants and relevant verb parameters have been analysed. The variables that were studied included mean length of utterance (MLU), inflectional errors, verb tokens and types, copulas and auxiliaries. Further, all verbs produced were classified as per their argument structure.
RESULTS: The results from English data supported previous findings on agrammatic output. The agrammatic participants produced utterances with shorter MLU and simpler sentence structure. However, Kiswahili data surprisingly showed reversed results, with agrammatic speakers producing longer utterances than non-brain-damaged (NBD) controls. The results also revealed selective impairment in some agrammatic speakers who made inflectional errors. The verb argument structure showed contrasting results, with agrammatic speakers preferring transitive verbs whilst the NBD speakers used more intransitive verbs.
CONCLUSIONS: The study attempts for the first time to characterise English-Kiswahili bilingual spontaneous and narrative output. A quantitative analysis of verb and argument production is conducted. The results of the English data are consistent with those in the literature; agrammatic speakers produce utterances with shorter MLU and simpler sentence structure. However, Kiswahili data reveals a surprisingly reversed pattern most notably with respect to MLU with agrammatics producing longer utterances than NBD controls. Argument structure analysis revealed that agrammatics used more transitive verbs than intransitives.},
	language = {eng},
	number = {1},
	journal = {The South African Journal of Communication Disorders = Die Suid-Afrikaanse Tydskrif Vir Kommunikasieafwykings},
	author = {Sang, Hillary K.},
	month = jun,
	year = {2015},
	pmid = {26304215},
	keywords = {aphasia-dementia},
	pages = {E1--10}
}

@article{rhys_adaptation_2013,
	title = {Adaptation to aphasia: grammar, prosody and interaction},
	volume = {27},
	issn = {1464-5076},
	shorttitle = {Adaptation to aphasia},
	doi = {10.3109/02699206.2012.736010},
	abstract = {This paper investigates recurrent use of the phrase very good by a speaker with non-fluent agrammatic aphasia. Informal observation of the speaker's interaction reveals that she appears to be an effective conversational partner despite very severe word retrieval difficulties that result in extensive reliance on variants of the phrase very good. The question that this paper addresses using an essentially conversation analytic framework is: What is the speaker achieving through these variants of very good and what are the linguistic and interactional resources that she draws on to achieve these communicative effects? Tokens of very good in the corpus were first analyzed in a bottom-up fashion, attending to sequential position, structure and participant orientation. This revealed distinct uses that were subsequently subjected to detailed acoustic analysis in order to investigate specific prosodic characteristics within and across the interactional variants. We identified specific clusters of prosodic cues that were exploited by the speaker to differentiate interactional uses of very good. The analysis thus shows how, in the adaptation to aphasia, the speaker exploits the rich interface between prosody, grammar and interaction both to manage the interactional demands of conversation and to communicate propositional content.},
	language = {eng},
	number = {1},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Rhys, Catrin S. and Ulbrich, Christiane and Ordin, Mikhail},
	month = jan,
	year = {2013},
	pmid = {23237417},
	keywords = {aphasia-dementia},
	pages = {46--71}
}

@article{kopkalli-yavuz_analysis_2011,
	title = {Analysis of {VOT} in {Turkish} speakers with aphasia},
	volume = {25},
	issn = {1464-5076},
	doi = {10.3109/02699206.2010.529541},
	abstract = {Studies investigating voicing onset time (VOT) production by speakers with aphasia have shown that nonfluent aphasics show a deficit in the articulatory programming of speech sounds based on the range of VOT values produced by aphasic individuals. If the VOT value lies between the normal range of VOT for the voiced and voiceless categories, then it is a phonetic distortion, thus a phonetic/articulatory deficit. A number of studies in different languages (French, English, Thai, Taiwanese) have investigated VOT in aphasic subjects in which their VOT values have been compared to those of normal speakers. This study investigates the VOT productions of voiced and voiceless stops by Turkish speakers with aphasia. Six patients with different aetiologies but similar language characteristics participated in this study. The results suggest that although Turkish nonfluent aphasics exhibit unimodal distribution of VOT production, the VOT values and ranges show language-specific properties.},
	language = {eng},
	number = {4},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Kopkalli-Yavuz, Handan and Mavis, Ilknur and Akyildiz, Didem},
	month = apr,
	year = {2011},
	pmid = {21091206},
	keywords = {aphasia-dementia},
	pages = {287--301}
}

@article{dunton_investigating_2011,
	title = {Investigating the impact of unfamiliar speaker accent on auditory comprehension in adults with aphasia},
	volume = {46},
	issn = {1460-6984},
	doi = {10.3109/13682820903560294},
	abstract = {BACKGROUND: In an increasingly multicultural society, all individuals are likely to come into contact with speakers with unfamiliar accents. Recent figures suggest that such accent variation may be particularly apparent within the healthcare workforce. Research on accent variation has demonstrated that an unfamiliar speaker accent can affect listener comprehension, but the impact of speaker accent on the comprehension skills of listeners with neurological impairment has not been widely explored.
AIMS: To investigate the effect of an unfamiliar accent on the sentence comprehension of individuals with aphasia following stroke.
METHODS \& PROCEDURES: The impact of two different accents (south-east England and Nigerian) on accuracy and response time for 16 individuals with aphasia and 16 healthy control subjects was measured. Participants were presented with a computerized sentence-to-picture matching task and their accuracy and response times were recorded.
OUTCOMES \& RESULTS: Results showed that individuals with aphasia made significantly more errors in comprehension of sentences spoken in an unfamiliar accent than in a familiar accent, a finding that was not demonstrated by the control group when outliers were excluded. Individuals with aphasia were slower overall; however, response times did not show significant effects of speaker accent for either group.
CONCLUSIONS \& IMPLICATIONS: The impact of speaker accent should be considered in the rehabilitation of individuals with aphasia following stroke. Clinical implications include the possibility of underestimating an individual's language abilities on assessment, and the potential errors in comprehension that may occur.},
	language = {eng},
	number = {1},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Dunton, Jane and Bruce, Carolyn and Newton, Caroline},
	month = feb,
	year = {2011},
	pmid = {20178407},
	keywords = {aphasia-dementia},
	pages = {63--73}
}

@article{maas_feedforward_2015,
	title = {Feedforward and feedback control in apraxia of speech: effects of noise masking on vowel production},
	volume = {58},
	issn = {1558-9102},
	shorttitle = {Feedforward and feedback control in apraxia of speech},
	doi = {10.1044/2014_JSLHR-S-13-0300},
	abstract = {PURPOSE: This study was designed to test two hypotheses about apraxia of speech (AOS) derived from the Directions Into Velocities of Articulators (DIVA) model (Guenther et al., 2006): the feedforward system deficit hypothesis and the feedback system deficit hypothesis.
METHOD: The authors used noise masking to minimize auditory feedback during speech. Six speakers with AOS and aphasia, 4 with aphasia without AOS, and 2 groups of speakers without impairment (younger and older adults) participated. Acoustic measures of vowel contrast, variability, and duration were analyzed.
RESULTS: Younger, but not older, speakers without impairment showed significantly reduced vowel contrast with noise masking. Relative to older controls, the AOS group showed longer vowel durations overall (regardless of masking condition) and a greater reduction in vowel contrast under masking conditions. There were no significant differences in variability. Three of the 6 speakers with AOS demonstrated the group pattern. Speakers with aphasia without AOS did not differ from controls in contrast, duration, or variability.
CONCLUSION: The greater reduction in vowel contrast with masking noise for the AOS group is consistent with the feedforward system deficit hypothesis but not with the feedback system deficit hypothesis; however, effects were small and not present in all individual speakers with AOS. Theoretical implications and alternative interpretations of these findings are discussed.},
	language = {eng},
	number = {2},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Maas, Edwin and Mailend, Marja-Liisa and Guenther, Frank H.},
	month = apr,
	year = {2015},
	pmid = {25565143},
	pmcid = {PMC4398652},
	keywords = {aphasia-dementia},
	pages = {185--200},
	file = {Accepted Version:/Users/transfer/Zotero/storage/RA9DTZ3Z/Maas et al. - 2015 - Feedforward and feedback control in apraxia of spe.pdf:application/pdf}
}

@article{miceli_discrimination_1978,
	title = {Discrimination of voice versus place contrasts in aphasia},
	volume = {6},
	issn = {0093-934X},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Miceli, G. and Caltagirone, C. and Gainotti, G. and Payer-Rigo, P.},
	month = jul,
	year = {1978},
	pmid = {698783},
	keywords = {aphasia-dementia},
	pages = {47--51}
}

@article{levy_stronger_2011,
	title = {Stronger accent following a stroke: the case of a trilingual with aphasia},
	volume = {25},
	issn = {1464-5076},
	shorttitle = {Stronger accent following a stroke},
	doi = {10.3109/02699206.2011.570408},
	abstract = {This study documents patterns of change in speech production in a multilingual with aphasia following a cerebrovascular accident (CVA). EC, a right-handed Hebrew-English-French trilingual man, had a left fronto-temporo-parietal CVA, after which he reported that his (native) Hebrew accent became stronger in his (second language) English. Recordings of his pre- and post-CVA speech permitted an investigation of changes in his accent. In sentence- and segment-listening tasks, native American English listeners (n = 13 and 15, respectively) judged EC's pre- and post-CVA speech. EC's speech was perceived as more foreign-accented, slow, strained and hesitant, but not less intelligible, post-CVA. Acoustic analysis revealed less coarticulation and longer vowel- and word-durations post-CVA. This case extends knowledge about perceptual and acoustic changes in speech production in multilinguals following CVAs. It is suggested that EC's stronger accent post-CVA may have resulted from damage to the neuronal networks that led to impairment in his other language domains.},
	language = {eng},
	number = {10},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Levy, Erika S. and Goral, Mira and Castelluccio De Diesbach, Catharine and Law, Franzo},
	month = oct,
	year = {2011},
	pmid = {21591932},
	keywords = {aphasia-dementia},
	pages = {815--830}
}

@article{jacks_vowel_2010,
	title = {Vowel acoustics in adults with apraxia of speech},
	volume = {53},
	issn = {1558-9102},
	doi = {10.1044/1092-4388(2009/08-0017)},
	abstract = {PURPOSE: To investigate the hypothesis that vowel production is more variable in adults with acquired apraxia of speech (AOS) relative to healthy individuals with unimpaired speech. Vowel formant frequency measures were selected as the specific target of focus.
METHOD: Seven adults with AOS and aphasia produced 15 repetitions of 6 American English vowels in /hVC/ context (hid, head, hat, hot, hub, hoot). Vowel formant frequency measures (F1, F2) were Bark transformed and compared with data from archival sources.
RESULTS: Measures of vowel acoustics in speakers with AOS did not differ from those of unimpaired speakers, including absolute Bark formant values, vowel space area, intervowel distance, and individual trial-to-trial formant variability.
CONCLUSION: Comparison with normative acoustic measures suggested that vowel production at the word level is unimpaired in the current speakers with AOS, supporting previous studies that have shown vowel production is relatively intact in AOS.},
	language = {eng},
	number = {1},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Jacks, Adam and Mathes, Katey A. and Marquardt, Thomas P.},
	month = feb,
	year = {2010},
	pmid = {20008683},
	keywords = {aphasia-dementia},
	pages = {61--74}
}

@article{seddoh_prosodic_2004,
	title = {Prosodic disturbance in aphasia: speech timing versus intonation production},
	volume = {18},
	issn = {0269-9206},
	shorttitle = {Prosodic disturbance in aphasia},
	abstract = {Temporal control has often been suspected to be a critical factor in intonation production. In particular, disturbance in the production of fundamental frequency (F0) associated with intonation in patients with aphasia has been attributed to a primary underlying deficit in speech timing. The present study examined the speech timing abilities of two groups of patients with fluent and nonfluent aphasia who were found in a companion study to have relatively normal intonation production ability. Results indicated severe temporal control abnormalities for the patients with nonfluent aphasia. The fluent aphasic patients performed at comparable levels with the normal subjects, although in absolute terms their durations were also generally longer than normal. These findings do not support the view that intonation production depends critically on speech timing, and that its disturbance in aphasia is due to underlying temporal control deficit.},
	language = {eng},
	number = {1},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Seddoh, S. Amebu},
	month = feb,
	year = {2004},
	pmid = {15053266},
	keywords = {aphasia-dementia},
	pages = {17--38}
}

@article{gandour_perception_1988,
	title = {Perception and production of tone in aphasia},
	volume = {35},
	issn = {0093-934X},
	abstract = {An acoustical and perceptual study of lexical tone was conducted to evaluate the extent and nature of tonal disruption in aphasia. The language under investigation was Thai, a tone language which has five lexical tones--mid, low, falling, high, and rising. Subjects included six left brain-damaged aphasics (two Broca's, one transcortical motor, one global, one conduction, one Wernicke), one right brain-damaged nonaphasic, one cerebellar dysarthric, and five normals. High-quality tape recordings of each subject's productions of a minimal set of five, monosyllabic Thai words were presented to 10 adult Thai listeners for identification. Results from the phonemic identification tests indicated that tone production is relatively spared in aphasic patients with unilateral left hemisphere lesions. The performance of the global aphasic, however, was considerably below normal. Patterns of tonal confusions further revealed that the performance of all aphasics, except the global, differed from that of normal speakers primarily in degree rather than in kind. Tonal contrasts were signaled at a high level of proficiency by the right brain-damaged and dysarthric patients. Acoustical analysis revealed that F0 contours associated with the five tones for all aphasics, except the global, were similar in overall shape as well as position in the tone space to those of normals. F0 contours for the right brain-damaged patient and the dysarthric also generally agreed with those of normals in terms of shape and position. F0 ranges of both aphasic and nonaphasic brain-damaged speakers were generally larger than those of normals for all five tones. The relationship between tone and vowel duration was generally similar to that of normals for all brain-damaged speakers. A comparison of aphasics' performance on tone perception (J. Gandour \& R. Dardarananda, 1983, Brain and Language, 18, 94-114) and tone production indicated that, for the normal and right brain-damaged subjects, performance on the perception task was higher than on production, whereas the opposite was true for the aphasics. These data are brought to bear on issues related to tone production in aphasia, consonant and vowel production in aphasia, hemispheric specialization for tone production, intonation production in aphasia, relationship between speech perception and speech production, and tone production in dysarthria with cerebellar disease.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Gandour, J. and Petty, S. H. and Dardarananda, R.},
	month = nov,
	year = {1988},
	pmid = {3208070},
	keywords = {aphasia-dementia},
	pages = {201--240}
}

@article{kimelman_prosody_1999,
	title = {Prosody, linguistic demands, and auditory comprehension in aphasia},
	volume = {69},
	issn = {0093-934X},
	doi = {10.1006/brln.1999.2142},
	abstract = {Prosody plays a clear role in the auditory comprehension of narratives by aphasic listeners. Previous research, however, has pointed to questions regarding variables which increase task complexity (e.g., memory, reading level) and the influence of the severity of aphasia. This study examined the role of the severity of aphasia and linguistic complexity in narrative comprehension by aphasic listeners. Findings indicate that while all subject groups improved their auditory comprehension when emphasis was present, people with severe aphasia improved significantly more, but only in a low linguistic complexity condition. However, subjects had additional opportunity for improved performance in both low and high linguistic complexity conditions. These results pose additional questions about perceived task difficulty (and performance) and resource allocation strategies.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Kimelman, M. D.},
	month = sep,
	year = {1999},
	pmid = {10447991},
	keywords = {aphasia-dementia},
	pages = {212--221}
}

@article{haley_toward_2012,
	title = {Toward a quantitative basis for assessment and diagnosis of apraxia of speech},
	volume = {55},
	issn = {1558-9102},
	doi = {10.1044/1092-4388(2012/11-0318)},
	abstract = {PURPOSE: We explored the reliability and validity of 2 quantitative approaches to document presence and severity of speech properties associated with apraxia of speech (AOS).
METHOD: A motor speech evaluation was administered to 39 individuals with aphasia. Audio-recordings of the evaluation were presented to 3 experienced clinicians to determine AOS diagnosis and to rate severity of 11 speech dimensions. Additionally, research assistants coded 11 operationalized metrics of articulation, fluency, and prosody in the same speech samples and in recordings from 20 neurologically healthy participants.
RESULTS: Agreement among the 3 clinicians was limited for both AOS diagnosis and perceptual scaling, but inter-observer reliability for the operationalized metrics was strong. The relationships between most operationalized metrics and mean severity ratings for corresponding perceptual dimensions were moderately strong and statistically significant. Both perceptual scaling and operationalized quantification approaches were sensitive to the presence or absence of AOS.
CONCLUSIONS: Perceptual scaling and operationalized metrics are promising quantification techniques that can help establish diagnostic transparency for AOS. However, because satisfactory reliability cannot be assumed for scaling techniques, effective training and calibration procedures should be implemented. Operationalized metrics show strong potential for enhancing diagnostic objectivity and sensitivity.},
	language = {eng},
	number = {5},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Haley, Katarina L. and Jacks, Adam and de Riesthal, Michael and Abou-Khalil, Rima and Roth, Heidi L.},
	month = oct,
	year = {2012},
	pmid = {23033444},
	keywords = {aphasia-dementia},
	pages = {S1502--1517}
}

@article{walker_production_2009,
	title = {The production of linguistic prosody in subjects with aphasia},
	volume = {23},
	issn = {0269-9206},
	doi = {10.1080/02699200902946944},
	abstract = {This study investigated the production of linguistic prosody in subjects with left hemisphere damage (LHD). Three experiments involving the production of lexical stress in nouns vs verbs, compound nouns vs tag constructions, and echo questions vs statements were conducted. Acoustic measurements (fundamental frequency (F(0)), duration and amplitude) of the prosodic structures were examined and naive listeners were asked to identify the meanings of the utterances. The results of the acoustic measurements indicated that LHD subjects did not produce prosodic structures that were comparable to control subjects to convey different linguistic meanings in all three experiments. Naive listeners had greater difficulty identifying the intended meanings of the utterances produced by the LHD subjects than control subjects in all three experiments. The results suggest that the left hemisphere plays a role in the production of linguistic prosody.},
	language = {eng},
	number = {7},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Walker, Judy P. and Joseph, Lydia and Goodman, Jeffrey},
	month = jul,
	year = {2009},
	pmid = {19585312},
	keywords = {aphasia-dementia},
	pages = {529--549}
}

@article{balan_effect_1999,
	title = {Effect of sentence length on the production of linguistic stress by left- and right-hemisphere-damaged patients},
	volume = {67},
	issn = {0093-934X},
	doi = {10.1006/brln.1998.2035},
	abstract = {An acoustical/perceptual study of phonemic stress (e.g., HOTdog vs. hot DOG) was conducted to evaluate the effect of sentence length on stress production after brain damage. Productions of phonemic stress pairs were elicited in sentence contexts of increasing length from eight left-hemisphere-damaged nonfluent (LHD-NFL), fluent LHD-FL), right-hemisphere-damaged (RHD), and normal speakers (n = 32). Tape recordings of subjects' productions were presented to naïve listeners for perceptual identification of stress placement. Acoustic analysis focused on fundamental frequency, duration, and intensity of the initial and final syllables as well as pause duration between syllables. Perceptual tests indicated that regardless of sentence length, all brain-damaged groups exhibited an impairment in the production of linguistic stress when compared to normals. The LHD-NFL group experienced the greatest difficulty in signaling stress contrasts, followed in order by the LHD-FL and RHD groups. In medium-length sentences, the LHD-FL group's performance was degraded by comparison to short-length sentences. Acoustic analysis showed that pause duration was the strongest predictor of phonemic stress for all groups. Acoustic profiles of the RHD group were similar qualitatively to those of normals, but differed quantitatively in terms of magnitude of effect associated with shifts in stress patterns. Findings are brought to bear on the nature of the stress production deficit after unilateral brain damage, the role of the right hemisphere in linguistic prosody, and the concept of "subtle phonetic deficit" in fluent aphasia.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Balan, A. and Gandour, J.},
	month = apr,
	year = {1999},
	pmid = {10092343},
	keywords = {aphasia-dementia},
	pages = {73--94}
}

@article{baque_lexical_2017,
	title = {Lexical stress contrast marking in fluent and non-fluent aphasia in {Spanish}: {The} relationship between acoustic cues and compensatory strategies},
	volume = {31},
	issn = {1464-5076},
	shorttitle = {Lexical stress contrast marking in fluent and non-fluent aphasia in {Spanish}},
	doi = {10.1080/02699206.2017.1305449},
	abstract = {This study sought to investigate stress production in Spanish by patients with Broca's (BA) and conduction aphasia (CA) as compared to controls. Our objectives were to assess whether: a) there were many abnormal acoustic correlates of stress as produced by patients, b) these abnormalities had a phonetic component and c) ability for articulatory compensation for stress marking was preserved. The results showed abnormal acoustic values in both BA and CA's productions, affecting not only duration but also F0 and intensity cues, and an interaction effect of stress pattern and duration on intensity cubes in BA, but not in CA or controls. The results are interpreted as deriving from two different underlying phenomena: in BA, a compensatory use of intensity as a stress cue in order to avoid 'equal stress'; in CA, related to either a 'subtle phonetic deficit' involving abnormal stress acoustic cue-processing or to 'clear-speech' effects.},
	language = {eng},
	number = {7-9},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Baqué, Lorraine},
	year = {2017},
	pmid = {28409649},
	keywords = {aphasia-dementia},
	pages = {642--664}
}

@article{shinn_phonetic_1983,
	title = {Phonetic disintegration in aphasia: acoustic analysis of spectral characteristics for place of articulation},
	volume = {20},
	issn = {0093-934X},
	shorttitle = {Phonetic disintegration in aphasia},
	abstract = {In this study, we attempted to determine whether phonetic disintegration of speech in Broca's aphasia affects the spectral characteristics of speech sounds as has been shown for the temporal characteristics of speech. To this end, we investigated the production of place of articulation in Broca's aphasics. Acoustic analysis of the spectral characteristics for stop consonants were conducted. Results indicated that the static aspects of speech production were preserved, as Broca's aphasics seemed to be able to reach the articulatory configuration for the appropriate place of articulation. However, the dynamic aspects of speech production seemed to be impaired, as their productions reflected problems with the source characteristics of speech sounds and with the integration of articulatory movements in the vocal tract. Listener perceptions of the aphasics' productions were compared with acoustic analyses for these same productions. The two measures were related; that is, the spectral characteristics of the utterances provided salient cues for place of articulation perception. An analysis of the occurrences of errors along the dimensions of voicing and place showed that aphasics rarely produce utterances containing both voice and place substitutions.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Shinn, P. and Blumstein, S. E.},
	month = sep,
	year = {1983},
	pmid = {6626948},
	keywords = {aphasia-dementia},
	pages = {90--114}
}

@article{ryalls_acoustic_1986,
	title = {An acoustic study of vowel production in aphasia},
	volume = {29},
	issn = {0093-934X},
	abstract = {A group of five anterior and seven posterior aphasic patients were recorded for their vowel productions of the nine nondipthong vowels of American English and compared to a group of seven normal speakers. All phonemic substitutions were eliminated from the data base. A Linear Predictive Coding (LPC) computer program was used to extract the first and the second formant frequencies at the midpoint of the vowel for each of the remaining repetitions of the nine vowels. The vowel duration and the fundamental frequency of phonation were also measured. Although there were no significant differences in the formant frequency means across groups, there were significantly larger standard deviations for the aphasic groups compared to normals. Anterior aphasics were not significantly different from posterior aphasics with respect to this greater formant variability. There was a main effect for vowel duration means, but no individual group was significantly different from the other. Standard deviations of duration were significantly greater for the anterior aphasics compared to normal speakers, but not significantly different from posterior aphasics. Posterior aphasics did not have significantly greater standard deviations of duration than did normal subjects. Greater acoustic variability was considered to evidence a phonetic production deficit on the part of both groups of aphasic speakers, in the context of fairly well-preserved phonemic organization for vowels.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Ryalls, J. H.},
	month = sep,
	year = {1986},
	pmid = {3756461},
	keywords = {aphasia-dementia},
	pages = {48--67}
}

@article{van_lancker_sidtis_prosodic_2010,
	title = {Prosodic changes in aphasic speech: timing},
	volume = {24},
	issn = {1464-5076},
	shorttitle = {Prosodic changes in aphasic speech},
	doi = {10.3109/02699200903464439},
	abstract = {Controversy remains about the impairment of prosody in aphasia, particularly with regard to speech timing. This paper addresses this topic through an analysis of timing in four sets of a common morphological paradigm. The paradigm consisted of a basic form (stem) and two longer derived forms (e.g. zip, zipper, zippering). Normally, vowel durations are shorter in longer derived forms (e.g. zippering) than in the stem (e.g. zip), due to a process called 'initial shortening'. Twelve patients with aphasia (four each Broca, Wernicke, and Anomic), and 11 age-matched healthy adults were assessed. Structural (CT) and functional brain imaging (PET) were available for all patients. While all groups showed initial shortening between the stem and the derived forms, the patients with Broca's aphasia presented an inverse pattern between the two derived forms (longer initial vowel in 'zippering' than 'zipper'), and the patients with Wernicke's aphasia produced significantly longer vowel durations overall than the healthy participants. The results are related to radiological information regarding the location of structural and functional brain damage and relative preservation and loss of prosodic features in cerebral damage.},
	language = {eng},
	number = {2},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Van Lancker Sidtis, Diana and Kempler, Daniel and Jackson, Catherine and Metter, E. Jeffrey},
	month = feb,
	year = {2010},
	pmid = {20100044},
	pmcid = {PMC5999022},
	keywords = {aphasia-dementia},
	pages = {155--167},
	file = {Full Text:/Users/transfer/Zotero/storage/4T4FAFGY/Van Lancker Sidtis et al. - 2010 - Prosodic changes in aphasic speech timing.pdf:application/pdf}
}

@article{baum_rate_1993,
	title = {Rate of speech effects in aphasia: voice onset time},
	volume = {44},
	issn = {0093-934X},
	shorttitle = {Rate of speech effects in aphasia},
	doi = {10.1006/brln.1993.1026},
	abstract = {This study investigated the ability to produce appropriate voice onset time (VOT) contrasts under conditions of rate modulation in groups of nonfluent aphasic subjects, fluent aphasic subjects, and nonneurological controls. Acoustic analyses of the consonants [b d g p t k] produced in the context of the vowels [i e a o u] at two different rates of speech revealed that normal subjects' VOTs were significantly shorter at the fast rate of speech relative to the slow/normal rate, as expected. In addition, the rate change had a significantly greater effect on voiceless stops as compared to voiced and on velar consonants as compared to labials and alveolars. The nonfluent aphasic patients exhibited a similar pattern except that no differences in magnitude of rate-related changes were found across place of articulation. Further, similar to previous studies, the nonfluent aphasic patients produced voice and voiceless consonants with somewhat overlapping VOT distributions, indicating an impairment in temporal integration in these subjects. Finally, the fluent aphasic patients demonstrated a surprisingly aberrant pattern of results, with VOTs under th fast condition shorter than under the slow, but no differences in magnitude of change across place of articulation or voicing categories. The results are discussed in relation to the nature of speech production deficits in both nonfluent and fluent aphasic patients. Implications for remediation are considered.},
	language = {eng},
	number = {4},
	journal = {Brain and Language},
	author = {Baum, S. R. and Ryan, L.},
	month = may,
	year = {1993},
	pmid = {8319082},
	keywords = {aphasia-dementia},
	pages = {431--445}
}

@article{williams_comparison_1986,
	title = {A comparison of speech sound durations in three syndromes of aphasia},
	volume = {29},
	issn = {0093-934X},
	abstract = {This study compared the durations of selected vowels and consonants produced by three groups of aphasics and a normal control group in confrontation naming and single-word repetition tasks. There were seven aphasic subjects in each of the syndromes of Broca's, Wernicke's, amnesic, and conduction aphasia, in addition to a group of seven normal subjects. Wide-band spectrograms were used to measure speech sound durations. Analysis of group data revealed no significant differences in the durations of vowels or consonants across the four subject groups. In addition, there were no differences in speech sound durations for the confrontation naming versus repetition tasks. When two speech-language pathologists listened to tape recordings of all subjects performing the two tasks, they judged the speech of two Broca's aphasics as being labored, while the speech of the remaining subjects was not judged as labored. Clinical judgments of labored speech appeared to correspond to acoustical measurements of speech sound duration, as the two Broca's aphasics judged to be labored displayed longer durations than those subjects who were not judged as labored. The increase in duration was particularly marked for vowels and for sounds in polysyllabic words. The results are discussed in relation to current descriptions of the articulatory characteristics of Broca's aphasics. Clinical implications are also addressed.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Williams, S. E. and Seaver, E. J.},
	month = sep,
	year = {1986},
	pmid = {3756457},
	keywords = {aphasia-dementia},
	pages = {171--182}
}

@article{metz-lutz_real-time_1992,
	title = {A real-time approach to spoken language processing in aphasia},
	volume = {43},
	issn = {0093-934X},
	abstract = {The study is based on an on-line investigation of spoken language comprehension processes in 25 French-speaking aphasics using a syllable-monitoring task. Nonsense syllables were presented in three different conditions: context-free (embedded in strings of nonsense syllables), lexical context (where the target nonsense syllable is the initial, medial, or final syllable of real three-syllable words), and sentence context. This study builds on an earlier one that explored the relationship between the acoustic-phonetic, lexical, and sentential levels of spoken language processing in French-speaking normals and gave evidence of top-down lexical and sentential influence on syllable recognition. In the present study, aphasic patients from various diagnostic categories were classified as high (N = 13) or low (N = 12) comprehenders. The results show that low comprehending aphasics make no use of sentence information in the syllable-recognition task. As for top-down effect at the single word level that is observed in normal listeners. However, a subgroup analysis shows that the Broca's are the only high comprehending aphasics who perform in the same way as normal listeners; this sets them apart from the anomics and conduction aphasics.},
	language = {eng},
	number = {4},
	journal = {Brain and Language},
	author = {Metz-Lutz, M. N. and Wioland, F. and Brock, G.},
	month = nov,
	year = {1992},
	pmid = {1483190},
	keywords = {aphasia-dementia},
	pages = {565--582}
}

@article{baum_anticipatory_1998,
	title = {Anticipatory coarticulation in aphasia: effects of utterance complexity},
	volume = {63},
	issn = {0093-934X},
	shorttitle = {Anticipatory coarticulation in aphasia},
	doi = {10.1006/brln.1997.1938},
	abstract = {The magnitude and extent of anticipatory coarticulation were examined in groups of fluent and nonfluent aphasic patients and normal control subjects. One- and two-syllable target utterances were elicited at slow and fast rates of speech with or without a consonant intervening between the target consonant and vowel, and with or without a preceding schwa, to manipulate utterance complexity. Acoustic analyses (F2 and centroid frequencies) revealed that both groups of aphasic patients exhibited relatively normal patterns of anticipatory coarticulation. However, small but significant differences among the groups emerged in certain conditions. Surprisingly, increased utterance complexity was not found to reduce coarticulatory effects to a greater degree in the nonfluent relative to the fluent aphasic group. Perceptual tests largely confirmed the acoustic analyses.},
	language = {eng},
	number = {3},
	journal = {Brain and Language},
	author = {Baum, S. R.},
	month = jul,
	year = {1998},
	pmid = {9672765},
	keywords = {aphasia-dementia},
	pages = {357--380}
}

@article{healy_speech_2007,
	title = {Speech perception in {MRI} scanner noise by persons with aphasia},
	volume = {50},
	issn = {1092-4388},
	doi = {10.1044/1092-4388(2007/023)},
	abstract = {PURPOSE: To examine reductions in performance on auditory tasks by aphasic and neurologically intact individuals as a result of concomitant magnetic resonance imaging (MRI) scanner noise.
METHOD: Four tasks together forming a continuum of linguistic complexity were developed. They included complex-tone pitch discrimination, same-different discrimination of minimal pair syllables, lexical decision, and sentence plausibility. Each task was performed by persons with aphasia (PWA) and by controls. The stimuli were presented in silence and also in the noise recorded from within the bore of a 3 Tesla MRI scanner at 3 signal-to-noise (S/N) ratios.
RESULTS: Across the 4 tasks, the PWA scored lower than the controls, and performance fell as a function of decreased S/N. However, the rate at which performance fell was not different across the 2 listener groups in any task.
CONCLUSIONS: Depending on the relative levels of the signals and noise, the intense noise accompanying MRI scanning has the potential to severely disrupt performance. However, PWA are no more susceptible to the disruptive influence of this noise than are unimpaired individuals usually employed as controls. Thus, functional MRI data from aphasic and control individuals may be interpreted without complications associated with large interactions between scanner noise and performance reduction.},
	language = {eng},
	number = {2},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Healy, Eric W. and Moser, Dana C. and Morrow-Odom, K. Leigh and Hall, Deborah A. and Fridriksson, Julius},
	month = apr,
	year = {2007},
	pmid = {17463232},
	keywords = {aphasia-dementia},
	pages = {323--334},
	file = {Submitted Version:/Users/transfer/Zotero/storage/WHXURKKW/Healy et al. - 2007 - Speech perception in MRI scanner noise by persons .pdf:application/pdf}
}

@article{gandour_speech_2000,
	title = {Speech timing in {Thai} left- and right-hemisphere-damaged individuals},
	volume = {36},
	issn = {0010-9452},
	abstract = {An acoustic analysis of syllable duration in short Thai phrases was conducted to evaluate the effects of focal brain damage on the control of speech timing. Almost all 35 of the subjects had participated in each of four previous companion studies: 13 left-brain-damaged (6 nonfluent aphasics; 7 fluent aphasics), 14 right-brain-damaged patients, and 8 normal controls. Somewhat surprisingly, results revealed relatively normal timing patterns in 3-syllable phrases in all subject groups. A comparison of the current study and the four others, however, led us to conclude that Thai-speaking nonfluent aphasics exhibit a speech timing deficit regardless of the linguistic level of representation, whereas timing deficits in fluent aphasics appear to be restricted to units larger than a syllable. Speech timing, on the other hand, appears to be intact across the board in right-brain-damaged individuals. Findings are brought to bear on theories of temporal control in brain-damaged patients.},
	language = {eng},
	number = {2},
	journal = {Cortex; a Journal Devoted to the Study of the Nervous System and Behavior},
	author = {Gandour, J. and Ponglorpisit, S. and Khunadorn, F. and Dechongkit, S. and Boongird, P. and Satthamnuwong, N.},
	month = apr,
	year = {2000},
	pmid = {10815711},
	keywords = {aphasia-dementia},
	pages = {281--288}
}

@article{blumstein_effects_1985,
	title = {The effects of slowed speech on auditory comprehension in aphasia},
	volume = {24},
	issn = {0093-934X},
	abstract = {The present study investigates the effects of slowed speech on auditory comprehension in aphasia. Specifically, an attempt was made to isolate the effects of added time on comprehension at the language processing stages of auditory perception, by increasing the duration of the vowel segments in each word; word recognition and semantic analysis, by adding silences between words; and syntactic analysis, by adding silences at constituent phrase boundaries. Sentences were also read at a slow rate to see the effects of naturally slowed speech on sentence comprehension. Test sentences consisted of simple active and passive declarative sentences, and complex sentences with embedded medial and final relative clauses. Sentences were either semantically reversible or nonreversible. Thirty-four aphasic patients who varied in both severity and type of aphasia were tested on a picture verification task. Results indicated that slowing facilitated language comprehension significantly only in the syntactic condition. Neither syntactic complexity nor semantic reversibility interacted with slowed speech to facilitate auditory language comprehension. Further, it was only the Wernicke's aphasics who showed significant improvement with time added at constituent boundaries. These results suggest that time alone does not facilitate language comprehension in aphasia, but that rather it is the interaction of time with syntactic processing which improves comprehension.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Blumstein, S. E. and Katz, B. and Goodglass, H. and Shrier, R. and Dworetsky, B.},
	month = mar,
	year = {1985},
	pmid = {2579705},
	keywords = {aphasia-dementia},
	pages = {246--265}
}

@article{katz_anticipatory_1988,
	title = {Anticipatory coarticulation in aphasia: acoustic and perceptual data},
	volume = {35},
	issn = {0093-934X},
	shorttitle = {Anticipatory coarticulation in aphasia},
	abstract = {Two experiments investigated speech motor planning in aphasia by contrasting the degree of labial and lingual anticipatory coarticulation evident in normal subjects' speech with that found in the speech of aphasic subjects. In the first experiment, Linear Predictive Coding (LPC) analyses were conducted for the initial consonants of CV [si su ti tu ki ku] and CCV [sti stu ski sku] productions by 6 normal and 10 aphasic (5 anterior, 5 posterior) subjects. For normal subjects' productions, reliable coarticulatory shift was found for almost all measurements, indicating that acoustic correlates for anticipatory coarticulation obtain for [s], [t], and [k] in a prevocalic environment, as well as when [s] is the initial consonant of a CCV syllable. The data for the aphasic subjects were statistically indistinguishable from those of the normal subject group, and there were no differences noted as a function of aphasia type. In the second experiment, a subset of the consonantal stimuli produced by the normal and aphasic subjects was presented to a group of 10 naive listeners for a vowel identification task. Listeners were able to identify the productions of all subjects at a level well above chance. In addition, small but statistically significant Group differences were observed, with the [sV], [skV], and [tV] productions by anterior aphasics showing significantly lower perceptual scores than those of normal subjects.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Katz, W. F.},
	month = nov,
	year = {1988},
	pmid = {3208077},
	keywords = {aphasia-dementia},
	pages = {340--368}
}

@article{sussman_anticipatory_1988,
	title = {Anticipatory coarticulation in aphasia: some methodological considerations},
	volume = {35},
	issn = {0093-934X},
	shorttitle = {Anticipatory coarticulation in aphasia},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Sussman, H. M. and Marquardt, T. P. and MacNeilage, P. F. and Hutchinson, J. A.},
	month = nov,
	year = {1988},
	pmid = {3208078},
	keywords = {aphasia-dementia},
	pages = {369--385}
}

@article{ryalls_motor_1981,
	title = {Motor aphasia: acoustic correlates of phonetic disintegration in vowels},
	volume = {19},
	issn = {0028-3932},
	shorttitle = {Motor aphasia},
	language = {eng},
	number = {3},
	journal = {Neuropsychologia},
	author = {Ryalls, J. H.},
	year = {1981},
	pmid = {7266829},
	keywords = {aphasia-dementia},
	pages = {365--374}
}

@article{danly_fundamental_1983,
	title = {Fundamental frequency, language processing, and linguistic structure in {Wernicke}'s aphasia},
	volume = {19},
	issn = {0093-934X},
	abstract = {Five Wernicke's aphasics and five normal control subjects were tested in order to assess several aspects of fundamental frequency (F0) in speech production. The clinical impression of normal prosody in Wernicke's aphasia is correct inasmuch as these patients generally exhibited F0 declination. However, F0 declination ranged over shorter domains than in normal speech. Moreover, the increased use of F0 continuation rises by the Wernicke's aphasics indicated their inability to maintain a single F0 contour over constituents which are normally integral. The hypermelodic quality of F0 in the speech of Wernicke's aphasics further supported the notion that speech prosody was not strictly normal. F0 attributes tended to be normal when they corresponded to the global linguistic variable of sentence length, while they were abnormal when they corresponded to the processing of syntactic structure. No evidence was found that paraphasias and neologisms directly affected the programming of F0. The results are discussed in terms of speech processing abilities and limitations in Wernicke's aphasia.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Danly, M. and Cooper, W. E. and Shapiro, B.},
	month = may,
	year = {1983},
	pmid = {6860930},
	keywords = {aphasia-dementia},
	pages = {1--24}
}

@article{beeke_prosody_2009,
	title = {Prosody as a compensatory strategy in the conversations of people with agrammatism},
	volume = {23},
	issn = {0269-9206},
	doi = {10.1080/02699200802602985},
	abstract = {Historically, agrammatism, a symptom of Broca's aphasia, has been associated with dysprosody, on account of speakers' slow, halting, and effortful speech. Almost all investigations of this phenomenon use experimental methods (reading, repetition). Thus, little is known about how prosody is used by speakers with agrammatism and understood by their interlocutors in everyday conversations. This paper takes an interactional approach to prosody, using Conversation Analysis to explore everyday conversations between three speakers with agrammatism and their family members/friends, recorded in the home. A distinct prosodic pattern is revealed in their talk, whereby non-final words in an agrammatic utterance are produced with mid-level or minor rising pitch, and final words with a prominent pitch excursion. The analysis shows that conversation partners orient to terminal pitch movement as a signal of turn completion. Conversely, they do not take the floor when pitch signals continuation, despite significant pausing and severe grammatical disruption. Thus, prosody appears to function to regulate turn taking in the same way as it does in typical (non-language disordered) conversation. For these three speakers, intact prosodic skills appear to compensate for impaired grammatical ability, by packaging a series of haltingly produced words into an utterance, the meaning of which is responded to by the conversation partner as the sum of its agrammatic parts.},
	language = {eng},
	number = {2},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Beeke, Suzanne and Wilkinson, Ray and Maxim, Jane},
	month = feb,
	year = {2009},
	pmid = {19197582},
	keywords = {aphasia-dementia},
	pages = {133--155}
}

@article{lafon_[various_1968,
	title = {[{Various} aspects of auditory discrimination and their occurrence in aphasics and deaf children]},
	volume = {89},
	issn = {0035-1334},
	language = {fre},
	number = {7},
	journal = {Revue De Laryngologie - Otologie - Rhinologie},
	author = {Lafon, J. C.},
	month = aug,
	year = {1968},
	pmid = {5715338},
	keywords = {aphasia-dementia},
	pages = {393--400}
}

@article{baum_fricative_1996,
	title = {Fricative production in aphasia: effects of speaking rate},
	volume = {52},
	issn = {0093-934X},
	shorttitle = {Fricative production in aphasia},
	doi = {10.1006/brln.1996.0015},
	abstract = {The present study investigated the effects of alterations in speaking rate on the production of the fricatives [f s v z] by 10 nonfluent aphasics, 7 fluent aphasics, and 10 normal control subjects. An examination of fricative consonants allowed us to address whether previous conflicting findings for vowels and stop consonants produced by nonfluent aphasic patients were due to basic differences in the treatment of major sound classes or to differences in the length of the segments under investigation. Acoustic analyses revealed that all subjects were able to manipulate rate of speech. Both groups of aphasic patients produced rate changes that were smaller in magnitude than those of the normal subjects. Further analyses demonstrated that both the fluent and the nonfluent aphasic patients were able to instantiate the rate changes in terms of fricative duration. However, both patient groups exhibited breakdowns in the ability to maintain contrastive differences between voiced and voiceless fricatives, particularly at fast rates of speech. Possible sources of these breakdowns are explored.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Baum, S. R.},
	month = feb,
	year = {1996},
	pmid = {8811964},
	keywords = {aphasia-dementia},
	pages = {328--341}
}

@article{boyczuk_influence_1999,
	title = {The influence of neighborhood density on phonetic categorization in aphasia},
	volume = {67},
	issn = {0093-934X},
	doi = {10.1006/brln.1998.2049},
	abstract = {The present study examined the contribution of lexically based sources of information to acoustic-phonetic processing in fluent and nonfluent aphasic subjects and age-matched normals. To this end, two phonetic identification experiments were conducted which required subjects to label syllable-initial bilabial stop consonants varying along a VOT continuum as either /b/ or /p/. Factors that were controlled included the lexical status (word/nonword) and neighborhood density values corresponding to the two possible syllable interpretations in each set of stimuli. Findings indicated that all subject groups were influenced by both lexical status and neighborhood density in making phonetic categorizations. Results are discussed with respect to theories of acoustic-phonetic perception and lexical access in normal and aphasic populations.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Boyczuk, J. P. and Baum, S. R.},
	month = mar,
	year = {1999},
	pmid = {10191000},
	keywords = {aphasia-dementia},
	pages = {46--70}
}

@article{baum_acoustic_1993,
	title = {An acoustic analysis of rate of speech effects on vowel production in aphasia},
	volume = {44},
	issn = {0093-934X},
	doi = {10.1006/brln.1993.1025},
	abstract = {The present investigation examined the production of tense and lax vowel duration differences at two speaking rates in the speech of 10 nonfluent aphasics, 8 fluent aphasics, and 10 normal control subjects. Subjects produced four repetitions of each of the vowels [i e ae o u I epsilon upsilon --] at each speaking rate. Acoustic analyses revealed that subjects in all three groups were able to manipulate overall rate of speech. In addition, normal controls and fluent aphasic subjects produced vowels under the fast rate condition which were significantly shorter than those under the slow rate condition. Despite a change in overall speaking rate, the nonfluent aphasics did not exhibit a significant difference in vowel duration at the two rates of speech, suggesting a deficit in the implementation of this temporal parameter. Both normal controls and fluent aphasic patients produced nonoverlapping distributions of tense and lax vowels at both speaking rates. In contrast, the nonfluent aphasics demonstrated a great deal of overlap in the distribution of tense and lax vowel durations at the fast rate. Results are discussed in relation to the nature of the speech production deficits in nonfluent and fluent aphasic patients.},
	language = {eng},
	number = {4},
	journal = {Brain and Language},
	author = {Baum, S. R.},
	month = may,
	year = {1993},
	pmid = {8319081},
	keywords = {aphasia-dementia},
	pages = {414--430}
}

@article{tsunoda_functional_1975,
	title = {Functional differences between right- and left-cerebral hemispheres detected by the key-tapping method},
	volume = {2},
	issn = {0093-934X},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Tsunoda, T.},
	month = apr,
	year = {1975},
	pmid = {1182491},
	keywords = {aphasia-dementia},
	pages = {152--170}
}

@article{bislick_nature_2017,
	title = {The {Nature} of {Error} {Consistency} in {Individuals} {With} {Acquired} {Apraxia} of {Speech} and {Aphasia}},
	volume = {26},
	issn = {1558-9110},
	doi = {10.1044/2017_AJSLP-16-0080},
	abstract = {Purpose: The primary characteristics used to define acquired apraxia of speech (AOS) have evolved to better reflect a disorder of motor planning/programming. However, there is debate regarding the feature of relatively consistent error location and type.
Method: Ten individuals with acquired AOS and aphasia and 11 individuals with aphasia without AOS participated in this study. In the context of a 2-group experimental design, error consistency was examined via 5 repetitions of 30 multisyllabic words. The influence of error rate, severity of impairment, and stimulus presentation condition (blocked vs. random) on error consistency was also explored, as well as between-groups differences in the types of errors produced.
Results: Groups performed similarly on consistency of error location; however, adults with AOS demonstrated greater variability of error type in a blocked presentation condition only. Stimulus presentation condition, error rate, and severity of impairment did not influence error consistency in either group. Groups differed in the production of phonetic errors (e.g., sound distortions) but not phonemic errors.
Conclusions: Overall, findings do not support relatively consistent errors as a differentiating characteristic of AOS.},
	language = {eng},
	number = {2S},
	journal = {American Journal of Speech-Language Pathology},
	author = {Bislick, Lauren and McNeil, Malcolm and Spencer, Kristie A. and Yorkston, Kathryn and Kendall, Diane L.},
	month = jun,
	year = {2017},
	pmid = {28654943},
	pmcid = {PMC5576968},
	keywords = {aphasia-dementia},
	pages = {611--630},
	file = {Full Text:/Users/transfer/Zotero/storage/XRYPFJX9/Bislick et al. - 2017 - The Nature of Error Consistency in Individuals Wit.pdf:application/pdf}
}

@article{jose_is_2016,
	title = {Is {Language} a {Factor} in the {Perception} of {Foreign} {Accent} {Syndrome}?},
	volume = {59},
	issn = {0023-8309},
	doi = {10.1177/0023830915586612},
	abstract = {Neurogenic foreign accent syndrome (FAS) is diagnosed when listeners perceive speech associated with motor speech impairments as foreign rather than disordered. Speakers with foreign accent syndrome typically have aphasia. It remains unclear how far language changes might contribute to the perception of foreign accent syndrome independent of accent. Judges with and without training in language analysis rated orthographic transcriptions of speech from people with foreign accent syndrome, speech-language disorder and no foreign accent syndrome, foreign accent without neurological impairment and healthy controls on scales of foreignness, normalness and disorderedness. Control speakers were judged as significantly more normal, less disordered and less foreign than other groups. Foreign accent syndrome speakers' transcriptions consistently profiled most closely to those of foreign speakers and significantly different to speakers with speech-language disorder. On normalness and foreignness ratings there were no significant differences between foreign and foreign accent syndrome speakers. For disorderedness, foreign accent syndrome participants fell midway between foreign speakers and those with speech-language impairment only. Slower rate, more hesitations, pauses within and between utterances influenced judgments, delineating control scripts from others. Word-level syntactic and morphological deviations and reduced syntactic and semantic repertoire linked strongly with foreignness perceptions. Greater disordered ratings related to word fragments, poorly intelligible grammatical structures and inappropriate word selection. Language changes influence foreignness perception. Clinical and theoretical issues are addressed.},
	language = {eng},
	number = {Pt 2},
	journal = {Language and Speech},
	author = {Jose, Linda and Read, Jennifer and Miller, Nick},
	month = jun,
	year = {2016},
	pmid = {27363254},
	keywords = {aphasia-dementia},
	pages = {219--235}
}

@article{pritchard_reviewing_2017,
	title = {Reviewing the quality of discourse information measures in aphasia},
	volume = {52},
	issn = {1460-6984},
	doi = {10.1111/1460-6984.12318},
	abstract = {BACKGROUND: Discourse is fundamental to everyday communication, and is an increasing focus of clinical assessment, intervention and research. Aphasia can affect the information a speaker communicates in discourse. Little is known about the psychometrics of the tools for measuring information in discourse, which means it is unclear whether these measures are of sufficient quality to be used as clinical outcome measures or diagnostic tools.
AIMS: To profile the measures used to describe information in aphasic discourse, and to assess the quality of these measures against standard psychometric criteria.
METHODS \& PROCEDURES: A scoping review method was employed. Studies were identified using a systematic search of Scopus, Medline and Embase databases. Standard psychometric criteria were used to evaluate the measures' psychometric properties.
MAIN CONTRIBUTION: The current review summarizes and collates the information measures used to describe aphasic discourse, and evaluates their quality in terms of the psychometric properties of acceptability, reliability and validity. Seventy-six studies described 58 discourse information measures, with a mean of 2.28 measures used per study (SD = 1.29, range = 1-7). Measures were classified as 'functional' measures (n = 33), which focused on discourse macrostructure, and 'functional and structural' measures (n = 25), which focused on micro-linguistic and macro-structural approaches to discourse. There were no reports of the acceptability of data generated by the measures (distribution of scores, missing data). Test-retest reliability was reported for just 8/58 measures with 3/8 {\textgreater} 0.80. Intra-rater reliability was reported for 9/58 measures and in all cases percentage agreement was reported rather than reliability. Per cent agreement was also frequently reported for inter-rater reliability, with only 4/76 studies reporting reliability statistics for 12/58 measures; this was generally high ({\textgreater}.80 for 11/12 measures). The majority of measures related clearly to the discourse production model indicating content validity. A total of 36/58 measures were used to make 41 comparisons between participants with aphasia (PWA) and neurologically healthy participants (NHP), with 31/41 comparisons showing a difference between the groups. Four comparisons were made between discourse genres, with two measures showing a difference between genres, and two measures showing no difference.
CONCLUSIONS: There is currently insufficient information available to justify the use of discourse information measures as sole diagnostic or outcome measurement tools. Yet the majority of measures are rooted in relevant theory, and there is emerging evidence regarding their psychometric properties. There is significant scope for further psychometric strengthening of discourse information measurement tools.},
	language = {eng},
	number = {6},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Pritchard, Madeleine and Hilari, Katerina and Cocks, Naomi and Dipper, Lucy},
	year = {2017},
	pmid = {28560767},
	keywords = {aphasia-dementia},
	pages = {689--732},
	file = {Submitted Version:/Users/transfer/Zotero/storage/4PFGPHD5/Pritchard et al. - 2017 - Reviewing the quality of discourse information mea.pdf:application/pdf}
}

@article{ramsberger_temporal_1985,
	title = {Temporal speech characteristics associated with anterior left hemisphere cortical and subcortical lesions: a preliminary case study report},
	volume = {24},
	issn = {0093-934X},
	shorttitle = {Temporal speech characteristics associated with anterior left hemisphere cortical and subcortical lesions},
	abstract = {There is disagreement in the literature regarding the characteristics of cortical and subcortical forms of aphasia. M. L. Albert, H. Goodglass, N. A. Helm, A. B. Rubens, and M. P. Alexander (Clinical Aspects of Dysphasia, Vienna/New York: Springer-Verlag, 1980) state that the two are indistinguishable. The opposing view has been presented by M. A. Naeser, M. P. Alexander, N. Helm-Estabrook, H. L. Levine, S. A. Laughlin, and N. Geschwind (Archives of Neurology, 39, 1982) and A. R. Damasio, H. Damasio, M. Rizzo, N. Varney, and F. Gersh (Archives of Neurology, 39, 15-20, 1982), who suggest that subcortical aphasias are not adequately described by the classic, cortical aphasia descriptions. In this study the temporal speech characteristics of a neurologically normal individual, an aphasic patient with anterior cortical and subcortical lesion locus, and a second aphasic patient, whose lesion was limited to anterior subcortical structures, were studied utilizing acoustic analysis of isolated word and phrase productions. The results of this investigation showed individually unique temporal patterns in the speech of each of the subjects studied. While the results must be interpreted conservatively due to the small number of cases described, they do provide tentative support for the Naeser et al. (1982) and Damasio et al. (1982) position. Furthermore, the results demonstrate the potential value of combining sensitive radiographic and acoustic measures in future studies that seek to compare cortical and subcortical forms of aphasia.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Ramsberger, G. and Hillman, R. E.},
	month = jan,
	year = {1985},
	pmid = {3971136},
	keywords = {aphasia-dementia},
	pages = {59--73}
}

@article{baum_compensation_1997,
	title = {Compensation for jaw fixation by aphasic patients},
	volume = {56},
	issn = {0093-934X},
	doi = {10.1006/brln.1997.1734},
	abstract = {The ability to compensate for fixation of the jaw by a bite block was investigated in 6 nonfluent aphasics, 6 fluent aphasics, and 10 normal control subjects. Acoustic analyses of the vowels [i u a ae] and fricatives [s s] revealed substantial but incomplete compensation for the perturbation in all three subject groups. Perceptual identification scores and quality ratings by naive and phonetically trained listeners indicated poorer identification of the high vowels [i u] under compensatory conditions relative to normal production. Of particular interest was the fact that all three groups of subjects exhibited similar patterns of results. The findings suggest that any deficit in speech motor programming demonstrated by the nonfluent aphasic patients did not affect compensatory abilities. Results are discussed with respect to normal speech adaptation skills and the nature of articulatory breakdown in nonfluent aphasia.},
	language = {eng},
	number = {3},
	journal = {Brain and Language},
	author = {Baum, S. R. and Kim, J. A. and Katz, W. F.},
	month = feb,
	year = {1997},
	pmid = {9070417},
	keywords = {aphasia-dementia},
	pages = {354--376}
}

@article{marshall_selective_1988,
	title = {Selective impairment of phonation: a case study},
	volume = {35},
	issn = {0093-934X},
	shorttitle = {Selective impairment of phonation},
	abstract = {A 47-year-old right-handed man underwent craniotomy for clipping of an aneurism at the trifurcation of the left middle cerebral artery. Subsequently, he suffered a left hemisphere CVA after which his speech and language resembled that of Broca's aphasia with accompanying apraxia of speech. Medical, behavioral, and acoustical data amassed over a period of several months indicated numerous contraindications to traditional diagnoses of Broca's aphasia, apraxia of speech, and dysarthria. Ultimately, it was determined that the patient had a selective impairement of phonation or laryngeal apraxia. This was illustrated dramatically when he was taught to use an electrolarynx which allowed him to bypass his disrupted phonatory system. Speaking with the electrolarynx, the patient communicated normally. Any semblance of Broca's aphasia disappeared. Supralaryngeal articulation was normal; apraxia of speech behaviors were absent. This case report indicates that dissociation of oral and laryngeal gestures due to brain injury is possible. Mechanisms underlying such a dissociation for this case are reviewed. The possibility of discrete center lesions in the frontal motor association area causing different types of apraxia of speech is discussed.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Marshall, R. C. and Gandour, J. and Windsor, J.},
	month = nov,
	year = {1988},
	pmid = {3208076},
	keywords = {aphasia-dementia},
	pages = {313--339}
}

@article{gandour_lexical_1992,
	title = {Lexical tones in {Thai} after unilateral brain damage},
	volume = {43},
	issn = {0093-934X},
	abstract = {An acoustic perceptual investigation of the five lexical tones of Thai was conducted to evaluate the nature of tonal disruption in patients with unilateral lesions in the left and right hemisphere. Subjects (n = 48) included 10 young normal adults, 10 old normal adults, 11 right hemisphere nonaphasics, 9 left hemisphere fluent aphasics, and 8 left hemisphere nonfluent aphasics. The five Thai tones (mid, low, falling, high, rising) were produced in isolated monosyllables, presented for tonal identification judgments, and measured for fundamental frequency (Fo) and duration. Results of an analysis of variance indicated that left hemisphere nonfluent speakers signaled and tonal contrasts at a lower level of proficiency. The extent of their impairment varied depending on severity level of aphasia. When compared to normal speakers, tonal identification for less severe nonfluent aphasics differed more in degree than in kind, and for more severe nonfluent aphasics differed both in kind and in degree. Acoustic analysis revealed that with the exception of one left nonfluent, average Fo contours were comparable in shape across speaker groups. Variability in Fo production, however, was greater in left nonfluent speakers than in any of the other four groups of speakers. Issues are discussed regarding the extent and nature of tonal disruption in aphasia and hemispheric specialization for tone production.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Gandour, J. and Ponglorpisit, S. and Khunadorn, F. and Dechongkit, S. and Boongird, P. and Boonklam, R. and Potisuk, S.},
	month = aug,
	year = {1992},
	pmid = {1393523},
	keywords = {aphasia-dementia},
	pages = {275--307}
}

@article{duffy_primary_2015,
	title = {Primary progressive apraxia of speech: clinical features and acoustic and neurologic correlates},
	volume = {24},
	issn = {1558-9110},
	shorttitle = {Primary progressive apraxia of speech},
	doi = {10.1044/2015_AJSLP-14-0174},
	abstract = {PURPOSE: This study summarizes 2 illustrative cases of a neurodegenerative speech disorder, primary progressive apraxia of speech (AOS), as a vehicle for providing an overview of the disorder and an approach to describing and quantifying its perceptual features and some of its temporal acoustic attributes.
METHOD: Two individuals with primary progressive AOS underwent speech-language and neurologic evaluations on 2 occasions, ranging from 2.0 to 7.5 years postonset. Performance on several tests, tasks, and rating scales, as well as several acoustic measures, were compared over time within and between cases. Acoustic measures were compared with performance of control speakers.
RESULTS: Both patients initially presented with AOS as the only or predominant sign of disease and without aphasia or dysarthria. The presenting features and temporal progression were captured in an AOS Rating Scale, an Articulation Error Score, and temporal acoustic measures of utterance duration, syllable rates per second, rates of speechlike alternating motion and sequential motion, and a pairwise variability index measure.
CONCLUSIONS: AOS can be the predominant manifestation of neurodegenerative disease. Clinical ratings of its attributes and acoustic measures of some of its temporal characteristics can support its diagnosis and help quantify its salient characteristics and progression over time.},
	language = {eng},
	number = {2},
	journal = {American Journal of Speech-Language Pathology},
	author = {Duffy, Joseph R. and Strand, Edythe A. and Clark, Heather and Machulda, Mary and Whitwell, Jennifer L. and Josephs, Keith A.},
	month = may,
	year = {2015},
	pmid = {25654422},
	pmcid = {PMC4451786},
	keywords = {aphasia-dementia},
	pages = {88--100},
	file = {Accepted Version:/Users/transfer/Zotero/storage/8M4G6ECZ/Duffy et al. - 2015 - Primary progressive apraxia of speech clinical fe.pdf:application/pdf}
}

@article{itoh_voice_1982,
	title = {Voice onset time characteristics in apraxia of speech},
	volume = {17},
	issn = {0093-934X},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Itoh, M. and Sasanuma, S. and Tatsumi, I. F. and Murakami, S. and Fukusako, Y. and Suzuki, T.},
	month = nov,
	year = {1982},
	pmid = {7159832},
	keywords = {aphasia-dementia},
	pages = {193--210}
}

@article{canter_contrasting_1985,
	title = {Contrasting speech patterns in apraxia of speech and phonemic paraphasia},
	volume = {24},
	issn = {0093-934X},
	abstract = {This study was designed to determine if perceptual phonological analysis would reveal distinctions between patients with apraxia of speech and patients with phonemic paraphasic speech. Test findings from 10 Broca's aphasics with apraxia of speech were compared to findings from 10 paraphasic speakers (5 conduction and 5 Wernicke's aphasics). Several marked differences were revealed. Predominant locus of errors and relative difficulty of different classes of phonemic segments were significant discriminators. There was a nonsignificant trend for substituted phonemes to be further from target phonetically in the paraphasic patients. In addition, the two groups showed certain consistent differences in the types of errors they produced. Apraxic patients produced many errors of transitionalization, while sequencing errors were more typical of the patients with phonemic paraphasia. The findings are interpreted in relation to a neuropsychological model of speech. It is suggested that phonemic paraphasia represents a breakdown mainly in the retrieval of phonological word patterns, while apraxia of speech is characterized predominantly by a disturbance in encoding phonological patterns into appropriate speech movements.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Canter, G. J. and Trost, J. E. and Burns, M. S.},
	month = mar,
	year = {1985},
	pmid = {3978403},
	keywords = {aphasia-dementia},
	pages = {204--222}
}

@article{holloman_perceptual_1991,
	title = {Perceptual and acoustical analyses of phonemic paraphasias in nonfluent and fluent dysphasia},
	volume = {24},
	issn = {0021-9924},
	abstract = {Phonemic paraphasias produced by nonfluent and fluent dysphasic adults during connected speech elicitations were examined using four perceptual and two acoustical variables. Results revealed important findings for each of the examined variables. The acoustical variables, however, were more helpful for differentiating the two dysphasic categories. The findings obtained also relate to factors such as phoneme frequency, suprasegmental feature of stress placement, anatomicophysiological characteristics of phonemes, and the interaction between the linguistic parameters of phonology and semantics. These factors have implications for the treatment of verbal dyspraxia in nonfluent and fluent dysphasia.},
	language = {eng},
	number = {4},
	journal = {Journal of Communication Disorders},
	author = {Holloman, A. L. and Drummond, S. S.},
	month = aug,
	year = {1991},
	pmid = {1791217},
	keywords = {aphasia-dementia},
	pages = {301--312}
}

@article{ryalls_atypical_2006,
	title = {An atypical case of {Foreign} {Accent} {Syndrome}},
	volume = {20},
	issn = {0269-9206},
	doi = {10.1080/02699200400026900},
	abstract = {A new case of Foreign Accent Syndrome is described. This American woman presented with a British- or Australian- sounding accent after stroke, which resulted in a lacunar infarct in the left internal capsule. The atypical etiology and apparent changes in lexical use are described. It is hypothesized that an abnormally tense vocal tract posture may account for phonetic changes in vowel quality and a higher average fundamental frequency.},
	language = {eng},
	number = {2-3},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Ryalls, Jack and Whiteside, Janet},
	month = may,
	year = {2006},
	pmid = {16428232},
	keywords = {aphasia-dementia},
	pages = {157--162}
}

@article{jacks_bite_2008,
	title = {Bite block vowel production in apraxia of speech},
	volume = {51},
	issn = {1092-4388},
	doi = {10.1044/1092-4388(2008/066)},
	abstract = {PURPOSE: This study explored vowel production and adaptation to articulatory constraints in adults with acquired apraxia of speech (AOS) plus aphasia.
METHOD: Five adults with acquired AOS plus aphasia and 5 healthy control participants produced the vowels [i], [epsilon], and [ae] in four word-length conditions in unconstrained and bite block conditions. In addition to acoustic and perceptual measures of vowel productions, individually determined idealized vowels based on each participant's best performance were used to assess vowel accuracy and distinctiveness.
RESULTS: Findings showed (a) clear separation of vowel formants in speakers with AOS; (b) impaired vowel production in speakers with AOS, shown by perceptual measures of vowel quality and acoustic measures of vowel accuracy and contrastivity; and (c) incomplete compensation to bite block compensation both for individuals with AOS and for healthy controls.
CONCLUSIONS: Although adults with AOS were less accurate overall in vowel production than unimpaired speakers, introduction of a bite block resulted in similar patterns of decreased vowel accuracy for the two groups. Findings suggest that feedback control for vowel production is relatively intact in these individuals with AOS and aphasia. Predominant use of feedback control mechanisms is hypothesized to account for characteristic vowel deficits of the disorder.},
	language = {eng},
	number = {4},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Jacks, Adam},
	month = aug,
	year = {2008},
	pmid = {18658060},
	keywords = {aphasia-dementia},
	pages = {898--913}
}

@article{duffy_temporal_2017,
	title = {Temporal acoustic measures distinguish primary progressive apraxia of speech from primary progressive aphasia},
	volume = {168},
	issn = {1090-2155},
	doi = {10.1016/j.bandl.2017.01.012},
	abstract = {The purpose of this study was to determine if acoustic measures of duration and syllable rate during word and sentence repetition, and a measure of within-word lexical stress, distinguish speakers with primary progressive apraxia of speech (PPAOS) from nonapraxic speakers with the agrammatic or logopenic variants of primary progressive aphasia (PPA), and control speakers. Results revealed that the PPAOS group had longer durations and reduced rate of syllable production for most words and sentences, and the measure of lexical stress. Sensitivity and specificity indices for the PPAOS versus the other groups were highest for longer multisyllabic words and sentences. For the PPAOS group, correlations between acoustic measures and perceptual ratings of AOS were moderately high to high. Several temporal measures used in this study may aid differential diagnosis and help quantify features of PPAOS that are distinct from those associated with PPA in which AOS is not present.},
	language = {eng},
	journal = {Brain and Language},
	author = {Duffy, Joseph R. and Hanley, Holly and Utianski, Rene and Clark, Heather and Strand, Edythe and Josephs, Keith A. and Whitwell, Jennifer L.},
	year = {2017},
	pmid = {28187331},
	pmcid = {PMC5366265},
	keywords = {aphasia-dementia},
	pages = {84--94},
	file = {Accepted Version:/Users/transfer/Zotero/storage/77HFI4QC/Duffy et al. - 2017 - Temporal acoustic measures distinguish primary pro.pdf:application/pdf}
}

@article{martin_computational_1992,
	title = {A computational account of deep dysphasia: evidence from a single case study},
	volume = {43},
	issn = {0093-934X},
	shorttitle = {A computational account of deep dysphasia},
	abstract = {We present a case study of a patient, NC, who demonstrates the defining characteristics of deep dysphasia including semantic errors in repetition and an inability to repeat nonwords. In addition, NC's single word repetition and lexical decision performances are influenced by the imageability of the word input. NC also demonstrates a severely restricted phonological short-term memory (one digit, one word). Although his phonological discrimination is good in a minimal pairs judgment task, it becomes impaired when a delay is imposed or rehearsal is prevented between presentation of each member of a pair. NC's output is fluent but contains many formal paraphasias and neologisms. NC's total language profile is evaluated within the framework of Dell's (1986) interactive spreading activation model of language production. Adapting this output model to input processes, we account for all of NC's deep dysphasic symptoms as well as his pattern of production in a way that is more parsimonious than other attempts to model this disorder. In particular, we suggest that the semantic and formal paraphasias in naming and repetition result from a pathological increase in the rate of decay of primed nodes in the semantic-lexical-phonological network. This rapid decay increases the probability that phonologically and/or semantically related lexical nodes primed by top-down and bottom-up feedback during the operation of lexical activation and retrieval will be activated and selected instead of the lexical target. The advantages of using this model to account for aphasic symptoms and the implications for other lexical theories are discussed.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Martin, N. and Saffran, E. M.},
	month = aug,
	year = {1992},
	pmid = {1393522},
	keywords = {aphasia-dementia},
	pages = {240--274}
}

@article{alpert_comparison_2002,
	title = {A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia},
	volume = {36},
	issn = {0022-3956},
	abstract = {In this report we compare clinical ratings of flat affect and alogia with objective measures of the patient's speech prosody and productivity. Thirty schizophrenic patients were evaluated with the Scale for the Assessment of Negative Symptoms (SANS) and the St. Hans Rating Scale for extra pyramidal side effects. Their speech was recorded and analyzed acoustically for measures of prosody and productivity. Correlations between pairs of SANS items and acoustic measures (e.g. Vocal Inflection and Fundamental Frequency Variance) were weak. The SANS item and global ratings were strongly related. Ratings of bradykinesia overlapped with the SANS ratings but not with the acoustic measures. The SANS ratings appear to be derived from global impressions, with diffuse confounding of flat affect with alogia, and with bradykinesia. Acoustic analysis has the potential to provide objective measures that may help develop operational definitions of these constructs and enhance clinical assessment.},
	language = {eng},
	number = {5},
	journal = {Journal of Psychiatric Research},
	author = {Alpert, Murray and Shaw, Richard J. and Pouget, Enrique R. and Lim, Kelvin O.},
	month = oct,
	year = {2002},
	pmid = {12127603},
	keywords = {aphasia-dementia},
	pages = {347--353}
}

@article{mcdonald_dice_1995,
	title = {The 'dice' game: a new test of pragmatic language skills after closed-head injury},
	volume = {9},
	issn = {0269-9052},
	shorttitle = {The 'dice' game},
	abstract = {There are few clinical tools available to assess communication skills following closed-head injury. This paper describes one such task in which the subject is required to explain a board game to a naive listener. The explanation is taped, transcribed and the content is quantified. Reliability studies demonstrated that the test can be consistently scored. A group of 43 normal subjects was investigated, and some variation in performance according to age and educational background was revealed. A group of 20 brain-injured male adults with executive-type deficits were then compared to a matched subgroup of the controls. The clinical group produced less essential information and relatively more unnecessary information than their non-brain-damaged counterparts. Qualitative features of discourse disorganization were also revealed.},
	language = {eng},
	number = {3},
	journal = {Brain Injury},
	author = {McDonald, S. and Pearce, S.},
	month = apr,
	year = {1995},
	pmid = {7541680},
	keywords = {aphasia-dementia},
	pages = {255--271}
}

@article{gandour_interaction_1997,
	title = {Interaction between tone and intonation in {Thai} after unilateral brain damage},
	volume = {58},
	issn = {0093-934X},
	doi = {10.1006/brln.1997.1768},
	abstract = {Intonational characteristics of Thai sentences were used to evaluate fundamental frequency (F(0)) control in brain-damaged patients with unilateral left and right hemisphere lesions. Subjects (n = 41) included 9 young and 10 old normal adults, 12 right hemisphere patients, and 10 left hemisphere aphasic patients (7 fluent and 3 nonfluent). Sentences were comprised of six words, three of which were keywords occurring in sentence-initial, -medial, and -final positions. All 125 possible sequences of three of the five Thai tones (mid, low, falling, high, rising) were superimposed on monosyllabic keywords. Utterances were produced at a conversational speaking rate. Average F(0) of keywords was analyzed as a function of sentence position, tone, and group. For both normal and brain-damaged speakers, results indicated that tones in sentence-final position were significantly lower in F(0) than in either sentence-initial or -medial position; falling and high tones were significantly higher in F(0) than mid, low, and rising tones. Findings are discussed in relation to issues pertaining to hemispheric specialization and the nature of F(0) deficits in nonfluent and fluent aphasic patients.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Gandour, J. and Ponglorpisit, S. and Potisuk, S. and Khunadorn, F. and Boongird, P. and Dechongkit, S.},
	month = jun,
	year = {1997},
	pmid = {9184102},
	keywords = {aphasia-dementia},
	pages = {174--196}
}

@article{riedel_extending_1985,
	title = {Extending formant transitions may not improve aphasics' perception of stop consonant place of articulation},
	volume = {24},
	issn = {0093-934X},
	abstract = {Synthetic speech stimuli were used to investigate whether aphasics' ability to perceive stop consonant place of articulation was enhanced by the extension of initial formant transitions in CV syllables. Phoneme identification and discrimination tests were administered to 12 aphasic patients, 5 fluent and 7 nonfluent. There were no significant differences in performance due to the extended transitions, and no systematic pattern of performance due to aphasia type. In both groups, discrimination was generally high and significantly better than identification, demonstrating that auditory capacity was retained, while phonetic perception was impaired; this result is consistent with repeated demonstrations that auditory and phonetic processes may be dissociated in normal listeners. Moreover, significant rank order correlations between performances on the Token Test and on both perceptual tasks suggest that impairment on these tests may reflect a general cognitive rather than a language-specific deficit.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Riedel, K. and Studdert-Kennedy, M.},
	month = mar,
	year = {1985},
	pmid = {3978404},
	keywords = {aphasia-dementia},
	pages = {223--232}
}

@article{kurowski_nature_2003,
	title = {The nature of speech production impairments in anterior aphasics: an acoustic analysis of voicing in fricative consonants},
	volume = {84},
	issn = {0093-934X},
	shorttitle = {The nature of speech production impairments in anterior aphasics},
	abstract = {This study investigated the acoustic characteristics of voicing in English fricative consonants produced by anterior aphasics and the effects of phonetic context on these characteristics. Three patients produced voiced and voiceless fricative-vowel syllables in isolation, following a voiced velar stop, and following a voiceless velar stop. Acoustic analyses were conducted of the amplitude and patterning of glottal excitation, as well as fricative noise duration. Results showed that, although the patients are able to coordinate the articulatory gestures for voicing in fricative consonants, they demonstrated abnormal patterns of glottal excitation in the amplitude measures, owing to weaker amplitudes of glottal excitation in voiced fricatives. Context effects failed to emerge because of dysfluent speech. These results suggest that the locus of the speech production deficit of anterior aphasics is not at the higher stages of phoneme selection or planning but rather in articulatory implementation, one related to laryngeal control.},
	language = {eng},
	number = {3},
	journal = {Brain and Language},
	author = {Kurowski, Kathleen and Hazen, Eric and Blumstein, Sheila E.},
	month = mar,
	year = {2003},
	pmid = {12662976},
	keywords = {aphasia-dementia},
	pages = {353--371}
}

@article{shah_neural_2006,
	title = {Neural substrates of linguistic prosody: evidence from syntactic disambiguation in the productions of brain-damaged patients},
	volume = {96},
	issn = {0093-934X},
	shorttitle = {Neural substrates of linguistic prosody},
	doi = {10.1016/j.bandl.2005.04.005},
	abstract = {The present investigation focussed on the neural substrates underlying linguistic distinctions that are signalled by prosodic cues. A production experiment was conducted to examine the ability of left- (LHD) and right- (RHD) hemisphere-damaged patients and normal controls to use temporal and fundamental frequency cues to disambiguate sentences which include one or more Intonational Phrase level prosodic boundaries. Acoustic analyses of subjects' productions of three sentence types-parentheticals, appositives, and tags-showed that LHD speakers, compared to RHD and normal controls, exhibited impairments in the control of temporal parameters signalling phrase boundaries, including inconsistent patterns of pre-boundary lengthening and longer-than-normal pause durations in non-boundary positions. Somewhat surprisingly, a perception test presented to a group of normal native listeners showed listeners experienced greatest difficulty in identifying the presence or absence of boundaries in the productions of the RHD speakers. The findings support a cue lateralization hypothesis in which prosodic domain plays an important role.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Shah, Amee P. and Baum, Shari R. and Dwivedi, Veena D.},
	month = jan,
	year = {2006},
	pmid = {15922444},
	keywords = {aphasia-dementia},
	pages = {78--89}
}

@article{romani_patterns_2002,
	title = {Patterns of phonological errors as a function of a phonological versus an articulatory locus of impairment},
	volume = {38},
	issn = {0010-9452},
	abstract = {We present the case of two aphasic patients: one with fluent speech, MM, and one with dysfluent speech, DB. Both patients make similar proportions of phonological errors in speech production and the errors have similar characteristics. A closer analysis, however, shows a number of differences. DB's phonological errors involve, for the most part, simplifications of syllabic structure; they affect consonants more than vowels; and, among vowels, they show effects of sonority/complexity. This error pattern may reflect articulatory difficulties. MM's errors, instead, show little effect of syllable structure, affect vowels at least as much as consonants and, and affect all different vowels to a similar extent. This pattern is consistent with a more central impairment involving the selection of the right phoneme among competing alternatives. We propose that, at this level, vowel selection may be more difficult than consonant selection because vowels belong to a smaller set of repeatedly activated units.},
	language = {eng},
	number = {4},
	journal = {Cortex; a Journal Devoted to the Study of the Nervous System and Behavior},
	author = {Romani, Cristina and Olson, Andrew and Semenza, Carlo and Granà, Alessia},
	month = sep,
	year = {2002},
	pmid = {12465668},
	keywords = {aphasia-dementia},
	pages = {541--567}
}

@article{kurowski_consonant_1998,
	title = {Consonant and vowel production of right hemisphere patients},
	volume = {63},
	issn = {0093-934X},
	doi = {10.1006/brln.1997.1939},
	abstract = {Recent reports of subclinical phonetic deficits in posterior and most particularly in Wernicke's aphasics have challenged the traditional dichotomy which characterized speech deficits in aphasia as anterior/phonetic and posterior/phonological. It is unclear whether the basis of the phonetic deficit in posterior aphasics reflects the fact that the speech production system extends to more posterior regions of the left hemisphere than previously thought or alternatively is the result of generalized brain damage effects. The present study explores the latter possibility by investigating the patterns of speech production in right hemisphere brain-damaged, non-aphasic patients with anterior and posterior lesions. Acoustic analyses conducted on a range of consonant and vowel parameters showed differences between the speech patterns of both anterior and posterior right hemisphere patients and that of Wernicke's aphasics. These findings suggest that the subclinical deficit of Wernicke's aphasics can not simply be ascribed to a generalized brain-damage effect and raise the possibility that the right hemisphere also plays some role, if only a minor one, in the phonetic implementation of speech.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Kurowski, K. M. and Blumstein, S. E. and Mathison, H.},
	month = jun,
	year = {1998},
	pmid = {9654435},
	keywords = {aphasia-dementia},
	pages = {276--300}
}

@article{gandour_anticipatory_1993,
	title = {Anticipatory tonal coarticulation in {Thai} noun compounds after unilateral brain damage},
	volume = {45},
	issn = {0093-934X},
	doi = {10.1006/brln.1993.1030},
	abstract = {The time course and extent of anticipatory coarticulation between tones was investigated in normal and brain-damaged Thai-speaking subjects. Subjects were classified into five groups including 11 young normal, 9 old normal, 12 right hemisphere, 9 left hemisphere fluent, and 6 left hemisphere nonfluent. Stimuli consisted of five bisyllabic noun compounds with a falling tone on the initial syllable and each of the five Thai tones (mid, low, falling, high, rising) on the final syllable. Height and slope of F0 was measured at 10\% intervals throughout the duration of the initial syllable. Results indicated anticipatory effects on both height and slope of the falling tone. Height effects extended throughout from the beginning. The falling tone was generally higher when occurring before the low/rising tones than when occurring before the mid/falling/high tones. Slope effects were restricted to the terminal portion. The falling tone before low/rising tones exhibited a steeper slope than before falling/high tones. In magnitude of effect, patients with left and right hemisphere lesions were statistically indistinguishable from those of normal subjects. No differences were noted in coarticulatory patterns as a function of aphasia type. All brain-damaged speakers were more variable in F0 production than normals. Findings are interpreted to highlight properties of nonfluent aphasic speech and neurological bases of speech production.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Gandour, J. and Ponglorpisit, S. and Dechongkit, S. and Khunadorn, F. and Boongird, P. and Potisuk, S.},
	month = jul,
	year = {1993},
	pmid = {8353725},
	keywords = {aphasia-dementia},
	pages = {1--20}
}

@article{jakubowicz_processing_1995,
	title = {Processing of number and gender inflections by {French}-speaking aphasics},
	volume = {51},
	issn = {0093-934X},
	doi = {10.1006/brln.1995.1060},
	abstract = {This study investigates French-speaking aphasics' sensitivity to gender (of human nouns) and number marking in a sentential context. Using a forced picture choice task, we tested sentences in which grammatical marking surfaced either on a function word or on a content word, within or outside a noun phrase (NP) whose gender or number was required to be identified. Ten fluent and 10 nonfluent aphasics together with 20 adults without neurological history were tested. Results showed that neither group of aphasics presented an across-the-board deficit. Nonfluent patients were strongly impaired when marking surfaced on a content word outside NP (verbs and adjectives), but their sensitivity to grammatical marking was relatively well preserved in the within NP condition (determiners and nouns) and for function words in the outside NP condition (the copula). Fluent patients showed a specific impairment in dealing with semantic gender (as opposed to number information); and their difficulty was exacerbated when the information conveyed by the suffix of a content word must be integrated into an higher order semantic representation, as in the outside NP condition (adjectives). These results are consistent with the view that for both nonfluent and fluent aphasics, the functional locus of their impairment lies on a reduction in the computational resources available to the language processor, which is more severe in the former than in the latter group.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Jakubowicz, C. and Goldblum, M. C.},
	month = nov,
	year = {1995},
	pmid = {8564471},
	keywords = {aphasia-dementia},
	pages = {242--268}
}

@article{kurowski_foreign_1996,
	title = {The foreign accent syndrome: a reconsideration},
	volume = {54},
	issn = {0093-934X},
	shorttitle = {The foreign accent syndrome},
	doi = {10.1006/brln.1996.0059},
	abstract = {This study compared the post-CVA speech of a patient presenting with the foreign accent syndrome (FAS) to both a premorbid baseline for that patient and to similarly analyzed data from an earlier reported case of FAS. The object of this research was to provide quantitative acoustic data to determine whether: (1) the constellation of phonetic features associated with FAS is the same across patients and (2) a common neural mechanism underlies FAS. Acoustic parameters investigated included features of consonant production (voicing, place and manner of articulation), vowel production (formant frequency and duration), and prosody. Results supported the characterization of FAS patients as having a "generic" foreign accent and the hypothesis that FAS deficits are qualitatively different from that of Broca's aphasia. However, comparison of this case with recent studies revealed the extent to which the constellation of phonetic features may vary among FAS patients, challenging the notion that a general prosodic disturbance is the sole underlying mechanism in FAS.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Kurowski, K. M. and Blumstein, S. E. and Alexander, M.},
	month = jul,
	year = {1996},
	pmid = {8811940},
	keywords = {aphasia-dementia},
	pages = {1--25}
}

@article{yang_[acoustic_2008,
	title = {[{Acoustic} characteristics of adductor spasmodic dysphonia]},
	volume = {43},
	issn = {1673-0860},
	abstract = {OBJECTIVE: To explore the acoustic characteristics of adductor spasmodic dysphonia.
METHODS: The acoustic characteristics, including acoustic signal of recorded voice, three-dimensional sonogram patterns and subjective assessment of voice, between 10 patients (7 women, 3 men) with adductor spasmodic dysphonia and 10 healthy volunteers (5 women, 5 men), were compared.
RESULTS: The main clinical manifestation of adductor spasmodic dysphonia included the disorders of sound quality, rhyme and fluency. It demonstrated the tension dysphonia when reading, acoustic jitter, momentary fluctuation of frequency and volume, voice squeezing, interruption, voice prolongation, and losing normal chime. Among 10 patients, there were 1 mild dysphonia (abnormal syllable number {\textless} 25\%), 6 moderate dysphonia (abnormal syllable number 25\%-49\%), 1 severe dysphonia (abnormal syllable number 50\%-74\%) and 2 extremely severe dysphonia (abnormal syllable number {\textgreater} or = 75\%). The average reading time in 10 patients was 49 s, with reading time extension and aphasia area interruption in acoustic signals, whereas the average reading time in health control group was 30 s, without voice interruption. The aphasia ratio averaged 42\%. The respective symptom syllable in different patients demonstrated in the three-dimensional sonogram. There were voice onset time prolongation, irregular, interrupted and even absent vowel formants. The consonant of symptom syllables displayed absence or prolongation of friction murmur in the block-friction murmur occasionally.
CONCLUSIONS: The acoustic characteristics of adductor spasmodic dysphonia is the disorders of sound quality, rhyme and fluency. The three-dimensional sonogram of the symptom syllables show distinctive changes of proportional vowels or consonant phonemes.},
	language = {chi},
	number = {6},
	journal = {Zhonghua Er Bi Yan Hou Tou Jing Wai Ke Za Zhi = Chinese Journal of Otorhinolaryngology Head and Neck Surgery},
	author = {Yang, Yang and Wang, Li-Ping},
	month = jun,
	year = {2008},
	pmid = {18826092},
	keywords = {aphasia-dementia},
	pages = {419--423}
}

@article{bacon_auditory_1992,
	title = {Auditory comprehension of "yes-no" questions by adult aphasics},
	volume = {25},
	issn = {0021-9924},
	abstract = {Two groups of adult aphasics were administered four different types of auditory-verbal "yes-no" questions. One group received questions including egocentric, environmental, pictorial, and relationship items in a consistent order. The second group received the same questions in random order. Support was found for the existence of a hierarchy of difficulty among the types of auditory-verbal "yes-no" questions. There was no significant difference between the two groups' performance even though the consistent presentation group was slightly superior to the random order group on the auditory-verbal "yes-no" questions.},
	language = {eng},
	number = {1},
	journal = {Journal of Communication Disorders},
	author = {Bacon, G. M. and Potter, R. E. and Seikel, J. A.},
	month = mar,
	year = {1992},
	pmid = {1401227},
	keywords = {aphasia-dementia},
	pages = {23--29}
}

@article{stark_analysis_1979,
	title = {Analysis of stop consonant production errors in developmentally dysphasic children},
	volume = {66},
	issn = {0001-4966},
	abstract = {The speech production skills of 12 dysphasic children and of 12 normal children were compared. The dysphasic children were found to have significantly greater difficulty than the normal children in producing stop consonants. In addition, it was found that seven of the dysphasic children, who had difficulty in perceiving initial stop consonants, had greater difficulty in producing stop consonants than the remaining five dysphasic children who showed no such perceptual difficulty. A detailed phonetic analysis indicated that the dysphasic children seldom omitted stops or substituted nonstop for stop consonants. Instead, their errors were predominantly of voicing or place of articulation. Acoustic analyses suggested that the voicing errors were related to lack of precise control over the timing of speech events, specifically, voice onset time for initial stops and vowel duration preceding final stops. The number of voicing errors on final stops, however, was greater than expected on the basis of lack of differentiation of vowel duration alone. They appeared also to be related to a tendency in the dysphasic children to produce final stops with exaggerated aspiration. The possible relationship of poor timing control in speech production in these children and auditory temporal processing deficits in speech perception is discussed.},
	language = {eng},
	number = {6},
	journal = {The Journal of the Acoustical Society of America},
	author = {Stark, R. E. and Tallal, P.},
	month = dec,
	year = {1979},
	pmid = {521554},
	keywords = {aphasia-dementia},
	pages = {1703--1712}
}

@article{yeni-komshian_discrimination_1983,
	title = {Discrimination and identification of voicing and place contrasts in aphasic patients},
	volume = {37},
	issn = {0008-4255},
	language = {eng},
	number = {1},
	journal = {Canadian Journal of Psychology},
	author = {Yeni-Komshian, G. H. and Lafontaine, L.},
	month = mar,
	year = {1983},
	pmid = {6640436},
	keywords = {aphasia-dementia},
	pages = {107--131}
}

@article{pellat_aphemia_1991,
	title = {Aphemia after a penetrating brain wound: a case study},
	volume = {40},
	issn = {0093-934X},
	shorttitle = {Aphemia after a penetrating brain wound},
	abstract = {The speech of a patient with aphemia (pure anarthria) resulting from a penetrating brain wound was studied using linguistic and acoustic observations as well as electromyographic recordings from four labial muscles. The results are discussed in relation to phonetic disintegration's syndrome and apraxia of speech which, respectively, enhance linguistic disorders and motor programming disturbance.},
	language = {eng},
	number = {4},
	journal = {Brain and Language},
	author = {Pellat, J. and Gentil, M. and Lyard, G. and Vila, A. and Tarel, V. and Moreau, O. and Benabid, A. L.},
	month = may,
	year = {1991},
	pmid = {1878779},
	keywords = {aphasia-dementia},
	pages = {459--470}
}

@article{gandour_production_2001,
	title = {Production of stress retraction by left- and right-hemisphere-damaged patients},
	volume = {79},
	issn = {0093-934X},
	doi = {10.1006/brln.2001.2562},
	abstract = {An acoustic-perceptual investigation of a phonological phenomenon in which stress is retracted in double-stressed words (e.g., thirTEEN vs THIRteen MEN) was undertaken to identify the locus of functional impairments in speech prosody. Subjects included left-hemisphere-damaged (LHD) and right-hemisphere-damaged (RHD) patients and nonneurological controls. They were instructed to read sentences containing double-stressed target words in the presence of a clause boundary or its absence. Whereas all three groups of subjects were capable of manipulating the acoustic parameters that signal a shift in stress, there were some differences between the performance of the patient groups and that of the normal controls. Further, stress production deficits were more severe in LHD aphasic patients than in RHD patients. LHD speakers exhibited deficits in the control of both temporal and F0 cues. Their F0 disturbance appears to be secondary to a primary deficit in temporal control at the phase or sentence level, as an increased number of continuation rises found for the LHD patients seemed to arise from lengthy pauses within sentences. Findings are highlighted to address the nature of breakdown in speech prosody and the competing views of prosodic lateralization.},
	language = {eng},
	number = {3},
	journal = {Brain and Language},
	author = {Gandour, J. and Baum, S. R.},
	month = dec,
	year = {2001},
	pmid = {11781055},
	keywords = {aphasia-dementia},
	pages = {482--494}
}

@article{lubert_auditory_1981,
	title = {Auditory perceptual impairments in children with specific language disorders: a review of the literature},
	volume = {46},
	issn = {0022-4677},
	shorttitle = {Auditory perceptual impairments in children with specific language disorders},
	abstract = {This article reviews the literature on auditory perceptual impairments in children with language disorders. It is suggested that, rather than a higher-order cognitive or "linguistic" deficit, the underlying deficit in childhood language disorders is a perceptual one. The perceptual impairment may consist of a deficiency in detecting acoustic features in the speech wave that normally cue certain phonemes. Support for this hypothesis comes from clinical observations and experimental studies of aphasic adults as well as language-disordered children. The most consistent finding of the studies with language-disordered children has been that they have difficulty making perceptual judgments of the order of rapid sequences of brief sounds, such as synthetic speech and non-speech stimuli. However, these children perceive the sequences more accurately if the duration of the stimuli or the inter-stimulus intervals are extended. This suggests a "rate-specific" auditory perceptual deficit in language-disordered children for rapid acoustic information, such as the distinctive acoustic features of speech sounds. Treatment and future research implications are discussed.},
	language = {eng},
	number = {1},
	journal = {The Journal of Speech and Hearing Disorders},
	author = {Lubert, N.},
	month = feb,
	year = {1981},
	pmid = {7206670},
	keywords = {aphasia-dementia},
	pages = {1--9}
}

@article{knobel_evaluating_2007,
	title = {Evaluating computational models in cognitive neuropsychology: the case from the consonant/vowel distinction},
	volume = {100},
	issn = {0093-934X},
	shorttitle = {Evaluating computational models in cognitive neuropsychology},
	doi = {10.1016/j.bandl.2006.06.008},
	abstract = {Caramazza et al. [Caramazza, A., Chialant, D., Capasso, R., \& Miceli, G. (2000). Separable processing of consonants and vowels. Nature, 403(6768), 428-430.] report two patients who exhibit a double dissociation between consonants and vowels in speech production. The patterning of this double dissociation cannot be explained by appealing to sub-phonemic distinctions, such as sonority level or damage to specific phonological features. They argue that consonant/vowel status is an autonomous level of representation. Monaghan and Shillcock [Monaghan, P., \& Shillcock, R. (2003). Connectionist modelling of the separable processing of consonants and vowels. Brain and Language, 86(1), 83-98.] present computational models which supposedly exhibit a similar double dissociation. They contend that these models can explain the patient data, without appeal to such supra-phonemic distinctions as consonant/vowel status. Here we argue that their claim fails to meet two necessary criteria. Their models do not fit the pattern of the patient data, either quantitatively or qualitatively. Furthermore, the motivation for these models is unclear beyond just being an attempt to explain this specific phenomenon. We conclude that these models, in their current form, do not provide an alternative explanation to the representation of consonants and vowels.},
	language = {eng},
	number = {1},
	journal = {Brain and Language},
	author = {Knobel, Mark and Caramazza, Alfonso},
	month = jan,
	year = {2007},
	pmid = {16879863},
	keywords = {aphasia-dementia},
	pages = {95--100; discussion 101--108}
}

@article{lind_prosodic_2007,
	title = {Prosodic contextualization of minimal responses to yes/no-questions in aphasic talk-in-interaction: a descriptive single-case study of a {Norwegian} aphasic speaker},
	volume = {32},
	issn = {1401-5439},
	shorttitle = {Prosodic contextualization of minimal responses to yes/no-questions in aphasic talk-in-interaction},
	doi = {10.1080/14015430600630860},
	abstract = {The article explores aspects of the role of prosody as a contextualization cue in aphasic conversation through auditory and acoustic analysis of an aphasic speaker's use of pitch variation in responses to closed yes/no-requests. The results reveal two prosodic realizations of 'yes' and 'no' contextualizing different kinds of responses: a flat realization with no prolongation and minimal pauses, signalling decisiveness, and a realization with movement in pitch, prolongation and preceding pauses, signalling indecisiveness. The analysis also shows how the aphasic uses a particular realization manipulatively for interactional purposes. The study illustrates the vital role that seemingly unimportant details play in the co-constructive process of creating meaning in interaction. The results indicate an area of competence that seems undisturbed in this speaker.},
	language = {eng},
	number = {1},
	journal = {Logopedics, Phoniatrics, Vocology},
	author = {Lind, Marianne},
	year = {2007},
	pmid = {17454655},
	keywords = {aphasia-dementia},
	pages = {9--16},
	file = {Submitted Version:/Users/transfer/Zotero/storage/TI7E9HDI/Lind - 2007 - Prosodic contextualization of minimal responses to.pdf:application/pdf}
}

@article{leeper_altered_1986,
	title = {Altered acoustic cue discrimination in {Broca}'s and conduction aphasics},
	volume = {19},
	issn = {0021-9924},
	abstract = {The present investigation explored the acoustic cue discrimination abilities of eight Broca's and four conduction aphasic patients and nine normal controls. A word-discrimination test was used to assess the subjects' ability to discriminate selected acoustic cues for distinctive features of phonemes. The words differed from one another by a selected minimal feature, such as stop-gap duration, duration of fricative noise, direction and extent of final format transition, or relative location of friction noise in the spectrum. Results indicated that performance for normal and aphasic subjects was poorer for altered temporal subtest items than for altered spectral subtest items. Within the spectral subtest, fewer Broca's aphasics than conduction aphasics passed the items, while 90\% of the normals passed. Within the temporal subtest, fewer conduction aphasics than Broca's aphasics passed the items, while 75\% of the normal subjects passed this subtest. The results support previous research suggesting that deficiencies in auditory processing of selected acoustic cues are not limited to Wernicke's aphasic individuals but may be found to a varying degree in several aphasic groups.},
	language = {eng},
	number = {2},
	journal = {Journal of Communication Disorders},
	author = {Leeper, H. A. and Shewan, C. M. and Booth, J. C.},
	month = apr,
	year = {1986},
	pmid = {3700708},
	keywords = {aphasia-dementia},
	pages = {83--103}
}

@article{collins_spectrographic_1983,
	title = {Spectrographic analysis of vowel and word duration in apraxia of speech},
	volume = {26},
	issn = {0022-4685},
	abstract = {Most normal speakers of English reduce the duration of the stem word vowel as words increase in length. Theoretically, this durational reduction reflects low-level linguistic knowledge. We posed two questions in this study: First, do speakers with apraxia of speech progressively reduce vowel durations as words increase in length, and second, do these vowel and word durations differ significantly from normal productions? We asked 11 apraxia of speech patients and 11 normal speakers to repeat three sets of three words which progressively increased in length, and we analyzed these productions spectrographically. Our results revealed that both groups reduced vowel duration as words increased in length. Word and vowel duration for apraxia of speech patients, however, were often significantly longer than those for normal speakers. Our results suggest that vowel reduction is a robust phenomenon which resists impairment in apraxia of speech, despite often significant disturbances in motor programming.},
	language = {eng},
	number = {2},
	journal = {Journal of Speech and Hearing Research},
	author = {Collins, M. and Rosenbek, J. C. and Wertz, R. T.},
	month = jun,
	year = {1983},
	pmid = {6887809},
	keywords = {aphasia-dementia},
	pages = {224--230}
}

@article{pashek_effects_1982,
	title = {Effects of rate of speech and linguistic stress on auditory paragraph comprehension of aphasic individuals},
	volume = {25},
	issn = {0022-4685},
	abstract = {Auditory comprehension performance of 20 aphasic and 8 nonaphasic subjects was analyzed in a paragraph comprehension task in which rate of speech and linguistic stress were systematically altered. Aphasic subjects were assigned to either high- or low-level auditory comprehension groups on the basis of their performance on a shortened form of the Token Test. paragraphs were presented either with slow rate of speech (120 wpm) or normal rate of speech (150 wpm) with either normal or exaggerated stress given to critical elements within sentences in the paragraphs. Paragraph comprehension was measured by analyzing subjects' response accuracy on a series of yes/no questions which followed each paragraph. Scores of both aphasic subject groups were significantly higher for paragraphs presented with slow rate of speech than for those presented at normal rate and for paragraphs presented with exaggerated stress than for normal stress paragraphs. No significant interactions between rate and stress were observed. Rate ad stress did not affect performance of nonaphasic subjects. A significant positive correlation between Token Test scores and paragraph scores was observed for high-level aphasic subjects; the correlation between these measures was low and nonsignificant for low-level aphasic subjects. Implications of these findings are discussed for diagnosis and treatment of auditory comprehension deficits in aphasic individuals.},
	language = {eng},
	number = {3},
	journal = {Journal of Speech and Hearing Research},
	author = {Pashek, G. V. and Brookshire, R. H.},
	month = sep,
	year = {1982},
	pmid = {7176610},
	keywords = {aphasia-dementia},
	pages = {377--383}
}

@article{pell_unilateral_1997,
	title = {Unilateral brain damage, prosodic comprehension deficits, and the acoustic cues to prosody},
	volume = {57},
	issn = {0093-934X},
	doi = {10.1006/brln.1997.1736},
	abstract = {Stimuli from two previously presented comprehension tasks of affective and linguistic prosody (Pell \& Baum, 1997) were analyzed acoustically and subjected to several discriminant function analyses, following Van Lancker and Sidtis (1992). An analysis of the errors made on these tasks by left-hemisphere-damaged (LHD) and right-hemisphere-damaged (RHD) subjects examined whether each clinical group relied on specific (and potentially different) acoustic features in comprehending prosodic stimuli (Van Lancker \& Sidtis, 1992). Analyses also indicated whether the brain-damaged patients tested in Pell and Baum (1997) exhibited perceptual impairments in the processing of intonation. Acoustic analyses of the utterances reaffirmed the importance of F0 cues in signaling affective and linguistic prosody. Analyses of subjects' affective misclassifications did not suggest that LHD and RHD patients were biased by different sets of the acoustic features to prosody in judging their meaning, in contrast to Van Lancker and Sidtis (1992). However, qualitative differences were noted in the ability of LHD and RHD patients to identify linguistic prosody, indicating that LHD subjects may be specifically impaired in decoding linguistically defined categorical features of prosodic patterns.},
	language = {eng},
	number = {2},
	journal = {Brain and Language},
	author = {Pell, M. D. and Baum, S. R.},
	month = apr,
	year = {1997},
	pmid = {9126413},
	keywords = {aphasia-dementia},
	pages = {195--214}
}

@article{yamamoto_[dysprosody_2004,
	title = {[{Dysprosody} associated with environmental auditory sound agnosia in right temporal lobe hypoperfusion--a case report]},
	volume = {44},
	issn = {0009-918X},
	abstract = {A 60-year-old right-handed man showed dysprosody and agnosia for environmental sounds. His mother tongue was Japanese, and he could not speak foreign languages. He gradually developed difficulty in speaking from the age of 57 years, speaking non-native Japanese. In addition, he often complained of difficulty in hearing sounds, but audiometry showed no abnormalities. At the age of 60 years, the standard language test of aphasia showed no abnormalities in repetition, verbal comprehension, or reading, suggesting the absence of aphasia. However, in speaking, marked abnormality in rhythm, and occasional lack of postpositional particles and syllable-stumblings were observed. Writing was almost accurate, but a few grammatical errors were observed in speaking were observed. There were no cerebellar symptoms, pyramidal signs, pathologic reflexes, or abnormalities in phonation-related organs. Though the recognition of verbal sounds was maintained, impairment in the recognition of non-verbal sounds was observed. An environmental sound perception test showed correct answers only in 8 of 21 non-verbal sound sources (such as a car starting, glass breaking and so on), suggesting agnosia for environmental sounds. He insisted that the difficulty in perception was due to hearing impairment. However, re-examination with an increase in the sound volume showed similar results. He had no inconvenience in daily life and was not aware of agnosia for environmental sounds. He could recognize and differentiate sounds he heard once. His intelligence was normal, and neither apraxia nor frontal lobe symptoms were observed. MRI of the brain revealed slight atrophy of the right temporal lobe. Cerebral blood flow SPECT showed decreased blood flow from the superior temporal gyrus to the area around the arcuate fasciculi in the right temporal lobe. We considered that the lesion responsible for environmental auditory sound agnosia was present in the area around the secondary auditory area of the right temporal lobe and this patient differed from slowly progressive aphasia characterized by decreased blood flow in the left temporal lobe. Although the pathological process occurring in the area of hypoperfusion remained unclear, early stage of some degenerative disorders was more likely than cerebrovascular disease.},
	language = {jpn},
	number = {1},
	journal = {Rinsho Shinkeigaku = Clinical Neurology},
	author = {Yamamoto, Toshiyuki and Kikuchi, Takeshi and Nagae, Junko and Ogata, Katsuhisa and Ogawa, Masafumi and Kawai, Mitsuru},
	month = jan,
	year = {2004},
	pmid = {15199735},
	keywords = {aphasia-dementia},
	pages = {28--33}
}

@article{tomic_speech_2009,
	title = {Speech and language disorders secondary to diffuse subcortical vascular lesions: {Neurolinguistic} and acoustic analysis. {A} case report},
	volume = {283},
	issn = {1878-5883},
	shorttitle = {Speech and language disorders secondary to diffuse subcortical vascular lesions},
	doi = {10.1016/j.jns.2009.02.361},
	abstract = {BACKGROUND AND PURPOSE: Subcortical white matter (WM) plays an important role in speech production and language processing. Most frequently, cerebral WM lesions are secondary to small vessel disease in patients with vascular risk factors. We report the case of a 53-year-old man with history of hypertension and ischemic subcortical lesions, who presented with speech difficulties and mild cognitive impairment.
METHODS: Language and cognitive assessment included Boston Diagnostic Aphasia Examination, Boston Naming Test, Rey Auditory-Verbal Learning Test, Rey-Osterrieth Complex Figure Test, Trail Making Test A and B, Wisconsin Card Sorting Test, Scale for Evaluation of Perceptive Characteristics of Voice and Speech, and Multidimensional Evaluation of Speech and Voice.
RESULTS: Brain MRI showed ischemic WM lesions and lacunar infarcts in the brainstem and right cerebellum. Cognitive testing revealed mild cognitive impairment, predominantly affecting attention and executive functions. Speech and language analysis demonstrated dysarthria, dysphonia with hypophonia, and imprecise articulation, as well as short rushes of speech, palilalia and mild subcortical dysphasia.
CONCLUSIONS: Neurolinguistic and acoustic analysis in patients with ischemic WM lesions can provide additional information in the understanding of language and speech disturbances, and can assist in patient management.},
	language = {eng},
	number = {1-2},
	journal = {Journal of the Neurological Sciences},
	author = {Tomić, Gordana and Stojanović, Milena and Pavlović, Aleksandra and Stanković, Predrag and Zidverc-Trajković, Jasna and Pavlović, Dragan and Marković-Jovanović, Zagorka and Covicković-Sternić, Nadezda},
	month = aug,
	year = {2009},
	pmid = {19298971},
	keywords = {aphasia-dementia},
	pages = {163--169}
}

@article{basilakos_multivariate_2017,
	title = {A {Multivariate} {Analytic} {Approach} to the {Differential} {Diagnosis} of {Apraxia} of {Speech}},
	volume = {60},
	issn = {1558-9102},
	doi = {10.1044/2017_JSLHR-S-16-0443},
	abstract = {Purpose: Apraxia of speech (AOS) is a consequence of stroke that frequently co-occurs with aphasia. Its study is limited by difficulties with its perceptual evaluation and dissociation from co-occurring impairments. This study examined the classification accuracy of several acoustic measures for the differential diagnosis of AOS in a sample of stroke survivors.
Method: Fifty-seven individuals were included (mean age = 60.8 ± 10.4 years; 21 women, 36 men; mean months poststroke = 54.7 ± 46). Participants were grouped on the basis of speech/language testing as follows: AOS-Aphasia (n = 20), Aphasia Only (n = 24), and Stroke Control (n = 13). Normalized Pairwise Variability Index, proportion of distortion errors, voice onset time variability, and amplitude envelope modulation spectrum variables were obtained from connected speech samples. Measures were analyzed for group differences and entered into a linear discriminant analysis to predict diagnostic classification.
Results: Out-of-sample classification accuracy of all measures was over 90\%. The envelope modulation spectrum variables had the greatest impact on classification when all measures were analyzed together.
Conclusions: This study contributes to efforts to identify objective acoustic measures that can facilitate the differential diagnosis of AOS. Results suggest that further study of these measures is warranted to determine the best predictors of AOS diagnosis.
Supplemental Materials: https://doi.org/10.23641/asha.5611309.},
	language = {eng},
	number = {12},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Basilakos, Alexandra and Yourganov, Grigori and den Ouden, Dirk-Bart and Fogerty, Daniel and Rorden, Chris and Feenaughty, Lynda and Fridriksson, Julius},
	month = dec,
	year = {2017},
	pmid = {29181537},
	pmcid = {PMC6111519},
	keywords = {aphasia-dementia},
	pages = {3378--3392}
}

@article{haley_perceptually_2017,
	title = {Perceptually {Salient} {Sound} {Distortions} and {Apraxia} of {Speech}: {A} {Performance} {Continuum}},
	volume = {26},
	issn = {1558-9110},
	shorttitle = {Perceptually {Salient} {Sound} {Distortions} and {Apraxia} of {Speech}},
	doi = {10.1044/2017_AJSLP-16-0103},
	abstract = {Purpose: We sought to characterize articulatory distortions in apraxia of speech and aphasia with phonemic paraphasia and to evaluate the diagnostic validity of error frequency of distortion and distorted substitution in differentiating between these disorders.
Method: Study participants were 66 people with speech sound production difficulties after left-hemisphere stroke or trauma. They were divided into 2 groups on the basis of word syllable duration, which served as an external criterion for speaking rate in multisyllabic words and an index of likely speech diagnosis. Narrow phonetic transcriptions were completed for audio-recorded clinical motor speech evaluations, using 29 diacritic marks.
Results: Partial voicing and altered vowel tongue placement were common in both groups, and changes in consonant manner and place were also observed. The group with longer word syllable duration produced significantly more distortion and distorted-substitution errors than did the group with shorter word syllable duration, but variations were distributed on a performance continuum that overlapped substantially between groups.
Conclusions: Segment distortions in focal left-hemisphere lesions can be captured with a customized set of diacritic marks. Frequencies of distortions and distorted substitutions are valid diagnostic criteria for apraxia of speech, but further development of quantitative criteria and dynamic performance profiles is necessary for clinical utility.},
	language = {eng},
	number = {2S},
	journal = {American Journal of Speech-Language Pathology},
	author = {Haley, Katarina L. and Jacks, Adam and Richardson, Jessica D. and Wambaugh, Julie L.},
	month = jun,
	year = {2017},
	pmid = {28654944},
	pmcid = {PMC5576969},
	keywords = {aphasia-dementia},
	pages = {631--640},
	file = {Full Text:/Users/transfer/Zotero/storage/U5Q8HS34/Haley et al. - 2017 - Perceptually Salient Sound Distortions and Apraxia.pdf:application/pdf}
}

@article{baylor_assessing_2017,
	title = {Assessing the {Believability} of {Standardized} {Patients} {Trained} to {Portray} {Communication} {Disorders}},
	volume = {26},
	issn = {1558-9110},
	doi = {10.1044/2017_AJSLP-16-0068},
	abstract = {Purpose: The purpose of this study was to evaluate the believability of standardized patients portraying individuals with communication disorders as part of a larger study in which standardized patients help train medical and allied health students about communication disorders.
Method: Two women portrayed persons with aphasia, and 2 men depicted persons with dysarthria associated with Parkinson's disease. Two stakeholder groups rated believability. Speech-language pathologists rated believability of videos online. Persons with aphasia rated aphasia videos during in-person sessions with the researchers.
Results: Targeted believability was 80 or higher (0-100 scale; 0 = not at all believable, 100 = very believable). For speech-language pathologist raters, average ratings met the target for the portrayals of the aphasia characteristics of word-finding problems, agrammaticism, nonverbal communication, and overall portrayal but not for auditory comprehension problems. Targets for the portrayals were met for the dysarthria characteristics of reduced speech movements, reduced loudness, reduced intonation, flat affect, and overall portrayal but not for speech rate. Ratings for different standardized patients portraying the same case were not significantly different from each other on most characteristics. Ratings from persons with aphasia were highly variable.
Conclusion: Standardized patients who do not have communication disorders can portray disorder characteristics in a believable manner.},
	language = {eng},
	number = {3},
	journal = {American Journal of Speech-Language Pathology},
	author = {Baylor, Carolyn and Burns, Michael I. and Struijk, Jennie and Herron, Lindsay and Mach, Helen and Yorkston, Kathryn},
	month = aug,
	year = {2017},
	pmid = {28595263},
	pmcid = {PMC5829793},
	keywords = {aphasia-dementia},
	pages = {791--805}
}

@article{den_ouden_vowel_2018,
	title = {Vowel {Formant} {Dispersion} {Reflects} {Severity} of {Apraxia} of {Speech}},
	volume = {32},
	issn = {0268-7038},
	doi = {10.1080/02687038.2017.1385050},
	abstract = {Background: Apraxia of Speech (AOS) has been associated with deviations in consonantal voice-onset-time (VOT), but studies of vowel acoustics have yielded conflicting results. However, a speech motor planning disorder that is not bound by phonological categories is expected to affect vowel as well as consonant articulations.
Aims: We measured consonant VOTs and vowel formants produced by a large sample of stroke survivors, and assessed to what extent these variables and their dispersion are predictive of AOS presence and severity, based on a scale that uses clinical observations to rate gradient presence of AOS, aphasia, and dysarthria.
Methods \& Procedures: Picture-description samples were collected from 53 stroke survivors, including unimpaired speakers (12) and speakers with primarily aphasia (19), aphasia with AOS (12), primarily AOS (2), aphasia with dysarthria (2), and aphasia with AOS and dysarthria (6). The first three formants were extracted from vowel tokens bearing main stress in open-class words, as well as VOTs for voiced and voiceless stops. Vowel space was estimated as reflected in the formant centralization ratio. Stepwise Linear Discriminant Analyses were used to predict group membership, and ordinal regression to predict AOS severity, based on the absolute values of these variables, as well as the standard deviations of formants and VOTs within speakers.
Outcomes and Results: Presence and severity of AOS were most consistently predicted by the dispersion of F1, F2, and voiced-stop VOT. These phonetic-acoustic measures do not correlate with aphasia severity.
Conclusions: These results confirm that the AOS affects articulation across-the-board and does not selectively spare vowel production.},
	language = {eng},
	number = {8},
	journal = {Aphasiology},
	author = {den Ouden, Dirk-Bart and Galkina, Elena and Basilakos, Alexandra and Fridriksson, Julius},
	year = {2018},
	pmid = {30297975},
	pmcid = {PMC6173518},
	keywords = {aphasia-dementia},
	pages = {902--921}
}

@article{shega_validity_2008,
	title = {Validity of pain behaviors in persons with mild to moderate cognitive impairment},
	volume = {56},
	issn = {1532-5415},
	doi = {10.1111/j.1532-5415.2008.01831.x},
	abstract = {OBJECTIVES: To evaluate the validity of traditional pain behaviors (guarding, bracing, rubbing, grimacing, and sighing) in persons with and without cognitive impairment and chronic low back pain (CLBP).
DESIGN: Prospective observational study.
SETTING: Outpatient clinics.
PARTICIPANTS: Thirty-seven cognitively intact and 40 cognitively impaired participants with and without CLBP.
MEASUREMENTS: Frequency of traditional pain behaviors.
RESULTS: Forty-six of the participants were pain free, and 31 had CLBP. The internal consistency reliability coefficient of the five pain behaviors was 0.32, suggesting that a unidimensional scale did not exist. Multivariate analysis of variance analysis according to the independent variables pain status (pain free vs CLBP) and cognitive status (intact vs impaired) with the dependent variable frequency of pain behaviors found significant differences according to pain status (F[5,61]=3.06, P=.02) and cognitive status (F[5,61]=5.41, P{\textless}.001) but without evidence of an interaction (F[5,61]=1.14, P=.35). Participants with CLBP exhibited significantly higher levels of grimacing (P{\textless}.001) and guarding (P=.02) than pain-free participants. Intact subjects exhibited fewer guarding (P=.02) and rubbing behaviors (P{\textless}.001) but a higher number of bracing behaviors (P=.03) than cognitively impaired participants.
CONCLUSION: These results support the utility of facial grimacing in assessing pain in patients with mild to moderate cognitive impairment and call into question the validity of guarding and rubbing in assessing pain in persons with mild to moderate cognitive impairment.},
	language = {eng},
	number = {9},
	journal = {Journal of the American Geriatrics Society},
	author = {Shega, Joseph W. and Rudy, Thomas and Keefe, Francis J. and Perri, Lisa Caitlin and Mengin, Olga Telgarska and Weiner, Debra K.},
	month = sep,
	year = {2008},
	pmid = {18662203},
	pages = {1631--1637}
}

@article{ersek_developing_2018,
	title = {Developing a {Pain} {Intensity} {Measure} for {Persons} with {Dementia}: {Initial} {Construction} and {Testing}},
	issn = {1526-4637},
	shorttitle = {Developing a {Pain} {Intensity} {Measure} for {Persons} with {Dementia}},
	doi = {10.1093/pm/pny180},
	abstract = {Objective: The goal of this study was to identify a limited set of pain indicators that were most predicive of physical pain. We began with 140 items culled from existing pain observation tools and used a modified Delphi approach followed by statistical analyses to reduce the item pool.
Methods: Through the Delphi Method, we created a candidate item set of behavioral indicators. Next, trained staff observed nursing home residents and rated the items on scales of behavior intensity and frequency. We evaluated associations among the items and expert clinicians' assessment of pain intensity.
Setting: Four government-owned nursing homes and 12 community nursing homes in Alabama and Southeastern Pennsylvania.
Participants: Ninety-five residents (mean age = 84.9 years) with moderate to severe cognitive impairment.
Results: Using the least absolute shrinkage and selection operator model, we identified seven items that best predicted clinicians' evaluations of pain intensity. These items were rigid/stiff body or body parts, bracing, complaining, expressive eyes, grimacing, frowning, and sighing. We also found that a model based on ratings of frequency of behaviors did not have better predictive ability than a model based on ratings of intensity of behaviors.
Conclusions: We used two complementary approaches-expert opinion and statistical analysis-to reduce a large pool of behavioral indicators to a parsimonious set of items to predict pain intensity in persons with dementia. Future studies are needed to examine the psychometric properties of this scale, which is called the Pain Intensity Measure for Persons with Dementia.},
	language = {eng},
	journal = {Pain Medicine (Malden, Mass.)},
	author = {Ersek, Mary and Herr, Keela and Hilgeman, Michelle M. and Neradilek, Moni Blazej and Polissar, Nayak and Cook, Karon F. and Nash, Princess and Snow, A. Lynn and McDarby, Meghan and Nelson, Francis X.},
	month = oct,
	year = {2018},
	pmid = {30285252}
}

@article{le_normand_lexical_2008,
	title = {Lexical diversity and productivity in {French} preschoolers: developmental, gender and sociocultural factors},
	volume = {22},
	issn = {0269-9206},
	shorttitle = {Lexical diversity and productivity in {French} preschoolers},
	doi = {10.1080/02699200701669945},
	abstract = {In this study, we examined the influence of child gender and sociocultural (SCL) factors in language production. Subjects were French Parisian children in nine age groups (24, 27, 30, 33, 36, 39, 42, 45 and 48 months). A total of 316 language samples were recorded during a 20-min standardized play session. Measures of grammatical and lexical development included Mean Length of Utterance (MLU) and word type and token - specifically, grammatical words such as determiners, prepositions and pronouns as well as verbs. ANOVAs revealed strong influences of SCL, with children from high SCL families showing more complex lexical productions and a higher rate of development. These observations suggest that amount of exposure to language accounts for this differential rate of acquisition. Analyses also revealed a general effect of gender, showing a small advantage in language production for girls over boys until 36 months of age.},
	language = {eng},
	number = {1},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Le Normand, Marie-Thérèse and Parisse, Christophe and Cohen, Henri},
	month = jan,
	year = {2008},
	pmid = {18092219},
	pages = {47--58}
}

@article{gibson_role_2017,
	title = {The {Role} of {Lexical} {Stress} on the {Use} of {Vocal} {Fry} in {Young} {Adult} {Female} {Speakers}},
	volume = {31},
	issn = {1873-4588},
	doi = {10.1016/j.jvoice.2016.02.005},
	abstract = {OBJECTIVES: Vocal fry is a voice register often used by young adult women for sociolinguistic purposes. Some acoustic correlates of lexical stress, however, appear incompatible with the use of vocal fry. The objective of this study was to systematically examine the role of lexical stress in the use of vocal fry by young adult women.
STUDY DESIGN: This is a semi-randomized controlled laboratory study.
METHODS: Fifty female undergraduate students were recorded repeating one-, two-, three-, and four-syllable nonwords that conformed to English phonotactics. Nonwords were presented in order from shorter to longer lengths, with stimuli randomized within syllable length. Perceptual analyses of recordings were augmented by acoustic analyses to identify each syllable in which vocal fry occurred.
RESULTS: Eighty-six percent of participants produced at least one episode of vocal fry. Vocal fry was more likely to occur in unstressed than stressed position, and the likelihood increased as distance from the stressed syllable increased. There was considerable variability in the use of vocal fry. Frequent and infrequent users varied on the degree to which they used vocal fry in single-syllable nonwords.
CONCLUSIONS: Vocal fry use persists among young adult women even in the absence of syntactic and pragmatic influences. Lexical stress appeared to dramatically reduce the use of vocal fry. Patterns of vocal fry use appeared to be different for frequent and infrequent users of this vocal register.},
	language = {eng},
	number = {1},
	journal = {Journal of Voice: Official Journal of the Voice Foundation},
	author = {Gibson, Todd A.},
	month = jan,
	year = {2017},
	pmid = {27091470},
	pages = {62--66}
}

@article{ferreira_cognitive_2017,
	title = {Cognitive {Variability} during {Middle}-{Age}: {Possible} {Association} with {Neurodegeneration} and {Cognitive} {Reserve}},
	volume = {9},
	issn = {1663-4365},
	shorttitle = {Cognitive {Variability} during {Middle}-{Age}},
	doi = {10.3389/fnagi.2017.00188},
	abstract = {Objective: Increased variability in cognition with age has been argued as an indication of pathological processes. Focusing on early detection of neurodegenerative disorders, we investigated variability in cognition in healthy middle-aged adults. In order to understand possible determinants of this variability, we also investigated associations with cognitive reserve, neuroimaging markers, subjective memory complaints, depressive symptomatology, and gender. Method: Thirty-one 50 ± 2 years old individuals were investigated as target group and deviation was studied in comparison to a reference younger group of 30 individuals 40 ± 2 years old. Comprehensive neuropsychological and structural imaging protocols were collected. Brain regional volumes and cortical thickness were calculated with FreeSurfer, white matter hyperintensities with CASCADE, and mean diffusivity with FSL. Results: Across-individuals variability showed greater dispersion in lexical access, processing speed, executive functions, and memory. Variability in global cognition correlated with, reduced cortical thickness in the right parietal-temporal-occipital association cortex, and increased mean diffusivity in the cingulum bundle and right inferior fronto-occipital fasciculus. A trend was also observed for the correlation between global cognition and hippocampal volume and female gender. All these associations were influenced by cognitive reserve. No correlations were found with subjective memory complaints, white matter hyperintensities and depressive symptomatology. Across-domains and across-tasks variability was greater in several executive components and cognitive processing speed. Conclusion: Variability in cognition during middle-age is associated with neurodegeneration in the parietal-temporal-occipital association cortex and white matter tracts connecting this to the prefrontal dorsolateral cortex and the hippocampus. Moreover, this effect is influenced by cognitive reserve. Studying variability offers valuable information showing that differences do not occur in the same magnitude and direction across individuals, cognitive domains and tasks. These findings may have important implications for early detection of subtle cognitive impairment and clinical interpretation of deviation from normality.},
	language = {eng},
	journal = {Frontiers in Aging Neuroscience},
	author = {Ferreira, Daniel and Machado, Alejandra and Molina, Yaiza and Nieto, Antonieta and Correia, Rut and Westman, Eric and Barroso, José},
	year = {2017},
	pmid = {28649200},
	pmcid = {PMC5465264},
	pages = {188},
	file = {Full Text:/Users/transfer/Zotero/storage/P86QVHFV/Ferreira et al. - 2017 - Cognitive Variability during Middle-Age Possible .pdf:application/pdf}
}

@article{lopez-higes_interindividual_2010,
	title = {Interindividual variability in vocabulary, sentence comprehension and working memory in the elderly: effects of cognitive deterioration},
	volume = {13},
	issn = {1138-7416},
	shorttitle = {Interindividual variability in vocabulary, sentence comprehension and working memory in the elderly},
	abstract = {Interindividual variability in vocabulary, sentence comprehension and working memory is studied in older people with mild cognitive impairment, very low cognitive impairment and normal state, according to the Mini Examen Cognoscitivo (MEC). In the study participated 71 seniors, aged between 62 to 90 years of age, with low instructional level (from one to five years of regular education). Variability measures were calculated in a test of lexical knowledge, another of working memory, and also in one of sentence comprehension. The results obtained using a polynomial regression analysis of the absolute residual scores on the MEC, showed that: (a) variability increases in a linear fashion as the MEC score decreases in the case of nouns, and sentences with one proposition that do not follow the canonical order of constituents in Spanish; (b) Performance on the simpler sentences (one proposition and canonical order) and in the most complex ones (two propositions and non-canonical order) variability showed a change in its trend from MEC scores that indicate cognitive deterioration; (c) In relation to performance on the verbs, variability's change of trend is not linked to cognitive deterioration. We discuss the results in terms of the utility of these measures as potential indicators of cognitive impairment.},
	language = {eng},
	number = {1},
	journal = {The Spanish Journal of Psychology},
	author = {López-Higes, Ramón and Rubio Valdehita, Susana and Martín Aragoneses, Ma Teresa and Del Río, David},
	month = may,
	year = {2010},
	pmid = {20480679},
	pages = {75--87}
}

@article{teubner-rhodes_aging-resilient_2016,
	title = {Aging-{Resilient} {Associations} between the {Arcuate} {Fasciculus} and {Vocabulary} {Knowledge}: {Microstructure} or {Morphology}?},
	volume = {36},
	issn = {1529-2401},
	shorttitle = {Aging-{Resilient} {Associations} between the {Arcuate} {Fasciculus} and {Vocabulary} {Knowledge}},
	doi = {10.1523/JNEUROSCI.4342-15.2016},
	abstract = {Vocabulary knowledge is one of the few cognitive functions that is relatively preserved in older adults, but the reasons for this relative preservation have not been well delineated. We tested the hypothesis that individual differences in vocabulary knowledge are influenced by arcuate fasciculus macrostructure (i.e., shape and volume) properties that remain stable during the aging process, rather than white matter microstructure that demonstrates age-related declines. Vocabulary was not associated with age compared to pronounced age-related declines in cognitive processing speed across 106 healthy adults (19.92-88.29 years) who participated in this neuroimaging experiment. Fractional anisotropy in the left arcuate fasciculus was significantly related to individual variability in vocabulary. This effect was present despite marked age-related differences in a T1-weighted/T2-weighted ratio (T1w/T2w) estimate of myelin that were observed throughout the left arcuate fasciculus and associated with age-related differences in cognitive processing speed. However, atypical patterns of arcuate fasciculus morphology or macrostructure were associated with decreased vocabulary knowledge. These results suggest that deterioration of tissue in the arcuate fasciculus occurs with normal aging, while having limited impact on tract organization that underlies individual differences in the acquisition and retrieval of lexical and semantic information.
SIGNIFICANCE STATEMENT: Vocabulary knowledge is resilient to widespread age-related declines in brain structure that limit other cognitive functions. We tested the hypothesis that arcuate fasciculus morphology, which supports the development of reading skills that bolster vocabulary, could explain this relative preservation. We disentangled (1) the effects of age-related declines in arcuate microstructure (mean diffusivity; myelin content estimate) that predicted cognitive processing speed but not vocabulary, from (2) relatively stable arcuate macrostructure (shape/volume) that explained significant variance in an age-independent association between fractional anisotropy and vocabulary. This latter result may reflect differences in fiber trajectory and organization that are resilient to aging. We propose that developmental sculpting of the arcuate fasciculus determines acquisition, storage, and access of lexical information across the adult lifespan.},
	language = {eng},
	number = {27},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	author = {Teubner-Rhodes, Susan and Vaden, Kenneth I. and Cute, Stephanie L. and Yeatman, Jason D. and Dougherty, Robert F. and Eckert, Mark A.},
	year = {2016},
	pmid = {27383595},
	pmcid = {PMC4938863},
	pages = {7210--7222},
	file = {Full Text:/Users/transfer/Zotero/storage/3V2DUWLD/Teubner-Rhodes et al. - 2016 - Aging-Resilient Associations between the Arcuate F.pdf:application/pdf}
}

@article{kemper_aging_2010,
	title = {Aging and the vulnerability of speech to dual task demands},
	volume = {25},
	issn = {1939-1498},
	doi = {10.1037/a0020000},
	abstract = {Tracking a digital pursuit rotor task was used to measure dual task costs of language production by young and older adults. Tracking performance by both groups was affected by dual task demands: time on target declined and tracking error increased as dual task demands increased from the baseline condition to a moderately demanding dual task condition to a more demanding dual task condition. When dual task demands were moderate, older adults' speech rate declined but their fluency, grammatical complexity, and content were unaffected. When the dual task was more demanding, older adults' speech, like young adults' speech, became highly fragmented, ungrammatical, and incoherent. Vocabulary, working memory, processing speed, and inhibition affected vulnerability to dual task costs: vocabulary provided some protection for sentence length and grammaticality, working memory conferred some protection for grammatical complexity, and processing speed provided some protection for speech rate, propositional density, coherence, and lexical diversity. Further, vocabulary and working memory capacity provided more protection for older adults than for young adults although the protective effect of processing speed was somewhat reduced for older adults as compared to the young adults.},
	language = {eng},
	number = {4},
	journal = {Psychology and Aging},
	author = {Kemper, Susan and Schmalzried, RaLynn and Hoffman, Lesa and Herman, Ruth},
	month = dec,
	year = {2010},
	pmid = {21186917},
	pmcid = {PMC3050491},
	pages = {949--962},
	file = {Full Text:/Users/transfer/Zotero/storage/9LFDSWWY/Kemper et al. - 2010 - Aging and the vulnerability of speech to dual task.pdf:application/pdf}
}

@article{taler_comprehension_2009,
	title = {Comprehension of lexical ambiguity in healthy aging, mild cognitive impairment, and mild {Alzheimer}'s disease},
	volume = {47},
	issn = {0028-3932},
	doi = {10.1016/j.neuropsychologia.2009.01.028},
	abstract = {Two experiments examined processing of lexical ambiguity in healthy older control (HC), mild cognitive impairment (MCI) and Alzheimer's disease (AD) participants. In Experiment 1, groups of HC, MCI and AD participants took part in an ERP study in which they read lexically ambiguous items presented in a subordinate context and primed by the same item presented in a dominant context. Ambiguous items were homonyms (e.g., bank), metaphorical polysemes (e.g., star), or metonyms (e.g., rabbit). All participants exhibited smaller N400s for items preceded by a related prime. In addition, HC participants exhibited a smaller N400 for metonyms than for metaphorical polysemes or homonyms; this effect was diminished in MCI and AD participants. In Experiment 2, HC and MCI participants completed a primed lexical decision task where targets related to the subordinate meaning/sense of ambiguous items were preceded by primes biasing the dominant meaning/sense (e.g., financial-bank-river). In contrast to the results of Experiment 1, both HC and MCI participants showed priming for metonymic items, but not homonyms or metaphorical polysemes. These results suggest that basic knowledge of multiple senses of metonyms is preserved in MCI, but the processing advantage conveyed by this semantic richness is diminished in MCI and AD.},
	language = {eng},
	number = {5},
	journal = {Neuropsychologia},
	author = {Taler, Vanessa and Klepousniotou, Ekaterini and Phillips, Natalie A.},
	month = apr,
	year = {2009},
	pmid = {19428397},
	pages = {1332--1343}
}

@article{hoffman_broadly_2014,
	title = {Broadly speaking: vocabulary in semantic dementia shifts towards general, semantically diverse words},
	volume = {55},
	issn = {1973-8102},
	shorttitle = {Broadly speaking},
	doi = {10.1016/j.cortex.2012.11.004},
	abstract = {One of the cardinal features of semantic dementia (SD) is a steady reduction in expressive vocabulary. We investigated the nature of this breakdown by assessing the psycholinguistic characteristics of words produced spontaneously by SD patients during an autobiographical memory interview. Speech was analysed with respect to frequency and imageability, and a recently-developed measure called semantic diversity. This measure quantifies the degree to which a word can be used in a broad range of different linguistic contexts. We used this measure in a formal exploration of the tendency for SD patients to replace specific terms with more vague and general words, on the assumption that more specific words are used in a more constrained set of contexts. Relative to healthy controls, patients were less likely to produce low-frequency, high-imageability words, and more likely to produce highly frequent, abstract words. These changes in the lexical-semantic landscape were related to semantic diversity: the highly frequent and abstract words most prevalent in the patients' speech were also the most semantically diverse. In fact, when the speech samples of healthy controls were artificially engineered such that low semantic diversity words (e.g., garage, spanner) were replaced with broader terms (e.g., place, thing), the characteristics of their speech production came to closely resemble that of SD patients. A similar simulation in which low-frequency words were replaced was less successful in replicating the patient data. These findings indicate systematic biases in the deterioration of lexical-semantic space in SD. As conceptual knowledge degrades, speech increasingly consists of general terms that can be applied in a broad range of linguistic contexts and convey less specific information.},
	language = {eng},
	journal = {Cortex; a Journal Devoted to the Study of the Nervous System and Behavior},
	author = {Hoffman, Paul and Meteyard, Lotte and Patterson, Karalyn},
	month = jun,
	year = {2014},
	pmid = {23261549},
	pages = {30--42},
	file = {Submitted Version:/Users/transfer/Zotero/storage/7RBVRWBV/Hoffman et al. - 2014 - Broadly speaking vocabulary in semantic dementia .pdf:application/pdf}
}

@article{horton_corpus_2010,
	title = {A corpus analysis of patterns of age-related change in conversational speech},
	volume = {25},
	issn = {1939-1498},
	doi = {10.1037/a0019424},
	abstract = {Conversational speech from over 300 speakers from 17 to 68 years of age was analyzed for age-related changes in the timing and content of spoken language production. Overall, several relationships between the lexical content, timing, and fluency of speech emerged, such that more novel and lower frequency words were associated with slower speech and higher levels of disfluencies. Speaker age was associated with slower speech and more filled pauses, particularly those associated with lexical selection. Increasing age, however, was also associated with longer utterances and greater lexical diversity. On balance, these analyses present a picture of age-related changes in speech performance that largely support data obtained from controlled laboratory studies. However, particular patterns of age-related change may be moderated in conversational situations.},
	language = {eng},
	number = {3},
	journal = {Psychology and Aging},
	author = {Horton, William S. and Spieler, Daniel H. and Shriberg, Elizabeth},
	month = sep,
	year = {2010},
	pmid = {20677883},
	pmcid = {PMC2943985},
	pages = {708--713},
	file = {Accepted Version:/Users/transfer/Zotero/storage/JQESDGWR/Horton et al. - 2010 - A corpus analysis of patterns of age-related chang.pdf:application/pdf}
}

@article{lopez-higes_interindividual_2010-1,
	title = {Interindividual variability in vocabulary, sentence comprehension and working memory in the elderly: effects of cognitive deterioration},
	volume = {13},
	issn = {1138-7416},
	shorttitle = {Interindividual variability in vocabulary, sentence comprehension and working memory in the elderly},
	abstract = {Interindividual variability in vocabulary, sentence comprehension and working memory is studied in older people with mild cognitive impairment, very low cognitive impairment and normal state, according to the Mini Examen Cognoscitivo (MEC). In the study participated 71 seniors, aged between 62 to 90 years of age, with low instructional level (from one to five years of regular education). Variability measures were calculated in a test of lexical knowledge, another of working memory, and also in one of sentence comprehension. The results obtained using a polynomial regression analysis of the absolute residual scores on the MEC, showed that: (a) variability increases in a linear fashion as the MEC score decreases in the case of nouns, and sentences with one proposition that do not follow the canonical order of constituents in Spanish; (b) Performance on the simpler sentences (one proposition and canonical order) and in the most complex ones (two propositions and non-canonical order) variability showed a change in its trend from MEC scores that indicate cognitive deterioration; (c) In relation to performance on the verbs, variability's change of trend is not linked to cognitive deterioration. We discuss the results in terms of the utility of these measures as potential indicators of cognitive impairment.},
	language = {eng},
	number = {1},
	journal = {The Spanish Journal of Psychology},
	author = {López-Higes, Ramón and Rubio Valdehita, Susana and Martín Aragoneses, Ma Teresa and Del Río, David},
	month = may,
	year = {2010},
	pmid = {20480679},
	pages = {75--87}
}

@article{kemper_aging_2010-1,
	title = {Aging and the vulnerability of speech to dual task demands},
	volume = {25},
	issn = {1939-1498},
	doi = {10.1037/a0020000},
	abstract = {Tracking a digital pursuit rotor task was used to measure dual task costs of language production by young and older adults. Tracking performance by both groups was affected by dual task demands: time on target declined and tracking error increased as dual task demands increased from the baseline condition to a moderately demanding dual task condition to a more demanding dual task condition. When dual task demands were moderate, older adults' speech rate declined but their fluency, grammatical complexity, and content were unaffected. When the dual task was more demanding, older adults' speech, like young adults' speech, became highly fragmented, ungrammatical, and incoherent. Vocabulary, working memory, processing speed, and inhibition affected vulnerability to dual task costs: vocabulary provided some protection for sentence length and grammaticality, working memory conferred some protection for grammatical complexity, and processing speed provided some protection for speech rate, propositional density, coherence, and lexical diversity. Further, vocabulary and working memory capacity provided more protection for older adults than for young adults although the protective effect of processing speed was somewhat reduced for older adults as compared to the young adults.},
	language = {eng},
	number = {4},
	journal = {Psychology and Aging},
	author = {Kemper, Susan and Schmalzried, RaLynn and Hoffman, Lesa and Herman, Ruth},
	month = dec,
	year = {2010},
	pmid = {21186917},
	pmcid = {PMC3050491},
	pages = {949--962},
	file = {Full Text:/Users/transfer/Zotero/storage/AAQPYHIG/Kemper et al. - 2010 - Aging and the vulnerability of speech to dual task.pdf:application/pdf}
}

@article{kemper_structure_2001,
	title = {The structure of verbal abilities in young and older adults},
	volume = {16},
	issn = {0882-7974},
	abstract = {Four language sample measures as well as measures of vocabulary, verbal fluency, and memory span were obtained from a sample of young adults and a sample of older adults. Factor analysis was used to analyze the structure of the vocabulary, fluency, and span measures for each age group. Then an "extension" analysis was performed by using structural modeling techniques to determine how the language sample measures were related to the other measures. The measure of grammatical complexity was associated with measures of working memory including reading span and digit span. Two measures, sentence length in words and a measure of lexical diversity, were associated with the vocabulary measures. The fourth measure, propositional density, was associated with the fluency measures as a measure of processing efficiency. The structure of verbal abilities in young and older adults is somewhat different, suggesting age differences in processing efficiency.},
	language = {eng},
	number = {2},
	journal = {Psychology and Aging},
	author = {Kemper, S. and Sumner, A.},
	month = jun,
	year = {2001},
	pmid = {11405318},
	pages = {312--322}
}

@article{pakhomov_characterizing_2016,
	title = {Characterizing cognitive performance in a large longitudinal study of aging with computerized semantic indices of verbal fluency},
	volume = {89},
	issn = {1873-3514},
	doi = {10.1016/j.neuropsychologia.2016.05.031},
	abstract = {A computational approach for estimating several indices of performance on the animal category verbal fluency task was validated, and examined in a large longitudinal study of aging. The performance indices included the traditional verbal fluency score, size of semantic clusters, density of repeated words, as well as measures of semantic and lexical diversity. Change over time in these measures was modeled using mixed effects regression in several groups of participants, including those that remained cognitively normal throughout the study (CN) and those that were diagnosed with mild cognitive impairment (MCI) or Alzheimer's disease (AD) dementia at some point subsequent to the baseline visit. The results of the study show that, with the exception of mean cluster size, the indices showed significantly greater declines in the MCI and AD dementia groups as compared to CN participants. Examination of associations between the indices and cognitive domains of memory, attention and visuospatial functioning showed that the traditional verbal fluency scores were associated with declines in all three domains, whereas semantic and lexical diversity measures were associated with declines only in the visuospatial domain. Baseline repetition density was associated with declines in memory and visuospatial domains. Examination of lexical and semantic diversity measures in subgroups with high vs. low attention scores (but normal functioning in other domains) showed that the performance of individuals with low attention was influenced more by word frequency rather than strength of semantic relatedness between words. These findings suggest that various automatically semantic indices may be used to examine various aspects of cognitive performance affected by dementia.},
	language = {eng},
	journal = {Neuropsychologia},
	author = {Pakhomov, Serguei V. S. and Eberly, Lynn and Knopman, David},
	year = {2016},
	pmid = {27245645},
	pmcid = {PMC4996679},
	pages = {42--56},
	file = {Accepted Version:/Users/transfer/Zotero/storage/IUB8JLEC/Pakhomov et al. - 2016 - Characterizing cognitive performance in a large lo.pdf:application/pdf}
}

@article{hoyau_effect_2018,
	title = {Effect of social leisure activities on object naming in healthy aging {A} multimodal approach},
	volume = {16},
	issn = {2115-7863},
	doi = {10.1684/pnv.2017.0715},
	abstract = {Environmental factors contribute to the constitution and maintenance of the cognitive reserve and partially explain the variability of cognitive performance in older individuals. We assessed the role of leisure activities - social and individual - on the access to lexico-semantic representations evaluated through a task of object naming (ON). We hypothesize that compared to individual, social leisure activities explain better the ON performance in the older adults, which is explained by a mechanism of neural reserve. Our results in older adults indicate (a) a significant correlation between leisure social activities and the response time for ON, (b) a significant correlation between link the neural activity of the left superior and medial frontal (SmFG) for ON and leisure social activities. Interestingly, the activity of the left SmFG partially mediates the relationship between social activities and OD performance. We suggest that social leisure activities may contribute to maintain ON performances in healthy aging, through a neural reserve mechanism, in relation with left SmFG activity. This region is typically involved in the access to semantic representations, guided by the emotional state. These results open interesting perspectives on the role of social leisure activities on lexical production during aging.},
	language = {eng},
	number = {1},
	journal = {Geriatrie Et Psychologie Neuropsychiatrie Du Vieillissement},
	author = {Hoyau, Elena and Gigleux, Marion and Cousin, Émilie and Fournet, Nathalie and Pichat, Cédric and Jaillard, Assia and Baciu, Monica},
	month = mar,
	year = {2018},
	pmid = {29402757},
	pages = {96--105}
}

@article{lai_validating_2016,
	title = {Validating the {Use} of {D} for {Measuring} {Lexical} {Diversity} in {Low}-{Income} {Kindergarten} {Children}},
	volume = {47},
	issn = {1558-9129},
	doi = {10.1044/2016_LSHSS-15-0028},
	abstract = {PURPOSE: Children from low-socioeconomic status families often perform poorly on standardized vocabulary assessments. The primary purpose of the study was to determine whether lexical diversity as measured by D (Malvern, Richards, Chipere, \& Durán, 2004) serves as a valid measure of vocabulary in at-risk, low-income, predominantly African American kindergartners.
METHOD: Kane's (1992) argument-based approach was used to validate D. Six assumptions were examined. Kindergartners (N = 210) from a high-poverty, low-achievement region of the United States were recorded narrating a wordless picture book and assessed using the Expressive Vocabulary Test, Second Edition (Williams, 2007), and the Kaufman Test of Educational Achievement, Second Edition-Listening Comprehension subtest (Kaufman \& Kaufman, 2004).
RESULTS: D was distributed normally and did not vary as a function of language sample length or child ethnicity. D was significantly but weakly related to the Expressive Vocabulary Test, Second Edition, indicating some distinction between D and the Expressive Vocabulary Test, Second Edition, scores. Further, D was only marginally related to the Kaufman Test of Educational Achievement, Second Edition-Listening Comprehension subtest.
CONCLUSIONS: Although evidence was somewhat mixed, the study supported the view that D is a potentially valid measure of lexical diversity among low-income, predominantly African American kindergartners and could be a useful supplement to standardized vocabulary measures.},
	language = {eng},
	number = {3},
	journal = {Language, Speech, and Hearing Services in Schools},
	author = {Lai, Stephanie A. and Schwanenflugel, Paula J.},
	year = {2016},
	pmid = {27392306},
	pages = {225--235}
}

@article{bromley_aspects_1991,
	title = {Aspects of written language production over adult life},
	volume = {6},
	issn = {0882-7974},
	abstract = {Self-descriptions written by adults were analyzed to explore the effects of age, gender, vocabulary, nonverbal intelligence, and educational-occupational status on lexical aspects of language and grammatical complexity. Multivariate analyses indicated that, after controlling for other background variables, age had a significant effect on vocabulary diversity, sentence complexity, subordinating conjunctions, and possibly sentence length. Four variables--word output, word length, long words, and readability--were affected mainly by vocabulary and educational-occupational status. An unexpected and small but significant gender difference in the readability of the descriptions was observed across all age groups.},
	language = {eng},
	number = {2},
	journal = {Psychology and Aging},
	author = {Bromley, D. B.},
	month = jun,
	year = {1991},
	pmid = {1863399},
	pages = {296--308}
}

@article{barrett_building_2011-1,
	title = {Building a biomedical tokenizer using the token lattice design pattern and the adapted {Viterbi} algorithm},
	volume = {12},
	number = {3},
	journal = {BMC bioinformatics},
	author = {Barrett, Neil and Weber-Jahnke, Jens},
	year = {2011},
	pages = {S1}
}

@article{dai_enhancing_2015-1,
	title = {Enhancing of chemical compound and drug name recognition using representative tag scheme and fine-grained tokenization},
	volume = {7},
	number = {S1},
	journal = {Journal of cheminformatics},
	author = {Dai, Hong-Jie and Lai, Po-Ting and Chang, Yung-Chun and Tsai, Richard Tzong-Han},
	year = {2015},
	pages = {S14}
}

@article{dressler_transcribing_2000-1,
	title = {Transcribing oral discourse: {A} survey and a model system},
	volume = {29},
	shorttitle = {Transcribing oral discourse},
	number = {1},
	journal = {Discourse Processes},
	author = {Dressler, Richard A. and Kreuz, Roger J.},
	year = {2000},
	pages = {25--36}
}

@inproceedings{arens_preliminary_2004-2,
	title = {A preliminary look into the use of named entity information for bioscience text tokenization},
	booktitle = {Proceedings of the {Student} {Research} {Workshop} at {HLT}-{NAACL} 2004},
	publisher = {Association for Computational Linguistics},
	author = {Arens, Robert},
	year = {2004},
	pages = {37--42}
}

@article{bhamidipati_stemming_2007-1,
	title = {Stemming via distribution-based word segregation for classification and retrieval},
	volume = {37},
	number = {2},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Bhamidipati, Narayan L. and Pal, Sankar K.},
	year = {2007},
	pages = {350--360}
}

@inproceedings{schuller_interspeech_2010-1,
	title = {The {INTERSPEECH} 2010 paralinguistic challenge},
	booktitle = {Proc. {INTERSPEECH} 2010, {Makuhari}, {Japan}},
	author = {Schuller, Björn and Steidl, Stefan and Batliner, Anton and Burkhardt, Felix and Devillers, Laurence and Müller, Christian and Narayanan, Shrikanth},
	year = {2010},
	pages = {2794--2797}
}

@article{roach_transcription_1998-1,
	title = {Transcription of prosodic and paralinguistic features of emotional speech},
	volume = {28},
	number = {1-2},
	journal = {Journal of the International Phonetic Association},
	author = {Roach, Peter and Stibbard, Richard and Osborne, Jane and Arnfield, Simon and Setter, Jane},
	year = {1998},
	pages = {83--94}
}

@article{poyatos_cross-cultural_1975-1,
	title = {Cross-cultural study of paralinguistic “alternants” in face-to-face interaction},
	journal = {Organization of Behavior in Face-to-Face Interaction},
	author = {Poyatos, Fernando},
	year = {1975},
	pages = {285--314}
}

@article{boyer_automated_2015-2,
	title = {Automated detection of health websites' {HONcode} conformity: can {N}-gram tokenization replace stemming?},
	volume = {216},
	shorttitle = {Automated detection of health websites' {HONcode} conformity},
	journal = {Studies in health technology and informatics},
	author = {Boyer, Célia and Dolamic, Ljiljana and Grabar, Natalia},
	year = {2015},
	pages = {1064--1064}
}

@article{bullinaria_extracting_2012-1,
	title = {Extracting semantic representations from word co-occurrence statistics: stop-lists, stemming, and {SVD}},
	volume = {44},
	shorttitle = {Extracting semantic representations from word co-occurrence statistics},
	number = {3},
	journal = {Behavior research methods},
	author = {Bullinaria, John A. and Levy, Joseph P.},
	year = {2012},
	pages = {890--907}
}

@article{hess_sample_1986-3,
	title = {Sample size and type-token ratios for oral language of preschool children},
	volume = {29},
	number = {1},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Hess, Carla W. and Sefton, Karen M. and Landry, Richard G.},
	year = {1986},
	pages = {129--134}
}

@article{covington_cutting_2010-1,
	title = {Cutting the {Gordian} knot: {The} moving-average type–token ratio ({MATTR})},
	volume = {17},
	shorttitle = {Cutting the {Gordian} knot},
	number = {2},
	journal = {Journal of quantitative linguistics},
	author = {Covington, Michael A. and McFall, Joe D.},
	year = {2010},
	pages = {94--100}
}

@article{richards_type/token_1987-3,
	title = {Type/token ratios: {What} do they really tell us?},
	volume = {14},
	shorttitle = {Type/token ratios},
	number = {2},
	journal = {Journal of child language},
	author = {Richards, Brian},
	year = {1987},
	pages = {201--209}
}

@article{pressman_observing_2017-1,
	title = {Observing conversational laughter in frontotemporal dementia},
	journal = {J Neurol Neurosurg Psychiatry},
	author = {Pressman, Peter S. and Simpson, Michaela and Gola, Kelly and Shdo, Suzanne M. and Spinelli, Edoardo G. and Miller, Bruce L. and Gorno-Tempini, Maria Luisa and Rankin, Katherine and Levenson, Robert W.},
	year = {2017},
	pages = {jnnp--2016}
}

@misc{noauthor_2_nodate,
	title = {(2) {Temporal} features of spontaneous speech in {Alzheimer}’s disease {\textbar} {Request} {PDF}},
	url = {https://www.researchgate.net/publication/43097276_Temporal_features_of_spontaneous_speech_in_Alzheimer%27s_disease},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-10-10},
	journal = {ResearchGate}
}

@article{ranasinghe_distinct_2016-1,
	title = {Distinct subtypes of behavioral variant frontotemporal dementia based on patterns of network degeneration},
	volume = {73},
	number = {9},
	journal = {JAMA neurology},
	author = {Ranasinghe, Kamalini G. and Rankin, Katherine P. and Pressman, Peter S. and Perry, David C. and Lobach, Iryna V. and Seeley, William W. and Coppola, Giovanni and Karydas, Anna M. and Grinberg, Lea T. and Shany-Ur, Tal},
	year = {2016},
	pages = {1078--1088}
}

@article{pressman_neuroanatomy_2018-1,
	title = {Neuroanatomy of shared conversational laughter in neurodegenerative disease},
	volume = {9},
	journal = {Frontiers in neurology},
	author = {Pressman, Peter S. and Shdo, Suzanne and Simpson, Michaela and Chen, Kuan-Hua and Mielke, Clinton and Miller, Bruce L. and Rankin, Katherine P. and Levenson, Robert W.},
	year = {2018},
	pages = {464}
}

@article{fraser_linguistic_2016-1,
	title = {Linguistic features identify {Alzheimer}’s disease in narrative speech},
	volume = {49},
	number = {2},
	journal = {Journal of Alzheimer's Disease},
	author = {Fraser, Kathleen C. and Meltzer, Jed A. and Rudzicz, Frank},
	year = {2016},
	pages = {407--422}
}

@article{singh_evaluation_2001-1,
	title = {Evaluation of an objective technique for analysing temporal variables in {DAT} spontaneous speech},
	volume = {15},
	number = {6},
	journal = {Aphasiology},
	author = {Singh, Sameer and Bucks, Romola S. and Cuerden, Joanne M.},
	year = {2001},
	pages = {571--583}
}

@article{bucks_analysis_2000-1,
	title = {Analysis of spontaneous, conversational speech in dementia of {Alzheimer} type: {Evaluation} of an objective technique for analysing lexical performance},
	volume = {14},
	shorttitle = {Analysis of spontaneous, conversational speech in dementia of {Alzheimer} type},
	number = {1},
	journal = {Aphasiology},
	author = {Bucks, Romola S. and Singh, Sameer and Cuerden, Joanne M. and Wilcock, Gordon K.},
	year = {2000},
	pages = {71--91}
}

@inproceedings{cohen_metamap_2011,
	title = {{MetaMap} is a {Superior} {Baseline} to a {Standard} {Document} {Retrieval} {Engine} for the {Task} of {Finding} {Patient} {Cohorts} in {Clinical} {Free} {Text}.},
	booktitle = {{TREC}},
	publisher = {Citeseer},
	author = {Cohen, K. Bretonnel and Christiansen, Tom and Hunter, Lawrence E.},
	year = {2011}
}

@inproceedings{cohen_supercat:_2016-1,
	title = {{SuperCAT}: {The} ({New} and {Improved}) {Corpus} {Analysis} {Toolkit}},
	volume = {2016},
	shorttitle = {{SuperCAT}},
	booktitle = {International {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {NIH Public Access},
	author = {Cohen, K. Bretonnel and Baumgartner Jr, William A. and Temnikova, Irina},
	year = {2016},
	pages = {2784}
}

@inproceedings{temnikova_sublanguage_2014-2,
	title = {Sublanguage {Corpus} {Analysis} {Toolkit}: {A} tool for assessing the representativeness and sublanguage characteristics of corpora},
	volume = {2014},
	shorttitle = {Sublanguage {Corpus} {Analysis} {Toolkit}},
	booktitle = {International {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {NIH Public Access},
	author = {Temnikova, Irina P. and Baumgartner Jr, William A. and Hailu, Negacy D. and Nikolova, Ivelina and McEnery, Tony and Kilgarriff, Adam and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2014},
	pages = {1714}
}

@inproceedings{temnikova_measuring_2013-1,
	title = {Measuring closure properties of patent sublanguages},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	author = {Temnikova, Irina and Hailu, Negacy and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2013},
	pages = {659--666}
}

@inproceedings{temnikova_recognizing_2013-1,
	title = {Recognizing sublanguages in scientific journal articles through closure properties},
	booktitle = {Proceedings of the 2013 {Workshop} on {Biomedical} {Natural} {Language} {Processing}},
	author = {Temnikova, Irina and Cohen, Kevin},
	year = {2013},
	pages = {72--79}
}

@inproceedings{temnikova_closure_2013-1,
	title = {Closure properties of {Bulgarian} clinical text},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	author = {Temnikova, Irina and Nikolova, Ivelina and Baumgartner, William A. and Angelova, Galia and Cohen, K. Bretonnel},
	year = {2013},
	pages = {667--675}
}

@article{decullier_retractations_2012,
	title = {Rétractations pour erreur et pour fraude},
	volume = {41},
	issn = {07554982},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0755498212003594},
	doi = {10.1016/j.lpm.2012.05.006},
	language = {fr},
	number = {9},
	urldate = {2018-10-13},
	journal = {La Presse Médicale},
	author = {Decullier, Evelyne and Samson, Géraldine and Huot, Laure},
	month = sep,
	year = {2012},
	keywords = {reproducibility, female first or senior, francais, France},
	pages = {847--852},
	file = {Decullier et al. - 2012 - Rétractations pour erreur et pour fraude.pdf:/Users/transfer/Zotero/storage/ERFNDIWE/Decullier et al. - 2012 - Rétractations pour erreur et pour fraude.pdf:application/pdf}
}

@book{gordin_scientific_2015,
	title = {Scientific {Babel}: {How} science was done before and after global {English}},
	shorttitle = {Scientific {Babel}},
	publisher = {University of Chicago Press},
	author = {Gordin, Michael D.},
	year = {2015},
	file = {Snapshot:/Users/transfer/Zotero/storage/LAP2ZHMS/books.html:text/html}
}

@book{gordin_pseudoscience_2012,
	title = {The pseudoscience wars: {Immanuel} {Velikovsky} and the birth of the modern fringe},
	shorttitle = {The pseudoscience wars},
	publisher = {University of Chicago Press},
	author = {Gordin, Michael D.},
	year = {2012},
	file = {Snapshot:/Users/transfer/Zotero/storage/5A5CYSLL/books.html:text/html}
}

@misc{lynch_honeywell_nodate,
	title = {Honeywell {Looks} {At} {Mind} and {Speech} {Control} for {Future} {Cockpits}},
	url = {https://www.ainonline.com/aviation-news/business-aviation/2016-06-04/honeywell-looks-mind-and-speech-control-future-cockpits},
	abstract = {Honeywell is researching a range of pilot inputs to create an environment in which the pilot has multiple means to control an aircraft.},
	language = {en},
	urldate = {2018-10-15},
	journal = {Aviation International News},
	author = {Lynch, Kerry},
	file = {Snapshot:/Users/transfer/Zotero/storage/8CYEM3MH/honeywell-looks-mind-and-speech-control-future-cockpits.html:text/html}
}

@misc{noauthor_adacel_nodate,
	title = {{ADACEL} - {Voice} {Activated} {Cockpit}},
	url = {http://www.adacel.com/VAC.html},
	urldate = {2018-10-15},
	file = {ADACEL - Voice Activated Cockpit:/Users/transfer/Zotero/storage/4BZGEEAQ/VAC.html:text/html}
}

@article{saxena_assessing_2014,
	title = {Assessing speech dysfunction using {BOLD} and acoustic analysis in parkinsonism},
	volume = {20},
	issn = {1873-5126},
	doi = {10.1016/j.parkreldis.2014.04.024},
	abstract = {INTRODUCTION: Speech dysfunction is often associated with parkinsonism (Parkinson's disease (PD), Multiple System Atrophy (MSA), and Progressive Supranuclear Palsy (PSP)), along with characteristic motor features. Any or all of the following i.e. respiratory, phonatory, resonatory, or articulatory components of speech production may be affected. Articulatory imprecision, repetition of syllables (tachyphrenia), and tremor of oropharyngeal structures add to speech unintelligibility. We studied acoustics using spectrogram and its correlation with BOLD activation during voice/speech production across these subjects.
METHODS: BOLD studies were conducted on 108 subjects (29 PD, 20 MSA and 19 PSP and 40 controls) on 1.5 T MR scanner using 130 dynamics. Active phase involved acquisition (10 volumes each) of audible reading of visually presented bi-syllabic meaningful Hindi simple words (5 types of non-nasal stop consonant categories, i.e. namely velars, palatals, retroflexes, dentals, bilabials and one nasal stop consonant) with interleaved silence during baseline. The subjects' voice samples were analyzed for acoustic parameters, namely formant frequencies of the adjoining vowels, voice onset time (VOT), and intensities using spectrogram. Correlation of BOLD activation in different brain areas with acoustic parameters was evaluated.
RESULTS: Voice intensity was significantly lowered, while VOTs were delayed in these patients as compared to healthy controls. All acoustic parameters were significantly affected for nasal consonants. BOLD activation correlated positively in primary motor cortex to VOTs, while F2 formants to activation of supplementary motor area.
CONCLUSION: The differences in the acoustic quality of various stop consonants in patients may be helpful in differentiating these three parkinsonian disorders.},
	language = {eng},
	number = {8},
	journal = {Parkinsonism \& Related Disorders},
	author = {Saxena, Mohit and Behari, Madhuri and Kumaran, S. Senthil and Goyal, Vinay and Narang, Vaishna},
	month = aug,
	year = {2014},
	pmid = {24857769},
	pages = {855--861}
}

@article{bayestehtashk_fully_2015,
	title = {Fully automated assessment of the severity of {Parkinson}'s disease from speech},
	volume = {29},
	number = {1},
	journal = {Computer speech \& language},
	author = {Bayestehtashk, Alireza and Asgari, Meysam and Shafran, Izhak and McNames, James},
	year = {2015},
	pages = {172--185},
	file = {Fulltext:/Users/transfer/Zotero/storage/UNIFZ6XI/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/VAKHIJVB/chooseorg.html:text/html}
}

@article{rusz_acoustic_2011,
	title = {Acoustic assessment of voice and speech disorders in {Parkinson}'s disease through quick vocal test},
	volume = {26},
	issn = {1531-8257},
	doi = {10.1002/mds.23680},
	language = {eng},
	number = {10},
	journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
	author = {Rusz, Jan and Cmejla, Roman and Růžičková, Hana and Klempíř, Jiří and Majerová, Veronika and Picmausová, Jana and Roth, Jan and Růžička, Evžen},
	month = aug,
	year = {2011},
	pmid = {21484873},
	pages = {1951--1952}
}

@article{konig_automatic_2015,
	title = {Automatic speech analysis for the assessment of patients with predementia and {Alzheimer}'s disease},
	volume = {1},
	number = {1},
	journal = {Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
	author = {König, Alexandra and Satt, Aharon and Sorin, Alexander and Hoory, Ron and Toledo-Ronen, Orith and Derreumaux, Alexandre and Manera, Valeria and Verhey, Frans and Aalten, Pauline and Robert, Phillipe H.},
	year = {2015},
	pages = {112--124},
	file = {Fulltext:/Users/transfer/Zotero/storage/PUKCA5BL/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/ERXN99D6/chooseorg.html:text/html}
}

@inproceedings{jarrold_aided_2014,
	title = {Aided diagnosis of dementia type through computer-based analysis of spontaneous speech},
	booktitle = {Proceedings of the {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
	author = {Jarrold, William and Peintner, Bart and Wilkins, David and Vergryi, Dimitra and Richey, Colleen and Gorno-Tempini, Maria Luisa and Ogar, Jennifer},
	year = {2014},
	pages = {27--37},
	file = {Fulltext:/Users/transfer/Zotero/storage/WMVK8SRC/Jarrold et al. - 2014 - Aided diagnosis of dementia type through computer-.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/23KAEWBB/Jarrold et al. - 2014 - Aided diagnosis of dementia type through computer-.pdf:application/pdf}
}

@article{ballard_logopenic_2014,
	title = {Logopenic and nonfluent variants of primary progressive aphasia are differentiated by acoustic measures of speech production},
	volume = {9},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0089864},
	abstract = {Differentiation of logopenic (lvPPA) and nonfluent/agrammatic (nfvPPA) variants of Primary Progressive Aphasia is important yet remains challenging since it hinges on expert based evaluation of speech and language production. In this study acoustic measures of speech in conjunction with voxel-based morphometry were used to determine the success of the measures as an adjunct to diagnosis and to explore the neural basis of apraxia of speech in nfvPPA. Forty-one patients (21 lvPPA, 20 nfvPPA) were recruited from a consecutive sample with suspected frontotemporal dementia. Patients were diagnosed using the current gold-standard of expert perceptual judgment, based on presence/absence of particular speech features during speaking tasks. Seventeen healthy age-matched adults served as controls. MRI scans were available for 11 control and 37 PPA cases; 23 of the PPA cases underwent amyloid ligand PET imaging. Measures, corresponding to perceptual features of apraxia of speech, were periods of silence during reading and relative vowel duration and intensity in polysyllable word repetition. Discriminant function analyses revealed that a measure of relative vowel duration differentiated nfvPPA cases from both control and lvPPA cases (r(2) = 0.47) with 88\% agreement with expert judgment of presence of apraxia of speech in nfvPPA cases. VBM analysis showed that relative vowel duration covaried with grey matter intensity in areas critical for speech motor planning and programming: precentral gyrus, supplementary motor area and inferior frontal gyrus bilaterally, only affected in the nfvPPA group. This bilateral involvement of frontal speech networks in nfvPPA potentially affects access to compensatory mechanisms involving right hemisphere homologues. Measures of silences during reading also discriminated the PPA and control groups, but did not increase predictive accuracy. Findings suggest that a measure of relative vowel duration from of a polysyllable word repetition task may be sufficient for detecting most cases of apraxia of speech and distinguishing between nfvPPA and lvPPA.},
	language = {eng},
	number = {2},
	journal = {PloS One},
	author = {Ballard, Kirrie J. and Savage, Sharon and Leyton, Cristian E. and Vogel, Adam P. and Hornberger, Michael and Hodges, John R.},
	year = {2014},
	pmid = {24587083},
	pmcid = {PMC3938536},
	pages = {e89864},
	file = {Full Text:/Users/transfer/Zotero/storage/S88HUW38/Ballard et al. - 2014 - Logopenic and nonfluent variants of primary progre.pdf:application/pdf}
}

@article{toth_speech_2018,
	title = {A speech recognition-based solution for the automatic detection of mild cognitive impairment from spontaneous speech},
	volume = {15},
	number = {2},
	journal = {Current Alzheimer Research},
	author = {Toth, Laszlo and Hoffmann, Ildikó and Gosztolya, Gabor and Vincze, Veronika and Szatloczki, Greta and Banreti, Zoltan and Pákáski, Magdolna and Kalman, Janos},
	year = {2018},
	pages = {130--138},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZPPP2BYA/PMC5815089.html:text/html;Snapshot:/Users/transfer/Zotero/storage/995WFA9E/art00006.html:text/html}
}

@article{shinagawa_when_2016,
	title = {When a little knowledge can be dangerous: false-positive diagnosis of behavioral variant frontotemporal dementia among community clinicians},
	volume = {41},
	shorttitle = {When a little knowledge can be dangerous},
	number = {1-2},
	journal = {Dementia and geriatric cognitive disorders},
	author = {Shinagawa, Shunichiro and Catindig, Joseree Ann and Block, Nikolas R. and Miller, Bruce L. and Rankin, Katherine P.},
	year = {2016},
	pages = {99--108},
	file = {Fulltext:/Users/transfer/Zotero/storage/EWMBSU79/PMC4835218.html:text/html;Snapshot:/Users/transfer/Zotero/storage/JLKB3UT3/438454.html:text/html}
}

@article{bradford_missed_2009,
	title = {Missed and delayed diagnosis of dementia in primary care: prevalence and contributing factors},
	volume = {23},
	shorttitle = {Missed and delayed diagnosis of dementia in primary care},
	number = {4},
	journal = {Alzheimer disease and associated disorders},
	author = {Bradford, Andrea and Kunik, Mark E. and Schulz, Paul and Williams, Susan P. and Singh, Hardeep},
	year = {2009},
	pages = {306},
	file = {Fulltext:/Users/transfer/Zotero/storage/I2NJ5ZVR/PMC2787842.html:text/html;Snapshot:/Users/transfer/Zotero/storage/PURVY8NA/PMC2787842.html:text/html}
}

@article{woolley_diagnostic_2011,
	title = {The diagnostic challenge of psychiatric symptoms in neurodegenerative disease; rates of and risk factors for prior psychiatric diagnosis in patients with early neurodegenerative disease},
	volume = {72},
	number = {2},
	journal = {The Journal of clinical psychiatry},
	author = {Woolley, Josh D. and Khan, Baber K. and Murthy, Nikhil K. and Miller, Bruce L. and Rankin, Katherine P.},
	year = {2011},
	pages = {126},
	file = {Fulltext:/Users/transfer/Zotero/storage/JD22IQIE/PMC3076589.html:text/html;Snapshot:/Users/transfer/Zotero/storage/H7TGZAZJ/PMC3076589.html:text/html}
}

@article{levenson_emotional_2014,
	title = {Emotional and behavioral symptoms in neurodegenerative disease: a model for studying the neural bases of psychopathology},
	volume = {10},
	shorttitle = {Emotional and behavioral symptoms in neurodegenerative disease},
	journal = {Annual review of clinical psychology},
	author = {Levenson, Robert W. and Sturm, Virginia E. and Haase, Claudia M.},
	year = {2014},
	pages = {581--606},
	file = {Fulltext:/Users/transfer/Zotero/storage/YMQXVFWV/annurev-clinpsy-032813-153653.html:text/html;Snapshot:/Users/transfer/Zotero/storage/IG6YNGFP/annurev-clinpsy-032813-153653.html:text/html}
}

@article{just_autism_2012,
	title = {Autism as a neural systems disorder: a theory of frontal-posterior underconnectivity},
	volume = {36},
	shorttitle = {Autism as a neural systems disorder},
	number = {4},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Just, Marcel Adam and Keller, Timothy A. and Malave, Vicente L. and Kana, Rajesh K. and Varma, Sashank},
	year = {2012},
	pages = {1292--1313},
	file = {Fulltext:/Users/transfer/Zotero/storage/354CRG9H/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7DLL3923/chooseorg.html:text/html}
}

@article{rankin_structural_2006,
	title = {Structural anatomy of empathy in neurodegenerative disease},
	volume = {129},
	number = {11},
	journal = {Brain},
	author = {Rankin, Katherine P. and Gorno-Tempini, Maria Luisa and Allison, Stephen C. and Stanley, Christine M. and Glenn, Shenly and Weiner, Michael W. and Miller, Bruce L.},
	year = {2006},
	pages = {2945--2956},
	file = {Fulltext:/Users/transfer/Zotero/storage/Q5J7VKXZ/291961.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7QV99WRT/291961.html:text/html}
}

@article{ranasinghe_cognition_2016,
	title = {Cognition and neuropsychiatry in behavioral variant frontotemporal dementia by disease stage},
	volume = {86},
	number = {7},
	journal = {Neurology},
	author = {Ranasinghe, Kamalini G. and Rankin, Katherine P. and Lobach, Iryna V. and Kramer, Joel H. and Sturm, Virginia E. and Bettcher, Brianne M. and Possin, Katherine and You, S. Christine and Lamarre, Amanda K. and Shany-Ur, Tal},
	year = {2016},
	pages = {600--610},
	file = {Fulltext:/Users/transfer/Zotero/storage/C8FDGZZF/600.html:text/html;Snapshot:/Users/transfer/Zotero/storage/BVGWANT2/600.html:text/html}
}

@incollection{gorno-tempini_introduction_2015,
	title = {Introduction to primary progressive aphasia},
	booktitle = {Neurobiology of language},
	publisher = {Elsevier},
	author = {Gorno-Tempini, Maria Luisa and Pressman, Peter},
	year = {2015},
	pages = {935--952},
	file = {Snapshot:/Users/transfer/Zotero/storage/HRQ4RY55/chooseorg.html:text/html}
}

@article{katz_early_2016,
	title = {Early clinical features of the parkinsonian-related dementias},
	journal = {The Behavioral Neurology of Dementia},
	author = {Katz, Maya and Pressman, Peter and Boeve, Bradley F.},
	year = {2016},
	pages = {232--244},
	file = {Snapshot:/Users/transfer/Zotero/storage/3KXYL7QF/books.html:text/html}
}

@article{j._holmes_voice_2000,
	title = {Voice characteristics in the progression of {Parkinson}'s disease},
	volume = {35},
	number = {3},
	journal = {International Journal of Language \& Communication Disorders},
	author = {J. Holmes, Rhonda and M. Oates, Jennifer and J. Phyland, Debbie and J. Hughes, Andrew},
	year = {2000},
	pages = {407--418},
	file = {Fulltext:/Users/transfer/Zotero/storage/JPBPZW68/J. Holmes et al. - 2000 - Voice characteristics in the progression of Parkin.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/56H4ZDLQ/136828200410654.html:text/html}
}

@article{fogel_artificial_2018,
	title = {Artificial intelligence powers digital medicine},
	volume = {1},
	number = {1},
	journal = {npj Digital Medicine},
	author = {Fogel, Alexander L. and Kvedar, Joseph C.},
	year = {2018},
	pages = {5},
	file = {Fulltext:/Users/transfer/Zotero/storage/Q6WBPHJB/s41746-017-0012-2.html:text/html;Snapshot:/Users/transfer/Zotero/storage/WVS45URE/s41746-017-0012-2.html:text/html}
}

@book{boersma_praat:_2009,
	title = {Praat: doing phonetics by computer ({Version} 5.1. 05)[{Computer} program]. {Retrieved} {May} 1, 2009},
	shorttitle = {Praat},
	author = {Boersma, Paul and Weenink, David},
	year = {2009}
}

@inproceedings{eyben_opensmile:_2010,
	title = {Opensmile: the munich versatile and fast open-source audio feature extractor},
	shorttitle = {Opensmile},
	booktitle = {Proceedings of the 18th {ACM} international conference on {Multimedia}},
	publisher = {ACM},
	author = {Eyben, Florian and Wöllmer, Martin and Schuller, Björn},
	year = {2010},
	pages = {1459--1462},
	file = {Fulltext:/Users/transfer/Zotero/storage/4NI3NDWG/Eyben et al. - 2010 - Opensmile the munich versatile and fast open-sour.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/UHAKHJSM/citation.html:text/html}
}

@article{pressman_neuroanatomy_2018-2,
	title = {Neuroanatomy of shared conversational laughter in neurodegenerative disease},
	volume = {9},
	journal = {Frontiers in neurology},
	author = {Pressman, Peter S. and Shdo, Suzanne and Simpson, Michaela and Chen, Kuan-Hua and Mielke, Clinton and Miller, Bruce L. and Rankin, Katherine P. and Levenson, Robert W.},
	year = {2018},
	pages = {464},
	file = {Fulltext:/Users/transfer/Zotero/storage/A3YZ78RG/full.html:text/html;Snapshot:/Users/transfer/Zotero/storage/FMTAA6YE/full.html:text/html}
}

@article{pressman_observing_2017-2,
	title = {Observing conversational laughter in frontotemporal dementia},
	journal = {J Neurol Neurosurg Psychiatry},
	author = {Pressman, Peter S. and Simpson, Michaela and Gola, Kelly and Shdo, Suzanne M. and Spinelli, Edoardo G. and Miller, Bruce L. and Gorno-Tempini, Maria Luisa and Rankin, Katherine and Levenson, Robert W.},
	year = {2017},
	pages = {jnnp--2016},
	file = {Fulltext:/Users/transfer/Zotero/storage/XG6QIH5Y/jnnp-2016-314931.html:text/html}
}

@article{mckhann_diagnosis_2011,
	title = {The diagnosis of dementia due to {Alzheimer}’s disease: {Recommendations} from the {National} {Institute} on {Aging}-{Alzheimer}’s {Association} workgroups on diagnostic guidelines for {Alzheimer}'s disease},
	volume = {7},
	shorttitle = {The diagnosis of dementia due to {Alzheimer}’s disease},
	number = {3},
	journal = {Alzheimer's \& dementia},
	author = {McKhann, Guy M. and Knopman, David S. and Chertkow, Howard and Hyman, Bradley T. and Jack Jr, Clifford R. and Kawas, Claudia H. and Klunk, William E. and Koroshetz, Walter J. and Manly, Jennifer J. and Mayeux, Richard},
	year = {2011},
	pages = {263--269},
	file = {Fulltext:/Users/transfer/Zotero/storage/PJBYCENQ/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/YK94JCD9/chooseorg.html:text/html}
}

@article{ossenkoppele_behavioural/dysexecutive_2015,
	title = {The behavioural/dysexecutive variant of {Alzheimer}’s disease: clinical, neuroimaging and pathological features},
	volume = {138},
	shorttitle = {The behavioural/dysexecutive variant of {Alzheimer}’s disease},
	number = {9},
	journal = {Brain},
	author = {Ossenkoppele, Rik and Pijnenburg, Yolande AL and Perry, David C. and Cohn-Sheehy, Brendan I. and Scheltens, Nienke ME and Vogel, Jacob W. and Kramer, Joel H. and van der Vlies, Annelies E. and Joie, Renaud La and Rosen, Howard J.},
	year = {2015},
	pages = {2732--2749},
	file = {Fulltext:/Users/transfer/Zotero/storage/22RENSMN/311444.html:text/html;Snapshot:/Users/transfer/Zotero/storage/R42WINH9/311444.html:text/html}
}

@article{armstrong_criteria_2013,
	title = {Criteria for the diagnosis of corticobasal degeneration},
	volume = {80},
	number = {5},
	journal = {Neurology},
	author = {Armstrong, Melissa J. and Litvan, Irene and Lang, Anthony E. and Bak, Thomas H. and Bhatia, Kailash P. and Borroni, Barbara and Boxer, Adam L. and Dickson, Dennis W. and Grossman, Murray and Hallett, Mark},
	year = {2013},
	pages = {496--503},
	file = {Fulltext:/Users/transfer/Zotero/storage/DCLWW3E7/496.html:text/html;Snapshot:/Users/transfer/Zotero/storage/4Q8SF5FQ/496.html:text/html}
}

@article{litvan_clinical_1996,
	title = {Clinical research criteria for the diagnosis of progressive supranuclear palsy ({Steele}-{Richardson}-{Olszewski} syndrome) report of the {NINDS}-{SPSP} international workshop},
	volume = {47},
	number = {1},
	journal = {Neurology},
	author = {Litvan, I. and Agid, Y. and Calne, D. and Campbell, G. and Dubois, B. and Duvoisin, R. C. and Goetz, C. G. and Golbe, L. Iò and Grafman, J. and Growdon, J. H.},
	year = {1996},
	pages = {1--9},
	file = {Fulltext:/Users/transfer/Zotero/storage/IYPW2ZX7/Litvan et al. - 1996 - Clinical research criteria for the diagnosis of pr.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/B2HVMJ9Z/1.html:text/html}
}

@article{gorno-tempini_classification_2011,
	title = {Classification of primary progressive aphasia and its variants},
	journal = {Neurology},
	author = {Gorno-Tempini, Maria Luisa and Hillis, Argye E. and Weintraub, Sandra and Kertesz, Andrew and Mendez, Mario and Cappa, SF et al and Ogar, J. M. and Rohrer, J. D. and Black, S. and Boeve, B. F.},
	year = {2011},
	pages = {WNL--0b013e31821103e6},
	file = {Fulltext:/Users/transfer/Zotero/storage/J99ELY2Y/Gorno-Tempini et al. - 2011 - Classification of primary progressive aphasia and .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/5AIJ68E5/WNL.0b013e31821103e6.html:text/html}
}

@article{rascovsky_sensitivity_2011,
	title = {Sensitivity of revised diagnostic criteria for the behavioural variant of frontotemporal dementia},
	volume = {134},
	number = {9},
	journal = {Brain},
	author = {Rascovsky, Katya and Hodges, John R. and Knopman, David and Mendez, Mario F. and Kramer, Joel H. and Neuhaus, John and Van Swieten, John C. and Seelaar, Harro and Dopper, Elise GP and Onyike, Chiadi U.},
	year = {2011},
	pages = {2456--2477},
	file = {Fulltext:/Users/transfer/Zotero/storage/2D2J6BSI/413439.html:text/html;Snapshot:/Users/transfer/Zotero/storage/QZZZCJXN/413439.html:text/html}
}

@article{neary_frontotemporal_1998,
	title = {Frontotemporal lobar degeneration {A} consensus on clinical diagnostic criteria},
	volume = {51},
	number = {6},
	journal = {Neurology},
	author = {Neary, David and Snowden, Julie S. and Gustafson, Lars and Passant, Ulla and Stuss, Donald and Black, SASA and Freedman, M. and Kertesz, Andrew and Robert, P. H. and Albert, Marilyn},
	year = {1998},
	pages = {1546--1554},
	file = {Fulltext:/Users/transfer/Zotero/storage/ERIRBHEM/Neary et al. - 1998 - Frontotemporal lobar degeneration A consensus on c.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/R4YNPAD8/1546.html:text/html}
}

@article{mckeith_diagnosis_2017,
	title = {Diagnosis and management of dementia with {Lewy} bodies: {Fourth} consensus report of the {DLB} {Consortium}},
	volume = {89},
	shorttitle = {Diagnosis and management of dementia with {Lewy} bodies},
	number = {1},
	journal = {Neurology},
	author = {McKeith, Ian G. and Boeve, Bradley F. and Dickson, Dennis W. and Halliday, Glenda and Taylor, John-Paul and Weintraub, Daniel and Aarsland, Dag and Galvin, James and Attems, Johannes and Ballard, Clive G.},
	year = {2017},
	pages = {88--100},
	file = {Fulltext:/Users/transfer/Zotero/storage/7CN54TYD/88.html:text/html;Snapshot:/Users/transfer/Zotero/storage/YU245NEL/88.html:text/html}
}

@article{hughes_accuracy_1992,
	title = {Accuracy of clinical diagnosis of idiopathic {Parkinson}'s disease: a clinico-pathological study of 100 cases.},
	volume = {55},
	shorttitle = {Accuracy of clinical diagnosis of idiopathic {Parkinson}'s disease},
	number = {3},
	journal = {Journal of Neurology, Neurosurgery \& Psychiatry},
	author = {Hughes, Andrew J. and Daniel, Susan E. and Kilford, Linda and Lees, Andrew J.},
	year = {1992},
	pages = {181--184},
	file = {Fulltext:/Users/transfer/Zotero/storage/HMMV5TNF/Hughes et al. - 1992 - Accuracy of clinical diagnosis of idiopathic Parki.pdf:application/pdf}
}

@article{pressman_diagnosis_2014,
	title = {Diagnosis and management of behavioral variant frontotemporal dementia},
	volume = {75},
	number = {7},
	journal = {Biological psychiatry},
	author = {Pressman, Peter S. and Miller, Bruce L.},
	year = {2014},
	pages = {574--581},
	file = {Fulltext:/Users/transfer/Zotero/storage/KSNGYA6A/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/568N8N5A/chooseorg.html:text/html}
}

@article{ranasinghe_distinct_2016-2,
	title = {Distinct subtypes of behavioral variant frontotemporal dementia based on patterns of network degeneration},
	volume = {73},
	number = {9},
	journal = {JAMA neurology},
	author = {Ranasinghe, Kamalini G. and Rankin, Katherine P. and Pressman, Peter S. and Perry, David C. and Lobach, Iryna V. and Seeley, William W. and Coppola, Giovanni and Karydas, Anna M. and Grinberg, Lea T. and Shany-Ur, Tal},
	year = {2016},
	pages = {1078--1088},
	file = {Fulltext:/Users/transfer/Zotero/storage/T4RDWLDP/2533709.html:text/html;Snapshot:/Users/transfer/Zotero/storage/I8FTRL4H/2533709.html:text/html}
}

@article{levenson_marital_1983,
	title = {Marital interaction: physiological linkage and affective exchange.},
	volume = {45},
	shorttitle = {Marital interaction},
	number = {3},
	journal = {Journal of personality and social psychology},
	author = {Levenson, Robert W. and Gottman, John M.},
	year = {1983},
	pages = {587},
	file = {Fulltext:/Users/transfer/Zotero/storage/2G8T6JJZ/Levenson and Gottman - 1983 - Marital interaction physiological linkage and aff.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/VE4WVS5B/1984-12022-001.html:text/html}
}

@article{hughes_new_1982,
	title = {A new clinical scale for the staging of dementia},
	volume = {140},
	number = {6},
	journal = {The British journal of psychiatry},
	author = {Hughes, Charles P. and Berg, Leonard and Danziger, Warren and Coben, Lawrence A. and Martin, Ronald L.},
	year = {1982},
	pages = {566--572},
	file = {Fulltext:/Users/transfer/Zotero/storage/DG7WLCID/openurl.html:text/html;Snapshot:/Users/transfer/Zotero/storage/7EYEU7C2/D1AAE7A0836C1E36B450461613521D20.html:text/html}
}

@inproceedings{eyben_opensmile:_2010-1,
	title = {Opensmile: the munich versatile and fast open-source audio feature extractor},
	shorttitle = {Opensmile},
	booktitle = {Proceedings of the 18th {ACM} international conference on {Multimedia}},
	publisher = {ACM},
	author = {Eyben, Florian and Wöllmer, Martin and Schuller, Björn},
	year = {2010},
	pages = {1459--1462},
	file = {Fulltext:/Users/transfer/Zotero/storage/ZKHD686Y/Eyben et al. - 2010 - Opensmile the munich versatile and fast open-sour.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/3SPUDFSW/citation.html:text/html}
}

@inproceedings{eyben_recent_2013,
	title = {Recent developments in opensmile, the munich open-source multimedia feature extractor},
	booktitle = {Proceedings of the 21st {ACM} international conference on {Multimedia}},
	publisher = {ACM},
	author = {Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Björn},
	year = {2013},
	pages = {835--838},
	file = {Fulltext:/Users/transfer/Zotero/storage/ACUWL6AD/Eyben et al. - 2013 - Recent developments in opensmile, the munich open-.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/N7ZHXR49/citation.html:text/html}
}

@article{konig_automatic_2015-1,
	title = {Automatic speech analysis for the assessment of patients with predementia and {Alzheimer}'s disease},
	volume = {1},
	number = {1},
	journal = {Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
	author = {König, Alexandra and Satt, Aharon and Sorin, Alexander and Hoory, Ron and Toledo-Ronen, Orith and Derreumaux, Alexandre and Manera, Valeria and Verhey, Frans and Aalten, Pauline and Robert, Phillipe H.},
	year = {2015},
	pages = {112--124},
	file = {Fulltext:/Users/transfer/Zotero/storage/IWURB5K5/chooseorg.html:text/html;Snapshot:/Users/transfer/Zotero/storage/8B3GGG9N/chooseorg.html:text/html}
}

@article{feigin_global_2017,
	title = {Global, regional, and national burden of neurological disorders during 1990–2015: a systematic analysis for the {Global} {Burden} of {Disease} {Study} 2015},
	volume = {16},
	shorttitle = {Global, regional, and national burden of neurological disorders during 1990–2015},
	number = {11},
	journal = {The Lancet Neurology},
	author = {Feigin, Valery L. and Abajobir, Amanuel Alemu and Abate, Kalkidan Hassen and Abd-Allah, Foad and Abdulle, Abdishakur M. and Abera, Semaw Ferede and Abyu, Gebre Yitayih and Ahmed, Muktar Beshir and Aichour, Amani Nidhal and Aichour, Ibtihel},
	year = {2017},
	pages = {877--897},
	file = {Fulltext:/Users/transfer/Zotero/storage/GSZCKAA7/fulltext.html:text/html}
}

@book{molnar_interpretable_nodate,
	title = {Interpretable {Machine} {Learning}},
	url = {https://christophm.github.io/interpretable-ml-book/index.html},
	abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.},
	urldate = {2018-10-16},
	author = {Molnar, Christoph},
	file = {Snapshot:/Users/transfer/Zotero/storage/T4EVBPP4/index.html:text/html}
}

@book{nee_methodes_2017,
	title = {Méthodes et outils informatiques pour l'analyse des discours},
	publisher = {Presses universitaires de Rennes},
	author = {Née, Émilie},
	year = {2017}
}

@book{mcenery_corpus_2001,
	title = {Corpus linguistics: an introduction.},
	shorttitle = {Corpus linguistics},
	publisher = {Edinburgh University Press},
	author = {McEnery, Anthony M. and Wilson, Anita},
	year = {2001},
	file = {Snapshot:/Users/transfer/Zotero/storage/49P6DJGH/1810.html:text/html}
}

@article{carney_power_2010,
	title = {Power posing: {Brief} nonverbal displays affect neuroendocrine levels and risk tolerance},
	volume = {21},
	shorttitle = {Power posing},
	number = {10},
	journal = {Psychological science},
	author = {Carney, Dana R. and Cuddy, Amy JC and Yap, Andy J.},
	year = {2010},
	pages = {1363--1368},
	file = {Full Text:/Users/transfer/Zotero/storage/NRPVVG8H/Carney et al. - 2010 - Power posing Brief nonverbal displays affect neur.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/432M6E93/0956797610383437.html:text/html}
}

@article{head_extent_2015,
	title = {The extent and consequences of p-hacking in science},
	volume = {13},
	issn = {1545-7885},
	doi = {10.1371/journal.pbio.1002106},
	abstract = {A focus on novel, confirmatory, and statistically significant results leads to substantial bias in the scientific literature. One type of bias, known as "p-hacking," occurs when researchers collect or select data or statistical analyses until nonsignificant results become significant. Here, we use text-mining to demonstrate that p-hacking is widespread throughout science. We then illustrate how one can test for p-hacking when performing a meta-analysis and show that, while p-hacking is probably common, its effect seems to be weak relative to the real effect sizes being measured. This result suggests that p-hacking probably does not drastically alter scientific consensuses drawn from meta-analyses.},
	language = {eng},
	number = {3},
	journal = {PLoS biology},
	author = {Head, Megan L. and Holman, Luke and Lanfear, Rob and Kahn, Andrew T. and Jennions, Michael D.},
	month = mar,
	year = {2015},
	pmid = {25768323},
	pmcid = {PMC4359000},
	pages = {e1002106},
	file = {Full Text:/Users/transfer/Zotero/storage/UJNQQW7W/Head et al. - 2015 - The extent and consequences of p-hacking in scienc.pdf:application/pdf}
}

@article{bishop_problems_2016,
	title = {Problems in using p-curve analysis and text-mining to detect rate of p-hacking and evidential value},
	volume = {4},
	issn = {2167-8359},
	doi = {10.7717/peerj.1715},
	abstract = {Background. The p-curve is a plot of the distribution of p-values reported in a set of scientific studies. Comparisons between ranges of p-values have been used to evaluate fields of research in terms of the extent to which studies have genuine evidential value, and the extent to which they suffer from bias in the selection of variables and analyses for publication, p-hacking. Methods. p-hacking can take various forms. Here we used R code to simulate the use of ghost variables, where an experimenter gathers data on several dependent variables but reports only those with statistically significant effects. We also examined a text-mined dataset used by Head et al. (2015) and assessed its suitability for investigating p-hacking. Results. We show that when there is ghost p-hacking, the shape of the p-curve depends on whether dependent variables are intercorrelated. For uncorrelated variables, simulated p-hacked data do not give the "p-hacking bump" just below .05 that is regarded as evidence of p-hacking, though there is a negative skew when simulated variables are inter-correlated. The way p-curves vary according to features of underlying data poses problems when automated text mining is used to detect p-values in heterogeneous sets of published papers. Conclusions. The absence of a bump in the p-curve is not indicative of lack of p-hacking. Furthermore, while studies with evidential value will usually generate a right-skewed p-curve, we cannot treat a right-skewed p-curve as an indicator of the extent of evidential value, unless we have a model specific to the type of p-values entered into the analysis. We conclude that it is not feasible to use the p-curve to estimate the extent of p-hacking and evidential value unless there is considerable control over the type of data entered into the analysis. In particular, p-hacking with ghost variables is likely to be missed.},
	language = {eng},
	journal = {PeerJ},
	author = {Bishop, Dorothy V. M. and Thompson, Paul A.},
	year = {2016},
	pmid = {26925335},
	pmcid = {PMC4768688},
	pages = {e1715},
	file = {Full Text:/Users/transfer/Zotero/storage/P6BM2B77/Bishop and Thompson - 2016 - Problems in using p-curve analysis and text-mining.pdf:application/pdf}
}

@article{bruns_p-curve_2016,
	title = {p-{Curve} and p-{Hacking} in {Observational} {Research}},
	volume = {11},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0149144},
	abstract = {The p-curve, the distribution of statistically significant p-values of published studies, has been used to make inferences on the proportion of true effects and on the presence of p-hacking in the published literature. We analyze the p-curve for observational research in the presence of p-hacking. We show by means of simulations that even with minimal omitted-variable bias (e.g., unaccounted confounding) p-curves based on true effects and p-curves based on null-effects with p-hacking cannot be reliably distinguished. We also demonstrate this problem using as practical example the evaluation of the effect of malaria prevalence on economic growth between 1960 and 1996. These findings call recent studies into question that use the p-curve to infer that most published research findings are based on true effects in the medical literature and in a wide range of disciplines. p-values in observational research may need to be empirically calibrated to be interpretable with respect to the commonly used significance threshold of 0.05. Violations of randomization in experimental studies may also result in situations where the use of p-curves is similarly unreliable.},
	language = {eng},
	number = {2},
	journal = {PloS One},
	author = {Bruns, Stephan B. and Ioannidis, John P. A.},
	year = {2016},
	pmid = {26886098},
	pmcid = {PMC4757561},
	pages = {e0149144},
	file = {Full Text:/Users/transfer/Zotero/storage/BTVNGUVL/Bruns and Ioannidis - 2016 - p-Curve and p-Hacking in Observational Research.pdf:application/pdf}
}

@article{simonsohn_better_2015,
	title = {Better {P}-curves: {Making} {P}-curve analysis more robust to errors, fraud, and ambitious {P}-hacking, a {Reply} to {Ulrich} and {Miller} (2015)},
	volume = {144},
	issn = {1939-2222},
	shorttitle = {Better {P}-curves},
	doi = {10.1037/xge0000104},
	abstract = {When studies examine true effects, they generate right-skewed p-curves, distributions of statistically significant results with more low (.01 s) than high (.04 s) p values. What else can cause a right-skewed p-curve? First, we consider the possibility that researchers report only the smallest significant p value (as conjectured by Ulrich \& Miller, 2015), concluding that it is a very uncommon problem. We then consider more common problems, including (a) p-curvers selecting the wrong p values, (b) fake data, (c) honest errors, and (d) ambitiously p-hacked (beyond p {\textless} .05) results. We evaluate the impact of these common problems on the validity of p-curve analysis, and provide practical solutions that substantially increase its robustness.},
	language = {eng},
	number = {6},
	journal = {Journal of Experimental Psychology. General},
	author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
	month = dec,
	year = {2015},
	pmid = {26595842},
	pages = {1146--1152},
	file = {Full Text:/Users/transfer/Zotero/storage/DPAZWR3V/Simonsohn et al. - 2015 - Better P-curves Making P-curve analysis more robu.pdf:application/pdf}
}

@article{yoshimoto_publication_2003,
	title = {Publication bias in neurosurgery: lessons from series of unruptured aneurysms},
	volume = {145},
	issn = {0001-6268},
	shorttitle = {Publication bias in neurosurgery},
	doi = {10.1007/s00701-002-1036-0},
	abstract = {BACKGROUND: Bias favouring publication of research with "positive" results over studies with "negative" results is widely suspected. The present investigation addressed this problem in the field of neurosurgery through a review of recent literature concerning outcome of surgery for unruptured intracranial aneurysms.
METHODS AND FINDINGS: A Medline search was performed seeking case series of surgical treatment for unruptured intracranial aneurysms that analyzed 50 or more patients. Ten type I studies (retrospective studies from a single institution; 1457 patients) met these entry criteria. In general, type I studies reported excellent surgical outcome, with mean combined mortality and morbidity of 7.8\% (95\% confidence interval (CI), 6.4\% to 9.2\%). We found 4 multicenter or community-based studies (type II studies; 5401 patients). Mean combined mortality and morbidity in the type II studies was 20.3\% (95\% CI, 19.2\% to 21.4\%), much higher than in type I studies. Relative risk was 2.6 (95\% CI, 2.2 to 3.1) for patients in type II studies compared with those in type I studies. Two meta-analyses (type III studies) described combined mortality and morbidity of 5.0\% and 12.7\%, essentially corresponding to results of type I studies.
INTERPRETATION: Publication bias is present in the neurosurgical literature. Studies with an excellent surgical outcome are more likely to be published than those with an average outcome. Conclusions of literature reviews or meta-analyses based on published work therefore may be misleading. The solution to the problem would be community-based prospective registration of all patients who underwent surgery, providing a sampling frame free from publication bias.},
	language = {eng},
	number = {1},
	journal = {Acta Neurochirurgica},
	author = {Yoshimoto, Y.},
	month = jan,
	year = {2003},
	pmid = {12545261},
	pages = {45--48}
}

@article{wilson_associations_2015,
	title = {Associations with publication and assessing publication bias in dementia diagnostic test accuracy studies},
	volume = {30},
	issn = {1099-1166},
	doi = {10.1002/gps.4283},
	abstract = {OBJECTIVE: Biomarkers are of increasing interest in dementia research. Studies describing favourable accuracy of various dementia tests have influenced research, guidelines and diagnostic criteria. Publication bias is known to compromise reports on efficacy of therapeutic interventions. Traditional methods of quantifying publication bias are not suited to reviews of diagnostic tests. We aimed to describe rates and predictors of publication of dementia test accuracy studies presented at scientific meetings.
METHODS: We chose three exemplar scientific meetings from 2009. Two independent researchers assessed conference proceedings and selected all abstracts relating to dementia diagnostics. We recorded basic descriptors and dichotomised results as 'positive' or 'neutral'. We assessed publication status using electronic literature databases and contacting lead authors. We described univariate and multivariate predictors of publication status using logistic regression modelling.
RESULTS: From n = 2257 abstracts, we identified n = 250 (11\%) abstracts relating to dementia diagnostics. The majority n = 209 (84\%) reported positive results. Only 97 (39\%) of these studies are published. Univariate predictors of publication status included positive result (p = 0.042), North American or European authors (p = 0.047), higher number of participants (p = 0.008) and use of a 'biomarker' test (p = 0.035). On multivariate analysis, only increasing number of participants was independently associated with publication (p = 0.034).
CONCLUSIONS: Our strategy did not prove or disprove a publication bias effect in dementia test accuracy studies. The substantial proportion of 'positive' studies may point to a downstream 'submission bias' effect on decision to submit data to meetings. Modest rate of publication of dementia test accuracy studies is concerning, and publication bias remains possible.},
	language = {eng},
	number = {12},
	journal = {International Journal of Geriatric Psychiatry},
	author = {Wilson, Claire and Kerr, Daniel and Noel-Storr, Anna and Quinn, Terence J.},
	month = dec,
	year = {2015},
	pmid = {25779466},
	pages = {1250--1256}
}

@article{liu_dealing_2009,
	title = {Dealing with publication bias in translational stroke research},
	volume = {2},
	issn = {1939-067X},
	abstract = {Publication bias has been around for about 50 years. It has become a concern for almost 20 years in the medical research community. This review briefly summarizes the current status of publication bias, potential sources where bias may arise from, and its common evaluation methods. In the field of translational stroke research, publication bias has long been suspected; however, it has not been addressed with sufficient efforts. Its status has remained the same during the last decade. The author emphasizes the important role that publishers might play in addressing publication bias.},
	language = {eng},
	number = {1},
	journal = {Journal of Experimental Stroke \& Translational Medicine},
	author = {Liu, Shimin},
	year = {2009},
	pmid = {20431704},
	pmcid = {PMC2860750},
	pages = {16--21}
}

@article{liebeskind_evidence_2006,
	title = {Evidence of publication bias in reporting acute stroke clinical trials},
	volume = {67},
	issn = {1526-632X},
	doi = {10.1212/01.wnl.0000237331.16541.ac},
	abstract = {OBJECTIVE: To ascertain the extent of publication bias in the reporting of acute stroke clinical trials.
METHODS: We identified controlled acute ischemic stroke clinical trials reported in English over a 45-year period from 1955 to 1999 through systematic search of MEDLINE, the Cochrane Controlled Stroke Trials Register, and additional databases. We analyzed trial methodology, quality, outcome, study sponsorship, and timing of publication to identify various forms of publication bias, including nonpublication bias, abbreviated publication bias, and time-lag bias.
RESULTS: One hundred seventy-eight acute ischemic stroke trials, enrolling 73,949 subjects, evaluated 75 agents or nonpharmacologic interventions. A greater proportion of harmful outcomes in unpublished studies (n = 4) compared with published trials (0.75 vs 0.06, p {\textless} 0.0001) and underreporting of smaller, nonbeneficial studies in acute stroke suggest nonpublication bias. Although a definite time-lag bias was not evident, nonbeneficial studies were slower to proceed from enrollment completion to publication (2.3 vs 2.0 years, p = 0.207), with an even longer delay for nonbeneficial corporate pharmaceutical sponsored trials (2.8 vs 2.1 years, p = 0.086), despite superior trial report quality scores for corporate-sponsored studies when compared with nonprofit/governmental studies (mean 69.2 +/- 95\% CI 3.9 vs 53.4 +/- 95\% CI 9.2, p {\textless} 0.005).
CONCLUSION: Publication bias is evident in the acute stroke research literature, supporting the need for prospective trial registration.},
	language = {eng},
	number = {6},
	journal = {Neurology},
	author = {Liebeskind, David S. and Kidwell, Chelsea S. and Sayre, James W. and Saver, Jeffrey L.},
	month = sep,
	year = {2006},
	pmid = {17000963},
	pages = {973--979}
}

@article{burke_consequences_2013,
	title = {Consequences of common data analysis inaccuracies in {CNS} trauma injury basic research},
	volume = {30},
	issn = {1557-9042},
	doi = {10.1089/neu.2012.2704},
	abstract = {The development of successful treatments for humans after traumatic brain or spinal cord injuries (TBI and SCI, respectively) requires animal research. This effort can be hampered when promising experimental results cannot be replicated because of incorrect data analysis procedures. To identify and hopefully avoid these errors in future studies, the articles in seven journals with the highest number of basic science central nervous system TBI and SCI animal research studies published in 2010 (N=125 articles) were reviewed for their data analysis procedures. After identifying the most common statistical errors, the implications of those findings were demonstrated by reanalyzing previously published data from our laboratories using the identified inappropriate statistical procedures, then comparing the two sets of results. Overall, 70\% of the articles contained at least one type of inappropriate statistical procedure. The highest percentage involved incorrect post hoc t-tests (56.4\%), followed by inappropriate parametric statistics (analysis of variance and t-test; 37.6\%). Repeated Measures analysis was inappropriately missing in 52.0\% of all articles and, among those with behavioral assessments, 58\% were analyzed incorrectly. Reanalysis of our published data using the most common inappropriate statistical procedures resulted in a 14.1\% average increase in significant effects compared to the original results. Specifically, an increase of 15.5\% occurred with Independent t-tests and 11.1\% after incorrect post hoc t-tests. Utilizing proper statistical procedures can allow more-definitive conclusions, facilitate replicability of research results, and enable more accurate translation of those results to the clinic.},
	language = {eng},
	number = {10},
	journal = {Journal of Neurotrauma},
	author = {Burke, Darlene A. and Whittemore, Scott R. and Magnuson, David S. K.},
	month = may,
	year = {2013},
	pmid = {23186206},
	pmcid = {PMC3660075},
	pages = {797--805},
	file = {Full Text:/Users/transfer/Zotero/storage/TVMISITI/Burke et al. - 2013 - Consequences of common data analysis inaccuracies .pdf:application/pdf}
}

@article{button_power_2013,
	title = {Power failure: why small sample size undermines the reliability of neuroscience},
	volume = {14},
	issn = {1471-0048},
	shorttitle = {Power failure},
	doi = {10.1038/nrn3475},
	abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
	language = {eng},
	number = {5},
	journal = {Nature Reviews. Neuroscience},
	author = {Button, Katherine S. and Ioannidis, John P. A. and Mokrysz, Claire and Nosek, Brian A. and Flint, Jonathan and Robinson, Emma S. J. and Munafò, Marcus R.},
	year = {2013},
	pmid = {23571845},
	pages = {365--376},
	file = {Full Text:/Users/transfer/Zotero/storage/DJP9Q2LB/Button et al. - 2013 - Power failure why small sample size undermines th.pdf:application/pdf}
}

@article{kilicoglu_biomedical_2017,
	title = {Biomedical text mining for research rigor and integrity: tasks, challenges, directions},
	issn = {1477-4054},
	shorttitle = {Biomedical text mining for research rigor and integrity},
	doi = {10.1093/bib/bbx057},
	abstract = {An estimated quarter of a trillion US dollars is invested in the biomedical research enterprise annually. There is growing alarm that a significant portion of this investment is wasted because of problems in reproducibility of research findings and in the rigor and integrity of research conduct and reporting. Recent years have seen a flurry of activities focusing on standardization and guideline development to enhance the reproducibility and rigor of biomedical research. Research activity is primarily communicated via textual artifacts, ranging from grant applications to journal publications. These artifacts can be both the source and the manifestation of practices leading to research waste. For example, an article may describe a poorly designed experiment, or the authors may reach conclusions not supported by the evidence presented. In this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part toward enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise.},
	language = {eng},
	journal = {Briefings in Bioinformatics},
	author = {Kilicoglu, Halil},
	month = jun,
	year = {2017},
	pmid = {28633401}
}

@article{akkasi_chemtok:_2016-1,
	title = {{ChemTok}: {A} {New} {Rule} {Based} {Tokenizer} for {Chemical} {Named} {Entity} {Recognition}},
	volume = {2016},
	issn = {2314-6141},
	shorttitle = {{ChemTok}},
	doi = {10.1155/2016/4248026},
	abstract = {Named Entity Recognition (NER) from text constitutes the first step in many text mining applications. The most important preliminary step for NER systems using machine learning approaches is tokenization where raw text is segmented into tokens. This study proposes an enhanced rule based tokenizer, ChemTok, which utilizes rules extracted mainly from the train data set. The main novelty of ChemTok is the use of the extracted rules in order to merge the tokens split in the previous steps, thus producing longer and more discriminative tokens. ChemTok is compared to the tokenization methods utilized by ChemSpot and tmChem. Support Vector Machines and Conditional Random Fields are employed as the learning algorithms. The experimental results show that the classifiers trained on the output of ChemTok outperforms all classifiers trained on the output of the other two tokenizers in terms of classification performance, and the number of incorrectly segmented entities.},
	language = {eng},
	journal = {BioMed Research International},
	author = {Akkasi, Abbas and Varoğlu, Ekrem and Dimililer, Nazife},
	year = {2016},
	pmid = {26942193},
	pmcid = {PMC4749772},
	pages = {4248026},
	file = {Full Text:/Users/transfer/Zotero/storage/G778KUYH/Akkasi et al. - 2016 - ChemTok A New Rule Based Tokenizer for Chemical N.pdf:application/pdf}
}

@inproceedings{webster_tokenization_1992,
	title = {Tokenization as the initial phase in {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Webster, Jonathan J. and Kit, Chunyu},
	year = {1992},
	pages = {1106--1110},
	file = {Full Text:/Users/transfer/Zotero/storage/ERKDI3YY/Webster and Kit - 1992 - Tokenization as the initial phase in NLP.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/AIJNAFEQ/citation.html:text/html}
}

@article{he_comparison_2006,
	title = {A {Comparison} of 13 {Tokenizers} on {MEDLINE}},
	volume = {48},
	journal = {Bethesda, MD: The Lister Hill National Center for Biomedical Communications},
	author = {He, Ying and Kayaalp, Mehmet},
	year = {2006},
	file = {Full Text:/Users/transfer/Zotero/storage/Z42CSFLE/He and Kayaalp - 2006 - A Comparison of 13 Tokenizers on MEDLINE.pdf:application/pdf}
}

@incollection{cohen_colorado_2017,
	title = {The {Colorado} richly annotated full text ({CRAFT}) corpus: multi-model annotation in the biomedical domain},
	shorttitle = {The {Colorado} richly annotated full text ({CRAFT}) corpus},
	booktitle = {Handbook of {Linguistic} {Annotation}},
	publisher = {Springer},
	author = {Cohen, K. Bretonnel and Verspoor, Karin and Fort, Karën and Funk, Christopher and Bada, Michael and Palmer, Martha and Hunter, Lawrence E.},
	year = {2017},
	pages = {1379--1394},
	file = {Snapshot:/Users/transfer/Zotero/storage/AE6JU4VE/978-94-024-0881-2_53.html:text/html}
}

@article{zwicky_clitics_1985,
	title = {Clitics and particles},
	journal = {Language},
	author = {Zwicky, Arnold M.},
	year = {1985},
	pages = {283--305},
	file = {Full Text:/Users/transfer/Zotero/storage/3HMK2LP7/Zwicky - 1985 - Clitics and particles.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/LHLYY4J4/414146.html:text/html}
}

@article{lou_comparison_2012,
	title = {A {Comparison} of {Productive} {Vocabulary} in {Chinese} and {American} {Advanced} {English} {Learners}' {Academic} {Writings}.},
	volume = {2},
	number = {6},
	journal = {Theory \& Practice in Language Studies},
	author = {Lou, Xixiang and Ma, Guanghui},
	year = {2012},
	file = {Full Text:/Users/transfer/Zotero/storage/36S7FS8V/Lou and Ma - 2012 - A Comparison of Productive Vocabulary in Chinese a.pdf:application/pdf}
}

@article{gui_survey_2008,
	title = {A {Survey} of the {Development} of {Lexical} {Richness} in {L}2 {Compositions} from a {Multidimensional} {Perspective} [{J}]},
	volume = {5},
	journal = {Computer-Assisted Foreign Language Education in China},
	author = {Gui, B. A. O.},
	year = {2008},
	file = {Snapshot:/Users/transfer/Zotero/storage/BKQI7HEC/CJFDTOTAL-WYDH200805010.html:text/html}
}

@article{open_science_collaboration_psychology._2015,
	title = {{PSYCHOLOGY}. {Estimating} the reproducibility of psychological science},
	volume = {349},
	issn = {1095-9203},
	doi = {10.1126/science.aac4716},
	abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	language = {eng},
	number = {6251},
	journal = {Science (New York, N.Y.)},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pmid = {26315443},
	pages = {aac4716},
	file = {Submitted Version:/Users/transfer/Zotero/storage/E9YDJ9YM/Open Science Collaboration - 2015 - PSYCHOLOGY. Estimating the reproducibility of psyc.pdf:application/pdf}
}

@misc{simmons_joseph_p._power_2015,
	title = {Power {Posing}: {Reassessing} {The} {Evidence} {Behind} {The} {Most} {Popular} {TED} {Talk}},
	shorttitle = {[37] {Power} {Posing}},
	url = {http://datacolada.org/37},
	abstract = {A recent paper in Psych Science (.pdf) reports a failure to replicate the study that inspired a TED Talk that has been seen 25 million times. ((This TED talk is ranked 2nd in overall downloads and …},
	language = {en-US},
	urldate = {2018-11-25},
	journal = {Data Colada},
	author = {Simmons, Joseph P., Joseph P. and Simonsohn, Uri, Uri},
	month = may,
	year = {2015},
	file = {Snapshot:/Users/transfer/Zotero/storage/R4C228HI/37.html:text/html}
}

@article{stephanie_s._rude_language_2004,
	title = {Language {Use} of {Depressed} and {Depression}-{Vulnerable} {College} {Students}},
	volume = {18},
	language = {en},
	number = {8},
	urldate = {2018-11-25},
	journal = {Cognition and Emotion},
	author = {{Stephanie S. Rude} and {Eva-Maria Gortner} and {James W. Pennebaker}},
	year = {2004},
	pages = {1121--1133},
	file = {Snapshot:/Users/transfer/Zotero/storage/RYMDLMVA/254221761_Language_Use_of_Depressed_and_Depression-Vulnerable_College_Students.html:text/html}
}

@article{schwab_fathers_2018,
	title = {Fathers' repetition of words is coupled with children's vocabularies},
	volume = {166},
	issn = {1096-0457},
	doi = {10.1016/j.jecp.2017.09.012},
	abstract = {Differences in vocabulary size among children can be explained in part by differences in parents' language input, but features of caregivers' input can be more or less beneficial depending on children's language abilities. The current study focused on a specific feature of infant-directed speech: parents' repetition of words across utterances. Although previous work with infants showed a positive relation between repetition and children's vocabulary, we predicted that this would not be the case later in development. Instead, parents may use less repetition as their children become increasingly proficient language learners. In the current study, we examined the extent to which low-income fathers of 24-month-olds (N=41) repeat words to their children using three indices: type-token ratio, automated repetition index, and partial repetition of open-class words. The same finding emerged across all measures of repetition: Fathers whose children had larger vocabularies at 24months repeated wordslessoften, suggesting a developmental coupling of fathers' input and children's language proficiency.},
	language = {eng},
	journal = {Journal of Experimental Child Psychology},
	author = {Schwab, Jessica F. and Rowe, Meredith L. and Cabrera, Natasha and Lew-Williams, Casey},
	month = feb,
	year = {2018},
	pmid = {29055826},
	pmcid = {PMC5696106},
	pages = {437--450}
}

@article{cook_stuttering_2013,
	title = {Stuttering severity, psychosocial impact and lexical diversity as predictors of outcome for treatment of stuttering},
	volume = {38},
	issn = {1873-801X},
	doi = {10.1016/j.jfludis.2012.08.001},
	abstract = {OBJECTIVE: This study assessed factors that predicted therapy outcome for children and adolescents who stuttered after attendance at an intensive therapy course. The factors examined were stuttering severity, lexical diversity measured by Type Token Ratio, and psychosocial impact of stuttering on the child's life.
DESIGN: Fifty-four children who stuttered (CWS) participated in the study. The hypotheses were: (1) CWS with high initial stuttering severity would be more likely to persist than those with low initial severity; (2) lexical diversity before treatment should be related to therapy outcome; (3) psychosocial factors would affect therapy outcome. The predictions were assessed by linear and logistic regression analyses.
RESULTS: Initial stuttering severity was the only significant predictor for stuttering severity after therapy. However, psychosocial impact correlated with improvement in fluency, and lexical diversity correlated with therapy outcome.
CONCLUSIONS: Only initial stuttering severity was a significant predictor of therapy outcome after an intensive therapy intervention. This is in agreement with the study of Howell and Davis (2011).
EDUCATIONAL OBJECTIVES: Readers will get an overview of the literature on risk factors that are considered to predict therapy outcomes for CWS. They will be able to (a) identify what variable represent potential risk factors, (b) describe the psychosocial impact of stuttering, (c) explain how lexical diversity is measured, and (d) describe different assessment instruments used to decide on the outcome of therapy.},
	language = {eng},
	number = {2},
	journal = {Journal of Fluency Disorders},
	author = {Cook, Susanne and Donlan, Chris and Howell, Peter},
	month = jun,
	year = {2013},
	pmid = {23773665},
	pages = {124--133}
}

@article{camaioni_noun_2001,
	title = {Noun versus verb emphasis in {Italian} mother-to-child speech},
	volume = {28},
	number = {3},
	journal = {Journal of Child Language},
	author = {Camaioni, Luigia and Longobardi, Emiddia},
	year = {2001},
	pages = {773--785},
	file = {Snapshot:/Users/transfer/Zotero/storage/9UVAGFTJ/4EAA4B9295E1256638EA04DC763D2C7C.html:text/html}
}

@article{sandhofer_counting_2000,
	title = {Counting nouns and verbs in the input: {Differential} frequencies, different kinds of learning?},
	volume = {27},
	shorttitle = {Counting nouns and verbs in the input},
	number = {3},
	journal = {Journal of child language},
	author = {Sandhofer, Catherine M. and Smith, Linda B. and Luo, Jun},
	year = {2000},
	pages = {561--585},
	file = {Full Text:/Users/transfer/Zotero/storage/Y3Q5AJFH/Sandhofer et al. - 2000 - Counting nouns and verbs in the input Differentia.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/G86TI4Y8/DF9558CCB2FE397DFA7862B4C28EA7C5.html:text/html}
}

@article{peters_language_2016,
	title = {Language, terminology and the readability of online cancer information},
	volume = {42},
	issn = {1473-4265},
	doi = {10.1136/medhum-2015-010766},
	abstract = {Medical terms are a recognised problem in doctor-patient consultations. By contrast, the language difficulties of online healthcare documents are underestimated, even though patients are often encouraged to go to the internet for information. Literacy levels in the community vary, and for patients, carers and health workers with limited reading skills (including first- and second-language users of English), the language of web-based health documents may be challenging or impenetrable. Online delivery of health information is inherently problematic because it cannot provide two-way discussion; and amid the range of health documents on the web, the intended readership (whether general or specialist) is rarely indicated up front. In this research study, we focus on the language and readability of web-based cancer documents, using lexicostatistical methods to profile the vocabularies in two large test databases of breast cancer information, one consisting of material designed for health professionals, the other for the general public. They yielded significantly different word frequency rankings and keyness values, broadly correlating with their different readerships, that is, scientifically literate readers for the professional dataset, and non-specialist readers for the public dataset. The higher type/token ratio in the professional dataset confirms its greater lexical demands, with no concessions to the variable language and literacy skills among second-language health workers. Their language needs can, however, be addressed by a new online multilingual termbank of breast cancer vocabulary, HealthTermFinder, designed to sit alongside health documents on the internet, and provide postconsultation help for patients and carers at their point of need.},
	language = {eng},
	number = {1},
	journal = {Medical Humanities},
	author = {Peters, Pam and Smith, Adam and Funk, Yasmin and Boyages, John},
	month = mar,
	year = {2016},
	pmid = {26530827},
	pages = {36--41}
}

@article{brookshire_speech_1994,
	title = {Speech sample size and test-retest stability of connected speech measures for adults with aphasia},
	volume = {37},
	issn = {0022-4685},
	abstract = {The effect of speech sample size on the test-retest stability of two measures of connected speech--words per minute (WPM) and percent of words that are correct information units (Percent CIUs)--was evaluated. A standard set of 10 stimuli was used to elicit connected speech from 20 non-brain-damaged adults and 20 adults with aphasia. Each subject's responses to the 10 stimuli were transcribed and scored for WPM and Percent CIUs. Then each subject's responses to the 10 stimuli were randomly divided to produce smaller speech samples representing his or her responses to 1, 2, 3, 4, 5, and 7 stimuli. The test-retest stability of the WPM and Percent CIUs measures was then evaluated for each of the smaller sample sizes and for the complete 10-stimulus sample. For both groups, the test-retest stability of the two measures increased as sample size increased, with the greatest increases occurring as samples increased in size from those representing 1 stimulus to those representing 4 or 5 stimuli, with smaller increases in stability thereafter. In general, these results suggest that the best balance between high test-retest stability and the time and effort required to transcribe and score speech samples can be achieved with samples representing 4 or 5 stimuli (an average of 300 to 400 words for aphasic subjects), although this will vary across individuals.},
	language = {eng},
	number = {2},
	journal = {Journal of Speech and Hearing Research},
	author = {Brookshire, R. H. and Nicholas, L. E.},
	month = apr,
	year = {1994},
	pmid = {8028321},
	pages = {399--407}
}

@article{covington_cutting_2010-2,
	title = {Cutting the {Gordian} knot: {The} moving-average type–token ratio ({MATTR})},
	volume = {17},
	shorttitle = {Cutting the {Gordian} knot},
	number = {2},
	journal = {Journal of quantitative linguistics},
	author = {Covington, Michael A. and McFall, Joe D.},
	year = {2010},
	pages = {94--100},
	file = {Full Text:/Users/transfer/Zotero/storage/UPVR92RF/09296171003643098.html:text/html;Snapshot:/Users/transfer/Zotero/storage/HZ6CRTI9/09296171003643098.html:text/html}
}

@article{gron_clinical_2018,
	title = {Clinical sublanguages: {Vocabulary} structure and its impact on term weighting},
	volume = {24},
	shorttitle = {Clinical sublanguages},
	number = {1},
	journal = {Terminology},
	author = {Grön, Leonie and Bertels, Ann},
	year = {2018},
	file = {Snapshot:/Users/transfer/Zotero/storage/C35ENA83/fulldisplay.html:text/html}
}

@misc{noauthor_acl_nodate,
	title = {{ACL} {Anthology} {Search} {Results} - {ACL} {Anthology}},
	url = {https://aclanthology.coli.uni-saarland.de/catalog?utf8=%E2%9C%93&search_field=all_fields&q=generalizability},
	urldate = {2018-12-05},
	file = {ACL Anthology Search Results - ACL Anthology:/Users/transfer/Zotero/storage/S7WA9TPU/catalog.html:text/html}
}

@inproceedings{bender_proceedings_2017,
	address = {Copenhagen, Denmark},
	title = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	url = {http://aclweb.org/anthology/W17-5400},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Bender, Emily and III, Hal Daumé and Ettinger, Allyson and Rao, Sudha},
	year = {2017},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/QAND5TYG/Bender et al. - 2017 - Proceedings of the First Workshop on Building Ling.pdf:application/pdf}
}

@inproceedings{ettinger_towards_2017,
	address = {Copenhagen, Denmark},
	title = {Towards {Linguistically} {Generalizable} {NLP} {Systems}: {A} {Workshop} and {Shared} {Task}},
	shorttitle = {Towards {Linguistically} {Generalizable} {NLP} {Systems}},
	url = {http://aclweb.org/anthology/W17-5401},
	doi = {10.18653/v1/W17-5401},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Ettinger, Allyson and Rao, Sudha and Daumé III, Hal and Bender, Emily M.},
	year = {2017},
	pages = {1--10},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/ZR8UIRAP/Ettinger et al. - 2017 - Towards Linguistically Generalizable NLP Systems .pdf:application/pdf}
}

@inproceedings{schneider_analysing_2017,
	address = {Copenhagen, Denmark},
	title = {Analysing {Errors} of {Open} {Information} {Extraction} {Systems}},
	url = {http://aclweb.org/anthology/W17-5402},
	doi = {10.18653/v1/W17-5402},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Schneider, Rudolf and Oberhauser, Tom and Klatt, Tobias and Gers, Felix A. and Löser, Alexander},
	year = {2017},
	pages = {11--18},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/SCULLIBS/Schneider et al. - 2017 - Analysing Errors of Open Information Extraction Sy.pdf:application/pdf}
}

@inproceedings{peters_massively_2017,
	address = {Copenhagen, Denmark},
	title = {Massively {Multilingual} {Neural} {Grapheme}-to-{Phoneme} {Conversion}},
	url = {http://aclweb.org/anthology/W17-5403},
	doi = {10.18653/v1/W17-5403},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Peters, Ben and Dehdari, Jon and van Genabith, Josef},
	year = {2017},
	pages = {19--26},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/CUSFSXEY/Peters et al. - 2017 - Massively Multilingual Neural Grapheme-to-Phoneme .pdf:application/pdf}
}

@inproceedings{li_bibi_2017,
	address = {Copenhagen, Denmark},
	title = {{BIBI} {System} {Description}: {Building} with {CNNs} and {Breaking} with {Deep} {Reinforcement} {Learning}},
	shorttitle = {{BIBI} {System} {Description}},
	url = {http://aclweb.org/anthology/W17-5404},
	doi = {10.18653/v1/W17-5404},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Yitong and Cohn, Trevor and Baldwin, Timothy},
	year = {2017},
	pages = {27--32},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/6Y5SFLZF/Li et al. - 2017 - BIBI System Description Building with CNNs and Br.pdf:application/pdf}
}

@inproceedings{mahler_breaking_2017,
	address = {Copenhagen, Denmark},
	title = {Breaking {NLP}: {Using} {Morphosyntax}, {Semantics}, {Pragmatics} and {World} {Knowledge} to {Fool} {Sentiment} {Analysis} {Systems}},
	shorttitle = {Breaking {NLP}},
	url = {http://aclweb.org/anthology/W17-5405},
	doi = {10.18653/v1/W17-5405},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Mahler, Taylor and Cheung, Willy and Elsner, Micha and King, David and de Marneffe, Marie-Catherine and Shain, Cory and Stevens-Guille, Symon and White, Michael},
	year = {2017},
	pages = {33--39},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/VLBTIDCR/Mahler et al. - 2017 - Breaking NLP Using Morphosyntax, Semantics, Pragm.pdf:application/pdf}
}

@inproceedings{jurczyk_cross-genre_2017,
	address = {Copenhagen, Denmark},
	title = {Cross-genre {Document} {Retrieval}: {Matching} between {Conversational} and {Formal} {Writings}},
	shorttitle = {Cross-genre {Document} {Retrieval}},
	url = {http://aclweb.org/anthology/W17-5407},
	doi = {10.18653/v1/W17-5407},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Jurczyk, Tomasz and Choi, Jinho D.},
	year = {2017},
	pages = {48--53},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/WHXKLP9U/Jurczyk and Choi - 2017 - Cross-genre Document Retrieval Matching between C.pdf:application/pdf}
}

@inproceedings{ferres_adaptable_2017,
	address = {Copenhagen, Denmark},
	title = {An {Adaptable} {Lexical} {Simplification} {Architecture} for {Major} {Ibero}-{Romance} {Languages}},
	url = {http://aclweb.org/anthology/W17-5406},
	doi = {10.18653/v1/W17-5406},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Ferrés, Daniel and Saggion, Horacio and Gómez Guinovart, Xavier},
	year = {2017},
	pages = {40--47},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/2IMH65NN/Ferrés et al. - 2017 - An Adaptable Lexical Simplification Architecture f.pdf:application/pdf}
}

@inproceedings{mukku_actsa:_2017,
	address = {Copenhagen, Denmark},
	title = {{ACTSA}: {Annotated} {Corpus} for {Telugu} {Sentiment} {Analysis}},
	shorttitle = {{ACTSA}},
	url = {http://aclweb.org/anthology/W17-5408},
	doi = {10.18653/v1/W17-5408},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Mukku, Sandeep Sricharan and Mamidi, Radhika},
	year = {2017},
	pages = {54--58},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/Q7MPKIIM/Mukku and Mamidi - 2017 - ACTSA Annotated Corpus for Telugu Sentiment Analy.pdf:application/pdf}
}

@inproceedings{cho_strawman:_2017,
	address = {Copenhagen, Denmark},
	title = {Strawman: {An} {Ensemble} of {Deep} {Bag}-of-{Ngrams} for {Sentiment} {Analysis}},
	shorttitle = {Strawman},
	url = {http://aclweb.org/anthology/W17-5409},
	doi = {10.18653/v1/W17-5409},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Cho, Kyunghyun},
	year = {2017},
	pages = {59--60},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/XCHMQK27/Cho - 2017 - Strawman An Ensemble of Deep Bag-of-Ngrams for Se.pdf:application/pdf}
}

@inproceedings{staliunaite_breaking_2017,
	address = {Copenhagen, Denmark},
	title = {Breaking {Sentiment} {Analysis} of {Movie} {Reviews}},
	url = {http://aclweb.org/anthology/W17-5410},
	doi = {10.18653/v1/W17-5410},
	urldate = {2018-12-05},
	booktitle = {Proceedings of the {First} {Workshop} on {Building} {Linguistically} {Generalizable} {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Staliūnaite, Ieva and Bonfil, Ben},
	year = {2017},
	pages = {61--64},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/HVX6KQGF/Staliūnaite and Bonfil - 2017 - Breaking Sentiment Analysis of Movie Reviews.pdf:application/pdf}
}

@article{read_sizing_2015,
	title = {Sizing the {Problem} of {Improving} {Discovery} and {Access} to {NIH}-{Funded} {Data}: {A} {Preliminary} {Study}},
	volume = {10},
	shorttitle = {Sizing the {Problem} of {Improving} {Discovery} and {Access} to {NIH}-{Funded} {Data}},
	number = {7},
	journal = {PloS one},
	author = {Read, Kevin B. and Sheehan, Jerry R. and Huerta, Michael F. and Knecht, Lou S. and Mork, James G. and Humphreys, Betsy L.},
	year = {2015},
	pages = {e0132735},
	file = {Full Text:/Users/transfer/Zotero/storage/PQGKYM4V/article.html:text/html}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	journal = {Scientific data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E.},
	year = {2016},
	file = {Full Text:/Users/transfer/Zotero/storage/8HZFZMBE/sdata201618.html:text/html}
}

@article{jonnalagadda_automating_2015,
	title = {Automating data extraction in systematic reviews: a systematic review},
	volume = {4},
	issn = {2046-4053},
	shorttitle = {Automating data extraction in systematic reviews},
	doi = {10.1186/s13643-015-0066-7},
	abstract = {BACKGROUND: Automation of the parts of systematic review process, specifically the data extraction step, may be an important strategy to reduce the time necessary to complete a systematic review. However, the state of the science of automatically extracting data elements from full texts has not been well described. This paper performs a systematic review of published and unpublished methods to automate data extraction for systematic reviews.
METHODS: We systematically searched PubMed, IEEEXplore, and ACM Digital Library to identify potentially relevant articles. We included reports that met the following criteria: 1) methods or results section described what entities were or need to be extracted, and 2) at least one entity was automatically extracted with evaluation results that were presented for that entity. We also reviewed the citations from included reports.
RESULTS: Out of a total of 1190 unique citations that met our search criteria, we found 26 published reports describing automatic extraction of at least one of more than 52 potential data elements used in systematic reviews. For 25 (48 \%) of the data elements used in systematic reviews, there were attempts from various researchers to extract information automatically from the publication text. Out of these, 14 (27 \%) data elements were completely extracted, but the highest number of data elements extracted automatically by a single study was 7. Most of the data elements were extracted with F-scores (a mean of sensitivity and positive predictive value) of over 70 \%.
CONCLUSIONS: We found no unified information extraction framework tailored to the systematic review process, and published reports focused on a limited (1-7) number of data elements. Biomedical natural language processing techniques have not been fully utilized to fully or even partially automate the data extraction step of systematic reviews.},
	language = {eng},
	journal = {Systematic Reviews},
	author = {Jonnalagadda, Siddhartha R. and Goyal, Pawan and Huffman, Mark D.},
	month = jun,
	year = {2015},
	pmid = {26073888},
	pmcid = {PMC4514954},
	pages = {78},
	file = {Full Text:/Users/transfer/Zotero/storage/UH6VG6QH/Jonnalagadda et al. - 2015 - Automating data extraction in systematic reviews .pdf:application/pdf}
}

@misc{charles_schmitt_tac_nodate,
	title = {{TAC} {SRIE} 2018 {Track}},
	url = {https://tac.nist.gov/2018/SRIE/},
	urldate = {2018-12-07},
	author = {{Charles Schmitt} and {Mary Wolfe} and {Michelle Angrish} and {Dina Demner-Fushman} and {Kristan Markey} and {Andrew Rooney} and {Michele Taylor} and {Vickie Walker} and {Byron Wallace}},
	file = {TAC SRIE 2018 Track:/Users/transfer/Zotero/storage/IBYTMPMQ/SRIE.html:text/html}
}

@misc{national_institutes_of_health_enhancing_nodate,
	title = {Enhancing {Reproducibility} through {Rigor} and {Transparency} {\textbar} grants.nih.gov},
	url = {https://grants.nih.gov/policy/reproducibility/index.htm},
	urldate = {2018-12-07},
	author = {{National Institutes of Health}},
	file = {Enhancing Reproducibility through Rigor and Transparency | grants.nih.gov:/Users/transfer/Zotero/storage/K9QTIMYN/index.html:text/html}
}

@article{baker_1500_2016,
	title = {1,500 scientists lift the lid on reproducibility},
	volume = {533},
	issn = {1476-4687},
	doi = {10.1038/533452a},
	language = {eng},
	number = {7604},
	journal = {Nature},
	author = {Baker, Monya},
	year = {2016},
	pmid = {27225100},
	pages = {452--454}
}

@article{open_science_collaboration_psychology._2015-1,
	title = {{PSYCHOLOGY}. {Estimating} the reproducibility of psychological science},
	volume = {349},
	issn = {1095-9203},
	doi = {10.1126/science.aac4716},
	abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	language = {eng},
	number = {6251},
	journal = {Science (New York, N.Y.)},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pmid = {26315443},
	pages = {aac4716},
	file = {Submitted Version:/Users/transfer/Zotero/storage/64FPBVNF/Open Science Collaboration - 2015 - PSYCHOLOGY. Estimating the reproducibility of psyc.pdf:application/pdf}
}

@book{cifu_ending_2015,
	title = {Ending medical reversals},
	publisher = {Johns Hopkins University Press, Baltimore Google Scholar},
	author = {Cifu, A. S. and Prasad, V. K.},
	year = {2015}
}

@article{livingston_kabob:_2015,
	title = {{KaBOB}: ontology-based semantic integration of biomedical databases},
	volume = {16},
	shorttitle = {{KaBOB}},
	number = {1},
	journal = {BMC bioinformatics},
	author = {Livingston, Kevin M. and Bada, Michael and Baumgartner, William A. and Hunter, Lawrence E.},
	year = {2015},
	pages = {126},
	file = {Full Text:/Users/transfer/Zotero/storage/596GH9LF/s12859-015-0559-3.html:text/html}
}

@article{liolios_metadata_2012,
	title = {The {Metadata} {Coverage} {Index} ({MCI}): {A} standardized metric for quantifying database metadata richness},
	volume = {6},
	issn = {1944-3277},
	shorttitle = {The {Metadata} {Coverage} {Index} ({MCI})},
	doi = {10.4056/sigs.2675953},
	abstract = {Variability in the extent of the descriptions of data ('metadata') held in public repositories forces users to assess the quality of records individually, which rapidly becomes impractical. The scoring of records on the richness of their description provides a simple, objective proxy measure for quality that enables filtering that supports downstream analysis. Pivotally, such descriptions should spur on improvements. Here, we introduce such a measure - the 'Metadata Coverage Index' (MCI): the percentage of available fields actually filled in a record or description. MCI scores can be calculated across a database, for individual records or for their component parts (e.g., fields of interest). There are many potential uses for this simple metric: for example; to filter, rank or search for records; to assess the metadata availability of an ad hoc collection; to determine the frequency with which fields in a particular record type are filled, especially with respect to standards compliance; to assess the utility of specific tools and resources, and of data capture practice more generally; to prioritize records for further curation; to serve as performance metrics of funded projects; or to quantify the value added by curation. Here we demonstrate the utility of MCI scores using metadata from the Genomes Online Database (GOLD), including records compliant with the 'Minimum Information about a Genome Sequence' (MIGS) standard developed by the Genomic Standards Consortium. We discuss challenges and address the further application of MCI scores; to show improvements in annotation quality over time, to inform the work of standards bodies and repository providers on the usability and popularity of their products, and to assess and credit the work of curators. Such an index provides a step towards putting metadata capture practices and in the future, standards compliance, into a quantitative and objective framework.},
	language = {eng},
	number = {3},
	journal = {Standards in Genomic Sciences},
	author = {Liolios, Konstantinos and Schriml, Lynn and Hirschman, Lynette and Pagani, Ioanna and Nosrat, Bahador and Sterk, Peter and White, Owen and Rocca-Serra, Philippe and Sansone, Susanna-Assunta and Taylor, Chris and Kyrpides, Nikos C. and Field, Dawn},
	month = jul,
	year = {2012},
	pmid = {23409217},
	pmcid = {PMC3558968},
	pages = {438--447},
	file = {Full Text:/Users/transfer/Zotero/storage/DHEZ8QEB/Liolios et al. - 2012 - The Metadata Coverage Index (MCI) A standardized .pdf:application/pdf}
}

@article{livingston_representing_2013,
	title = {Representing annotation compositionality and provenance for the {Semantic} {Web}},
	volume = {4},
	number = {1},
	journal = {Journal of biomedical semantics},
	author = {Livingston, Kevin M. and Bada, Michael and Hunter, Lawrence E. and Verspoor, Karin},
	year = {2013},
	pages = {38},
	file = {Full Text:/Users/transfer/Zotero/storage/J9YRXPTJ/2041-1480-4-38.html:text/html}
}

@inproceedings{cohen_reproducibility_2016,
	title = {Reproducibility in natural language processing: a case study of two {R} libraries for mining {PubMed}/{MEDLINE}},
	volume = {2016},
	shorttitle = {Reproducibility in natural language processing},
	booktitle = {{LREC}... {International} {Conference} on {Language} {Resources} \& {Evaluation}:[proceedings]. {International} {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {NIH Public Access},
	author = {Cohen, K. Bretonnel and Xia, Jingbo and Roeder, Christophe and Hunter, Lawrence E.},
	year = {2016},
	pages = {6},
	file = {Full Text:/Users/transfer/Zotero/storage/2MBACB7N/PMC5860830.html:text/html}
}

@article{leroy_shallow_2003,
	title = {A shallow parser based on closed-class words to capture relations in biomedical text},
	volume = {36},
	issn = {1532-0464},
	abstract = {Natural language processing for biomedical text currently focuses mostly on entity and relation extraction. These entities and relations are usually pre-specified entities, e.g., proteins, and pre-specified relations, e.g., inhibit relations. A shallow parser that captures the relations between noun phrases automatically from free text has been developed and evaluated. It uses heuristics and a noun phraser to capture entities of interest in the text. Cascaded finite state automata structure the relations between individual entities. The automata are based on closed-class English words and model generic relations not limited to specific words. The parser also recognizes coordinating conjunctions and captures negation in text, a feature usually ignored by others. Three cancer researchers evaluated 330 relations extracted from 26 abstracts of interest to them. There were 296 relations correctly extracted from the abstracts resulting in 90\% precision of the relations and an average of 11 correct relations per abstract.},
	language = {eng},
	number = {3},
	journal = {Journal of Biomedical Informatics},
	author = {Leroy, Gondy and Chen, Hsinchun and Martinez, Jesse D.},
	month = jun,
	year = {2003},
	pmid = {14615225},
	pages = {145--158}
}

@book{pustejovsky_natural_2012,
	title = {Natural {Language} {Annotation} for {Machine} {Learning}: {A} guide to corpus-building for applications},
	shorttitle = {Natural {Language} {Annotation} for {Machine} {Learning}},
	publisher = {" O'Reilly Media, Inc."},
	author = {Pustejovsky, James and Stubbs, Amber},
	year = {2012},
	file = {Full Text:/Users/transfer/Zotero/storage/7M9Z4QXW/Pustejovsky and Stubbs - 2012 - Natural Language Annotation for Machine Learning .pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/HTWZR8D7/books.html:text/html}
}

@article{schloss_identifying_2018,
	title = {Identifying and {Overcoming} {Threats} to {Reproducibility}, {Replicability}, {Robustness}, and {Generalizability} in {Microbiome} {Research}},
	volume = {9},
	issn = {2150-7511},
	doi = {10.1128/mBio.00525-18},
	abstract = {The "reproducibility crisis" in science affects microbiology as much as any other area of inquiry, and microbiologists have long struggled to make their research reproducible. We need to respect that ensuring that our methods and results are sufficiently transparent is difficult. This difficulty is compounded in interdisciplinary fields such as microbiome research. There are many reasons why a researcher is unable to reproduce a previous result, and even if a result is reproducible, it may not be correct. Furthermore, failures to reproduce previous results have much to teach us about the scientific process and microbial life itself. This Perspective delineates a framework for identifying and overcoming threats to reproducibility, replicability, robustness, and generalizability of microbiome research. Instead of seeing signs of a crisis in others' work, we need to appreciate the technical and social difficulties that limit reproducibility in the work of others as well as our own.},
	language = {eng},
	number = {3},
	journal = {mBio},
	author = {Schloss, Patrick D.},
	year = {2018},
	pmid = {29871915},
	pmcid = {PMC5989067},
	file = {Full Text:/Users/transfer/Zotero/storage/8VPY88AW/Schloss - 2018 - Identifying and Overcoming Threats to Reproducibil.pdf:application/pdf}
}

@article{kenett_clarifying_2015,
	title = {Clarifying the terminology that describes scientific reproducibility},
	volume = {12},
	copyright = {2015 Nature Publishing Group},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.3489},
	doi = {10.1038/nmeth.3489},
	abstract = {Clarifying the terminology that describes scientific reproducibility},
	language = {en},
	number = {8},
	urldate = {2018-12-07},
	journal = {Nature Methods},
	author = {Kenett, Ron S. and Shmueli, Galit},
	month = aug,
	year = {2015},
	pages = {699},
	file = {Full Text PDF:/Users/transfer/Zotero/storage/Q5VAC48X/Kenett and Shmueli - 2015 - Clarifying the terminology that describes scientif.pdf:application/pdf;Snapshot:/Users/transfer/Zotero/storage/D977IUUC/nmeth.html:text/html}
}